{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PH-b-S2fC8q6"
   },
   "source": [
    "### Tutorial: Visualizing the Silk Road Blockchain with Graphistry and Neo4j\n",
    "\n",
    "Investigating large datasets becomes easier by directly visualizing cypher (BOLT) query results with Graphistry. This tutorial walks through querying Neo4j, visualizing the results, and additional configurations and queries.\n",
    "\n",
    "This analysis is based on a ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigar ambiente e dispositivos disponíveis localmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VERSÕES DAS PRINCIPAIS BIBLIOTECAS INSTALADAS NO ENVIROMENT\n",
      "Interpretador em uso: /bin/python3\n",
      "    Ambiente Conda ativado: base\n",
      "     Python: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0] \n",
      "        Pip: 23.3.1 \n",
      "\n",
      "\n",
      "VERSÕES DOS DRIVERS CUDA, PYTORCH E GPU\n",
      "NVCC não encontrado no sistema: Command '/usr/local/cuda/bin/nvcc -V' returned non-zero exit status 127.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: /usr/local/cuda/bin/nvcc: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PyTorch: 2.1.1+cu121\n",
      "Dispositivo: cpu\n",
      "  ERRO!! Ao configurar a GPU: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys, pip\n",
    "import platform, subprocess\n",
    "\n",
    "def try_amb():\n",
    "    ## Visualizar versões dos principais componentes\n",
    "    \n",
    "    pyVer      = sys.version\n",
    "    pipVer     = pip.__version__\n",
    "    \n",
    "    print('\\nVERSÕES DAS PRINCIPAIS BIBLIOTECAS INSTALADAS NO ENVIROMENT')\n",
    "    print('Interpretador em uso:', sys.executable)\n",
    "    \n",
    "    # Improved handling of the 'CONDA_DEFAULT_ENV' environment variable\n",
    "    try:\n",
    "        print('    Ambiente Conda ativado:', os.environ['CONDA_DEFAULT_ENV'])\n",
    "    except KeyError:\n",
    "        print('    Ambiente Conda ativado: Não disponível')\n",
    "    \n",
    "    print('     Python: ' + pyVer, '\\n        Pip:', pipVer, '\\n')\n",
    "\n",
    "def check_nvcc():\n",
    "    # Identifica o sistema operacional\n",
    "    os_type = platform.system()\n",
    "    \n",
    "    # Dependendo do sistema operacional, altere o comando e o delimitador\n",
    "    if os_type == \"Linux\":\n",
    "        nvcc_path = \"/usr/local/cuda/bin/nvcc\"\n",
    "        cmd = \"which\"\n",
    "    elif os_type == \"Windows\":\n",
    "        cmd = \"where\"\n",
    "        nvcc_path = subprocess.check_output(f\"{cmd} nvcc\", shell=True).decode('utf-8').strip()\n",
    "    else:\n",
    "        print(\"Sistema Operacional não suportado.\")\n",
    "        return\n",
    "    try:\n",
    "        nvcc_output = subprocess.check_output(f\"{nvcc_path} -V\", shell=True).decode('utf-8')\n",
    "        print(nvcc_output)\n",
    "    except Exception as e:\n",
    "        print(f\"NVCC não encontrado no sistema: {e}\")\n",
    "\n",
    "def try_gpu():\n",
    "    print('\\nVERSÕES DOS DRIVERS CUDA, PYTORCH E GPU')\n",
    "    try:\n",
    "        check_nvcc()\n",
    "    except Exception as e:\n",
    "        print(\"NVCC não encontrado:\",e,\"\\n\")\n",
    "    try:\n",
    "        import torch\n",
    "        print('    PyTorch:',torch.__version__)\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print('Dispositivo:',device)\n",
    "        print('Disponível :',device,torch.cuda.is_available(),' | Inicializado:',torch.cuda.is_initialized(),'| Capacidade:',torch.cuda.get_device_capability(device=None))\n",
    "        print('Nome GPU   :',torch.cuda.get_device_name(0),'         | Quantidade:',torch.cuda.device_count(),'\\n')\n",
    "    except Exception as e:\n",
    "        print('  ERRO!! Ao configurar a GPU:',e,'\\n')\n",
    "\n",
    "try_amb()\n",
    "try_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalações para Plataforma computacional CUDA 12.x\n",
    "\n",
    "    setuptools\n",
    "    bilbiotecas especializadas Nvidia\n",
    "    Nvidia RAPIDS.AI\n",
    "\n",
    "Observação:\n",
    "Para melhor desempenho, a configuração usada para ajustar a heurística demanda instalação de:\n",
    "\n",
    "    cuDNN 8.9.6 em GPUs Maxwell e Pascal com CUDA 11.8, e \n",
    "\n",
    "    cuDNN 8.9.6 em todas as outras novas GPUs com CUDA 12.2 atualização 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U setuptools pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar bibliotecas especializadas Nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cuTensor\n",
    "cuTENSOR é uma biblioteca CUDA de alto desempenho para tensores primitivos.¶\n",
    "A escolha da instalação adequada conforme cada sistema operacional e ambiente é feita em:\n",
    "\n",
    "https://developer.nvidia.com/cutensor-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=22.04&target_type=deb_local\n",
    "\n",
    "### cuSPARSELt\n",
    "Nvidia cuSPARSELt é uma biblioteca CUDA de alto desempenho dedicada a operações gerais de matriz-matriz nas quais pelo menos um operando é uma matriz esparsa:\n",
    "\n",
    "$$ D = Activation(\\alpha op(A) \\cdot op(B) + \\beta op(C) + bias) \\cdot scale $$\n",
    "\n",
    "onde op(A)/op(B) refere-se à operações no local, como transposição/não transposição, e alfa, beta, scale são escalares.\n",
    "\n",
    "Demonstrações em:\n",
    "\n",
    "https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuSPARSELt/matmul\n",
    "\n",
    "https://github.com/NVIDIA/CUDALibrarySamples/blob/master/cuSPARSELt/matmul_advanced/matmul_advanced_example.cpp\n",
    "\n",
    "### Nvidia cuDNN\n",
    "A biblioteca NVIDIA CUDA® Deep Neural Network (cuDNN) é uma biblioteca de primitivas acelerada por GPU para redes neurais profundas . cuDNN fornece implementações altamente ajustadas para rotinas padrão, como convolução direta e reversa, atenção, matmul, pooling e normalização. \n",
    "\n",
    "Será preciso se cadastrar junto à Nvidia para ter acesso aos arquivos fonte e escolher o download adequado com os drivers CUDA instalados, por exemplo para CUDA 12.x escolher \"Download cuDNN v8.9.6 (November 1st, 2023), for CUDA 12.x\" e depois o sistema operacional adequado, por exemplo, para Linux Ubuntu: Local Installer for Ubuntu22.04 cross-sbsa (Deb).\n",
    "\n",
    "https://developer.nvidia.com/rdp/cudnn-download\n",
    "\n",
    "### Nvidia NCCL\n",
    "A NVIDIA Collective Communication Library (NCCL) implementa primitivas de comunicação multi-GPU e multi-nós otimizadas para GPUs e redes NVIDIA. NCCL fornece rotinas como all-gather, all-reduce, broadcast, redução, redução de dispersão, bem como envio e recebimento ponto a ponto que são otimizados para alcançar alta largura de banda e baixa latência em interconexões de alta velocidade PCIe e NVLink dentro um nó e pela rede NVIDIA Mellanox entre nós.\n",
    "\n",
    "https://developer.nvidia.com/nccl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Nvidia RAPIDS.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #https://rapids.ai/\n",
    "# !pip install \\\n",
    "#     --extra-index-url=https://pypi.nvidia.com \\\n",
    "#     cudf-cu12 dask-cudf-cu12 cuml-cu12 cugraph-cu12 cuspatial-cu12 cuproj-cu12 cuxfilter-cu12 cucim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware GPU compatível\n",
    "\n",
    "Verificar compatibilidade com sua GPU disponível em:\n",
    "\n",
    "https://developer.nvidia.com/cuda-gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install CuPy do PyPI \n",
    "\n",
    "CuPy é uma biblioteca de array compatível com NumPy/SciPy para computação acelerada por GPU com Python. CuPy atua como um substituto imediato para executar código NumPy/SciPy existente em plataformas NVIDIA CUDA ou AMD ROCm .\n",
    "\n",
    "CuPy fornece ndarraymatrizes esparsas e as rotinas associadas para dispositivos GPU, todos tendo a mesma API que NumPy e SciPy:\n",
    "\n",
    "    Matriz N-dimensional ( ndarray): cupy.ndarray\n",
    "\n",
    "Tipos de dados (dtypes): booleano ( bool_), inteiro ( int8, int16, int32, int64, uint8, uint16, uint32, uint64), float ( float16, float32, float64) e complexo ( complex64, complex128)\n",
    "\n",
    "Suporta a semântica idêntica a numpy.ndarray, incluindo indexação e transmissão básica/avançada\n",
    "\n",
    "    Matrizes esparsas : cupyx.scipy.sparse\n",
    "\n",
    "Matriz esparsa 2-D: csr_matrix, coo_matrix, csc_matrix, edia_matrix\n",
    "\n",
    "    Rotinas NumPy\n",
    "\n",
    "Funções em nível de módulo (cupy.*)\n",
    "\n",
    "Funções de Álgebra Linear (cupy.linalg.*)\n",
    "\n",
    "Transformada Rápida de Fourier (cupy.fft.*)\n",
    "\n",
    "Gerador de números aleatórios (cupy.random.*)\n",
    "\n",
    "    Rotinas SciPy\n",
    "\n",
    "Transformadas Discretas de Fourier (cupyx.scipy.fft.*ecupyx.scipy.fftpack.*)\n",
    "\n",
    "Álgebra Linear Avançada (cupyx.scipy.linalg.*)\n",
    "\n",
    "Processamento de imagens multidimensionais (cupyx.scipy.ndimage.*)\n",
    "\n",
    "Matrizes Esparsas (cupyx.scipy.sparse.*)\n",
    "\n",
    "Álgebra Linear Esparsa (cupyx.scipy.sparse.linalg.*)\n",
    "\n",
    "Funções Especiais (cupyx.scipy.special.*)\n",
    "\n",
    "Processamento de Sinal (cupyx.scipy.signal.*)\n",
    "\n",
    "Funções Estatísticas (cupyx.scipy.stats.*)\n",
    "\n",
    "As rotinas são apoiadas por bibliotecas CUDA (cuBLAS, cuFFT, cuSPARSE, cuSOLVER, cuRAND), Thrust, CUB e cuTENSOR para fornecer o melhor desempenho.\n",
    "\n",
    "Também é possível implementar facilmente kernels CUDA personalizados que funcionam ndarrayusando:\n",
    "\n",
    "    Modelos de kernel : defina rapidamente operações de redução e elemento a elemento como um único kernel CUDA\n",
    "\n",
    "    Kernel bruto : importe código CUDA C/C++ existente\n",
    "\n",
    "    Transpiler Just-in-time (JIT) : Gere o kernel CUDA a partir do código-fonte Python\n",
    "\n",
    "    Kernel Fusion : funde várias operações CuPy em um único kernel CUDA\n",
    "\n",
    "CuPy pode ser executado em ambientes multi-GPU ou cluster. O pacote de comunicação distribuída ( cupyx.distributed) fornece primitivas coletivas e ponto a ponto para ndarray, apoiado por NCCL.\n",
    "\n",
    "Para usuários que precisam de controle mais refinado para desempenho, o acesso aos recursos CUDA de baixo nível está disponível:\n",
    "\n",
    "    Fluxo e evento : fluxo CUDA e fluxo padrão por thread são suportados por todas as APIs\n",
    "\n",
    "    Pool de memória : alocador de memória personalizável com um pool de memória integrado\n",
    "\n",
    "    Profiler : Suporta código de criação de perfil usando CUDA Profiler e NVTX\n",
    "\n",
    "    Vinculação de API de host : chame diretamente bibliotecas CUDA, como APIs NCCL, cuDNN, cuTENSOR e cuSPARSELt do Python\n",
    "\n",
    "CuPy implementa APIs padrão para troca de dados e interoperabilidade, como DLPack , CUDA Array Interface , __array_ufunc__( NEP 13 ), __array_function__( NEP 18 ) e Array API Standard . Graças a esses protocolos, CuPy integra-se facilmente com NumPy, PyTorch, TensorFlow, MPI4Py e quaisquer outras bibliotecas que suportem o padrão.\n",
    "\n",
    "Wheels (pacotes binários pré-compilados) estão disponíveis para Linux e Windows. Os nomes dos pacotes são diferentes dependendo da versão do CUDA Toolkit.\n",
    "\n",
    "Siga as orientações em:\n",
    "\n",
    "https://docs.cupy.dev/en/stable/install.html#install-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Fri_Jan__6_16:45:21_PST_2023\n",
      "Cuda compilation tools, release 12.0, V12.0.140\n",
      "Build cuda_12.0.r12.0/compiler.32267302_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instalar para CUDA Drivers v11\n",
    "# !pip3 uninstall cupy\n",
    "# !pip3 uninstall cupy-cuda11x -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instalar para CUDA Drivers v12\n",
    "# !pip3 install cupy-cuda12x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cupy-cuda12x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Em Linux, executar no terminal\n",
    "\n",
    "    wget https://developer.download.nvidia.com/compute/libcutensor/1.7.0/local_installers/libcutensor-local-repo-ubuntu2204-1.7.0_1.0-1_amd64.deb\n",
    "    sudo dpkg -i libcutensor-local-repo-ubuntu2204-1.7.0_1.0-1_amd64.deb\n",
    "    sudo cp /var/libcutensor-local-repo-ubuntu2204-1.7.0/libcutensor-*-keyring.gpg /usr/share/keyrings/\n",
    "    sudo apt-get update\n",
    "    sudo apt-get -y install libcutensor1 libcutensor-dev libcutensor-doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_k-GZjJDO1I"
   },
   "source": [
    "# Extrair dados do Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Fri_Jan__6_16:45:21_PST_2023\n",
      "Cuda compilation tools, release 12.0, V12.0.140\n",
      "Build cuda_12.0.r12.0/compiler.32267302_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo apt-get install cuXfilter cuXfilter-dev\n",
    "# !pip3 install cuXfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "class Neo4jQuery:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self._driver.close()\n",
    "\n",
    "    def get_graph_data(self):\n",
    "        with self._driver.session() as session:\n",
    "            # Consulta para incluir filtros e lógicas específicas para gerar o grafo\n",
    "            result = session.run(\"MATCH (n)-[r]->(m) RETURN n, r, m\")\n",
    "            nodes = {}\n",
    "            links = []\n",
    "            node_labels_count = defaultdict(int)  # Para contar a frequência dos rótulos dos nós\n",
    "            relationship_types_count = defaultdict(int)  # Para contar a frequência dos tipos de relacionamentos\n",
    "\n",
    "            for record in result:\n",
    "                start_node = record['n']\n",
    "                end_node = record['m']\n",
    "                relationship = record['r']\n",
    "                \n",
    "                # Adiciona nós ao dicionário se ainda não estiverem presentes\n",
    "                if start_node.element_id not in nodes:\n",
    "                    nodes[start_node.element_id] = {'id': start_node.element_id, 'label': list(start_node.labels)[0]}\n",
    "                    node_labels_count[list(start_node.labels)[0]] += 1\n",
    "                if end_node.element_id not in nodes:\n",
    "                    nodes[end_node.element_id] = {'id': end_node.element_id, 'label': list(end_node.labels)[0]}\n",
    "                    node_labels_count[list(end_node.labels)[0]] += 1\n",
    "                \n",
    "                # Adiciona o relacionamento à lista de links\n",
    "                links.append({\n",
    "                    'source': start_node.element_id,\n",
    "                    'target': end_node.element_id,\n",
    "                    'type': relationship.type,\n",
    "                    'properties': dict(relationship)\n",
    "                })\n",
    "                relationship_types_count[relationship.type] += 1\n",
    "\n",
    "            graph_data = {\n",
    "                'nodes': list(nodes.values()),\n",
    "                'links': links,\n",
    "                'node_count': len(nodes),\n",
    "                'link_count': len(links),\n",
    "                'node_labels_count': dict(node_labels_count),  # Converte o defaultdict para um dicionário normal\n",
    "                'relationship_types_count': dict(relationship_types_count)  # Converte o defaultdict para um dicionário normal                \n",
    "            }\n",
    "\n",
    "            # Converte o dicionário de nós para uma lista para uso em d3.js\n",
    "            return graph_data\n",
    "\n",
    "# Uso da classe:\n",
    "neo4j_query = Neo4jQuery('neo4j://localhost:7687', 'neo4j', 'password')\n",
    "graph_data = neo4j_query.get_graph_data()\n",
    "neo4j_query.close()\n",
    "\n",
    "# Após a chamada, graph_data agora contém a contagem de nós e arestas\n",
    "print(f\"   Quantidade de nós: {graph_data['node_count']}\")\n",
    "# Defina a ordem específica das chaves\n",
    "ordered_node_labels = ['ÁrvoreCNPq', 'GrandeÁrea', 'Área', 'Subárea', 'Especialidade']\n",
    "\n",
    "# Imprima o conteúdo de graph_data['node_labels_count'] na ordem especificada\n",
    "for label in ordered_node_labels:\n",
    "    count = graph_data['node_labels_count'].get(label, 0)  # Obtém a contagem, ou 0 se a chave não existir\n",
    "    print(f\"{label:>20}: {count}\")\n",
    "\n",
    "print(f\"\\n Contagem de arestas: {graph_data['link_count']}\")\n",
    "# Defina a ordem específica das chaves\n",
    "ordered_edge_labels = ['CONTÉM', 'CONTÉM_ÁREA', 'CONTÉM_SUBÁREA', 'CONTÉM_ESPECIALIDADE']\n",
    "\n",
    "# Imprima o conteúdo de graph_data['node_labels_count'] na ordem especificada\n",
    "for label in ordered_edge_labels:\n",
    "    count = graph_data['relationship_types_count'].get(label, 0)  # Obtém a contagem, ou 0 se a chave não existir\n",
    "    print(f\"{label:>20}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cugraph\n",
    "import json\n",
    "\n",
    "# Conversão dos dados extraídos para DataFrames do RAPIDS.AI\n",
    "nodes_df = cudf.DataFrame(graph_data['nodes'])\n",
    "edges_df = cudf.DataFrame(graph_data['links'])\n",
    "\n",
    "# Criando um Graph no cuGraph\n",
    "G = cugraph.Graph()\n",
    "G.from_cudf_edgelist(edges_df, source='source', destination='target')\n",
    "\n",
    "# Identificação de comunidades com cugraph\n",
    "# Louvain é um método comum para detecção de comunidades\n",
    "partitions, modularity_score = cugraph.louvain(G)\n",
    "\n",
    "# Adiciona a informação de partição aos nós\n",
    "nodes_df = nodes_df.merge(partitions, left_on='id', right_on='vertex', how='left')\n",
    "\n",
    "# Agora, temos um DataFrame nodes_df que inclui a informação de comunidade para cada nó\n",
    "# Podemos visualizar isso com cuXfilter.\n",
    "\n",
    "# Instanciação e configuração do cuXfilter\n",
    "from cuXfilter import charts\n",
    "import cuXfilter\n",
    "\n",
    "# Criação de um DataFrame cuXfilter a partir do DataFrame cuDF\n",
    "cux_df = cuXfilter.DataFrame.from_dataframe(nodes_df)\n",
    "\n",
    "# Configuração dos gráficos para visualização\n",
    "chart1 = charts.cudatashader.scatter(x='x', y='y', aggregate_col='partition')\n",
    "chart2 = charts.panel_widgets.range_slider('partition')\n",
    "\n",
    "# Configuração do Dashboard\n",
    "d = cux_df.dashboard([chart1, chart2])\n",
    "\n",
    "# Mostrar o Dashboard\n",
    "# d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar dados para visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistent_graph_data = []\n",
    "for record in graph_data:\n",
    "    # Ensure all records have the same keys, potentially with None values\n",
    "    consistent_record = {key: record.get(key, None) for key in expected_keys}\n",
    "    consistent_graph_data.append(consistent_record)\n",
    "\n",
    "df = pd.DataFrame(consistent_graph_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cudf\n",
    "\n",
    "# Converta para DataFrame do pandas\n",
    "df = pd.DataFrame(graph_data)\n",
    "\n",
    "# Converta o DataFrame do pandas para o DataFrame do cuDF\n",
    "gdf = cudf.DataFrame.from_pandas(df)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar dados de grafos extraídos do Neo4j usando cuXfilter, você seguirá uma série de etapas gerais que envolvem:\n",
    "\n",
    "1. **Extração de Dados do Neo4j**: Utilize uma consulta Cypher para extrair dados de nós e arestas do banco de dados Neo4j.\n",
    "\n",
    "2. **Preparação dos Dados**: Transforme os dados extraídos para o formato adequado para serem processados por cuGraph e visualizados por cuXfilter.\n",
    "\n",
    "3. **Análise com cuGraph**: Realize a análise de grafos usando a biblioteca cuGraph da RAPIDS.AI, caso você queira detectar comunidades ou calcular outras métricas de grafos.\n",
    "\n",
    "4. **Visualização com cuXfilter**: Use a biblioteca cuXfilter para criar visualizações interativas a partir dos resultados da análise.\n",
    "\n",
    "### Exemplo de Workflow\n",
    "\n",
    "**1. Extração de dados do Neo4j:**\n",
    "```python\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Função para extrair dados\n",
    "def extract_data(uri, user, password, query):\n",
    "    data = []\n",
    "    driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    with driver.session() as session:\n",
    "        results = session.run(query)\n",
    "        for record in results:\n",
    "            data.append(record)\n",
    "    driver.close()\n",
    "    return data\n",
    "\n",
    "# Defina sua consulta Cypher aqui\n",
    "cypher_query = '''\n",
    "MATCH (n)-[r]->(m)\n",
    "RETURN id(n) as source, id(m) as target, type(r) as type, r.weight as weight\n",
    "'''\n",
    "\n",
    "# Substitua pelos seus detalhes de conexão do Neo4j\n",
    "neo4j_uri = 'bolt://localhost:7687'\n",
    "neo4j_user = 'neo4j'\n",
    "neo4j_password = 'password'\n",
    "\n",
    "# Extraia os dados\n",
    "graph_data = extract_data(neo4j_uri, neo4j_user, neo4j_password, cypher_query)\n",
    "```\n",
    "\n",
    "**2. Preparação dos Dados:**\n",
    "Assumindo que você já tem `graph_data` como uma lista de dicionários com chaves `source`, `target` e `weight`, você pode transformá-lo em um DataFrame pandas e, em seguida, converter para um DataFrame cuDF, que é o formato de dados necessário para a biblioteca RAPIDS cuGraph.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import cudf\n",
    "\n",
    "# Converta para DataFrame do pandas\n",
    "df = pd.DataFrame(graph_data)\n",
    "\n",
    "# Converta o DataFrame do pandas para o DataFrame do cuDF\n",
    "gdf = cudf.DataFrame.from_pandas(df)\n",
    "```\n",
    "\n",
    "**3. Análise com cuGraph:**\n",
    "```python\n",
    "import cugraph\n",
    "\n",
    "# Crie um grafo cuGraph\n",
    "G = cugraph.Graph()\n",
    "G.from_cudf_edgelist(gdf, source='source', destination='target', edge_attr='weight')\n",
    "```\n",
    "\n",
    "**4. Visualização com cuXfilter:**\n",
    "```python\n",
    "import cuxfilter as cxf\n",
    "\n",
    "# Defina o esquema de dados para cuXfilter\n",
    "chart = cxf.charts.datashader.edge_bundle(G, 'source', 'target')\n",
    "\n",
    "# Crie um dashboard cuXfilter\n",
    "d = cxf.DataFrame.from_dataframe(gdf)\n",
    "d.add_chart(chart)\n",
    "\n",
    "# Mostra o dashboard no Jupyter Notebook\n",
    "await d.preview()\n",
    "```\n",
    "\n",
    "Note que este é um fluxo de trabalho genérico e pode precisar ser ajustado de acordo com a sua configuração específica e os detalhes dos dados do Neo4j. Você também pode precisar instalar as bibliotecas necessárias e lidar com as dependências de hardware, como garantir que uma GPU compatível esteja disponível para uso com RAPIDS.AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect**\n",
    "\n",
    "* You may need to reconnect if your Neo4j connection closes\n",
    "* Uncomment the below section for non-Graphistry notebook servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSJfTLxNDQi5"
   },
   "outputs": [],
   "source": [
    "NEO4J = {\n",
    "    'uri': \"bolt://localhost:7687\", \n",
    "    'auth': (\"neo4j\", \"password\")\n",
    "}\n",
    "\n",
    "graphistry.register(bolt=NEO4J)\n",
    "\n",
    "# To specify Graphistry account & server, use:\n",
    "# graphistry.register(api=3, username='...', password='...', protocol='https', server='hub.graphistry.com')\n",
    "# For more options, see https://github.com/graphistry/pygraphistry#configure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sRQ-M4Q4sq-8"
   },
   "source": [
    "## Optional: Load tainted transactions into your own Neo4j DB\n",
    "To populate your own Neo4j instance, set one or both of the top commands to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIk1pGXzsvxr"
   },
   "outputs": [],
   "source": [
    "DELETE_EXISTING_DATABASE=True\n",
    "POPULATE_DATABASE=True\n",
    "\n",
    "if DELETE_EXISTING_DATABASE:\n",
    "    driver = GraphDatabase.driver(**NEO4J)\n",
    "    with driver.session() as session:      \n",
    "        # split into 2 transancations case of memory limit errors\n",
    "        print('Deleting existing transactions')\n",
    "        tx = session.begin_transaction()\n",
    "        tx.run(\"\"\"MATCH (a:Account)-[r]->(b) DELETE r\"\"\")      \n",
    "        tx.commit()      \n",
    "        print('Deleting existing accounts')\n",
    "        tx = session.begin_transaction()      \n",
    "        tx.run(\"\"\"MATCH (a:Account) DELETE a\"\"\")     \n",
    "        tx.commit()\n",
    "        print('Delete successful')\n",
    "\n",
    "if POPULATE_DATABASE:\n",
    "    edges = pd.read_csv('https://www.dropbox.com/s/q1daa707y99ind9/edges.csv?dl=1')\n",
    "    edges = edges.rename(columns={'Amount $': \"USD\", 'Transaction ID': 'Transaction'})[['USD', 'Date', 'Source', 'Destination', 'Transaction']]\n",
    "    id_len = len(edges['Source'][0].split('...')[0]) #truncate IDs (dirty data)\n",
    "    edges = edges.assign(\n",
    "    Source=edges['Source'].apply(lambda id: id[:id_len]),\n",
    "    Destination=edges['Destination'].apply(lambda id: id[:id_len]))\n",
    "    ROSS_FULL='2a37b3bdca935152335c2097e5da367db24209cc'\n",
    "    ROSS = ROSS_FULL[:32]\n",
    "    CARL_FULL = 'b2233dd22ade4c9978ec1fd1fbb36eb7f9b4609e'\n",
    "    CARL = CARL_FULL[:32]\n",
    "    CARL_NICK = 'Carl Force (DEA)'\n",
    "    ROSS_NICK = 'Ross Ulbricht (SilkRoad)'\n",
    "    nodes = pd.read_csv('https://www.dropbox.com/s/nf796f1asow8tx7/nodes.csv?dl=1')\n",
    "    nodes = nodes.rename(columns={'Balance $': 'USD', 'Balance (avg) $': 'USD_avg', 'Balance (max) $': 'USD_max', 'Tainted Coins': 'Tainted_Coins'})[['Account', 'USD', 'USD_avg', 'USD_max', 'Tainted_Coins']]\n",
    "    nodes['Account'] = nodes['Account'].apply(lambda id: id[:id_len])\n",
    "    nodes['Account'] = nodes['Account'].apply(lambda id: CARL_NICK if id == CARL else ROSS_NICK if id == ROSS else id)\n",
    "    driver = GraphDatabase.driver(**NEO4J)\n",
    "    with driver.session() as session:      \n",
    "        tx = session.begin_transaction()                  \n",
    "        print('Loading', len(nodes), 'accounts')\n",
    "        for index, row in nodes.iterrows():\n",
    "            if index % 2000 == 0:\n",
    "                print('Committing', index - 2000, '...', index)\n",
    "                tx.commit()\n",
    "                tx = session.begin_transaction()\n",
    "            tx.run(\"\"\"\n",
    "            CREATE (a:Account {\n",
    "              Account: $Account,\n",
    "              USD: $USD, USD_avg: $USD_avg, USD_max: $USD_max, Tainted_Coins: $Tainted_Coins\n",
    "            })            \n",
    "            RETURN id(a)\n",
    "            \"\"\", **row)\n",
    "            if index % 2000 == 0:\n",
    "                print(index)\n",
    "        print('Committing rest')\n",
    "        tx.commit()\n",
    "        tx = session.begin_transaction()\n",
    "        print('Creating index on Account')\n",
    "        # tx.run(\"\"\"  CREATE INDEX ON :Account(Account)  \"\"\") # Sintaxe na versão anterior à 4.x\n",
    "        tx.run(\"\"\"CREATE INDEX FOR (a:Account) ON (a.Account)\"\"\")\n",
    "        tx.commit()\n",
    "    STATUS=1000\n",
    "    BATCH=2000\n",
    "    driver = GraphDatabase.driver(**NEO4J)\n",
    "\n",
    "    with driver.session() as session:\n",
    "        tx = session.begin_transaction()\n",
    "        print('Loading', len(edges), 'transactions')      \n",
    "        for index, row in edges.iterrows(): \n",
    "            tx.run(\"\"\"MATCH (a:Account),(b:Account)\n",
    "                  WHERE a.Account = $Source AND b.Account = $Destination\n",
    "                  CREATE (a)-[r:PAYMENT { \n",
    "                    Source: $Source, Destination: $Destination, USD: $USD, Date: $Date, Transaction: $Transaction \n",
    "                  }]->(b)\n",
    "                  \"\"\", **row)\n",
    "            if index % STATUS == 0:\n",
    "                print(index)\n",
    "            if index % BATCH == 0 and index > 0:\n",
    "                print('sending batch out')\n",
    "                tx.commit()\n",
    "                print('... done')\n",
    "                tx = session.begin_transaction()\n",
    "        tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqbo_o0RMmkI"
   },
   "source": [
    "## Cypher Demos\n",
    "\n",
    "### 1a. Warmup: Visualize all $7K - $10K transactions\n",
    "Try panning and zooming (same touchpad/mouse controls as Google Maps), and clicking on individual wallets and transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRXlWQvtycCM"
   },
   "outputs": [],
   "source": [
    "g = graphistry.cypher(\"\"\"\n",
    "      MATCH (a)-[r:PAYMENT]->(b) WHERE r.USD > 7000 AND r.USD < 10000  RETURN a, r, b ORDER BY r.USD DESC\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "colab_type": "code",
    "id": "OrRqdkK4GhJl",
    "outputId": "2fc30291-063b-4a21-a704-2cde524b85e2"
   },
   "outputs": [],
   "source": [
    "g.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RkrYDjcYl6g2"
   },
   "source": [
    "Screenshot\n",
    "![Bitcoin transactions between $7K and 10K](https://www.dropbox.com/s/kt0str2k8azs922/screenshot0.png?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQzLQog09sjJ"
   },
   "source": [
    "### 1b. Cleanup: Configure node and edge titles to use amount fields\n",
    "* **Static config**: We can preconfigure the visualization from directly within the notebook\n",
    "* **Dynamic config**: Try dynamically improving the visualization on-the-fly within the tool by \n",
    "  * Do `add histogram for...` on `edge:USD` and `point:USD_MAX`\n",
    "  * Set edge/point coloring using them, and selecting a \"Gradient (Spectral7 7)\" blend, and toggling to reverse order (so cold to hot). \n",
    "  * For `point:USD_MAX`, toggle it to controling point size, and in the `Scene settings`,  increase the point size slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "colab_type": "code",
    "id": "B2Im4KZsDCLv",
    "outputId": "f2965600-2b14-421b-b780-6e8a0da7ca11"
   },
   "outputs": [],
   "source": [
    "g = g\\\n",
    "  .bind(point_title='Account')\\\n",
    "  .bind(edge_title='USD')\n",
    "\n",
    "g.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m4YvIWNP-fCe"
   },
   "source": [
    "### 2. Look for all transactions 1-5 hops from embezzling DEA Agent Carl Force\n",
    "\n",
    "#### 2a. Downstream\n",
    "Where did most of Carl's money go? \n",
    "* Try setting up filters on `edge:USD` to separate out small vs big money flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "colab_type": "code",
    "id": "Uywc60Xq-slC",
    "outputId": "3c593d83-c824-4a78-ca7c-a04a9c04b059"
   },
   "outputs": [],
   "source": [
    "g.cypher(\"\"\"\n",
    "    match (a)-[r:PAYMENT*1..20]->(b) \n",
    "    where a.Account = $root and ALL(transfer IN r WHERE transfer.USD > $min_amount and transfer.USD < $max_amount )\n",
    "    return a, r, b\n",
    "  \"\"\", \n",
    "  {'root': \"Carl Force (DEA)\", \n",
    "   'min_amount': 999, \n",
    "   'max_amount': 99999}).plot() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XaHKnft9cOf_"
   },
   "source": [
    "Screenshot:\n",
    "\n",
    "![Carl Force's bitcoin accounts](https://www.dropbox.com/s/nh1uo4iuqvav5xm/screenshot1.png?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kg5oaTufWqe6"
   },
   "source": [
    "#### 2b. Upstream\n",
    "From where did Carl get most of his money?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "colab_type": "code",
    "id": "hzv-tNMc_bZP",
    "outputId": "1462c06b-318f-4229-c4db-b265bdc4f868"
   },
   "outputs": [],
   "source": [
    "g.cypher(\"\"\"\n",
    "      match (a)-[r:PAYMENT*1..10]->(b) \n",
    "      where b.Account=$sink and ALL(transfer IN r WHERE transfer.USD > $min_amount and transfer.USD < $max_amount )\n",
    "      return r, a, b\n",
    "    \"\"\", \n",
    "    {'sink': \"Carl Force (DEA)\",\n",
    "    'min_amount': 1999, \n",
    "    'max_amount': 99999}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OhglbPE7gAhq"
   },
   "source": [
    "Screenshot:\n",
    "\n",
    "![Carl Force embezzling money from the Silk Road](https://www.dropbox.com/s/qvw6s5zi1dddq78/screenshot2.png?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gusmhJvHbvbh"
   },
   "source": [
    "## 3. Paths between Silk Road and Carl Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "colab_type": "code",
    "id": "kAnSUoJVWuQn",
    "outputId": "d31d0070-5eea-4a5c-b8c6-8915a2665f70"
   },
   "outputs": [],
   "source": [
    "g.cypher(\"match (a)-[r:PAYMENT*1..10]->(b) where a.Account=$silk and b.Account=$dea return r, a, b\", \n",
    "         {'dea': \"Carl Force (DEA)\", \"silk\": \"Ross Ulbricht (SilkRoad)\"}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvcNGnYIsgff"
   },
   "source": [
    "## Further Reading\n",
    "\n",
    "* UI Guide: https://hub.graphistry.com/docs/ui/index/\n",
    "* Python client tutorials & demos: https://github.com/graphistry/pygraphistry \n",
    "* DEA incident: https://arstechnica.com/tech-policy/2016/08/stealing-bitcoins-with-badges-how-silk-roads-dirty-cops-got-caught/ "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "graphistry_bolt_tutorial_public",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
