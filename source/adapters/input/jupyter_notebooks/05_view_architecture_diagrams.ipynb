{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><center>Diagramas Arquiteturais</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalação de pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --user IPython\n",
    "# %pip install --upgrade diagrams\n",
    "# %pip show -f diagrams\n",
    "# !apt-get install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmar caminho da instalação da bilbiotexa diagrams\n",
    "import os\n",
    "from pathlib import Path\n",
    "import diagrams\n",
    "\n",
    "def get_diagrams_library_path():\n",
    "    # Get the path of the currently imported diagrams module\n",
    "    diagrams_path = Path(diagrams.__file__).parent\n",
    "    return diagrams_path\n",
    "\n",
    "# Usage example:\n",
    "diagrams_path = get_diagrams_library_path()\n",
    "print(f\"Diagrams library path: {diagrams_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de busca e renderização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import site\n",
    "import base64\n",
    "import pkgutil\n",
    "import inspect\n",
    "import diagrams\n",
    "from IPython.display import Image, display, HTML\n",
    "from diagrams import Node\n",
    "\n",
    "def list_classes_from_namespace(namespace_filter):\n",
    "    class_map = {}\n",
    "    # Validar se o filtro de namespace existe dentro da biblioteca diagrams\n",
    "    if not hasattr(diagrams, namespace_filter):\n",
    "        return class_map\n",
    "\n",
    "    # Obter a referência ao módulo do namespace\n",
    "    namespace_module = getattr(diagrams, namespace_filter)\n",
    "\n",
    "    # Iterar sobre todos os módulos dentro do namespace do provedor de serviços\n",
    "    for importer, modname, ispkg in pkgutil.walk_packages(path=namespace_module.__path__, prefix=namespace_module.__name__ + '.'):\n",
    "        # Importar o módulo atual\n",
    "        module = __import__(modname, fromlist=\"dummy\")\n",
    "        class_list = []\n",
    "        # Iterar sobre membros do módulo atual\n",
    "        for name, obj in inspect.getmembers(module):\n",
    "            # Verificar se o membro é uma classe e se ela é uma subclasse de Node\n",
    "            if inspect.isclass(obj) and issubclass(obj, Node) and obj.__module__ == module.__name__:\n",
    "                class_list.append(name)\n",
    "        if class_list:\n",
    "            # Armazenar a lista de classes no dicionário com o nome do módulo como chave\n",
    "            class_map[modname] = class_list\n",
    "\n",
    "    return class_map\n",
    "\n",
    "def list_categories(namespace):\n",
    "    # Usar a função e imprimir os resultados para um namespace específico\n",
    "    available_classes = list_classes_from_namespace(namespace)\n",
    "\n",
    "    if available_classes:\n",
    "        for module, classes in available_classes.items():\n",
    "            print(f\"{module}:\")\n",
    "            for cls in classes:\n",
    "                print(f\"    {cls}\")\n",
    "    else:\n",
    "        print(f\"No classes found for namespace '{namespace}'\")\n",
    "\n",
    "def load_diagram_icon(category, name):\n",
    "    \"\"\"\n",
    "    Carrega e exibe um ícone do pacote 'diagrams' baseado na categoria e no nome do serviço.\n",
    "    \n",
    "    Parâmetros:\n",
    "    category (str): A categoria do serviço (ex.: 'compute', 'analytics').\n",
    "    name (str): O nome específico do serviço (ex.: 'ec2', 'lambda').\n",
    "    \n",
    "    Retorna:\n",
    "    Uma instância IPython.display.Image do ícone.\n",
    "    \"\"\"\n",
    "    # Lista de possíveis caminhos para pacotes de site e pacotes de usuário\n",
    "    site_packages_paths = site.getsitepackages() + [site.getusersitepackages()]\n",
    "\n",
    "    # Caminho base para a pasta 'resources'\n",
    "    resources_path = None\n",
    "    \n",
    "    for site_package_path in site_packages_paths:\n",
    "        potential_path = os.path.join(site_package_path, 'resources')\n",
    "        if os.path.isdir(potential_path):\n",
    "            resources_path = potential_path\n",
    "            break\n",
    "    \n",
    "    if not resources_path:\n",
    "        raise FileNotFoundError(\"Não foi possível localizar a pasta 'resources' na instalação do Python.\")\n",
    "    \n",
    "    # Constrói o caminho completo para o ícone\n",
    "    icon_path = os.path.join(resources_path, category, f\"{name}.png\")\n",
    "    \n",
    "    # Verifica se o arquivo do ícone existe\n",
    "    if not os.path.isfile(icon_path):\n",
    "        raise FileNotFoundError(f\"Não foi possível encontrar o ícone em {icon_path}\")\n",
    "    \n",
    "    # Carrega e exibe o ícone\n",
    "    display(Image(filename=icon_path))\n",
    "\n",
    "def render_namespace_icons(namespace):\n",
    "    \"\"\"\n",
    "    Renderiza todos os ícones de um namespace específico e exibe seus nomes ao lado deles no Jupyter Notebook.\n",
    "    \n",
    "    Parâmetros:\n",
    "    namespace (str): O namespace cujos ícones devem ser renderizados (ex.: 'aws/compute').\n",
    "    \n",
    "    Retorna:\n",
    "    Uma exibição HTML de ícones com seus nomes correspondentes.\n",
    "    \"\"\"\n",
    "    # Localiza a pasta 'resources' conforme implementado anteriormente\n",
    "    site_packages_paths = site.getsitepackages() + [site.getusersitepackages()]\n",
    "    resources_path = None\n",
    "    \n",
    "    for site_package_path in site_packages_paths:\n",
    "        potential_path = os.path.join(site_package_path, 'resources')\n",
    "        if os.path.isdir(potential_path):\n",
    "            resources_path = potential_path\n",
    "            break\n",
    "    \n",
    "    if not resources_path:\n",
    "        raise FileNotFoundError(\"Não foi possível localizar a pasta 'resources' na instalação do Python.\")\n",
    "    \n",
    "    namespace_path = os.path.join(resources_path, namespace)\n",
    "    \n",
    "    if not os.path.isdir(namespace_path):\n",
    "        raise FileNotFoundError(f\"Não foi possível localizar o namespace '{namespace}' em {resources_path}.\")\n",
    "\n",
    "    # Lista todos os arquivos PNG dentro do namespace\n",
    "    icon_files = [f for f in os.listdir(namespace_path) if os.path.isfile(os.path.join(namespace_path, f)) and f.endswith('.png')]\n",
    "    \n",
    "    icons_html_str = \"\"\n",
    "\n",
    "    for icon_file in icon_files:\n",
    "        icon_name = icon_file[:-4]\n",
    "        icon_path = os.path.join(namespace_path, icon_file)\n",
    "\n",
    "        # Encode the image in base64 and render it directly in the notebook\n",
    "        with open(icon_path, \"rb\") as image_file:\n",
    "            encoded_string = base64.b64encode(image_file.read()).decode()\n",
    "        \n",
    "        icon_base64 = f\"data:image/png;base64,{encoded_string}\"\n",
    "        \n",
    "        icons_html_str += f'<div style=\"float: left; text-align: center; margin: 5px;\">'\n",
    "        icons_html_str += f'<div style=\"margin-bottom: 5px;\"><strong>{icon_name}</strong></div>'\n",
    "        icons_html_str += f'<img src=\"{icon_base64}\" style=\"max-width: 100px; max-height: 100px;\">'\n",
    "        icons_html_str += f'</div>'\n",
    "\n",
    "    display(HTML(icons_html_str))\n",
    "\n",
    "\n",
    "def list_all_namespace_icons(namespace='aws'):\n",
    "    \"\"\"\n",
    "    List and render all icons in the given namespace, searching for the\n",
    "    'resources' directory in standard site-packages locations.\n",
    "    \n",
    "    :param namespace: The namespace to iterate over, defaults to 'aws'.\n",
    "    \"\"\"\n",
    "    # Localize the 'resources' folder as implemented previously\n",
    "    site_packages_paths = site.getsitepackages() + [site.getusersitepackages()]\n",
    "    resources_path = None\n",
    "\n",
    "    # Check each potential site-packages path for the 'resources' directory\n",
    "    for site_package_path in site_packages_paths:\n",
    "        potential_path = os.path.join(site_package_path, 'resources')\n",
    "        if os.path.isdir(potential_path):\n",
    "            resources_path = potential_path\n",
    "            break\n",
    "\n",
    "    # If 'resources' path was not found, raise an error\n",
    "    if not resources_path:\n",
    "        raise FileNotFoundError(\"Could not locate the 'resources' folder within the Python installation.\")\n",
    "\n",
    "    # Construct the path to the namespace within the 'resources' directory\n",
    "    namespace_path = os.path.join(resources_path, namespace)\n",
    "    \n",
    "    if not os.path.exists(namespace_path):\n",
    "        raise FileNotFoundError(f\"The namespace path '{namespace_path}' does not exist.\")\n",
    "    \n",
    "    # Iterate over the directories within the namespace\n",
    "    for category in os.listdir(namespace_path):\n",
    "        category_path = os.path.join(namespace_path, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            # Assume the directory name is the category name and render icons\n",
    "            print(f\"Rendering icons for category: {category}\")\n",
    "            render_namespace_icons(f'{namespace}/{category}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso para listar ícones, classes e namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes específicas dentro de categorias (namespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso para um ícone específico:\n",
    "load_diagram_icon('aws/compute', 'ec2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso para uma classe completa:\n",
    "render_namespace_icons('azure/integration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso para uma classe completa:\n",
    "render_namespace_icons('azure/database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso para uma classe completa:\n",
    "render_namespace_icons('aws/compute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Namespaces completos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso para uma classe namespace completa\n",
    "list_all_namespace_icons('generic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Web Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso para uma classe namespace completa\n",
    "list_all_namespace_icons('aws')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microsoft Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso para uma classe namespace completa\n",
    "list_all_namespace_icons('azure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Cloud Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso para uma classe namespace completa\n",
    "list_all_namespace_icons('gcp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar diagramas Arquiteturais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro da biblioteca `diagrams`, cada provedor de serviços em nuvem como a AWS, Azure ou GCP é geralmente referenciado como um \"provedor\" ou \"namespace\". Os termos técnicos podem variar com o contexto, mas geralmente o termo \"módulo\" é tecnicamente correto, já que em Python, um módulo é um arquivo contendo definições e instruções em Python.\n",
    "\n",
    "Assim, se você está se referindo à estrutura de módulos usada na biblioteca `diagrams` para organizar os ícones de serviços da Azure, você poderia dizer \"módulo Azure\" ou \"namespace Azure\".\n",
    "\n",
    "Para ser mais específico:\n",
    "\n",
    "- `diagrams.azure.compute` é um módulo.\n",
    "- `diagrams.azure` é o namespace ou provedor dentro da biblioteca `diagrams`.\n",
    "- Cada serviço dentro do `diagrams.azure.compute` como `VM` é uma classe.\n",
    "\n",
    "Quando você está se referindo à organização do código, \"módulo\" é o termo apropriado. Quando está falando sobre o uso dentro de um diagrama de arquitetura ou algo mais conceitual, \"provedor\" ou \"serviço\" seria mais adequado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_categories(\"azure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvimento em CI/CD ecossistema Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagrams import Cluster, Diagram\n",
    "from diagrams.azure.compute import FunctionApps\n",
    "from diagrams.azure.database import CosmosDb\n",
    "from diagrams.azure.ml import MachineLearningStudioWorkspaces\n",
    "from diagrams.azure.devops import Pipelines\n",
    "from diagrams.azure.database import DataFactory\n",
    "\n",
    "# Criação de diretório para salvar os diagramas se ainda não existir\n",
    "import os\n",
    "diagrams_dir = \"diagrams\"\n",
    "if not os.path.exists(diagrams_dir):\n",
    "    os.makedirs(diagrams_dir)\n",
    "\n",
    "filename = 'gml_simplified_architecture_diagram_azure'\n",
    "with Diagram(\"Azure Architecture Diagram\", filename=f\"{diagrams_dir}/{filename}\", direction=\"TB\", outformat=\"png\", show=False):\n",
    "\n",
    "    with Cluster(\"Data Processing\"):\n",
    "        data_factory = DataFactory(\"GraphDataRetriever\")\n",
    "        cosine_function = FunctionApps(\"CosineSimilarityRelationship\")  # Corrigido para FunctionApps\n",
    "\n",
    "    with Cluster(\"Graph Database\"):\n",
    "        cosmos_db = CosmosDb(\"Neo4jService\")\n",
    "\n",
    "    with Cluster(\"Model Training\"):\n",
    "        ml_workspace = MachineLearningStudioWorkspaces(\"GNNModel\")  # Corrigido para MachineLearningWorkspaces\n",
    "        pipeline = Pipelines(\"GraphTrainingPipeline\")\n",
    "\n",
    "    data_factory >> cosine_function >> cosmos_db\n",
    "    cosmos_db >> ml_workspace >> pipeline\n",
    "\n",
    "# Renderizar o diagrama diretamente em uma célula de um Jupyter Notebook.\n",
    "from IPython.display import Image\n",
    "\n",
    "# Verifique se o caminho para o diagrama gerado está correto e se a extensão corresponde ao `outformat` definido acima.\n",
    "path_to_diagram = f\"{diagrams_dir}/{filename}.png\"\n",
    "Image(path_to_diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagrams import Cluster, Diagram\n",
    "from diagrams.azure.compute import FunctionApps\n",
    "from diagrams.azure.database import CosmosDb\n",
    "from diagrams.azure.ml import MachineLearningStudioWebServices\n",
    "from diagrams.azure.integration import DataCatalog\n",
    "from diagrams.azure.devops import Pipelines\n",
    "\n",
    "# Criação de diretório para salvar os diagramas se ainda não existir\n",
    "import os\n",
    "diagrams_dir = \"diagrams\"\n",
    "if not os.path.exists(diagrams_dir):\n",
    "    os.makedirs(diagrams_dir)\n",
    "\n",
    "with Diagram(\"Azure Architecture Diagram\", filename=f\"{diagrams_dir}/azure_architecture_diagram\", direction=\"TB\", outformat=\"png\", show=False):\n",
    "\n",
    "    with Cluster(\"Data Processing\"):\n",
    "        data_factory = DataCatalog(\"GraphDataRetriever\")\n",
    "        cosine_function = FunctionApps(\"CosineSimilarityRelationship\")\n",
    "\n",
    "    with Cluster(\"Graph Database\"):\n",
    "        cosmos_db = CosmosDb(\"Neo4jService\")  # Usando CosmosDB para representar n4j\n",
    "\n",
    "    with Cluster(\"Model Training\"):\n",
    "        ml_workspace = MachineLearningStudioWebServices(\"GNNModel\")\n",
    "        pipeline = Pipelines(\"GraphTrainingPipeline\")\n",
    "\n",
    "    data_factory >> cosine_function >> cosmos_db\n",
    "    cosmos_db >> ml_workspace >> pipeline\n",
    "\n",
    "# Renderizar o diagrama diretamente em uma célula de um Jupyter Notebook.\n",
    "from IPython.display import Image\n",
    "\n",
    "# Verifique se o caminho para o diagrama gerado está correto e se a extensão corresponde ao `outformat` definido acima.\n",
    "path_to_diagram = f\"{diagrams_dir}/azure_architecture_diagram.png\"\n",
    "Image(path_to_diagram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagrams import Cluster, Diagram\n",
    "from diagrams.azure.compute import FunctionApps\n",
    "from diagrams.azure.database import CosmosDb\n",
    "from diagrams.azure.ml import MachineLearningStudioWebServices\n",
    "from diagrams.azure.devops import Pipelines\n",
    "from diagrams.azure.integration import DataFactory\n",
    "\n",
    "# Criação de diretório para salvar os diagramas se ainda não existir\n",
    "import os\n",
    "diagrams_dir = \"diagrams\"\n",
    "if not os.path.exists(diagrams_dir):\n",
    "    os.makedirs(diagrams_dir)\n",
    "\n",
    "with Diagram(\"Azure Architecture Diagram\", filename=f\"{diagrams_dir}/gml_simplified_architecture_diagram_azure\", direction=\"TB\", outformat=\"png\", show=False):\n",
    "\n",
    "    with Cluster(\"Data Processing\"):\n",
    "        data_factory = DataFactory(\"GraphDataRetriever\")\n",
    "        cosine_function = FunctionApps(\"CosineSimilarityRelationship\")\n",
    "\n",
    "    with Cluster(\"Graph Database\"):\n",
    "        cosmos_db = CosmosDB(\"Neo4jService\")\n",
    "\n",
    "    with Cluster(\"Model Training\"):\n",
    "        ml_service = MachineLearningService(\"GNNModel\")\n",
    "        pipeline = Pipelines(\"GraphTrainingPipeline\")\n",
    "\n",
    "    data_factory >> cosine_function >> cosmos_db\n",
    "    cosmos_db >> ml_service >> pipeline\n",
    "\n",
    "# Renderizar o diagrama diretamente em uma célula de um Jupyter Notebook.\n",
    "from IPython.display import Image\n",
    "\n",
    "# Verifique se o caminho para o diagrama gerado está correto e se a extensão corresponde ao `outformat` definido acima.\n",
    "path_to_diagram = f\"{diagrams_dir}/gml_simplified_architecture_diagram_azure.png\"\n",
    "Image(path_to_diagram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvimento em CI/CD ecossistema AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from diagrams import Cluster, Diagram\n",
    "from diagrams.aws.compute import ECS\n",
    "from diagrams.aws.database import RDS\n",
    "from diagrams.aws.integration import SQS\n",
    "from diagrams.aws.storage import S3\n",
    "from diagrams.aws.ml import Sagemaker\n",
    "from diagrams.aws.network import ELB\n",
    "from diagrams.onprem.vcs import Github\n",
    "from diagrams.onprem.ci import Jenkins\n",
    "from diagrams.onprem.container import Docker\n",
    "from diagrams.aws.management import Cloudwatch\n",
    "from IPython.display import Image\n",
    "\n",
    "# Nome do diretório onde as imagens serão salvas\n",
    "diagrams_dir = \"diagrams\"\n",
    "# Certifique-se de que o diretório exista\n",
    "os.makedirs(diagrams_dir, exist_ok=True)\n",
    "\n",
    "# Define o caminho do arquivo onde a imagem será salva\n",
    "output_filename = os.path.join(diagrams_dir, \"gml_simplified_architecture_diagram\")\n",
    "\n",
    "with Diagram(filename=output_filename, show=False, direction=\"TB\", outformat=\"png\"):\n",
    "    \n",
    "    # Repositório de Código Fonte\n",
    "    repo = Github(\"repo\")\n",
    "\n",
    "    # CI/CD pipeline\n",
    "    ci_cd_pipeline = Jenkins(\"ci/cd pipeline\")\n",
    "\n",
    "    # Contêineres Docker\n",
    "    docker_img = Docker(\"docker image\")\n",
    "\n",
    "    # AWS Services\n",
    "    with Cluster(\"AWS Cloud\"):\n",
    "        s3 = S3(\"data bucket\")\n",
    "        sqs = SQS(\"job queue\")\n",
    "        ecs = ECS(\"docker container\")\n",
    "        rds = RDS(\"database\")\n",
    "        sagemaker = Sagemaker(\"ML model training\")\n",
    "        elb = ELB(\"load balancer\")\n",
    "        cloudwatch = Cloudwatch(\"monitoring\")\n",
    "\n",
    "    # Conexões\n",
    "    repo >> ci_cd_pipeline >> docker_img >> ecs\n",
    "    ecs >> s3 >> sagemaker\n",
    "    ecs >> rds\n",
    "    ecs >> sqs >> sagemaker\n",
    "    sagemaker >> rds\n",
    "    ecs >> cloudwatch\n",
    "    elb >> ecs\n",
    "\n",
    "# Renderiza o diagrama e exibe no notebook\n",
    "Image(filename=f\"{output_filename}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O diagrama abaixo mostra a implementação das classes principais da aplicação como serviços em AWS:\n",
    "\n",
    "    Neo4jService:\n",
    "Serviço de banco de dados NoSQL do AWS (por exemplo, Amazon DynamoDB para representar o banco de dados do grafo).\n",
    "\n",
    "    CosineSimilarityRelationship:\n",
    "Serviço de computação serverless (por exemplo, AWS Lambda para representar a função de cálculo de similaridade).\n",
    "\n",
    "    GNNModel:\n",
    "Serviço como o Amazon SageMaker para treinamento e inferência do modelo de machine learning.\n",
    "\n",
    "    GraphModel:\n",
    "Representado por um serviço de orquestração (por exemplo, AWS Step Functions).\n",
    "\n",
    "    GraphDataRetriever:\n",
    "Representa o serviço de ETL do AWS (por exemplo, AWS Glue).\n",
    "\n",
    "    GraphTrainingPipeline:\n",
    "Representa a combinação de serviços, incluindo o AWS CodePipeline para a orquestração do pipeline de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produção em ecossistema AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from diagrams import Cluster, Diagram\n",
    "from diagrams.aws.database import Dynamodb\n",
    "from diagrams.aws.compute import Lambda\n",
    "from diagrams.aws.ml import Sagemaker\n",
    "from diagrams.aws.integration import StepFunctions\n",
    "from diagrams.aws.analytics import Glue\n",
    "from diagrams.aws.devtools import Codepipeline\n",
    "from diagrams.onprem.vcs import Github\n",
    "from diagrams.onprem.ci import Jenkins\n",
    "from diagrams.aws.management import Cloudwatch\n",
    "from IPython.display import Image\n",
    "\n",
    "# Nome do diretório onde as imagens serão salvas\n",
    "diagrams_dir = \"diagrams\"\n",
    "# Certifique-se de que o diretório exista\n",
    "os.makedirs(diagrams_dir, exist_ok=True)\n",
    "\n",
    "# Define o caminho do arquivo onde a imagem será salva\n",
    "output_filename = os.path.join(diagrams_dir, \"detailed_ml_pipeline_architecture_diagram\")\n",
    "\n",
    "with Diagram(filename=output_filename, show=False, direction=\"TB\", outformat=\"png\"):\n",
    "    \n",
    "    # Repositório de Código Fonte e CI/CD pipeline\n",
    "    repo = Github(\"repo\")\n",
    "    ci_cd_pipeline = Jenkins(\"ci/cd pipeline\")\n",
    "    \n",
    "    # Classes como serviços AWS\n",
    "    with Cluster(\"ML Pipeline Services\"):\n",
    "        neo4j_service = Dynamodb(\"Neo4jService\")\n",
    "        cosine_similarity = Lambda(\"CosineSimilarity\")\n",
    "        gnn_model = Sagemaker(\"GNNModel\")\n",
    "        graph_model = StepFunctions(\"GraphModel\")\n",
    "        graph_data_retriever = Glue(\"GraphDataRetriever\")\n",
    "        graph_training_pipeline = Codepipeline(\"GraphTrainingPipeline\")\n",
    "\n",
    "    # Monitoramento\n",
    "    cloudwatch = Cloudwatch(\"monitoring\")\n",
    "\n",
    "    # Conexões\n",
    "    repo >> ci_cd_pipeline >> graph_training_pipeline\n",
    "    graph_training_pipeline >> graph_data_retriever >> neo4j_service\n",
    "    neo4j_service >> cosine_similarity >> graph_model\n",
    "    graph_model >> gnn_model\n",
    "    [neo4j_service, cosine_similarity, gnn_model, graph_data_retriever, graph_model] >> cloudwatch\n",
    "\n",
    "# Renderiza o diagrama e exibe no notebook\n",
    "Image(filename=f\"{output_filename}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolver local visando produção em nuvem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para desenvolver e testar contêineres localmente sem utilizar diretamente os serviços AWS e, posteriormente, implantá-los em produção na AWS, é possível seguir um fluxo de trabalho que envolve a utilização de ferramentas locais de desenvolvimento, testes e ferramentas de CI/CD para automatizar a implantação. Abaixo, delineio uma abordagem passo a passo:\n",
    "\n",
    "### Desenvolvimento e Testes Locais:\n",
    "\n",
    "1. **Desenvolvimento Local**:\n",
    "   - Utilize o Docker localmente para conteinerizar a aplicação.\n",
    "   - Desenvolva e teste sua aplicação em um ambiente local que espelhe o ambiente de produção o mais próximo possível.\n",
    "\n",
    "2. **Dockerfile**:\n",
    "   - Crie um `Dockerfile` na raiz do projeto para construir a imagem do Docker.\n",
    "\n",
    "3. **Testes**:\n",
    "   - Escreva testes automatizados que podem ser executados dentro do contêiner.\n",
    "   - Teste a imagem do Docker localmente executando os contêineres e validando seu comportamento.\n",
    "\n",
    "### Integração e Implantação Contínua (CI/CD):\n",
    "\n",
    "4. **Sistema de Controle de Versão**:\n",
    "   - Use o Git para versionamento e armazene o código-fonte em um sistema de controle de versão como GitHub, GitLab, Bitbucket, etc.\n",
    "\n",
    "5. **Pipeline de CI/CD**:\n",
    "   - Configure uma pipeline de CI/CD utilizando ferramentas como Jenkins, CircleCI, GitHub Actions, etc., que não dependem diretamente de serviços AWS para a fase de construção e testes.\n",
    "   - A pipeline deve ser capaz de construir a imagem do Docker e executar todos os testes sempre que houver um push no repositório.\n",
    "\n",
    "6. **Conexão com AWS**:\n",
    "   - A pipeline deve ter etapas para autenticar com a AWS e empurrar a imagem do Docker construída para o Amazon Elastic Container Registry (ECR), que é o serviço de registro de contêiner da AWS.\n",
    "   - Crie um script ou utilize um plugin da pipeline que handle a implantação do contêiner no serviço de destino da AWS (como ECS ou EKS).\n",
    "\n",
    "### Implantação:\n",
    "\n",
    "7. **AWS Credentials**:\n",
    "   - Armazene as credenciais da AWS de forma segura na ferramenta de CI/CD para serem utilizadas durante a implantação.\n",
    "\n",
    "8. **Arquivos de Configuração**:\n",
    "   - Mantenha os arquivos de configuração necessários para a implantação (como task definitions para ECS, manifestos do Kubernetes para EKS, etc.) no repositório de código.\n",
    "\n",
    "9. **Automação da Implantação**:\n",
    "   - Após a construção e teste bem-sucedidos, a pipeline deve automaticamente implantar a imagem do Docker atualizada no ambiente de produção na AWS.\n",
    "   - Use templates de infraestrutura como código (Terraform, AWS CloudFormation) para garantir que a infraestrutura na AWS seja provisionada de forma idêntica à configuração testada.\n",
    "\n",
    "### Monitoramento e Feedback:\n",
    "\n",
    "10. **Monitoramento**:\n",
    "    - Utilize soluções de monitoramento (locais ou da AWS como CloudWatch) para monitorar a aplicação em produção.\n",
    "\n",
    "11. **Feedback**:\n",
    "    - Configure notificações e alertas para obter feedback sobre o status da implantação e o desempenho da aplicação em produção.\n",
    "\n",
    "Ao seguir esta abordagem, você pode desenvolver e testar contêineres localmente em um ambiente que é independente dos serviços AWS, mantendo a capacidade de implantar facilmente na AWS quando o contêiner estiver pronto para produção. A chave é garantir que a configuração local seja o mais próximo possível do ambiente de produção para minimizar as diferenças e os problemas potenciais de implantação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolver já dentro do ecossistema AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para desde o início do desenvolvimento já implementar CI/CD, sem o uso direto do GitHub, mas usando diretamente os serviços oferecidos pela AWS, há um conjunto de ferramentas integradas que podem ser utilizadas para criar um pipeline de CI/CD completo. \n",
    "\n",
    "Aqui estão os serviços-chave da AWS que podem ser usados para esse fim:\n",
    "\n",
    "1. **AWS CodeCommit**:\n",
    "   - Um serviço de controle de versão baseado na nuvem que hospeda repositórios Git privados seguros.\n",
    "   - Pode ser usado como uma alternativa ao GitHub para armazenar seu código fonte.\n",
    "\n",
    "2. **AWS CodeBuild**:\n",
    "   - Um serviço de compilação que compila o código fonte, executa testes e produz pacotes de software prontos para serem implantados.\n",
    "\n",
    "3. **AWS CodeDeploy**:\n",
    "   - Um serviço de implantação que automatiza as implantações de aplicativos em várias instâncias da AWS, como EC2, AWS Fargate e AWS Lambda.\n",
    "\n",
    "4. **AWS CodePipeline**:\n",
    "   - Um serviço de entrega contínua que automatiza as fases de compilação, teste e implantação do seu processo de lançamento de aplicativos cada vez que há uma mudança de código, com base nos modelos de release definidos.\n",
    "\n",
    "Para implementar CI/CD usando esses serviços, você seguiria as etapas abaixo:\n",
    "\n",
    "### Configuração de um Pipeline de CI/CD na AWS:\n",
    "\n",
    "1. **CodeCommit**:\n",
    "   - Crie um repositório no AWS CodeCommit e faça o push do código para este repositório.\n",
    "\n",
    "2. **CodeBuild**:\n",
    "   - Crie um projeto no AWS CodeBuild que será responsável por compilar o código, executar testes e gerar artefatos.\n",
    "   - Configure o projeto para usar o repositório CodeCommit como fonte.\n",
    "\n",
    "3. **CodeDeploy**:\n",
    "   - Configure o AWS CodeDeploy para implantar os artefatos gerados pelo CodeBuild nos ambientes de teste/staging/produção.\n",
    "\n",
    "4. **CodePipeline**:\n",
    "   - Crie um pipeline no AWS CodePipeline.\n",
    "   - Adicione uma etapa de origem vinculada ao seu repositório CodeCommit.\n",
    "   - Adicione uma etapa de compilação vinculada ao seu projeto CodeBuild.\n",
    "   - Adicione uma etapa de implantação vinculada ao seu aplicativo CodeDeploy.\n",
    "   - Configure o pipeline para ser disparado em commits de mudança no repositório ou agendado conforme desejado.\n",
    "\n",
    "5. **IAM (Identity and Access Management)**:\n",
    "   - Configure as políticas de IAM para gerenciar as permissões entre os serviços da AWS e garantir a segurança no acesso aos recursos.\n",
    "\n",
    "6. **Monitoramento e Notificações**:\n",
    "   - Use o AWS CloudWatch para monitorar os pipelines e o desempenho das aplicações.\n",
    "   - Configure o AWS SNS (Simple Notification Service) ou AWS Chatbot para receber notificações sobre o status do pipeline.\n",
    "\n",
    "### Preparação das Classes para AWS:\n",
    "\n",
    "Suas classes e funções Python precisam ser preparadas para execução na AWS. Isso geralmente inclui:\n",
    "\n",
    "- Containerização: Dockerizar suas aplicações, se aplicável, para facilitar a implantação em serviços como ECS ou EKS.\n",
    "- Serverless: Para implantação em AWS Lambda, seu código deve ser compatível com o modelo de execução do Lambda.\n",
    "- Dependências: Incluir um arquivo `requirements.txt` ou `Pipfile` para gerenciar as dependências Python.\n",
    "- Configuração: Gerenciar configurações de ambiente e segredos usando AWS Systems Manager Parameter Store ou AWS Secrets Manager.\n",
    "\n",
    "Ao seguir estas etapas, você terá um robusto pipeline de CI/CD na AWS que não depende de serviços externos como o GitHub, mantendo todo o processo dentro do ecossistema da AWS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolver visando multi-cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A utilização de múltiplos provedores de nuvem — conhecida como estratégia de nuvem múltipla ou multi-cloud — pode ser tanto simultânea quanto opcional, dependendo dos objetivos de negócio, requisitos técnicos, e estratégias de mitigação de riscos da organização. Abordarei as considerações chave que devem ser ponderadas ao tomar decisões arquiteturais para adoção de uma abordagem multi-cloud.\n",
    "\n",
    "### Simultaneidade vs. Opcionalidade:\n",
    "\n",
    "- **Simultânea**: Empregar vários provedores de nuvem ao mesmo tempo, com serviços diferentes ou similares sendo consumidos de diferentes nuvens. Isto é frequentemente feito para otimizar o desempenho, aproveitar funcionalidades únicas de cada provedor, ou para estratégias de resiliência e alta disponibilidade.\n",
    "\n",
    "- **Opcional**: A opção de usar um ou outro provedor, geralmente baseada em custo, desempenho ou mudanças na estratégia de negócios. Isto pode envolver a capacidade de migrar cargas de trabalho entre nuvens ou usar um provedor de nuvem como backup para outro.\n",
    "\n",
    "### Considerações de Arquitetura:\n",
    "\n",
    "1. **Portabilidade**:\n",
    "   - **Containers**: O uso de containers pode facilitar a portabilidade de aplicações entre nuvens.\n",
    "   - **Serviços Gerenciados**: A utilização de serviços gerenciados pode amarrar uma aplicação a um provedor específico, a menos que sejam adotadas interfaces e APIs abstratas que permitam a substituição desses serviços por equivalentes em outra nuvem.\n",
    "\n",
    "2. **Interoperabilidade**:\n",
    "   - **APIs e SDKs**: Garantir que as APIs e SDKs utilizados sejam compatíveis entre diferentes provedores de nuvem.\n",
    "   - **Protocolos de Comunicação**: Utilizar protocolos padrões de comunicação e dados para facilitar a integração entre diferentes plataformas.\n",
    "\n",
    "3. **Segurança e Conformidade**:\n",
    "   - Avaliar as diferenças nas práticas de segurança e conformidade entre os provedores de nuvem e garantir que todos os padrões necessários sejam cumpridos em cada plataforma.\n",
    "\n",
    "4. **Gerenciamento e Operações**:\n",
    "   - Implementar ferramentas de gerenciamento e orquestração que suportem ambientes multi-cloud.\n",
    "   - Definir políticas de governança e procedimentos operacionais que abrangem diferentes ambientes de nuvem.\n",
    "\n",
    "5. **Latência e Regionalidade**:\n",
    "   - Considerar a localização geográfica dos data centers dos provedores para otimizar a latência e atender a requisitos regulatórios ou de soberania de dados.\n",
    "\n",
    "6. **Custos**:\n",
    "   - Realizar uma análise detalhada dos custos associados a cada provedor, considerando não só o custo direto dos serviços, mas também a complexidade operacional e possíveis custos de saída de dados (egress fees).\n",
    "\n",
    "7. **Resiliência e Disponibilidade**:\n",
    "   - Desenhar a arquitetura para maximizar a disponibilidade, utilizando técnicas como replicação de dados e failover automático entre nuvens.\n",
    "\n",
    "8. **Estratégias de Deploy**:\n",
    "   - Definir estratégias de deploy que permitam atualizações e mudanças rápidas em um ambiente multi-cloud, tal como a infraestrutura como código.\n",
    "\n",
    "### Decisões Arquiteturais:\n",
    "\n",
    "As decisões de arquitetura em um contexto multi-cloud devem priorizar a flexibilidade, a portabilidade e a otimização de custos, sem comprometer a segurança ou a performance. Estratégias comuns incluem:\n",
    "\n",
    "- **Cloud Agnostic**: Desenvolver aplicações que sejam independentes de qualquer provedor de nuvem, geralmente usando containers e orquestração com Kubernetes, além de serviços abstratos através de camadas de adaptação.\n",
    "\n",
    "- **Best-of-Breed**: Selecionar o melhor serviço disponível para uma determinada função, independentemente do provedor, o que pode resultar em uma complexidade maior de integração e gerenciamento.\n",
    "\n",
    "- **Cloud Bursting**: Manter a maior parte da carga de trabalho em uma nuvem privada ou em um provedor de nuvem principal, expandindo para uma nuvem pública quando há picos de demanda.\n",
    "\n",
    "- **Cloud Disaster Recovery**: Utilizar um provedor de nuvem secundário para recuperação de desastres, como forma de garantir a continuidade do negócio.\n",
    "\n",
    "Em resumo, a escolha entre usar múltiplos provedores de nuvem de forma simultânea ou opcional depende de uma avaliação cuidadosa das necessidades de negócios, dos requisitos técnicos e dos riscos associados. Uma estratégia multi-cloud bem planejada e implementada pode oferecer flexibilidade, eficiência de custos e resiliência, mas requer uma abordagem consciente em relação à arquitetura de sistemas e à gestão operacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolver visando Multitenant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O desenvolvimento Multitenant, ou multilocatário, é um paradigma de arquitetura de software no qual uma única instância de uma aplicação serve a múltiplos clientes ou \"tenants\". Cada tenant tem sua própria vista segregada e segura dos dados, configurações e, em alguns casos, até personalizações específicas. Este modelo é amplamente utilizado em ambientes de nuvem e em soluções de Software como Serviço (SaaS), proporcionando uma maneira eficiente e escalável para oferecer serviços a um grande número de clientes.\n",
    "\n",
    "### Características Principais:\n",
    "\n",
    "1. **Isolamento de Dados**: Cada tenant tem seus dados isolados dos demais, o que é fundamental para garantir a privacidade e a segurança. Isso pode ser implementado em nível de aplicação ou banco de dados, seja através de esquemas de banco de dados separados, bancos de dados dedicados, ou mesmo dentro de uma mesma tabela, utilizando colunas que identificam a qual tenant cada registro pertence.\n",
    "\n",
    "2. **Customização**: Apesar da base do código ser compartilhada entre todos os tenants, a aplicação permite algum grau de personalização, como tema de interface, fluxos de trabalho específicos, extensões ou integrações com outros sistemas.\n",
    "\n",
    "3. **Eficiência de Custo e Recursos**: Por compartilhar a mesma aplicação entre vários clientes, o modelo multitenant reduz custos operacionais e de manutenção, pois as atualizações e melhorias na aplicação beneficiam todos os tenants imediatamente.\n",
    "\n",
    "4. **Elasticidade e Escalabilidade**: As aplicações multitenant são projetadas para serem naturalmente escaláveis, permitindo que recursos adicionais sejam facilmente alocados para atender a um aumento na demanda de qualquer tenant.\n",
    "\n",
    "### Desafios do Desenvolvimento Multitenant:\n",
    "\n",
    "1. **Complexidade de Design**: Projetar uma aplicação que efetivamente isole os dados e o desempenho entre tenants é mais complexo do que em modelos de tenant único, exigindo um design cuidadoso de banco de dados, autenticação e gerenciamento de sessões.\n",
    "\n",
    "2. **Segurança de Dados**: O modelo impõe a necessidade de mecanismos de segurança mais robustos para prevenir que tenants acessem dados de outros tenants.\n",
    "\n",
    "3. **Customização vs. Padronização**: Encontrar um equilíbrio entre a customização para atender às necessidades específicas de cada tenant e a padronização necessária para manter a aplicação gerenciável e eficiente.\n",
    "\n",
    "4. **Manutenção e Atualização**: As atualizações devem ser gerenciadas de tal forma que não perturbem o serviço para nenhum tenant e que todas as personalizações sejam preservadas.\n",
    "\n",
    "### Considerações Técnicas:\n",
    "\n",
    "- **Modelo de Dados**: Decidir entre esquemas separados, bancos de dados separados ou multitenancy baseado em campos.\n",
    "- **Performance**: Garantir que a performance da aplicação não seja comprometida pelo aumento do número de tenants.\n",
    "- **Isolamento Lógico vs. Físico**: Avaliar o nível de isolamento necessário e como ele será implementado tecnicamente.\n",
    "- **Autenticação e Autorização**: Assegurar que os sistemas de autenticação e autorização funcionem corretamente em um ambiente multitenant.\n",
    "\n",
    "### Implementação e Operação:\n",
    "\n",
    "- **Desenvolvimento e Teste**: Assegurar que o ambiente de desenvolvimento e os procedimentos de teste reflitam as complexidades multitenant.\n",
    "- **Monitoramento e Logging**: Implementar sistemas de monitoramento e logging que permitam rastrear a utilização e o comportamento da aplicação por tenant.\n",
    "- **Backup e Recuperação**: Desenvolver estratégias de backup e recuperação de dados que contemplem os requisitos multitenant.\n",
    "\n",
    "Em resumo, o desenvolvimento multitenant é uma abordagem poderosa para maximizar a eficiência operacional em ambientes de software como serviço, mas requer uma cuidadosa consideração de design, segurança e operações para garantir que os requisitos de todos os tenants sejam satisfeitos de forma segura e escalável."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O desenvolvimento de aplicações multitenant requer uma abordagem diferenciada em relação à arquitetura, segurança, gerenciamento de dados e configuração do ambiente para assegurar que os dados e configurações de cada tenant sejam isolados e gerenciados de forma eficiente. Aqui estão algumas considerações e mudanças que podem ser necessárias no desenvolvimento de uma aplicação multitenant, particularmente quando planejamos conteinerização e CI/CD:\n",
    "\n",
    "### Arquitetura e Design:\n",
    "\n",
    "1. **Isolamento de Dados**:\n",
    "   - É crucial projetar um esquema de banco de dados que isole os dados de cada tenant. Isso pode ser alcançado usando esquemas separados, bancos de dados separados ou através de uma abordagem de multitenancy baseada em campos, onde os dados de todos os tenants são armazenados juntos, mas são diferenciados por um identificador de tenant.\n",
    "\n",
    "2. **Configuração Dinâmica**:\n",
    "   - A aplicação deve ser capaz de alterar dinamicamente as configurações com base no tenant que está acessando o serviço. Isso geralmente é feito por meio do middleware que intercepta chamadas de serviço e ajusta o contexto da aplicação.\n",
    "\n",
    "3. **Gerenciamento de Recursos**:\n",
    "   - Assegure que os recursos de computação, armazenamento e outros serviços sejam alocados e monitorados de maneira que possam ser escalados de acordo com as necessidades de cada tenant.\n",
    "\n",
    "### Segurança:\n",
    "\n",
    "4. **Autenticação e Autorização**:\n",
    "   - Implemente uma camada robusta de autenticação e autorização que suporte o modelo multitenant. Assegure que os usuários tenham acesso apenas aos dados e funcionalidades permitidos para o seu tenant específico.\n",
    "\n",
    "5. **Controle de Acesso Baseado em Role (RBAC)**:\n",
    "   - Implemente RBAC para gerenciar o acesso a diferentes níveis de usuários dentro de um tenant.\n",
    "\n",
    "### Desenvolvimento e Testes:\n",
    "\n",
    "6. **Ambiente de Desenvolvimento**:\n",
    "   - Configure os ambientes de desenvolvimento e teste para suportar multitenancy. Isso pode incluir a criação de contêineres ou instâncias separadas para simular diferentes tenants.\n",
    "\n",
    "7. **Dados de Teste**:\n",
    "   - Garanta que os dados de teste reflitam cenários multitenant e que os testes cubram o isolamento e interação entre tenants.\n",
    "\n",
    "### CI/CD:\n",
    "\n",
    "8. **Pipelines de CI/CD**:\n",
    "   - As pipelines devem incluir passos que validem a aplicação em um ambiente multitenant. Isso pode incluir a execução de testes automatizados em ambientes que simulam vários tenants.\n",
    "\n",
    "9. **Scripts de Implantação**:\n",
    "   - Os scripts de implantação devem considerar a necessidade de configurar e implantar a aplicação de forma que ela suporte múltiplos tenants. Se estiver usando Terraform ou AWS CloudFormation, certifique-se de que os templates são desenhados para suportar multitenancy.\n",
    "\n",
    "10. **Monitoramento e Logging**:\n",
    "    - Configure o monitoramento e logging para que seja possível rastrear a atividade e os problemas para tenants específicos.\n",
    "\n",
    "### Operação:\n",
    "\n",
    "11. **Backup e Restauração**:\n",
    "    - Desenvolva estratégias de backup e restauração que considerem os dados de cada tenant separadamente, permitindo restaurações específicas quando necessário.\n",
    "\n",
    "12. **Atualizações e Manutenção**:\n",
    "    - Planeje cuidadosamente as atualizações e manutenções para minimizar o impacto nos tenants, possivelmente utilizando estratégias de implantação canário ou azul/verde para garantir que os tenants não sejam afetados negativamente.\n",
    "\n",
    "Em resumo, o desenvolvimento de uma aplicação multitenant requer uma abordagem cuidadosa em todas as fases do ciclo de vida do desenvolvimento de software. A contenção, o CI/CD e a infraestrutura na AWS devem ser configurados de maneira que suportem eficientemente as operações multitenant, garantindo ao mesmo tempo o isolamento e a segurança dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
