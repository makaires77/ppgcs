{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install groq qdrant-client\n",
    "# !pip install langchain-groq\n",
    "# !pip install langchainhub\n",
    "# !pip install langchain_community\n",
    "# !pip install gradio\n",
    "# %pip install pydantic<2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import numpy as np\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import numpy as np\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.agents import Tool\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "import gradio as gr\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Text from PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text content from a PDF file.\n",
    "\n",
    "    Args:\n",
    "    - pdf_path (str): The path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    - str: The extracted text content.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    extracted_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        extracted_text += page.extract_text()\n",
    "    return extracted_text\n",
    "\n",
    "def extract_text_from_pdfs_in_directory(directory):\n",
    "    \"\"\"\n",
    "    Extract text content from all PDF files in a directory and save as text files.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): The path to the directory containing PDF files.\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(directory, filename)\n",
    "            extracted_text = extract_text_from_pdf(pdf_path)\n",
    "            txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "            txt_filepath = os.path.join(directory, txt_filename)\n",
    "            with open(txt_filepath, \"w\") as txt_file:\n",
    "                txt_file.write(extracted_text)\n",
    "\n",
    "# Specify the directory containing PDF files\n",
    "# directory_path = \"Docs/\"\n",
    "directory_path = \"../../../../_data/in_pdf/\"\n",
    "\n",
    "# Extract text from PDFs in the directory and save as text files\n",
    "extract_text_from_pdfs_in_directory(directory_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = \"<GROQ_API_KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cnpq_tabela-areas-conhecimento.txt', 'Relatório_Autoavaliação_Produtividade Docente_V3.txt']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: List all .txt files in the directory\n",
    "directory_path = \"../../../../_data/in_pdf/\"\n",
    "txt_files = [file for file in os.listdir(directory_path) if file.endswith('.txt')]\n",
    "print(txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = {}\n",
    "for txt_file in txt_files:\n",
    "    loader = TextLoader(os.path.join(directory_path, txt_file))\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Step 2: Split documents into chunks and add metadata\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100, separator=\"\\n\")\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    for doc in docs:\n",
    "        doc.metadata[\"source\"] = txt_file  # Add source metadata\n",
    "\n",
    "    all_documents[txt_file] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TextEmbedding model\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Step 3: Initialize the TextEmbedding model\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create Qdrant vector store collections for each document\n",
    "qdrant_collections = {}\n",
    "for txt_file in txt_files:\n",
    "    qdrant_collections[txt_file] = Qdrant.from_documents(\n",
    "        all_documents[txt_file],\n",
    "        embeddings,\n",
    "        location=\":memory:\", \n",
    "        collection_name=txt_file,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt_file in txt_files:\n",
    "    print(f\"Collection: {qdrant_collections[txt_file].collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = {}\n",
    "for txt_file in txt_files:\n",
    "    retriever[txt_file] = qdrant_collections[txt_file].as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting ReAct Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age(name: str, person_database: dict) -> int:\n",
    "    \"\"\"\n",
    "    Get the age of a person from the database.\n",
    "\n",
    "    Args:\n",
    "    - name (str): The name of the person.\n",
    "    - person_database (dict): A dictionary containing person information.\n",
    "\n",
    "    Returns:\n",
    "    - int: The age of the person if found, otherwise None.\n",
    "    \"\"\"\n",
    "    if name in person_database:\n",
    "        return person_database[name][\"Age\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_age_info(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Get age and health information for a person.\n",
    "\n",
    "    Args:\n",
    "    - name (str): The name of the person.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string containing age and health information for the person.\n",
    "    \"\"\"\n",
    "    person_database = {\n",
    "        \"Sam\": {\"Age\": 21, \"Nationality\": \"US\"},\n",
    "        \"Alice\": {\"Age\": 25, \"Nationality\": \"UK\"},\n",
    "        \"Bob\": {\"Age\": 11, \"Nationality\": \"US\"}\n",
    "    }\n",
    "    age = get_age(name, person_database)\n",
    "    if age is not None:\n",
    "        return f\"\\nAge: {age}\\n\"\n",
    "    else:\n",
    "        return f\"\\nAge Information for {name} not found.\\n\"\n",
    "    \n",
    "\n",
    "\n",
    "def get_today_date(input : str) -> str:\n",
    "    import datetime\n",
    "    today = datetime.date.today()\n",
    "    return f\"\\n {today} \\n\"\n",
    "\n",
    "\n",
    "\n",
    "def get_relevant_document(name : str) -> str:\n",
    "    # String name for fuzzy search\n",
    "    search_name = name\n",
    "\n",
    "    # Find the best match using fuzzy search\n",
    "    best_match = process.extractOne(search_name, txt_files, scorer=fuzz.ratio)\n",
    "\n",
    "    # Get the selected file name\n",
    "    selected_file = best_match[0]\n",
    "    \n",
    "    selected_retriever = retriever[selected_file]\n",
    "\n",
    "    global query\n",
    "    results = selected_retriever.get_relevant_documents(query)\n",
    "    global retrieved_text\n",
    "    \n",
    "    total_content = \"\\n\\nBelow are the related document's content: \\n\\n\"\n",
    "    chunk_count = 0\n",
    "    for result in results:\n",
    "        chunk_count += 1\n",
    "        if chunk_count > 4:\n",
    "            break\n",
    "        total_content += result.page_content + \"\\n\"\n",
    "    retrieved_text = total_content\n",
    "    return total_content\n",
    "\n",
    "\n",
    "def get_summarized_text(name : str) -> str:\n",
    "    from transformers import pipeline\n",
    "    summarizer = pipeline(\"summarization\", model=\"Falconsai/text_summarization\")\n",
    "    global retrieved_text\n",
    "    article = retrieved_text\n",
    "    return summarizer(article, max_length=1000, min_length=30, do_sample=False)[0]['summary_text']\n",
    "\n",
    "\n",
    "# Define the Tool\n",
    "get_age_info_tool = Tool(\n",
    "    name=\"Get Age\",\n",
    "    func=get_age_info,\n",
    "    description=\"Useful for getting age information for any person. Input should be the name of the person.\"\n",
    ")\n",
    "\n",
    "get_today_date_tool = Tool(\n",
    "    name=\"Get Todays Date\",\n",
    "    func=get_today_date,\n",
    "    description=\"Useful for getting today's date\"\n",
    ")\n",
    "\n",
    "get_relevant_document_tool = Tool(\n",
    "    name=\"Get Relevant document\",\n",
    "    func=get_relevant_document,\n",
    "    description=\"Useful for getting relevant document that we need.\"\n",
    ")\n",
    "\n",
    "get_summarized_text_tool = Tool(\n",
    "    name=\"Get Summarized Text\",\n",
    "    func=get_summarized_text,\n",
    "    description=\"Useful for getting summarized text for any document.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Agent prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_react = hub.pull(\"hwchase17/react\")\n",
    "print(prompt_react.template) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the ReAct agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_text = \"\"\n",
    "tools = [get_relevant_document_tool, get_summarized_text_tool, get_today_date_tool, get_age_info_tool]\n",
    "\n",
    "model = ChatGroq(model_name=\"llama3-70b-8192\", groq_api_key=GROQ_API_KEY, temperature=0)\n",
    "# model = OpenAI(openai_api_key=\"<YOUR_OPENAI>\")\n",
    "\n",
    "react_agent = create_react_agent(model, tools=tools, prompt=prompt_react)\n",
    "react_agent_executor = AgentExecutor(\n",
    "    agent=react_agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Give me the summary for the question : What age requirement is specified for using the OpenAI Services, and what provision applies if the user is under 18?\"\n",
    "react_agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Give me summary of What resources does Google offer to users for assistance and guidance in using its services?\"\n",
    "react_agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are my rights to my data on Facebook?\"\n",
    "react_agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I am Bob. Will i be eligible in 2027 for the age requirement specified for using the OpenAI Services by OpenAI Terms?\"\n",
    "react_agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from io import StringIO\n",
    "import sys\n",
    "import re\n",
    "\n",
    "def generate_response(question):\n",
    "    \"\"\"\n",
    "    Generate a response based on the provided question using ChatGroq.\n",
    "\n",
    "    Args:\n",
    "    - question (str): The question input by the user.\n",
    "\n",
    "    Returns:\n",
    "    - str: The generated response based on the question.\n",
    "    \"\"\"\n",
    "    tools = [get_relevant_document_tool, get_summarized_text_tool, get_today_date_tool, get_age_info_tool]\n",
    "\n",
    "    model = ChatGroq(model_name=\"llama3-70b-8192\", groq_api_key=GROQ_API_KEY, temperature=0)\n",
    "    # model = OpenAI(openai_api_key=\"<YOUR_OPENAI>\")\n",
    "\n",
    "    react_agent = create_react_agent(model, tools=tools, prompt=prompt_react)\n",
    "    react_agent_executor = AgentExecutor(\n",
    "        agent=react_agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
    "    )\n",
    "    \n",
    "    # Redirect stdout to capture text\n",
    "    with StringIO() as text_output:\n",
    "        sys.stdout = text_output\n",
    "        completion = react_agent_executor.invoke({\"input\": question})\n",
    "        sys.stdout = sys.__stdout__  # Reset stdout\n",
    "        \n",
    "        # Get the captured text\n",
    "        text_output_str = text_output.getvalue()\n",
    "    \n",
    "    # Remove ANSI escape codes\n",
    "    text_output_str = re.sub(r'\\x1b\\[[0-9;]*m', '', text_output_str)\n",
    "\n",
    "    return text_output_str\n",
    "\n",
    "# Set up the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=generate_response,\n",
    "    inputs=[gr.Textbox(label=\"Question\")],  # Pass input as a list\n",
    "    outputs=[gr.Textbox(label=\"Generated Response\")],  # Pass output as a list\n",
    "    title=\"Intellegent RAG with Qdrant, LangChain ReAct and Llama3 from Groq Endpoint\",\n",
    "    description=\"Enter a question and get a generated response based on the retrieved text.\",\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
