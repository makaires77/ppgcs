{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "video_url = \"https://developer.download.nvidia.com/video/HPC/HPC-SDK_KV_1145x220_v005.mp4\"\n",
    "# Criar a tag de vídeo HTML com o atributo loop\n",
    "video_tag = f'<video width=\"100%\" controls loop> <source src=\"{video_url}\" type=\"video/mp4\"> </video>'\n",
    "HTML(video_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Contexto e definição do fluxo da pesquisa</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filosofia e ciência da economia baseada em inovação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grandes filósofos durante toda história tem se oposto ao totalitarismo. Pelo menos a partir da visão Aristotélica as formas degeneradas de governar já são apontadas. Dentre as chamadas formas degeneradas, a tirania pode ser entendida como a pior forma de sistema político, sendo o resultado da maior degeneração do poder centralizado em uma única pessoa (como em uma monarquia absolutista). Na tirania o tirano governa sem consultar a ninguém e, geralmente, sua tomada de poder é ilegítima, e a lei não tem papel algum. Na oligarquia, onde o poder de decisão do governo é constituído por um pequeno número de privilegiados, há uma subclassificação quanto ao número dos donos do poder, como por exemplo, na Politirania onde os oligarcas governam hereditariamente e na riqueza, mas respeitando mais a lei. Ou nas oligarquias com uma maior percentagem de oligarcas, quando passa-se da hereditariedade à nomeação dos amigos do governo, independentemente da linhagem sanguínea destes, dentre outros tipos de oligarquia. \n",
    "\n",
    "Tomas de Aquino foi um filósofo de referência no papel da moral como orientação maior para a sociedade. Mais recentemente, Karl Popper foi um severo crítico ao totalitarismo e utopias demagógicas. São perceptíveis interseções e diálogos filosóficos entre as ideias centrais dessas filosofias, especialmente em epistemologia e ética, têm sido tema de discussão acadêmica. Por exemplo, na dissertação de David Gregory Broderick, intitulada \"Objetividade: Tomás de Aquino e Karl Popper\", explora-se a relação entre as noções de objetividade nas obras de Aquino e Popper. A dissertação sugere que, embora haja diferenças terminológicas, históricas e de interesses entre Aquino e Popper, também existem paralelos significativos em suas abordagens sobre objetividade e o crescimento do conhecimento. Além disso, na discussão sobre as raízes éticas da epistemologia de Popper, explorada pelo Grupo Ciencia, Razón y Fe (CRYF) da Universidad de Navarra, destaca-se a complementaridade das posições de Aquino e Popper. Esta análise sugere que a forte defesa de Popper do realismo, da verdade objetiva e da metodologia para o crescimento do conhecimento conjectural pode ser vista como complementar, ou até mesmo fundamentada, nos princípios éticos e metafísicos delineados por Aquino.\n",
    "\n",
    "Entendemos portanto, que embora Popper possa não ter citado explicitamente Aquino em suas principais obras, as bases filosóficas de seus pensamentos, especialmente em relação à objetividade, ética e crescimento do conhecimento, têm grandes paralelos e áreas de convergência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, tal como acontece com a sua defesa das eleições numa democracia, o argumento de Popper a favor da engenharia social fragmentada baseia-se principalmente na sua compatibilidade com o método de tentativa e erro das ciências naturais: uma teoria é proposta e testada, erros na teoria são detectados e eliminado, e uma teoria nova e melhorada emerge, reiniciando o ciclo. Através da engenharia gradual, o processo de progresso social é, portanto, paralelo ao progresso científico. Na verdade, Popper diz que a engenharia social fragmentada é a única abordagem à política pública que pode ser genuinamente científica: \"Isto - e nenhum planeamento utópico ou profecia histórica - significaria a introdução do método científico na política, uma vez que todo o segredo do método científico é uma disposição para aprender com os erros\" ( Open Society Vol 1., 163)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papel da Inovação Tecnológica nas economias modernas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O termo \"inovação tecnológica\", no sentido moderno, começou a ser mais amplamente discutido e compreendido no início do século XX. Joseph Schumpeter, um economista austríaco, foi uma das figuras-chave que destacou a inovação tecnológica como um motor para o crescimento econômico. Após a Primeira Guerra Mundial, pensadores como Thorstein Veblen e Herbert Hoover também enfatizaram a importância da inovação tecnológica para a segurança nacional e competitividade industrial. Esse conceito se expandiu particularmente após a Segunda Guerra Mundial, quando a inovação tecnológica começou a ser vista como crucial para a prosperidade industrial e a segurança militar, especialmente nos Estados Unidos. \n",
    "\n",
    "fonte: Encyclopedia.com sobre Inovação Tecnológica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abordagem falseável em Metodologia da Pesquisa Científica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma contribuição seminal para abordagem falseável da ciência é a descrita por Karl Popper em sua obra \"A Lógica da Pesquisa Científica\", publicada originalmente em 1934. É nesta obra que Popper argumenta que a ciência deve adotar uma metodologia baseada na falseabilidade. Segundo ele, nenhuma quantidade de experimentos pode provar uma teoria, mas um único experimento ou observação reproduzível pode refutá-la. Esta abordagem destaca a importância da capacidade de uma teoria ser testada e potencialmente falsificada, em vez de apenas verificada. Popper diferencia as teorias científicas das pseudociências e da metafísica, salientando que as teorias científicas devem ser testáveis e passíveis de refutação, enquanto pseudociências e metafísicas não permitem essa possibilidade. Popper enfatiza que a ciência deve estar em constante evolução, com as hipóteses sendo submetidas a testes contínuos para acompanhar o desenvolvimento da ciência e das tecnologias (POPPER, 1934)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estruturar etapas da pesquisa para a tese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 01: Redigir uma boa questão de pesquisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como chegar à uma boa questão de pesquisa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gênese de uma boa questão de pesquisa também é abordada por outros autores notáveis no campo da metodologia científica. Antonio Carlos Gil descreve que a elaboração de projetos de pesquisa deve ser guiada pela apresentação clara e acessível dos elementos necessários para a pesquisa, além da organização de conhecimentos dispersos. Gil enfatiza a natureza prática da pesquisa, abordando a importância de esclarecer os procedimentos para a elaboração de projetos em diversos tipos de pesquisa. (GIL, 2022).\n",
    "\n",
    "Alguns dos critérios essenciais para avaliar a qualidade de uma questão de pesquisa, e como integrar ou considerar cada um deles no processo de formulação:\n",
    "\n",
    "<b>Clareza e Especificidade</b>: Uma boa questão de pesquisa deve ser clara e específica, evitando ambiguidades. Isto pode ser parcialmente garantido pelo processamento de linguagem natural, mas também requer revisão humana para garantir que a questão seja compreensível e precisamente focada.\n",
    "\n",
    "<b>Relevância Acadêmica ou Científica</b>: A questão deve ser relevante para o campo de estudo e contribuir de alguma forma para o conhecimento existente. Isso geralmente requer uma compreensão do contexto acadêmico e das pesquisas atuais, o que pode ser além do escopo da automação completa.\n",
    "\n",
    "<b>Viabilidade</b>: A pergunta deve ser algo que pode ser realisticamente respondido através de métodos de pesquisa disponíveis. Este aspecto pode ser parcialmente verificado por meio de regras heurísticas programadas, mas frequentemente requer avaliação humana, especialmente para julgar a disponibilidade de dados ou recursos de pesquisa.\n",
    "\n",
    "<b>Originalidade</b>: Uma boa questão de pesquisa deve oferecer novas perspectivas ou abordar lacunas existentes na literatura. A originalidade pode ser difícil de avaliar automaticamente, mas técnicas avançadas de NLP, como análise semântica e comparação com bancos de dados de literatura existente, podem ajudar.\n",
    "\n",
    "<b>Importância Prática ou Teórica</b>: A questão deve ter alguma importância prática ou contribuir para a compreensão teórica de um tópico. Isso geralmente exige conhecimento especializado na área de estudo para avaliar.\n",
    "\n",
    "<b>Estruturação Adequada</b>: A pergunta deve ser estruturada de forma a facilitar uma abordagem de pesquisa clara. Isso inclui a utilização de uma formulação que se alinhe com métodos de pesquisa qualitativos ou quantitativos, conforme apropriado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como Integrar critérios de validação para responder a questão de pesquisa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerar uma boa questão de pesquisa depende de uma combinação de processamento automatizado, conhecimento especializado e revisão humana. A automação pode fornecer uma base útil, mas a supervisão e o julgamento humanos são cruciais para garantir a qualidade final da pergunta de pesquisa. As seguintes estratégias são utilizadas em nossa solução para chegar a uma boa questão de pesquisa:\n",
    "\n",
    "\n",
    "<b>Integração de várias Fontes de Dados de Literatura</b>: Integrar um banco de dados de literatura existente pode ajudar a avaliar a originalidade e a relevância da pergunta, comparando-a com pesquisas já publicadas.\n",
    "\n",
    "<b>Automatização com Revisão Humana</b>: Uma abordagem prática é usar a automação para gerar uma primeira versão da pergunta, que é então revisada e refinada por pesquisadores humanos (pesquisador principal, equipe de pesquisa e orientador). A automação garante que certos critérios básicos sejam atendidos (como clareza e estruturação), enquanto a revisão humana aborda aspectos mais sutis, como relevância, viabilidade e originalidade.\n",
    "\n",
    "<b>Instrução ao Usuário</b>: Fornecer orientações e exemplos de boas perguntas de pesquisa aos usuários pode ajudá-los a formular ideias iniciais mais eficazes, levando a melhores resultados na formulação automática.\n",
    "\n",
    "<b>Feedback Interativo</b>: Incorporar um sistema de feedback no processo, onde o usuário pode refinar suas ideias iniciais ou ajustar a pergunta gerada, pode ajudar a melhorar a qualidade da questão de pesquisa final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 02: Encontrar fontes de dados adequadas para realizar a pesquisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Editoras científicas com políticas de Open Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Várias editoras científicas proeminentes oferecem conteúdos em Open Access, proporcionando acesso livre a uma vasta gama de pesquisas acadêmicas. Algumas das principais editoras incluem:\n",
    "\n",
    "<b>Public Library of Science (PLOS)</b>: Fundada como uma organização sem fins lucrativos, a PLOS tem como objetivo catalisar o movimento de acesso aberto. Publica periódicos em diversas áreas, incluindo medicina e ciências da vida.\n",
    "\n",
    "<b>Springer Nature</b>: Com mais de 600 periódicos totalmente em acesso aberto e mais de 1000 livros em acesso aberto, a Springer Nature é uma das pioneiras no campo da pesquisa aberta. Oferece uma variedade de opções de publicação em acesso aberto, mantendo rigorosos processos de revisão por pares e editoriais.\n",
    "\n",
    "<b>Wiley</b>: A Wiley oferece mais de 150 periódicos revisados por pares em acesso aberto, abrangendo diversas disciplinas de pesquisa. Seus periódicos em acesso aberto estão disponíveis para leitura, download e compartilhamento gratuitamente através da Wiley Online Library e do PubMed Central.\n",
    "\n",
    "<b>Oxford University Press (OUP)</b>: A OUP publica mais de 120 periódicos totalmente em acesso aberto e mais de 250 livros em acesso aberto, abrangendo uma ampla gama de disciplinas. Muitos de seus periódicos são classificados como \"diamond OA\", o que significa que não há taxas de processamento de artigos para autores ou leitores.\n",
    "\n",
    "<b>Frontiers</b>: Reconhecida como uma editora líder em Acesso Aberto e plataforma de Ciência Aberta, a Frontiers é muito citada, com mais de um bilhão de visualizações e downloads e 1.6 milhão de citações em seus artigos acessíveis gratuitamente. Ela é ativa em áreas como neurociências, psiquiatria, fisiologia, medicina clínica, ciências naturais e engenharia.\n",
    "\n",
    "<b>MDPI AG</b>: Uma empresa suíça com presença global, a MDPI AG publica periódicos em ciência e engenharia, ciências sociais e filosofia.\n",
    "\n",
    "<b>Informa PLC</b>: Uma das maiores editoras nas humanidades e ciências sociais, a Informa publica em acesso aberto sob quatro selos: Taylor & Francis Open, Dove Medical Press, Cogent OA e Routledge Open.\n",
    "\n",
    "<b>Hindawi</b>: Inicialmente uma editora de periódicos por assinatura, a Hindawi fez a transição para um modelo de publicação em acesso aberto entre 2004 e 2007. Ela publica periódicos em ciência e engenharia, ciências sociais e filosofia.\n",
    "\n",
    "Estas editoras são conhecidas não apenas pela qualidade e diversidade de suas publicações, mas também por suas contribuições significativas para o movimento de acesso aberto na comunidade acadêmica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bases de dados digitais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao focar a pesquisa em fontes que oferecem conteúdos completos em Open Access, há bases de dados e repositórios acadêmicos importantes que se destacam em relevância e quantidade de conteúdos:\n",
    "\n",
    "<b>Directory of Open Access Journals (DOAJ)</b>: O DOAJ é um diretório online que indexa e fornece acesso a periódicos de alta qualidade, todos de acesso livre e revisados por pares. É uma excelente fonte para pesquisar artigos em uma ampla gama de disciplinas. O DOAJ oferece uma API para acessar seu índice de periódicos e artigos. A documentação e detalhes sobre a API estão disponíveis em DOAJ API.\n",
    "\n",
    "<b>PubMed Central</b>: Operado pela Biblioteca Nacional de Medicina dos EUA, o PubMed Central é um repositório gratuito de artigos de ciências biomédicas e ciências da vida. Embora seu foco seja mais na área da saúde, ele pode ter artigos relevantes sobre inovação tecnológica no contexto da saúde. A PubMed Central oferece uma API chamada Entrez Programming Utilities (E-utilities) para interagir com a base de dados. Mais informações podem ser encontradas em Entrez Programming Utilities Help.\n",
    "\n",
    "<b>arXiv</b>: O arXiv é um repositório de preprints em campos como física, matemática, ciência da computação, biologia quantitativa, finanças quantitativas e estatística. É uma boa fonte para literatura mais técnica e teórica sobre inovação tecnológica. O arXiv fornece uma API para acesso aos seus preprints. Informações detalhadas e documentação sobre a API estão disponíveis em arXiv API.\n",
    "\n",
    "<b>OpenAIRE</b>: Uma infraestrutura que promove a descoberta e o acesso a publicações científicas europeias de acesso livre. É especialmente útil para pesquisas que envolvem colaborações europeias ou focam em políticas e práticas de inovação na Europa. OpenAIRE oferece uma API para acessar seu repositório. Você pode encontrar mais informações sobre como usar esta API em OpenAIRE API.\n",
    "\n",
    "<b>Google Scholar</b>: Apesar de não ser exclusivamente dedicado ao Open Access, o Google Scholar pode ser utilizado para localizar artigos de acesso livre. Ele indexa uma variedade de fontes acadêmicas e muitas vezes inclui links para versões de acesso livre dos artigos. O Google Scholar não oferece uma API oficial para acesso programático.\n",
    "\n",
    "<b>CORE</b>: Agregador que permite o acesso a milhões de artigos de acesso livre. Ele reúne conteúdo de repositórios e periódicos de todo o mundo, sendo uma excelente ferramenta para uma pesquisa abrangente. CORE oferece uma API que permite acessar seu vasto repositório de artigos de acesso livre. A documentação da API pode ser encontrada em CORE API.\n",
    "\n",
    "<b>ScienceOpen</b>: Plataforma de pesquisa e publicação que oferece acesso a mais de 60 milhões de artigos e registros de pesquisa em todas as áreas. Não há informações disponíveis sobre uma API pública para o ScienceOpen.\n",
    "\n",
    "<b>SSRN (Social Science Research Network)</b>: Especializado em ciências sociais, o SSRN é um repositório de preprints que abrange uma ampla gama de áreas, incluindo economia, direito e gestão corporativa, onde você pode encontrar trabalhos relacionados à gestão da inovação. O SSRN não fornece uma API pública para acesso programático aos seus conteúdos.\n",
    "\n",
    "\n",
    "O tipo de busca mais comum é por palavras-chave, usadas para descobrir e para refinar a pesquisa e localizar artigos relevantes sobre os temas de interesse, no nosso caso, a gestão da inovação tecnológica em organizações públicas e privadas. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 03: Modelar o problema de pesquisa em grafo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagrama estratégias para modelar o mundo real em grafos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` mermaid\n",
    "  mindmap\n",
    "  root((Modelagem do Mundo Real em Grafos para Aplicações em Saúde))\n",
    "    Grafos Simples\n",
    "      Aplicações\n",
    "        Interações Medicamento-Medicamento (Efeitos Adversos)\n",
    "        Co-ocorrência de Doenças (Comorbidades)\n",
    "      Limitações\n",
    "        Não modela a direção ou força das relações\n",
    "    Grafos Direcionados\n",
    "      Aplicações\n",
    "        Propagação de Doenças Infecciosas (Transmissão)\n",
    "        Vias Metabólicas (Reações Bioquímicas)\n",
    "      Limitações\n",
    "        Não modela múltiplas relações entre os mesmos elementos\n",
    "    Grafos Ponderados\n",
    "      Aplicações\n",
    "        Redes de Interação Proteína-Proteína (Afinidade de Ligação)\n",
    "        Redes de Coexpressão Gênica (Correlação)\n",
    "      Limitações\n",
    "        Não modela diferentes tipos de relações simultaneamente\n",
    "    Grafos Multicamadas (Multiplex)\n",
    "      Aplicações\n",
    "        Redes de Interação Fármaco-Alvo-Doença (Múltiplos Mecanismos)\n",
    "        Redes de Microbioma Humano (Diferentes Nichos Tecnológicos)\n",
    "      Limitações\n",
    "        Aumenta a complexidade da análise\n",
    "    Hipergrafos\n",
    "      Aplicações\n",
    "        Análise de Dados de Saúde Multimodais (Prontuários, Imagens, Genética)\n",
    "        Modelagem de Fatores de Risco Complexos para Doenças Multifatoriais\n",
    "      Limitações\n",
    "        Dificuldade de visualização e análise\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagrama desafio de promover inovação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` mermaid\n",
    "mindmap\n",
    "  root((Inovação, Competitividade e Novo Padrão Tecnológico da Indústria Brasileira))\n",
    "    (Conclusões)\n",
    "      Baixa intensidade de PDI como desafio para a competitividade\n",
    "      Necessidade de investimentos em PDI para aumentar a produtividade\n",
    "      Importância de políticas públicas de incentivo à inovação\n",
    "\n",
    "      (Implicações)\n",
    "          Foco em setores estratégicos com potencial de crescimento e inovação\n",
    "          Aumento do investimento em PDI\n",
    "          Políticas públicas que incentivem a inovação\n",
    "\n",
    "          (Recomendações)\n",
    "              Aumento do investimento público e privado em PDI\n",
    "              Incentivos fiscais para empresas que investem em inovação\n",
    "              Fortalecimento da cooperação entre universidades e empresas\n",
    "              Investimento em educação e formação de mão de obra qualificada\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "[![](https://mermaid.ink/img/pako:eNp9VM2O0zAQfpVRDqiVygvkxrJC6oFVBRxzmdqT7ojYk_VPBVrtuyA4IA6cEJe95sUYN_2L2iWKFHsy-f7s-LEyYqmqK8feOuwbDxBE0my29LLF4efwQxbwVlxPiRNv2aIlILiTrcAKbdD38ImMl274s2EjYBGW3g7PMQVGuAkYuSMOOJ8XbFAsb7och78UxwJAXeuHftYitPh6LfJ5fngDcIP8BYF9Ih9Hcr1Xr25VAx8VghGnzBSxZYEeAwKW2rnoE-QdGYonMPZbiokd-SQRyF2ij4C5dGBQ5D6IzZe4S9dLSMN3b9S4Aveaye_EBiP0w_O62412hEaRWAMcvp3RNH4CVdq1fhbTeL0TDVlVRkoSSAVr0JiGXyX8WEwrr4alGrpCZrTHjOYmpqagb_LYYWUSx7U0ph-urnl8yCeTioAvmCzXB1LF5O1Vq_9TtmcrpvrAW7QHsZcQy0PeEVqOBjmOK0qu13COegu4Quj9ktkx_pCwo0Oktuwz6Snst4oWA0H2ajyMW0xX6Mh0Tds0bbLZHKCgleD2E11Jt3_KWrU_ZOy41bQtNr5aVI60la3-yI-FpKnSPTlqqlqHllrMXWqqxj9pK-YkH796U9UpZFpUQfLmvqpb7KLOcm8x0S3jJqA7Vsmy7rb341GxOzGe_gFTjYIM?type=png)](https://mermaid.live/edit#pako:eNp9VM2O0zAQfpVRDqiVygvkxrJC6oFVBRxzmdqT7ojYk_VPBVrtuyA4IA6cEJe95sUYN_2L2iWKFHsy-f7s-LEyYqmqK8feOuwbDxBE0my29LLF4efwQxbwVlxPiRNv2aIlILiTrcAKbdD38ImMl274s2EjYBGW3g7PMQVGuAkYuSMOOJ8XbFAsb7och78UxwJAXeuHftYitPh6LfJ5fngDcIP8BYF9Ih9Hcr1Xr25VAx8VghGnzBSxZYEeAwKW2rnoE-QdGYonMPZbiokd-SQRyF2ij4C5dGBQ5D6IzZe4S9dLSMN3b9S4Aveaye_EBiP0w_O62412hEaRWAMcvp3RNH4CVdq1fhbTeL0TDVlVRkoSSAVr0JiGXyX8WEwrr4alGrpCZrTHjOYmpqagb_LYYWUSx7U0ph-urnl8yCeTioAvmCzXB1LF5O1Vq_9TtmcrpvrAW7QHsZcQy0PeEVqOBjmOK0qu13COegu4Quj9ktkx_pCwo0Oktuwz6Snst4oWA0H2ajyMW0xX6Mh0Tds0bbLZHKCgleD2E11Jt3_KWrU_ZOy41bQtNr5aVI60la3-yI-FpKnSPTlqqlqHllrMXWqqxj9pK-YkH796U9UpZFpUQfLmvqpb7KLOcm8x0S3jJqA7Vsmy7rb341GxOzGe_gFTjYIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagrama de blocos das fases da implementação do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` mermaid\n",
    "graph LR\n",
    "    subgraph Entrar e Pré-processar Dados\n",
    "        A[Currículos Pesquisadores\\nda ICT]\n",
    "        B[Entidades do\\nCEIS]\n",
    "        C[Produtos Estratégicos\\nCEIS]\n",
    "        D[Normalizar,\\nLimpar e\\nUnificar Termos]\n",
    "    end\n",
    "\n",
    "    subgraph Gerar Embeddings em GPU\n",
    "        H[Embedding Multilingue\\n Sentence Transformers]\n",
    "        I[Codificar\\nCompetências]\n",
    "        J[Codificar\\nÁreas de Pesquisa]\n",
    "    end\n",
    "\n",
    "    subgraph Construir e Analisar Grafos em GPU/CPU\n",
    "        K[Adicionar\\nNós e Arestas]\n",
    "        L[Grafo Multiplex\\nMacroprocessos PDI]\n",
    "    end\n",
    "\n",
    "    subgraph Modelo de Aprendizagem\\nNão-Supervisionada em Grafos    \n",
    "        M[Detectar\\nComunidades]\n",
    "        N[Analisar\\nSimilaridade]\n",
    "        O[Identificar Lacunas\\nao maximizar \\nModularidade]\n",
    "    end\n",
    "\n",
    "    subgraph Recomendar e Visualizar\n",
    "        P[Recomendar\\nAlinhamento\\nCompetências/Produtos]\n",
    "        Q[Visualizar\\nResultados]\n",
    "    end\n",
    "\n",
    "    A --> D\n",
    "    B --> D\n",
    "    C --> D\n",
    "    D --> H\n",
    "    H --> I\n",
    "    H --> J\n",
    "    I --> K\n",
    "    J --> K\n",
    "    N <--> M\n",
    "    L --> M\n",
    "    L --> N    \n",
    "    M --> O\n",
    "    N --> O\n",
    "    K --> L\n",
    "    O --> P\n",
    "    P --> Q\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagrama de componentes do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` mermaid\n",
    "flowchart LR\n",
    "    id1((Circle))\n",
    "    id2([Stadium])\n",
    "    id3[(Database)]\n",
    "    id4(Box with round corner)\n",
    "    id5{{Hex}}\n",
    "    id6[\\Parallelogram\\]\n",
    "    id7[\\Trapezoid/]\n",
    "\n",
    "    id1-- 1st line ---id2\n",
    "    id1--> |2nd line| id3\n",
    "    id1--- |3rd line| id4\n",
    "    id2-.-|4th line| id5\n",
    "    id3 == 5th line ==> id6\n",
    "    id4 <--> id7 --> id6\n",
    "\n",
    "    style id1 fill:green,stroke:black\n",
    "    style id2 fill:white,stroke:#f66,stroke-dasharray: 5, 5,color:black\n",
    "    style id3 fill:#66f,stroke:#f6f,stroke-width:4px\n",
    "    style id4 fill:red,stroke:yellow\n",
    "    style id5 fill:orange,stroke:white,color:black\n",
    "    style id6 fill:yellow,stroke:blue,color:black\n",
    "    style id7 fill:brown,stroke:blue\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quadrant diagram with dots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` mermaid\n",
    "quadrantChart\n",
    "    x-axis x1 --> x2\n",
    "    y-axis y1 --> y2\n",
    "    quadrant-1 Comenta\n",
    "    quadrant-2 Gosta\n",
    "    quadrant-3 Inscreve\n",
    "    quadrant-4 Compartilha\n",
    "    p1: [0.3, 0.7]\n",
    "    p2: [0.6, 0.2]\n",
    "    p3: [0.8, 0.9]\n",
    "    p4: [0.2, 0.4]\n",
    "    p5: [0.6, 0.7]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIMPAR CONDA PARA LIBERAR ESPAÇO EM DISCO, APAGAR AMBIENTES INATIVOS, USAR COM CUIDADO!\n",
    "# import subprocess\n",
    "\n",
    "# # Executa o comando e captura a saída\n",
    "# process = subprocess.Popen(['conda', 'clean', '--all'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "# # Lê a saída e verifica se há uma linha indicando arquivos a serem removidos\n",
    "# for line in process.stdout:\n",
    "#     print(line, end='')  # Imprime a saída na célula do notebook\n",
    "#     if 'tarball(s)' in line:  # Procura pela linha com a informação dos arquivos\n",
    "#         # Solicita a confirmação do usuário\n",
    "#         confirmacao = input(\"Deseja prosseguir com a limpeza? (s/n): \")\n",
    "#         if confirmacao.lower() == 's':\n",
    "#             process.stdin.write('y\\n')  # Envia 'y' para confirmar\n",
    "#         else:\n",
    "#             process.stdin.write('n\\n')  # Envia 'n' para cancelar\n",
    "#         process.stdin.flush()\n",
    "\n",
    "# # Aguarda o término do processo e imprime o resultado\n",
    "# stdout, stderr = process.communicate()\n",
    "# print(stdout)\n",
    "# print(stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principais operações utilizadas no modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operações de Matrizes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiplicação de Matrizes:** A operação mais comum em modelos de transformadores (como os utilizados pelo Sentence Transformers) é a multiplicação de matrizes, usada para calcular as atenções e as transformações lineares nas camadas do modelo.\n",
    "\n",
    "**Soma de Matrizes:** Soma de matrizes é utilizada para combinar os resultados de diferentes camadas ou para adicionar informações contextuais aos embeddings.\n",
    "\n",
    "**Normalização:** A normalização de vetores (por exemplo, Layer Normalization) é utilizada para estabilizar o treinamento e melhorar o desempenho do modelo.\n",
    "Outras Operações: Outras operações de matrizes, como transposição, concatenação e divisão por elemento, também podem ser utilizadas em diferentes etapas da conversão de embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de Ativação:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ReLU, GELU, etc.:** Funções de ativação não lineares são aplicadas aos resultados das operações de matrizes para introduzir não linearidade no modelo e permitir que ele aprenda padrões mais complexos nos dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operações Específicas do Modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax:** Utilizado para calcular as probabilidades de atenção em modelos de transformadores.\n",
    "\n",
    "**Embedding Lookup:** Utilizado para converter tokens de texto em embeddings de palavras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Princípios para otimizar cálculo em GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerações sobre o Hardware CPU x GPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPU:** A maioria das operações mencionadas acima é altamente paralelizável e pode ser acelerada significativamente por GPUs, que são projetadas para realizar cálculos de matrizes de forma eficiente.\n",
    "\n",
    "**CPU:** As CPUs podem ser usadas para realizar essas operações, mas geralmente são mais lentas do que as GPUs, especialmente para grandes volumes de dados ou modelos complexos.\n",
    "\n",
    "Portanto, a conversão de embeddings é um processo computacionalmente intensivo, onde a GPU pode acelerar significativamente esse processo, especialmente para grandes modelos e volumes de dados devido principalmente a necessidade de **operações de matrizes** e **funções de ativação**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquiteturas das Placas Nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tesla**:        Não possuem Tensor Cores. O número de núcleos CUDA por SM varia entre as diferentes gerações da arquitetura Tesla.\n",
    "\n",
    "**Pascal**:       Não possuem Tensor Cores. Cada SM possui 128 núcleos CUDA.\n",
    "\n",
    "**Volta**:        Introduziu os Tensor Cores. Cada SM possui 64 núcleos CUDA e 8 Tensor Cores.\n",
    "\n",
    "**Turing**:       Cada SM possui 64 núcleos CUDA e 8 Tensor Cores. Introduziu os RT Cores para acelerar o ray tracing.\n",
    "\n",
    "**Ampere**:       Cada SM possui 128 núcleos CUDA e 4 Tensor Cores de terceira geração. Os Tensor Cores de terceira geração são duas vezes mais rápidos que os da geração anterior.\n",
    "\n",
    "**Ada Lovelace**: Cada SM possui 128 núcleos CUDA e 4 Tensor Cores de quarta geração. Os Tensor Cores de quarta geração são ainda mais rápidos e eficientes que os da geração anterior.\n",
    "\n",
    "**Hopper**:       Cada SM possui 128 núcleos CUDA e 8 Tensor Cores de quarta geração. Introduziu o Transformer Engine, um novo tipo de núcleo especializado em acelerar modelos de linguagem baseados em Transformer.\n",
    "\n",
    "**Blackwell**:    (arquitetura futura): Ainda não há informações oficiais sobre a arquitetura Blackwell, mas espera-se que ela continue a tendência de aumentar o número de núcleos CUDA e Tensor Cores por SM, além de introduzir novas tecnologias para acelerar ainda mais as cargas de trabalho de IA e HPC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobre a utilização de Programação paralela em GPUs NVIDIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compreender como cada componente da GPU contribui para o desempenho em GML permite que você escolha a GPU certa, otimize seu código e obtenha o máximo desempenho em suas aplicações de aprendizado de máquina em grafos. Temos três tipos básicos de componentes processadores (CUDA cores e SMs) e memória, sendo eles:\n",
    "\n",
    "- Núcleos CUDA: Unidades básicas de processamento individuais na GPU.\n",
    "- SMs (Streaming Multiprocessor): Blocos maiores de processamento que agrupam núcleos CUDA e outros recursos.\n",
    "- Memória (VRAM): Onde os dados são armazenados para serem acessados pelos núcleos CUDA.\n",
    "\n",
    "Cada tipo de dispositivo na GPU tem sua respectivas frequências de clock, fornecendo informações sobre o desempenho atual da GPU em diferentes áreas de processamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados de clock e memória a cada instante são visualizáveis pelo nvidia-smi com os seguintes nomes:\n",
    "\n",
    "- Graphics (CUDA Cores): São as unidades de processamento mais básicas da GPU. Cada núcleo CUDA é capaz de executar uma única instrução de shader por vez. Eles são responsáveis pela execução em paralelo das operações matemáticas e lógicas necessárias para renderizar gráficos e realizar cálculos gerais. Os shaders são programas que processam gráficos e cálculos em paralelo. A frequência de clock \"Graphics\" indica a velocidade com que esses núcleos estão operando no momento. São os núcleos CUDA que acessam dados da memória da GPU (VRAM) para realizar seus cálculos. Quanto mais núcleos CUDA uma GPU tiver, maior será sua capacidade de processamento paralelo, porém, a velocidade com que eles podem acessar esses dados é influenciada pela largura de banda da memória.\n",
    "\n",
    "- SM: Significa \"Streaming Multiprocessor\". Cada SM é um conjunto de núcleos de processamento, caches e outros recursos dentro da GPU. A frequência de clock \"SM\" indica a velocidade com que os SMs estão operando.\n",
    "\n",
    "- Memory: Refere-se à memória de vídeo (VRAM) da GPU, onde são armazenados dados como texturas, modelos 3D e outros elementos gráficos, além de dados intermediários durante os cálculos. A frequência de clock \"Memory\" indica a velocidade com que a memória está operando.\n",
    "\n",
    "- Video: Refere-se ao mecanismo de codificação e decodificação de vídeo da GPU. É um componente de hardware dedicado ao processamento de vídeo que funciona como um motor de vídeo que pode acessar a Memory (VRAM) da GPU para ler e gravar dados de vídeo durante a codificação ou decodificação. Bem como pode usar os núcleos CUDA (Graphics) para realizar algumas etapas do processamento de vídeo, especialmente em codecs modernos que utilizam aceleração por hardware. A frequência de clock \"Video\" indica a velocidade com que esse mecanismo está operando. Os SMs gerenciam a execução dos threads nos núcleos CUDA, incluindo aqueles usados pelo motor de vídeo.\n",
    "\n",
    "Em síntese, os núcleos CUDA (Graphics) executam os shaders (programas que processam gráficos e cálculos em paralelo), que acessam dados na memória VRAM (Memory) e realizam cálculos. Os Streaming Multiprocessors (SMs) agrupam vários núcleos Graphics e outros recursos, permitindo que a GPU execute muitos shaders em paralelo. O motor de codificação e decodificação de vídeo (Video) é responsável por processar vídeos, codificando-os ou decodificando-os, e também pode acessar dados na Memory.\n",
    "\n",
    "Nem todas as GPUs possuem todos esses componentes. Algumas GPUs mais antigas podem não ter um mecanismo de vídeo dedicado, por exemplo. As frequências de clock podem variar dependendo da carga de trabalho da GPU e das configurações de energia. A seção \"Max Clocks\" no nvidia-smi mostra as frequências máximas que cada componente pode atingir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indo além do nvidi-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nvidia-smi não fornece informações diretas sobre a utilização dos Tensor Cores, uma das evoluções mais recentes na fabricação de GPUs. Essa é uma limitação da ferramenta, que se concentra principalmente em métricas gerais de utilização da GPU, como a porcentagem de tempo em que os núcleos CUDA estão ativos e o uso da memória. Isso acontece devido ao nível de abstração e complexidade mais superficial do nvidia-smi.\n",
    "\n",
    "Abstração de Hardware: O nvidia-smi é projetado para fornecer uma visão geral do estado da GPU, sem se aprofundar em detalhes específicos da arquitetura, como a utilização de unidades de hardware especializadas como os Tensor Cores.\n",
    "\n",
    "Complexidade de Monitoramento: O monitoramento preciso da utilização dos Tensor Cores exigiria um nível mais profundo de acesso ao hardware e à execução dos kernels CUDA, o que poderia impactar o desempenho geral da GPU.\n",
    "Alternativas para Monitorar a Utilização dos Tensor Cores\n",
    "\n",
    "Para monitorar a utilização dos Tensor Cores, é necessário usar ferramentas de profiling mais avançadas, como o NVidia Profiler (Nsight Compute) ou recursos de profiling fornecidos por bibliotecas de Deep Learning.\n",
    "\n",
    "A escolha da ferramenta depende do seu nível de conhecimento em CUDA e das necessidades específicas da sua aplicação.\n",
    "Mesmo sem monitorar diretamente a utilização dos Tensor Cores, você ainda pode otimizar seu código para aproveitá-los ao máximo, utilizando operações e formatos de dados que sejam compatíveis com eles, como operações de multiplicação de matrizes em precisão mista (FP16 ou BF16)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os Tensor Cores são unidades de hardware especializadas localizadas dentro dos SMs da GPU. Eles aceleram operações de multiplicação de matrizes em baixa precisão, melhorando o desempenho e a eficiência energética em tarefas como Deep Learning. Embora o nvidia-smi não mostre a utilização dos Tensor Cores diretamente, um alto uso da GPU e um menor consumo de energia podem indicar que eles estão sendo utilizados.\n",
    "\n",
    "Os Tensor Cores, embora não sejam explicitamente mostrados pelo nvidia-smi, estão intimamente relacionados aos Streaming Multiprocessors (SMs). Cada SM em uma GPU NVIDIA compatível com Tensor Cores contém um certo número desses núcleos especializados. Os Tensor Cores são projetados para acelerar operações específicas de multiplicação de matrizes em formatos de baixa precisão, como FP16 (meia precisão) e INT8 (inteiros de 8 bits).\n",
    "\n",
    "Os Tensor Cores funcionam em conjunto com os SMs em execução paralela aumentando o desempenho e eficiência energética:\n",
    "\n",
    "Execução Paralela: Os Tensor Cores operam em paralelo com os núcleos CUDA dentro de cada SM. Enquanto os núcleos CUDA executam instruções gerais de shader, os Tensor Cores se concentram em acelerar as operações de multiplicação de matrizes específicas para as quais foram projetados.\n",
    "\n",
    "Aumento de Desempenho: Ao descarregar essas operações de multiplicação de matrizes para os Tensor Cores, a GPU pode alcançar um desempenho significativamente maior em tarefas que se beneficiam desses cálculos, como o treinamento e a inferência de redes neurais profundas.\n",
    "\n",
    "Eficiência Energética: Os Tensor Cores são projetados para serem mais eficientes em termos de energia do que os núcleos CUDA para realizar essas operações específicas, o que pode levar a um menor consumo de energia da GPU.\n",
    "\n",
    "Monitoramento indireto de uso de Tensor cores pelo impacto nos dados do nvidia-smi:\n",
    "\n",
    "Utilização da GPU: Embora o nvidia-smi não mostre a utilização dos Tensor Cores diretamente, um alto uso da GPU (indicado pela métrica \"Gpu\" na seção \"Utilization\") pode sugerir que os Tensor Cores estão sendo utilizados, especialmente se a carga de trabalho envolve operações de multiplicação de matrizes em baixa precisão.\n",
    "\n",
    "Consumo de Energia: Se sua aplicação estiver utilizando os Tensor Cores de forma eficiente, você poderá observar um menor consumo de energia da GPU em comparação com uma aplicação semelhante que não utiliza os Tensor Cores.\n",
    "\n",
    "Desempenho: Em geral, aplicações que aproveitam os Tensor Cores tendem a ter um desempenho significativamente melhor em GPUs que os possuem, especialmente em tarefas de Deep Learning e outras que envolvem cálculos intensivos de matrizes.\n",
    "\n",
    "Para aproveitar ao máximo os Tensor Cores, é importante usar corretamente as bibliotecas e frameworks de Deep Learning que suportem operações em precisão mista e que sejam otimizados para GPUs NVIDIA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados principais disponíveis no nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seção: <b>PCIe Generation</b>\n",
    "\n",
    "    Max: A geração máxima do PCIe que a sua GPU suporta (neste caso, PCIe 4.0).\n",
    "    Current: A geração do PCIe que a sua GPU está atualmente usando (também PCIe 4.0).\n",
    "    Device Current/Max: A geração do PCIe que o dispositivo (GPU) está usando/suporta.\n",
    "    Host Max: A geração máxima do PCIe que a placa-mãe (host) suporta.\n",
    "    Seção: Link Width\n",
    "    Max: A largura de banda máxima do link PCIe que a sua GPU suporta (16x neste caso).\n",
    "    Current: A largura de banda do link PCIe que está sendo usada atualmente (também 16x).\n",
    "\n",
    "Seção: <b>Bridge Chip</b>\n",
    "\n",
    "    Replays Since Reset: O número de vezes que o barramento PCIe teve que retransmitir dados desde a última reinicialização. Idealmente, esse número deve ser baixo, indicando uma conexão estável.\n",
    "    Replay Number Rollovers: O número de vezes que o contador de replays foi reiniciado (estourou) desde a última reinicialização. Também deve ser baixo.\n",
    "    Tx Throughput: A taxa de transferência de dados transmitidos pela GPU através do barramento PCIe.\n",
    "    Rx Throughput: A taxa de transferência de dados recebidos pela GPU através do barramento PCIe.\n",
    "    Fan Speed: A velocidade atual da ventoinha da GPU em porcentagem da velocidade máxima.\n",
    "    Performance State: O estado de desempenho atual da GPU. P8 é o estado de desempenho mais alto, indicando que a GPU está operando em sua frequência máxima.\n",
    "\n",
    "Seção: <b>Clocks Event Reasons</b>\n",
    "\n",
    "    Idle: Indica se a GPU está ociosa (\"Active\") ou se está sendo usada por algum processo.\n",
    "\n",
    "Seção: <b>FB Memory Usage</b>\n",
    "\n",
    "    Total: A quantidade total de memória de vídeo (framebuffer) disponível na GPU.\n",
    "    Reserved: A quantidade de memória reservada pelo sistema operacional ou drivers.\n",
    "    Used: A quantidade de memória de vídeo atualmente em uso.\n",
    "    Free: A quantidade de memória de vídeo disponível para uso.\n",
    "\n",
    "Seção: <b>BAR1 Memory Usage (Base Address Register 1)</b>\n",
    "\n",
    "    Total: Tamanho total da BAR1 (Base Address Register 1), região de memória acessível pela CPU para comunicar com a GPU.\n",
    "    Used: A quantidade de memória BAR1 atualmente em uso.\n",
    "    Free: A quantidade de memória BAR1 disponível para uso.\n",
    "    \n",
    "Seção: <b>Conf Compute Protected Memory Usage</b>\n",
    "\n",
    "    Compute Mode: O modo de computação atual da GPU. \"Default\" significa que a GPU está operando no modo padrão, sem restrições especiais de acesso à memória.\n",
    "\n",
    "Seção: <b>Utilization</b>\n",
    "\n",
    "    Gpu: A porcentagem de utilização dos núcleos da GPU.\n",
    "    Memory: A porcentagem de utilização da memória de vídeo.\n",
    "    Encoder/Decoder/JPEG/OFA: Porcentagens de utilização de diferentes unidades de processamento da GPU, se aplicável.\n",
    "\n",
    "Seção: <b>Encoder Stats & FBC Stats</b>\n",
    "\n",
    "    Active Sessions/Average FPS/Average Latency: Informações sobre sessões de codificação e decodificação de vídeo ativas, se houver.\n",
    "\n",
    "Seção: <b>Temperature</b>\n",
    "\n",
    "    GPU Current Temp: A temperatura atual da GPU.\n",
    "    GPU Shutdown Temp: A temperatura na qual a GPU será desligada para evitar danos.\n",
    "    GPU Slowdown Temp: A temperatura na qual a GPU reduzirá sua frequência para evitar o superaquecimento.\n",
    "    GPU Max Operating Temp: A temperatura máxima de operação segura da GPU.\n",
    "    GPU Target Temperature: A temperatura alvo que a GPU tentará manter através do controle da ventoinha.\n",
    "\n",
    "Seção: <b>GPU Power Readings</b>\n",
    "\n",
    "    Power Draw: A potência atual sendo consumida pela GPU.\n",
    "    Current/Requested/Default/Min/Max Power Limit: Limites de potência configurados para a GPU.\n",
    "\n",
    "Seção: <b>Clocks</b>\n",
    "\n",
    "    Graphics/SM/Memory/Video: As frequências de clock atuais para diferentes componentes da GPU.\n",
    "\n",
    "Seção: <b>Max Clocks</b>\n",
    "\n",
    "    Graphics/SM/Memory/Video: As frequências de clock máximas que cada componente da GPU pode atingir.\n",
    "\n",
    "Seção: <b>Voltage</b>\n",
    "\n",
    "    Graphics: A tensão atual aplicada aos núcleos da GPU.\n",
    "\n",
    "Seção: <b>Health</b>\n",
    "\n",
    "    Processes: Lista os processos que estão usando a GPU atualmente. \"None\" significa que nenhum processo está usando a GPU no momento.\n",
    "\n",
    "Seção: <b>Capabilities</b>\n",
    "\n",
    "    EGM: Indica se o recurso de Gerenciamento de Memória de Erro (Error Memory Management) está habilitado ou desabilitado na GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profilling completo também a nível de Tensor Cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NVidia Profiler (Nsight Compute)*:\n",
    "Esta é a ferramenta oficial da NVIDIA para profiling e análise de desempenho de aplicações CUDA. Ela permite coletar métricas detalhadas sobre a execução de kernels CUDA, incluindo a utilização dos Tensor Cores. No entanto, o Nsight Compute requer conhecimento de CUDA e pode ter uma curva de aprendizado mais acentuada.\n",
    "\n",
    "*Bibliotecas de Deep Learning*:\n",
    "Algumas bibliotecas de Deep Learning, como o PyTorch e o TensorFlow, oferecem ferramentas de profiling que podem fornecer informações sobre a utilização dos Tensor Cores durante o treinamento e a inferência de modelos. É necessário\n",
    "consultar a documentação atualizada da biblioteca de Deep Learning em utilização para ver quando ela oferece recursos de profiling e como usá-los para monitorar os Tensor Cores.\n",
    "\n",
    "*Outras Ferramentas de Profiling*:\n",
    "Existem outras ferramentas de profiling de terceiros que podem fornecer informações sobre a utilização dos Tensor Cores, como o NSight Systems e o TAU (Tuning and Analysis Utilities).\n",
    "\n",
    "Apesar de muito completas e eficientes, essas ferramentas podem ser mais complexas de configurar e usar, e nem sempre oferecem suporte completo para todas as GPUs e versões do CUDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal uso em Graph Machine Learning dos compontentes das GPUs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Streaming Multiprocessor (SMs): Organizar e gerenciar a execução paralela.\n",
    "- Graphics (núcleos CUDA): Processar paralelamente as operações do GML.\n",
    "- Memory (VRAM): Armazenar temporáriamente os dados do grafo e do modelo.\n",
    "- Video: Motor de codificação e decodificação de vídeo tem o papel de visualizar os grafos e aplicações multimodais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linguagem CUDA para criar kernels otimizados para GML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O controle e a interação dos componentes da GPU (CUDA Cores, SMs, Memória) com outros elementos de hardware e software em CUDA para otimizar kernels de Graph Machine Learning (GML) envolvem vários aspectos:\n",
    "\n",
    "1. Gerenciamento de Threads e Blocos:\n",
    "\n",
    "- Threads e Blocos: Em CUDA, o código é executado por threads organizados em blocos. Cada thread dentro de um bloco tem um ID único, permitindo que você acesse e processe diferentes partes do grafo em paralelo.\n",
    "Hierarquia de Memória: CUDA oferece diferentes níveis de memória com velocidades e capacidades variadas:\n",
    "- Registradores: Memória mais rápida, privada para cada thread.\n",
    "- Memória Compartilhada: Memória mais rápida, compartilhada entre threads de um mesmo bloco. Ideal para armazenar dados acessados frequentemente dentro de um bloco.\n",
    "- Memória Global: Memória principal da GPU, acessível por todos os threads. Usada para armazenar a maior parte dos dados do grafo e do modelo.\n",
    "- Sincronização: Para garantir a correção dos resultados, é crucial sincronizar os threads dentro de um bloco (__syncthreads()) ou entre blocos (cudaDeviceSynchronize()), especialmente quando há dependências de dados entre eles.\n",
    "\n",
    "2. Otimização de Acesso à Memória:\n",
    "\n",
    "- Coalescência de Memória: Acessar dados da memória global de forma sequencial e alinhada maximiza a largura de banda da memória. Evite acessos aleatórios e desalinhados, que podem causar grandes penalidades de desempenho.\n",
    "- Caches: Utilize a memória compartilhada para armazenar dados acessados com frequência dentro de um bloco, reduzindo o número de acessos à memória global mais lenta.\n",
    "- Transferência de Dados: Minimize a transferência de dados entre a CPU e a GPU, pois isso pode ser um gargalo de desempenho. Utilize cudaMemcpyAsync para transferências assíncronas e pinned memory para otimizar a cópia de dados.\n",
    "\n",
    "3. Otimização para GML:\n",
    "\n",
    "- Particionamento de Grafos: Divida o grafo em partições menores que caibam na memória da GPU, processando cada partição em paralelo.\n",
    "- Amostragem de Vizinhança: Em grafos grandes, utilize técnicas de amostragem para selecionar apenas um subconjunto dos vizinhos de cada nó durante o treinamento, reduzindo a quantidade de dados a serem processados.\n",
    "- Compressão de Grafos: Utilize formatos de representação de grafos mais compactos, como CSR (Compressed Sparse Row) ou COO (Coordinate Format), para reduzir o consumo de memória e melhorar a eficiência do acesso aos dados.\n",
    "- Modelos Eficientes: Utilize modelos de GML projetados para serem eficientes em GPUs, como GNNs com camadas convolucionais esparsas ou modelos que exploram a estrutura do grafo para reduzir o número de operações."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Exemplo de Kernel CUDA para Agregação de Mensagens em GNNs:\n",
    "\n",
    "C++\n",
    "__global__ void aggregate_messages(float* features, int* edge_index, int num_nodes, int num_edges) {\n",
    "    int node_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (node_id < num_nodes) {\n",
    "        float aggregated_message = 0.0;\n",
    "        for (int i = 0; i < num_edges; i++) {\n",
    "            if (edge_index[2 * i + 1] == node_id) {  // Se o nó é o destino da aresta\n",
    "                int source_node = edge_index[2 * i];\n",
    "                aggregated_message += features[source_node];  // Agrega a mensagem do nó de origem\n",
    "            }\n",
    "        }\n",
    "        features[node_id] = aggregated_message;  // Atualiza as features do nó\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesma função para Agregar Mensagens em GNNs pode ser criada em python por meio do PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def aggregate_messages(features, edge_index):\n",
    "    \"\"\"\n",
    "    Agrega mensagens em um grafo usando PyTorch.\n",
    "\n",
    "    Args:\n",
    "        features: Tensor com as features dos nós (shape: [num_nodes, num_features]).\n",
    "        edge_index: Tensor com os índices das arestas (shape: [2, num_edges]).\n",
    "\n",
    "    Returns:\n",
    "        Tensor com as features agregadas dos nós (shape: [num_nodes, num_features]).\n",
    "    \"\"\"\n",
    "\n",
    "    # Criar um tensor esparso para representar o grafo\n",
    "    sparse_adj = torch.sparse_coo_tensor(edge_index, torch.ones(edge_index.shape[1]), \n",
    "                                         size=(features.shape[0], features.shape[0]))\n",
    "\n",
    "    # Realizar a agregação de mensagens usando multiplicação de matrizes esparsas\n",
    "    aggregated_messages = torch.sparse.mm(sparse_adj, features)\n",
    "\n",
    "    return aggregated_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frameworks e APIs de alto nível para otimizar execução em GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Geometric e DGL facilitam a criação de kernels otimizados para Graph Machine Learning (GML) de várias maneiras, abstraindo a complexidade da programação CUDA de baixo nível e fornecendo implementações eficientes de operações comuns em grafos.\n",
    "\n",
    "1. Abstração de CUDA:\n",
    "\n",
    "Foco no modelo, não na implementação: Ambas as bibliotecas permitem que você se concentre na definição do seu modelo de GML (GNNs, etc.) em Python, sem precisar escrever código CUDA diretamente. Elas cuidam da conversão do seu modelo em kernels CUDA otimizados nos bastidores.\n",
    "Flexibilidade: Você pode usar construções de alto nível do PyTorch (ou TensorFlow, no caso do DGL) para definir seu modelo, aproveitando a flexibilidade e expressividade dessas bibliotecas.\n",
    "\n",
    "Portabilidade: O código do seu modelo se torna mais portátil, pois não está diretamente vinculado a detalhes específicos da arquitetura da GPU ou da CUDA.\n",
    "\n",
    "2. Implementações Otimizadas:\n",
    "\n",
    "Operações comuns em grafos: Ambas as bibliotecas fornecem implementações otimizadas em CUDA para operações comuns em GML, como:\n",
    "\n",
    "- Convolução de grafos: Diferentes tipos de convolução, como GCNConv, GATConv, SAGEConv, etc.\n",
    "- Pooling de grafos: Para reduzir o tamanho do grafo, como TopKPooling, SAGPooling, etc.\n",
    "- Normalização de grafos: Para normalizar as features dos nós, como BatchNorm, LayerNorm, etc.\n",
    "- Outras operações: Funções de ativação, camadas lineares, etc.\n",
    "\n",
    "Aproveitamento de recursos da GPU: Essas implementações são projetadas para aproveitar ao máximo os recursos da GPU, como paralelismo, memória compartilhada e caches, para obter o melhor desempenho possível.\n",
    "\n",
    "Atualizações e otimizações: As bibliotecas são mantidas ativamente e recebem atualizações frequentes com novas otimizações e melhorias de desempenho.\n",
    "\n",
    "3. Abstração de detalhes de baixo nível:\n",
    "\n",
    "Gerenciamento de memória: As bibliotecas cuidam do gerenciamento de memória na GPU, alocando e liberando memória conforme necessário, para que você não precise se preocupar com esses detalhes.\n",
    "\n",
    "Sincronização de threads: A sincronização de threads é tratada automaticamente pelas bibliotecas, garantindo a correção dos resultados sem a necessidade de chamadas explícitas a __syncthreads().\n",
    "\n",
    "Transferência de dados: As bibliotecas otimizam a transferência de dados entre a CPU e a GPU, usando técnicas como cudaMemcpyAsync e pinned memory.\n",
    "\n",
    "4. Facilidade de uso:\n",
    "\n",
    "API intuitiva: Ambas as bibliotecas oferecem uma API Python de alto nível que é fácil de aprender e usar, mesmo para quem não tem experiência em CUDA.\n",
    "\n",
    "Documentação e exemplos: As bibliotecas possuem documentação abrangente e muitos exemplos de código que demonstram como usar as diferentes funcionalidades e construir modelos de GML.\n",
    "\n",
    "Comunidade ativa: Ambas as bibliotecas têm comunidades ativas e fóruns de suporte onde você pode encontrar ajuda e trocar ideias com outros usuários.\n",
    "\n",
    "Em resumo, PyTorch Geometric e DGL facilitam a criação de kernels otimizados para GML, permitindo que você se concentre na definição do seu modelo e abstraindo os detalhes de baixo nível da programação CUDA. Elas fornecem implementações eficientes de operações comuns em grafos, otimizam o uso dos recursos da GPU e oferecem uma API intuitiva e fácil de usar. Com essas bibliotecas, você pode desenvolver e implementar modelos de GML de forma mais rápida e eficiente, sem precisar ser um especialista em CUDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimizando uso da NVIDIA GeForce RTX 4080 SUPER para GML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na utilização da NVIDIA GeForce RTX 4080 SUPER em aplicações de Graph Machine Learning, no contexto de pesquisas com restrições orçamentárias, Ao otimizar o uso de cada componente da GPU e aplicar as melhores práticas de GML, um desempenho razoável nas tarefas de aprendizado de máquina em grafos pode ser alcançado. Esta GPU oferece um grau de paralelismo, uma capacidade de memória e recursos avançados de vídeo com boa relação custo/benefício tanto em aquisição como em consumo de energia elétrica dentre os modelos não-profissionais. \n",
    "\n",
    "Cada componente dessa GPU pode ser utilizada de forma otimizada:\n",
    "\n",
    "1. Núcleos CUDA (Graphics)\n",
    "\n",
    "- Paralelismo Massivo: A RTX 4080 SUPER possui 76 núcleos CUDA, permitindo um alto grau de paralelismo. Esses núcleos podem ser bem utilizados para processar um grande número de nós e arestas simultaneamente, acelerando operações como agregação de mensagens, propagação de features e cálculos de atenção em GNNs.\n",
    "\n",
    "- Uso em Grafos Densos: A arquitetura Ada Lovelace da RTX 4080 SUPER é particularmente eficiente em operações com matrizes densas, que podem ser usadas para representar grafos densos em GML.\n",
    "\n",
    "2. Streaming Multiprocessors (SMs)\n",
    "\n",
    "- Gerenciamento Eficiente de Threads: Os 76 SMs da RTX 4080 SUPER gerenciam a execução dos threads nos núcleos CUDA, garantindo uma utilização eficiente dos recursos da GPU.\n",
    "\n",
    "- Modelos Complexos: Utilize os SMs para lidar com modelos de GML complexos com um grande número de parâmetros e operações, permitindo um treinamento e inferência mais rápidos.\n",
    "\n",
    "- Técnicas Avançadas: Implemente técnicas avançadas de GML, como Graph Attention Networks (GATs) ou Graph Transformers, que exigem um alto grau de paralelismo e gerenciamento eficiente de threads.\n",
    "\n",
    "3. Memória de Vídeo (VRAM)\n",
    "\n",
    "- Capacidade de 16 GB: A RTX 4080 SUPER possui 16 GB de VRAM, o que permite armazenar grafos de tamanho moderado diretamente na memória da GPU.\n",
    "\n",
    "- Grafos de Tamanho Médio: Utilize a VRAM para armazenar grafos com até alguns milhões de nós e arestas, evitando a necessidade de transferir dados entre a CPU e a GPU durante o processamento, o que pode ser um gargalo de desempenho.\n",
    "\n",
    "- Técnicas de Otimização de Memória: Para grafos maiores que não cabem inteiramente na VRAM, utilize técnicas de otimização de memória, como particionamento de grafos, amostragem de vizinhos ou carregamento de dados em lotes.\n",
    "\n",
    "4. Codificador/Decodificador de Vídeo\n",
    "\n",
    "- Visualização Interativa: A RTX 4080 SUPER possui um poderoso mecanismo de vídeo que pode ser usado para visualizar grafos e seus embeddings em tempo real, permitindo uma análise interativa e exploratória dos seus dados e resultados.\n",
    "\n",
    "- Aplicações Multimodais: Se sua aplicação de GML envolve dados multimodais, como imagens ou vídeos associados aos nós do grafo, o codificador/decodificador de vídeo pode ser usado para processar e incorporar esses dados, enriquecendo a representação do grafo e melhorando o desempenho do modelo.\n",
    "\n",
    "Recomendações Gerais:\n",
    "\n",
    "Bibliotecas: Utilize bibliotecas de GML otimizadas para GPUs NVIDIA, como o PyTorch Geometric e o DGL, que aproveitam ao máximo os recursos da RTX 4080 SUPER.\n",
    "\n",
    "Precisão Mista (Mixed Precision): Utilize treinamento em precisão mista (FP16 ou BF16) para acelerar o treinamento e reduzir o consumo de memória, especialmente em modelos grandes e complexos.\n",
    "\n",
    "Paralelismo de Dados: Se possível, paralelize o treinamento do seu modelo em várias GPUs para acelerar ainda mais o processo.\n",
    "\n",
    "Monitoramento: Utilize ferramentas como o nvidia-smi para monitorar o uso da GPU durante o treinamento e a inferência, identificando gargalos de desempenho e oportunidades de otimização.\n",
    "\n",
    "Conclusão: A GeForce RTX 4080 SUPER é uma GPU apresente o melhor custo/benefício em relação processamento/preço, dispõe de recursos que podem ser bem aproveitados para algoritmos de Graph Machine Learning (GML) apresentando desempenho razoável, dentre os melhores na categoria de placas GPU de uso não-profissional. \n",
    "\n",
    "Com relação ao modelo mais potente da arquitetura Ada Lovelace a RTX 4090 (24 GB GDDR6X, 450 Watt), a RTX 4080 Super (16 GB GDDR6X, 320 Watt) atinge desempenho de 88% do desempenho da RTX 4090 por apenas 60% do custo de aquisição nos Estados Unidos. Para aquisição no Brasil a distância pode ser ainda maior, pode-se encontrar 4080 Super po aproximadamente 31% do preço de aquisição da 4090 (Preços na Amazon: RTX 4090 R$34.970,00 versus RTX 4080 Super R$11.001 no Brasil em 2024). \n",
    "\n",
    "A maior limitação realmente é o tamanho da memória em 16Gb, contra os 24Gb da 4090 RTX.\n",
    "\n",
    "A 4080 Super ainda apresenta eficiência energética bem superior (45,62%) com relação à 4090 (28,81%). \n",
    "\n",
    "https://technical.city/pt/video/GeForce-RTX-4090-vs-GeForce-RTX-4080-SUPER\n",
    "\n",
    "https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Um Modelo Grafo Multicamada para PDI</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridade Semântica em Grafos com Classificação Dinâmica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para alcançar o objetivo de criar um motor de análise de similaridade semântica em grafos com classificação dinâmica de nós, a combinação de Graph Machine Learning (GML) com técnicas de otimização de modularidade demanda implementar estratégias para representar as entidades do domínio, na forma de nós no modelo grafo, bem como representar as interações no mundo real entre essas entidades, através da representação dos relacionamentos em arestas do modelo grafo. Para tanto seguem as principais atividades a serem realizadas para implementar o modelo de análise em grafos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Representar entidades de mundo real como Nós e relacionamentos como Arestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Incorporação de Nós (Node Embeddings)**: Modelos de GML como Graph Neural Networks (GNNs) foram utilizados para aprender representações vetoriais (embeddings) dos nós [1,2], capturando assim, a similaridade semântica com base na estrutura do grafo e nas propriedades dos nós.\n",
    "\n",
    "**Incorporação de Arestas (Edge Embeddings)**: De acordo com o contexto real do domínio em análise, se além dos nós em si, as relações entre os nós também carregam informações semânticas importantes, é necessário aprender representações vetoriais também para as arestas.\n",
    "\n",
    "Referências:\n",
    "\n",
    "    [1] Graph Convolutional Networks for Text Classification (https://arxiv.org/abs/1810.08403)\n",
    "    [2] Inductive Representation Learning on Large Graphs (https://arxiv.org/abs/1706.02216)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Cálcular Similaridade Semântica no modelo grafo (entidades e relacionamentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métricas de Distância**: Utilizadas métricas de distância como cosseno, ou distância euclidiana, dependendo da questão específica tratada, para calcular a similaridade entre os embeddings dos nós."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Realizar a classificação dinâmica de nós e arestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algoritmos de Clustering**: Para permitir uma classificação dinâmica de nós e relacionamentos, aqui utilizamos algoritmos de clustering, que permitiram classificar os nós com base na similaridade semântica de suas propriedades, passadas como parâmetros de classificação, e na maximização da modularidade do grafo gerado pela interação entre essas entidades. \n",
    "\n",
    "Foram experimentados para essa atividade os algoritmos:\n",
    "\n",
    "    Louvain: Algoritmo eficiente e amplamente utilizado para otimização de modularidade.\n",
    "\n",
    "    Leiden: Variação do Louvain com maior precisão na detecção de comunidades.\n",
    "\n",
    "    Infomap: Algoritmo baseado em fluxo de informação para identificar comunidades.\n",
    "\n",
    "**Algoritmos de Clustering Hierárquico**: Permitem visualizar a estrutura de comunidades em diferentes níveis de granularidade.\n",
    "\n",
    "    Maximização da Modularidade: A modularidade mede a qualidade da divisão do grafo em comunidades. Utilize a modularidade como função objetivo durante o processo de clustering para garantir que os nós sejam agrupados em comunidades coesas e significativas. \n",
    "\n",
    "Referências:\n",
    "\n",
    "    [3] Finding community structure in very large networks (https://arxiv.org/abs/cond-mat/0408187)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Modelagem do Schema do Grafo e Questões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schema do Grafo: Defina o schema do grafo de forma a representar adequadamente os dados textuais e as relações entre eles. Utilize propriedades dos nós para armazenar informações relevantes para a análise de similaridade semântica.\n",
    "Questões: Formule as questões que deseja responder com a análise de similaridade semântica. Isso guiará a escolha das propriedades dos nós, o cálculo de similaridade e a interpretação dos resultados do clustering.\n",
    "Considerações Adicionais\n",
    "\n",
    "Pré-processamento de Texto: Aplique técnicas de pré-processamento de texto (tokenização, remoção de stop words, stemming/lemmatization) para melhorar a qualidade das representações vetoriais e a análise de similaridade semântica.\n",
    "Escolha do Modelo de GML: A escolha do modelo de GML (tipo de GNN, número de camadas, etc.) depende da complexidade do grafo e das características dos dados. Experimente diferentes modelos e avalie seu desempenho.\n",
    "Avaliação dos Resultados: Utilize métricas de avaliação de clustering para medir a qualidade das comunidades encontradas e a efetividade da classificação dinâmica dos nós.\n",
    "Escalabilidade: Para grafos muito grandes, considere técnicas de amostragem ou algoritmos de clustering distribuídos para lidar com a escalabilidade.\n",
    "\n",
    "Outas literaturas relevantes incluem os artigos:\n",
    "\n",
    "    [4] A Comprehensive Survey on Graph Neural Networks (https://arxiv.org/abs/1901.00596)\n",
    "    [5] Community Detection in Graphs\n",
    "\n",
    "Bibliotecas Python\n",
    "\n",
    "NetworkX: Para criação, manipulação e visualização de grafos.\n",
    "\n",
    "PyTorch Geometric: Para implementação de modelos de GML.\n",
    "\n",
    "Scikit-learn: Para algoritmos de clustering e métricas de avaliação.\n",
    "\n",
    "As características, tanto dos dados sendo processados, como das questões a responder são fundamentais para melhor abordagem de treinamento para combinar as técnicas e criar o motor de análise de similaridade semântica eficaz e dinâmico em grafos. Os testes de benchmarking para essa escolha são mostrados a seguir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simular interação de forças para visualizar análises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de forças no sistema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyVis para simula a busca por equilíbrio entre forças físicas nas entidades que interagem no grafo para determinar o posicionamento dos nós no grafo e assim criar o layout. As principais forças envolvidas são:\n",
    "\n",
    "#### 1. Força de Atração:\n",
    "\n",
    "Arestas (Links): As arestas entre os nós agem como molas, puxando os nós conectados um em direção ao outro. A intensidade dessa força é determinada pelo parâmetro springLength (comprimento ideal da mola) e springConstant (rigidez da mola).\n",
    "\n",
    "Gravidade Central: Uma força de atração em direção ao centro do grafo, controlada pelo parâmetro centralGravity. Essa força ajuda a evitar que os nós se dispersem muito e mantém o grafo mais compacto.\n",
    "\n",
    "#### 2. Força de Repulsão:\n",
    "\n",
    "Repulsão entre Nós: Os nós se repelem uns aos outros, como partículas carregadas com a mesma carga. A intensidade dessa força é determinada pelo parâmetro gravitationalConstant (constante gravitacional). Um valor negativo aumenta a repulsão, enquanto um valor positivo a diminui.\n",
    "\n",
    "Evitar Sobreposição: O parâmetro avoidOverlap controla se os nós devem evitar a sobreposição. Se ativado, uma força adicional é aplicada para afastar os nós que estão muito próximos.\n",
    "\n",
    "#### 3. Força de Amortecimento:\n",
    "\n",
    "Damping: O parâmetro damping controla o amortecimento do movimento dos nós. Um valor maior de amortecimento torna o movimento mais lento e suave, enquanto um valor menor permite movimentos mais rápidos e oscilatórios.\n",
    "\n",
    "#### 4. Forças Adicionais (Opcionais):\n",
    "\n",
    "Outras Forças: O PyVis permite adicionar outras forças personalizadas ao layout, como forças de atração/repulsão entre grupos de nós, ou forças que direcionam os nós para posições específicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como as Forças Interagem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo ForceAtlas2Based iterativamente calcula as forças resultantes sobre cada nó e ajusta suas posições de acordo. O processo continua até que o layout se estabilize ou um número máximo de iterações seja atingido.\n",
    "\n",
    "O algoritmo Barnes-Hut otimiza o cálculo das forças de longo alcance, aproximando as forças entre grupos de nós distantes. Isso melhora o desempenho do algoritmo, especialmente em grafos grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equilíbrio das Forças:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O objetivo do algoritmo é encontrar um equilíbrio entre as forças de atração e repulsão, de modo que os nós conectados fiquem próximos, mas sem se sobreporem, e o grafo tenha uma aparência geral agradável e informativa. O ajuste dos parâmetros do ForceAtlas2Based e do Barnes-Hut permite controlar esse equilíbrio e personalizar o layout do grafo de acordo com suas necessidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmos ForceAtlas2Based e Barnes-Hut:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ForceAtlas2Based é um algoritmo de layout que simula um sistema físico onde os nós se atraem e se repelem com base em certas forças. No entanto, calcular essas forças para todos os pares de nós em um grafo grande pode ser computacionalmente caro.\n",
    "\n",
    "Para otimizar o cálculo das forças, o ForceAtlas2Based utiliza o algoritmo Barnes-Hut. Esse algoritmo agrupa nós distantes em clusters e aproxima suas forças de atração/repulsão, reduzindo significativamente o número de cálculos necessários."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theta e a Distância entre Nós:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O parâmetro theta (θ) do Barnes-Hut define o limite entre as forças de curto e longo alcance. Quando a distância entre dois nós é menor que theta multiplicado pelo tamanho do cluster, as forças são calculadas individualmente (curto alcance). Caso contrário, as forças são aproximadas usando o centro de massa do cluster (longo alcance).\n",
    "\n",
    "Quando os nós estão muito próximos, a distância entre eles é menor que o limite definido por theta. Nesse caso, o algoritmo Barnes-Hut calcula as forças individualmente para cada par de nós, levando em consideração suas posições exatas. Isso permite que o ForceAtlas2Based posicione os nós próximos de forma mais precisa, evitando sobreposições e garantindo um layout visualmente agradável.\n",
    "\n",
    "Em resumo, o ForceAtlas2Based define as regras gerais para as forças de atração e repulsão entre os nós. No entanto, quando os nós estão próximos, o algoritmo Barnes-Hut assume o controle e calcula as forças de forma mais precisa, levando em consideração a distância exata entre os nós.\n",
    "\n",
    "O parâmetro theta do Barnes-Hut é fundamental para determinar o comportamento do layout em nós próximos, pois define o limite entre as forças de curto e longo alcance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O que é o Theta (θ)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O theta (θ) é um parâmetro interno do ForceAtlas2Based que controla o limite entre as forças de longo alcance (que afetam todos os nós) e as forças de curto alcance (que afetam apenas os nós próximos).\n",
    "\n",
    "Valores mais altos de theta: Aceleram o cálculo das forças, mas podem gerar mais erros e imprecisões no layout.\n",
    "Valores mais baixos de theta: Tornam o cálculo mais lento, mas produzem um layout mais preciso e com menos erros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como o Theta é Usado no ForceAtlas2Based?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ForceAtlas2Based utiliza uma técnica chamada Barnes-Hut para aproximar as forças de longo alcance, tornando o cálculo mais eficiente. O theta é usado para determinar quais nós estão \"próximos o suficiente\" para que suas forças sejam calculadas individualmente (curto alcance), e quais nós estão \"longe o suficiente\" para que suas forças sejam aproximadas usando a técnica Barnes-Hut (longo alcance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parâmetros do ForceAtlas2Based:\n",
    "\n",
    "gravitationalConstant: Define a força de atração global entre os nós. Valores negativos atraem os nós para o centro do grafo, enquanto valores positivos os repelem. Um valor mais negativo resultará em um grafo mais compacto, enquanto um valor mais positivo resultará em um grafo mais espalhado.\n",
    "\n",
    "centralGravity: Define a força de atração em direção ao centro do grafo. Valores maiores puxam os nós mais para o centro.\n",
    "\n",
    "springLength: Define o comprimento ideal das arestas (ligações entre os nós). Valores maiores resultam em arestas mais longas e um grafo mais espalhado.\n",
    "\n",
    "springConstant: Define a rigidez das arestas. Valores maiores tornam as arestas mais rígidas e o grafo menos flexível.\n",
    "\n",
    "damping: Controla a velocidade com que os nós se movem. Valores maiores amortecem o movimento, resultando em um layout mais estável, mas que pode levar mais tempo para convergir.\n",
    "\n",
    "avoidOverlap: Determina se os nós devem evitar a sobreposição. Um valor de 1 (verdadeiro) faz com que os nós se afastem uns dos outros para evitar sobreposição, enquanto um valor de 0 (falso) permite a sobreposição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Benchmarking de partes da implementação</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delinear formas de melhorar a eficiência dos processos de Gestão em PDI, com base na escolha bem fundamentada em dados sobre evidências do mundo real, é uma oportunidade para melhorar tanto a efetividade como a eficiência dos processos de gestão em Pesquisa Desenvolvimento e Inovação (PDI). No âmbito das Instituições de Ciência e Tecnologia brasileiras (ICT), para propor novas tecnologias e melhorar as existentes, a gestão em PDI precisa implementar processsos computacionais de extração, tratamento, análise, visualização e apresentação de resultados para tratar a massa de dados disponível e permitir uma melhor tomada de decisão aos níveis gerenciais e executivos das ICTs. \n",
    "\n",
    "Tais necessidades e oportunidades não deve ser negligenciadas, principalmente nas economias em desenvolvimento, por representar uma forma viável para reduzir custos, e com suporte ao desenvolvimento de tecnologias nacionais, reduzir os déficits da balança comercial do País. Para aproveitar essa oportunidade, aplicar uma abordagem de benchmarking não supervisionado para modelos de aprendizagem de máquina, destinados à suportar os processos em PDI, é uma contribuição valiosa para suportar à criação de processos e aplicações mais inteligentes na tomada de decisão em PDI. \n",
    "\n",
    "Neste artigo demonstramos como comparar e selecionar modelos pré-treinados mais eficientes para gerar vetores de incorporação de textos (embeedings), de forma objetiva e sistemática, mesmo na ausência de rótulos de dados. Foram exploradas diferentes métricas de avaliação, algoritmos de clustering e técnicas de visualização para aprimorar ainda mais o processo de benchmarking e seleção de modelos, baseado em dados da realidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking de Leituras de dataframes Paralelizável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura de dataframes com Pandas ou cuDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !which python\n",
    "# !echo $PATH\n",
    "# !conda list git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install GitPython\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import cudf\n",
    "import cugraph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from git import Repo\n",
    "\n",
    "def convert_to_dict(text):\n",
    "    try:\n",
    "        return ast.literal_eval(text)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "folder_utils = os.path.join(str(root_folder), 'utils') # type: ignore\n",
    "folder_domain = os.path.join(str(root_folder), 'source', 'domain') # type: ignore\n",
    "folder_data_input = os.path.join(str(root_folder), '_data', 'in_csv') # type: ignore\n",
    "folder_data_output = os.path.join(str(root_folder), '_data', 'out_json') # type: ignore\n",
    "filename = 'revistas_capes.csv'\n",
    "pathfilename = os.path.join(folder_data_input, filename)\n",
    "\n",
    "# read data into a Pandas DataFrame using read_csv\n",
    "start_time_cpu = time.time()\n",
    "pdf = pd.read_csv(pathfilename, header=0, delimiter=';')\n",
    "end_time_cpu = time.time()\n",
    "time_cpu = end_time_cpu - start_time_cpu\n",
    "print(f\"Tempos para gerar dataframes:\") \n",
    "print(f\"Na CPU com  Pandas: {time_cpu:>.2f} segundos\")\n",
    "\n",
    "# Apply the function to the 'detalhes' column\n",
    "# pdf['detalhes'] = pdf['detalhes'].apply(convert_to_dict)\n",
    "\n",
    "# Print the first 5 rows to verify\n",
    "# print(pdf.head()) \n",
    "\n",
    "# read data into a cuDF DataFrame using read_csv\n",
    "start_time_gpu = time.time()\n",
    "gdf = cudf.read_csv(pathfilename, header=0, delimiter=';')  # type: ignore\n",
    "qlin = len(gdf.index)\n",
    "end_time_gpu = time.time()\n",
    "time_gpu = end_time_gpu - start_time_gpu\n",
    "print(f\"Na GPU com cuGraph: {time_gpu:>.2f} segundos\")\n",
    "diff = time_cpu-time_gpu\n",
    "percent = np.round(diff/time_cpu*100,2)\n",
    "if time_gpu < time_cpu:\n",
    "    print(f\"cuGraph reduziu {percent:.2f}% do tempo do cálculo em CPU\")\n",
    "    print(f\"A leitura foi {time_cpu/time_gpu:.1f} vezes mais rápida com cuGraph\")\n",
    "else:\n",
    "    percent = np.round(-diff/time_cpu*100,2)\n",
    "    print(f\"cuGraph aumentou em {-diff:.2f} segundos o tempo de leitura do dataframe com {qlin} linhas\")\n",
    "    print(f\"A leitura foi {time_gpu/time_cpu:.1f} vezes mais lenta com cuGraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas lê arquivos CSV mais rápido que o cuDF em algumas situações, para arquivos menores ou em casos onde a sobrecarga de transferência de dados para a GPU supera o ganho de desempenho do processamento paralelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking do Cálculo de Centralidade Paralelizável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medir tempo de cálculos de centralidade com e sem GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import cugraph as cnx\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "# warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"huggingface_hub\")\n",
    "# warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"mensagem de aviso específica\")\n",
    "# help(cugraph.experimental)\n",
    "# help(cugraph.experimental.compat)\n",
    "# print(dir(cugraph.experimental))\n",
    "\n",
    "# Criar um grafo aleatório com 10mil nós e probabilidade de 1% de haver arestas entre cada par de nós\n",
    "print(f\"Criando grafo com 10000 nós e 10% de probabilidade de aresta entre nós...\")\n",
    "G = nx.gnp_random_graph(10000, 0.01) \n",
    "\n",
    "# Medir tempo para calcular centralidade de intermediação somente com uso de CPU\n",
    "print(f\"Iniciando cálculo de centralidade de intermediação com CPU...\")\n",
    "start_time = time.time()\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "end_time = time.time()\n",
    "time_cpu = end_time - start_time\n",
    "print(f\"  Tempos para calcular betweenness_centrality:\") \n",
    "print(f\"  Na CPU sem cuGraph: {time_cpu:>.2f} segundos\")\n",
    "\n",
    "# Medir tempo para calcular centralidade de intermediação com aceleração na GPU\n",
    "print(f\"Iniciando cálculo de centralidade de intermediação com GPU...\")\n",
    "start_time_gpu = time.time()\n",
    "betweenness_centrality_cugraph = cnx.betweenness_centrality(G)\n",
    "end_time_gpu = time.time()\n",
    "time_gpu = end_time_gpu - start_time_gpu\n",
    "\n",
    "# Mostrar os resultados comparativos\n",
    "print(f\"  Na GPU com cuGraph: {time_gpu:>.2f} segundos\")\n",
    "diff = time_cpu-time_gpu\n",
    "percent = np.round(diff/time_cpu*100,2)\n",
    "if time_gpu < time_cpu:\n",
    "    print(f\"\\ncuGraph reduziu {percent:.2f}% do tempo do cálculo em CPU\")\n",
    "    print(f\"O cálculo foi {time_cpu/time_gpu:.1f} vezes mais rápido com cuGraph\")\n",
    "else:\n",
    "    percent = np.round(-diff/time_cpu*100,2)\n",
    "    print(f\"cuGraph aumentou em {-diff:.2f} segundos o tempo de cálculo da centralidade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking da Geração de Embeedings Paralelizável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar métricas adequadas para avaliar os resultados de clustering é crucial para determinar qual algoritmo e configuração funcionam melhor para os dados no contexto em análise. As seguintes métricas foram utilizadas para avaliar a qualidade dos clusters com os embeedings de cada modelo:\n",
    "\n",
    "Silhouette Score: avalia a qualidade dos clusters, combinando medidas de coesão (quão próximos os pontos dentro de um cluster estão uns dos outros) e separação (quão distantes os clusters estão entre si). Os score varia de -1 a 1, onde valores próximos a 1 indicam que os pontos estão bem agrupados em seus clusters e bem separados dos outros clusters, e valores próximos a 0 indicam que os pontos estão perto da fronteira entre clusters, ou que o número de clusters pode não ser ideal. Já valores próximos a -1 sugerem que os pontos podem estar atribuídos aos clusters errados.\n",
    "\n",
    "Calinski-Harabasz Index (ou Variance Ratio Criterion): mede a razão entre a dispersão entre clusters e a dispersão dentro dos clusters. Quanto maior o valor, melhor a qualidade do clustering. Ou seja, um valor alto indica que os clusters estão bem separados e densos.\n",
    "\n",
    "Davies-Bouldin Index: mede a similaridade média entre cada cluster e seu cluster mais similar. Quanto menor o valor, melhor a qualidade do clustering. Ou seja, um valor baixo indica que os clusters estão mais separados e menos dispersos.\n",
    "\n",
    "O teste de benchmarking destaca:\n",
    "\n",
    "    o maior Silhouette Score dentre os resultados para indicar uma melhor qualidade de clustering, com clusters mais coesos e separados.\n",
    "\n",
    "    os maiores valores do Calinski-Harabasz Index para cada algoritmo e configuração, pois isso sugere uma melhor separação entre os clusters.\n",
    "\n",
    "    o algoritmo e configuração com o menor Davies-Bouldin Index, pois isso indica clusters mais distintos e compactos."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cuml.metrics.cluster.silhouette_score.cython_silhouette_score(X, labels, metric='euclidean', chunksize=None, convert_dtype=True, handle=None)\n",
    "\n",
    "[fonte]\n",
    "Calcula o coeficiente de silhueta médio para os dados fornecidos.\n",
    "\n",
    "Dado um conjunto de rótulos de cluster para cada amostra nos dados fornecidos, calcula a distância média intracluster (a) e a distância média do cluster mais próximo (b) para cada amostra. O coeficiente de silhueta para uma amostra é então (b - a) / max(a, b).\n",
    "\n",
    "Parâmetros\n",
    "X\n",
    "array-like, shape = (n_samples, n_features)\n",
    "Os vetores de recursos para todas as amostras.\n",
    "\n",
    "labels\n",
    "array-like, shape = (n_samples,)\n",
    "Os rótulos de cluster atribuídos para cada amostra.\n",
    "\n",
    "metric\n",
    "string\n",
    "Uma representação de string da métrica de distância a ser usada para avaliar a pontuação da silhueta. As opções disponíveis são \"cityblock\", \"cosine\", \"euclidean\", \"l1\", \"l2\", \"manhattan\" e \"sqeuclidean\".\n",
    "\n",
    "chunksize\n",
    "inteiro (padrão = Nenhum)\n",
    "Um inteiro, 1 <= chunksize <= n_samples para agrupar os cálculos da matriz de distância em pares, de modo a reduzir o uso de memória quadrática de ter toda a matriz de distância em pares na memória da GPU. Se Nenhum, o chunksize será automaticamente definido como 40000, o que por meio de experimentos provou ser um número seguro para o cálculo ser executado em uma GPU com 16 GB de VRAM.\n",
    "\n",
    "handle\n",
    "cuml.Handle\n",
    "Especifica o cuml.handle que contém o estado CUDA interno para cálculos neste modelo. Mais importante, isso especifica o fluxo CUDA que será usado para os cálculos do modelo, para que os usuários possam executar diferentes modelos simultaneamente em diferentes fluxos, criando identificadores em vários fluxos. Se for Nenhum, um novo é criado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install -c rapidsai -c conda-forge -c nvidia nx-cugraph\n",
    "\n",
    "# %pip install sentence_transformers\n",
    "# %pip install seaborn\n",
    "# %pip install nltk\n",
    "# %pip install contextualSpellCheck\n",
    "# %pip install langdetect\n",
    "# %pip install ipywidgets\n",
    "# %pip install huggingface_hub\n",
    "# %pip install --upgrade httpcore\n",
    "# %pip install --upgrade httpx\n",
    "\n",
    "## Importações não mais usadas na classe de análise de embeedings\n",
    "# from transformers.tokenization_utils_base import TruncationStrategy\n",
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "# from transformers import pipeline, TranslationPipeline\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# from langdetect import detect\n",
    "# import contextualSpellCheck\n",
    "\n",
    "## GoogleTranslate apresentou muitos conflitos e não funcionou, optei por langdetect\n",
    "## Versão httpx==0.13.3 Para compatibilizar com GoogleTranslate, porém atrapalha openai 1.44.0 e jupyterlab 4.2.4\n",
    "# ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
    "# openai 1.44.0 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
    "# jupyterlab 4.2.4 requires httpx>=0.25.0, but you have httpx 0.13.3 which is incompatible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Escolha multicritério para modelo de Embeddings</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No contexto de aprendizado de máquina e processamento de linguagem natural, \"embeddings\" se refere à representação matemática de um objeto (como uma palavra, frase ou imagem) em um espaço vetorial.\n",
    "\n",
    "Para analisar a qualidade dos clusters criados a partir do embeeding com modelos pré-treinados foi criada a classe EmbeddingsMulticriteriaAnalysis para oferecer uma análise completa e cientificamente válida para a escolha do melhor modelo de embedding. Foram utilizadas práticas de múltiplas rodadas e validação cruzada na classe nos métodos evaluate_clustering e calcular_pontuacao_multicriterio.\n",
    "\n",
    "O método evaluate_clustering executa o processo de clustering múltiplas vezes e calcula a média e o desvio padrão das métricas. A validação cruzada é incorporada dividindo os embeddings em conjuntos de treinamento e teste.\n",
    "\n",
    "O método calcular_pontuacao_multicriterio calcula a pontuação multicritério para cada algoritmo usando as médias das métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "!python -c \"import torch; print(torch.__version__)\"\n",
    "!python -c \"import torchvision; print(torchvision.__version__)\"\n",
    "\n",
    "# !pip uninstall torchvision\n",
    "# !pip install torchvision\n",
    "# !pip uninstall retrying -y\n",
    "# !pip install retry\n",
    "# !pip install GPUtil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar embeedings com cada um dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instanciar a classe para manipular modelos da biblioteca SenteceTransformer\n",
    "from gml_embeddings_analyser import EmbeddingsMulticriteriaAnalysis\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Definir os nomes de modelo do SentenceTransformer a serem comparados\n",
    "model_names = [\n",
    "    'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'all-MiniLM-L6-v2',\n",
    "    'all-mpnet-base-v2'\n",
    "]\n",
    "\n",
    "# Criar uma instância da classe EmbeddingsMulticriteriaAnalysis\n",
    "analise = EmbeddingsMulticriteriaAnalysis(\n",
    "    model_names=model_names,\n",
    "    models= [SentenceTransformer(model_name) for model_name in model_names]\n",
    ")\n",
    "\n",
    "## Gerar e salvar embeedings com cada modelo (15min/modelo em média)\n",
    "embeddings_dict = analise.generate_embeddings_batch()\n",
    "analise.save_embeddings_dict(\"embeddings_funding.pt\")\n",
    "\n",
    "print(\"Conteúdo de self.embeddings:\", analise.embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar embeedings e avaliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 12:11:40,628 - INFO - Use pytorch device_name: cuda\n",
      "2024-11-09 12:11:40,628 - INFO - Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2\n",
      "2024-11-09 12:11:43,387 - INFO - Use pytorch device_name: cuda\n",
      "2024-11-09 12:11:43,387 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2024-11-09 12:11:45,066 - INFO - Use pytorch device_name: cuda\n",
      "2024-11-09 12:11:45,067 - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "    Modelo de Base: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Tarefas aplicáveis: semantic textual similarity, semantic search, paraphrase mining, text classification, clustering\n",
      "Número de features: 384\n",
      "Detalhes da classe: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "    Modelo de Base: sentence-transformers/all-MiniLM-L6-v2\n",
      "Tarefas aplicáveis: semantic textual similarity, semantic search, paraphrase mining, text classification, clustering\n",
      "Número de features: 384\n",
      "Detalhes da classe: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "    Modelo de Base: sentence-transformers/all-mpnet-base-v2\n",
      "Tarefas aplicáveis: semantic textual similarity, semantic search, paraphrase mining, text classification, clustering\n",
      "Número de features: 768\n",
      "Detalhes da classe: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Arquivo de embeddings carregado: embeddings_funding.pt\n",
      "Número de modelos carregados: 3\n",
      "\n",
      "Iniciando avaliação de clustering com cuML...\n",
      "Avaliando modelo: paraphrase-multilingual-MiniLM-L12-v2\n",
      "  Split 1:\n",
      "    Tamanho de X_train: (276, 384)\n",
      "    Tamanho de X_test: (70, 384)\n",
      "    Tamanho de cluster_labels: (70,)\n",
      "    Tamanho de X_test_cp: (70, 384)\n",
      "    Tamanho de cluster_labels_cp: (70,)\n",
      "  Split 2:\n",
      "    Tamanho de X_train: (277, 384)\n",
      "    Tamanho de X_test: (69, 384)\n",
      "    Tamanho de cluster_labels: (69,)\n",
      "    Tamanho de X_test_cp: (69, 384)\n",
      "    Tamanho de cluster_labels_cp: (69,)\n",
      "  Split 3:\n",
      "    Tamanho de X_train: (277, 384)\n",
      "    Tamanho de X_test: (69, 384)\n",
      "    Tamanho de cluster_labels: (69,)\n",
      "    Tamanho de X_test_cp: (69, 384)\n",
      "    Tamanho de cluster_labels_cp: (69,)\n",
      "  Split 4:\n",
      "    Tamanho de X_train: (277, 384)\n",
      "    Tamanho de X_test: (69, 384)\n",
      "    Tamanho de cluster_labels: (69,)\n",
      "    Tamanho de X_test_cp: (69, 384)\n",
      "    Tamanho de cluster_labels_cp: (69,)\n",
      "  Split 5:\n",
      "    Tamanho de X_train: (277, 384)\n",
      "    Tamanho de X_test: (69, 384)\n",
      "    Tamanho de cluster_labels: (69,)\n",
      "    Tamanho de X_test_cp: (69, 384)\n",
      "    Tamanho de cluster_labels_cp: (69,)\n",
      "  Split 1:\n",
      "    Tamanho de X_train: (276, 384)\n",
      "    Tamanho de X_test: (70, 384)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "## Instanciar a classe para manipular modelos da biblioteca SenteceTransformer\n",
    "from gml_embeddings_analyser import EmbeddingsMulticriteriaAnalysis\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Definir os nomes de modelo do SentenceTransformer a serem comparados\n",
    "model_names = [\n",
    "    'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'all-MiniLM-L6-v2',\n",
    "    'all-mpnet-base-v2'\n",
    "]\n",
    "\n",
    "# Criar uma instância da classe EmbeddingsMulticriteriaAnalysis\n",
    "analise = EmbeddingsMulticriteriaAnalysis(\n",
    "    model_names=model_names,\n",
    "    models= [SentenceTransformer(model_name) for model_name in model_names]\n",
    ")\n",
    "\n",
    "## Carregar os embeddings previamente gerados (em caso de erro na avaliação a seguir)\n",
    "embeddings_dict = analise.load_embeddings_dict(\"embeddings_funding.pt\")\n",
    "\n",
    "## Realizar a análise de clusterização\n",
    "resultados = analise.evaluate_clustering(embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretação das Métricas\n",
    "\n",
    "     Silhouette score: quanto maior melhor clustering, por coesão e separação [-1 a 1]\n",
    "    Calinski_Harabasz: quanto maior melhor clustering, sugere uma melhor separação\n",
    "       Davies-Bouldin: quanto menor melhor clustering, clusters mais distintos e compactos\n",
    "\n",
    "\n",
    "Portanto, a lógica correta para cada métrica é:\n",
    "\n",
    "   Silhouette: Quanto maior, melhor.\n",
    "\n",
    "   Calinski-Harabasz: Quanto maior, melhor.\n",
    "\n",
    "   Davies-Bouldin: Quanto menor, melhor.\n",
    "   \n",
    "   Tempo: Quanto menor, melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar resultados salvos e gerar relatórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-09 16:19:25,019 - INFO - Use pytorch device_name: cuda\n",
      "2024-11-09 16:19:25,019 - INFO - Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2\n",
      "2024-11-09 16:19:27,935 - INFO - Use pytorch device_name: cuda\n",
      "2024-11-09 16:19:27,935 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2024-11-09 16:19:29,595 - INFO - Use pytorch device_name: cuda\n",
      "2024-11-09 16:19:29,595 - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "    Modelo de Base: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Tarefas aplicáveis: semantic textual similarity, semantic search, paraphrase mining, text classification, clustering\n",
      "Número de features: 384\n",
      "Detalhes da classe: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "    Modelo de Base: sentence-transformers/all-MiniLM-L6-v2\n",
      "Tarefas aplicáveis: semantic textual similarity, semantic search, paraphrase mining, text classification, clustering\n",
      "Número de features: 384\n",
      "Detalhes da classe: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "    Modelo de Base: sentence-transformers/all-mpnet-base-v2\n",
      "Tarefas aplicáveis: semantic textual similarity, semantic search, paraphrase mining, text classification, clustering\n",
      "Número de features: 768\n",
      "Detalhes da classe: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "paraphrase-multilingual-MiniLM-L12-v2\n",
      "KMeans\n",
      "  resultados: [{'silhouette': 0.36944809556007385, 'calinski_harabasz': 9.128763221659874, 'davies_bouldin': 1.392183098581599}, {'silhouette': 0.5765888094902039, 'calinski_harabasz': 13.889814757472392, 'davies_bouldin': 1.038760221368719}, {'silhouette': 0.42382174730300903, 'calinski_harabasz': 12.838740903106487, 'davies_bouldin': 1.4065865059642524}, {'silhouette': 0.39333781599998474, 'calinski_harabasz': 9.440283457465332, 'davies_bouldin': 1.0879816776417903}, {'silhouette': 0.4475652277469635, 'calinski_harabasz': 13.135452847306228, 'davies_bouldin': 1.1128031630478814}]\n",
      "  tempo: 0.012588214874267579\n",
      "DBSCAN\n",
      "  resultados: [{'silhouette': 0.321819931268692, 'calinski_harabasz': 15.090530177310887, 'davies_bouldin': 1.0150550175803155}, {'silhouette': 0.3629002273082733, 'calinski_harabasz': 15.01800144328273, 'davies_bouldin': 1.3603955652773623}, {'silhouette': 0.30377787351608276, 'calinski_harabasz': 12.566249869190711, 'davies_bouldin': 1.0454660416274628}, {'silhouette': 0.47120997309684753, 'calinski_harabasz': 37.11870438971799, 'davies_bouldin': 0.8746716010205505}, {'silhouette': 0.4005122184753418, 'calinski_harabasz': 17.192192268942744, 'davies_bouldin': 0.9109259535059275}]\n",
      "  tempo: 0.03151416778564453\n",
      "HDBSCAN\n",
      "  resultados: [{'silhouette': 0.08112388849258423, 'calinski_harabasz': 3.727802916575142, 'davies_bouldin': 5.008396768435895}, {'silhouette': 0.35145628452301025, 'calinski_harabasz': 17.731082951832345, 'davies_bouldin': 2.2170810939113514}, {'silhouette': 0.46700912714004517, 'calinski_harabasz': 20.917286120405592, 'davies_bouldin': 2.2078970025967504}, {'silhouette': 0.2795657217502594, 'calinski_harabasz': 13.09643110866392, 'davies_bouldin': 2.5134467510105982}, {'silhouette': 0.3146785497665405, 'calinski_harabasz': 13.737587413456234, 'davies_bouldin': 3.123694839920521}]\n",
      "  tempo: 0.018944501876831055\n",
      "all-MiniLM-L6-v2\n",
      "KMeans\n",
      "  resultados: [{'silhouette': 0.5687251091003418, 'calinski_harabasz': 16.096398340594455, 'davies_bouldin': 1.683627919674124}, {'silhouette': 0.5310932397842407, 'calinski_harabasz': 12.243313754884943, 'davies_bouldin': 1.5041806696779907}, {'silhouette': 0.40367186069488525, 'calinski_harabasz': 9.375604508301139, 'davies_bouldin': 1.7530805903269604}, {'silhouette': 0.367864727973938, 'calinski_harabasz': 8.050833877608303, 'davies_bouldin': 2.0754902541392357}, {'silhouette': 0.4317035675048828, 'calinski_harabasz': 9.644029551066527, 'davies_bouldin': 1.7757671665447756}]\n",
      "  tempo: 0.005193233489990234\n",
      "DBSCAN\n",
      "  resultados: [{'silhouette': 0.3446495532989502, 'calinski_harabasz': 14.971211640729464, 'davies_bouldin': 1.0244914241051364}, {'silhouette': 0.46197471022605896, 'calinski_harabasz': 31.71660045891539, 'davies_bouldin': 0.9876323089865086}, {'silhouette': 0.4486734867095947, 'calinski_harabasz': 14.39153081716427, 'davies_bouldin': 1.010062731975642}, {'silhouette': 0.3450596034526825, 'calinski_harabasz': 23.658204271136967, 'davies_bouldin': 0.9912511282118963}, {'silhouette': 0.2945430278778076, 'calinski_harabasz': 12.603687875903017, 'davies_bouldin': 1.017487858872755}]\n",
      "  tempo: 0.0007359027862548828\n",
      "HDBSCAN\n",
      "  resultados: [{'silhouette': 0.38609203696250916, 'calinski_harabasz': 15.550309072463607, 'davies_bouldin': 1.849119169782286}, {'silhouette': 0.40618765354156494, 'calinski_harabasz': 18.44529154979239, 'davies_bouldin': 1.6469062743666016}, {'silhouette': 0.40603163838386536, 'calinski_harabasz': 18.504073407700044, 'davies_bouldin': 1.5733347425423532}, {'silhouette': 0.44058749079704285, 'calinski_harabasz': 16.562511725148006, 'davies_bouldin': 1.864985924619089}, {'silhouette': 0.30787357687950134, 'calinski_harabasz': 10.707324776535689, 'davies_bouldin': 1.4798220921527871}]\n",
      "  tempo: 0.005246496200561524\n",
      "all-mpnet-base-v2\n",
      "KMeans\n",
      "  resultados: [{'silhouette': 0.4804669916629791, 'calinski_harabasz': 10.979667849944118, 'davies_bouldin': 1.7801389644628194}, {'silhouette': 0.39930057525634766, 'calinski_harabasz': 8.928410834278827, 'davies_bouldin': 2.002528953609854}, {'silhouette': 0.4487563669681549, 'calinski_harabasz': 10.40405051668342, 'davies_bouldin': 1.8713470011592948}, {'silhouette': 0.528346061706543, 'calinski_harabasz': 14.026803905497792, 'davies_bouldin': 1.7657520719977011}, {'silhouette': 0.4437907040119171, 'calinski_harabasz': 10.62576036551963, 'davies_bouldin': 1.9051333448836152}]\n",
      "  tempo: 0.005798912048339844\n",
      "DBSCAN\n",
      "  resultados: [{'silhouette': 0.42487263679504395, 'calinski_harabasz': 15.343935806042023, 'davies_bouldin': 0.9829564996425485}, {'silhouette': 0.4658724367618561, 'calinski_harabasz': 16.34382550124042, 'davies_bouldin': 0.9861804218576706}, {'silhouette': 0.41399285197257996, 'calinski_harabasz': 19.492051110894806, 'davies_bouldin': 0.985144313517586}, {'silhouette': 0.3853081464767456, 'calinski_harabasz': 27.278442404915328, 'davies_bouldin': 0.9608305461046283}, {'silhouette': 0.3923729360103607, 'calinski_harabasz': 16.850049452764235, 'davies_bouldin': 0.9630388014304438}]\n",
      "  tempo: 0.0007878780364990234\n",
      "HDBSCAN\n",
      "  resultados: [{'silhouette': 0.36569419503211975, 'calinski_harabasz': 13.203675861712073, 'davies_bouldin': 1.8089380902996552}, {'silhouette': 0.3096264898777008, 'calinski_harabasz': 12.81978953521317, 'davies_bouldin': 2.060636705042862}, {'silhouette': 0.37072473764419556, 'calinski_harabasz': 13.865273242782145, 'davies_bouldin': 2.159604671050154}, {'silhouette': 0.435062974691391, 'calinski_harabasz': 15.255573025284543, 'davies_bouldin': 2.118793804487504}, {'silhouette': 0.4740828275680542, 'calinski_harabasz': 15.155839615027064, 'davies_bouldin': 1.420020961194831}]\n",
      "  tempo: 0.004978036880493164\n"
     ]
    }
   ],
   "source": [
    "## Instanciar a classe para manipular modelos da biblioteca SenteceTransformer\n",
    "from gml_embeddings_analyser import EmbeddingsMulticriteriaAnalysis\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Definir os nomes de modelo do SentenceTransformer a serem comparados\n",
    "model_names = [\n",
    "    'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'all-MiniLM-L6-v2',\n",
    "    'all-mpnet-base-v2'\n",
    "]\n",
    "\n",
    "# Criar uma instância da classe EmbeddingsMulticriteriaAnalysis\n",
    "analise = EmbeddingsMulticriteriaAnalysis(\n",
    "    model_names=model_names,\n",
    "    models= [SentenceTransformer(model_name) for model_name in model_names]\n",
    ")\n",
    "\n",
    "## Realizar a análise de clusterização\n",
    "resultados = analise.load_results()\n",
    "from pprint import pprint\n",
    "\n",
    "for i,j in resultados.items():\n",
    "    print(i)\n",
    "    for k,l in j.items():\n",
    "        print(k)\n",
    "        for m,n in l.items():\n",
    "            print(f\"  {m}: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define os pesos para cada métrica (ajuste os valores conforme necessário)\n",
    "pesos = {\n",
    "    \"silhouette\": 0.3,\n",
    "    \"calinski_harabasz\": 0.3,\n",
    "    \"davies_bouldin\": 0.3,\n",
    "    \"tempo\": 0.1\n",
    "}\n",
    "\n",
    "pontuacoes = analise.calcular_pontuacao_multicriterio(resultados, pesos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paraphrase-multilingual-MiniLM-L12-v2': {'KMeans': 0.5763797457979797,\n",
       "  'DBSCAN': 0.5058100678855925,\n",
       "  'HDBSCAN': 0.44878652061991997},\n",
       " 'all-MiniLM-L6-v2': {'KMeans': 0.6026134049226664,\n",
       "  'DBSCAN': 0.6045122346593834,\n",
       "  'HDBSCAN': 0.5376007942355633},\n",
       " 'all-mpnet-base-v2': {'KMeans': 0.6006195973478434,\n",
       "  'DBSCAN': 0.6099728814086371,\n",
       "  'HDBSCAN': 0.5141425560383925}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pontuacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O melhor modelo é: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "legendgroup": "paraphrase-multilingual-MiniLM-L12-v2",
         "marker": {
          "color": "blue"
         },
         "name": "paraphrase-multilingual-MiniLM-L12-v2",
         "offsetgroup": "0",
         "showlegend": true,
         "type": "bar",
         "x": [
          "KMeans"
         ],
         "xaxis": "x",
         "y": [
          0.442152339220047
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "all-MiniLM-L6-v2",
         "marker": {
          "color": "green"
         },
         "name": "all-MiniLM-L6-v2",
         "offsetgroup": "1",
         "showlegend": true,
         "type": "bar",
         "x": [
          "KMeans"
         ],
         "xaxis": "x",
         "y": [
          0.4606117010116577
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "all-mpnet-base-v2",
         "marker": {
          "color": "yellow"
         },
         "name": "all-mpnet-base-v2",
         "offsetgroup": "2",
         "showlegend": true,
         "type": "bar",
         "x": [
          "KMeans"
         ],
         "xaxis": "x",
         "y": [
          0.46013213992118834
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "paraphrase-multilingual-MiniLM-L12-v2",
         "marker": {
          "color": "blue"
         },
         "name": "paraphrase-multilingual-MiniLM-L12-v2",
         "offsetgroup": "0",
         "showlegend": false,
         "type": "bar",
         "x": [
          "DBSCAN"
         ],
         "xaxis": "x",
         "y": [
          0.3720440447330475
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "all-MiniLM-L6-v2",
         "marker": {
          "color": "green"
         },
         "name": "all-MiniLM-L6-v2",
         "offsetgroup": "1",
         "showlegend": false,
         "type": "bar",
         "x": [
          "DBSCAN"
         ],
         "xaxis": "x",
         "y": [
          0.3789800763130188
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "all-mpnet-base-v2",
         "marker": {
          "color": "yellow"
         },
         "name": "all-mpnet-base-v2",
         "offsetgroup": "2",
         "showlegend": false,
         "type": "bar",
         "x": [
          "DBSCAN"
         ],
         "xaxis": "x",
         "y": [
          0.41648380160331727
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "paraphrase-multilingual-MiniLM-L12-v2",
         "marker": {
          "color": "blue"
         },
         "name": "paraphrase-multilingual-MiniLM-L12-v2",
         "offsetgroup": "0",
         "showlegend": false,
         "type": "bar",
         "x": [
          "HDBSCAN"
         ],
         "xaxis": "x",
         "y": [
          0.2987667143344879
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "all-MiniLM-L6-v2",
         "marker": {
          "color": "green"
         },
         "name": "all-MiniLM-L6-v2",
         "offsetgroup": "1",
         "showlegend": false,
         "type": "bar",
         "x": [
          "HDBSCAN"
         ],
         "xaxis": "x",
         "y": [
          0.38935447931289674
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "all-mpnet-base-v2",
         "marker": {
          "color": "yellow"
         },
         "name": "all-mpnet-base-v2",
         "offsetgroup": "2",
         "showlegend": false,
         "type": "bar",
         "x": [
          "HDBSCAN"
         ],
         "xaxis": "x",
         "y": [
          0.39103824496269224
         ],
         "yaxis": "y"
        },
        {
         "legendgroup": "paraphrase-multilingual-MiniLM-L12-v2",
         "marker": {
          "color": "blue"
         },
         "name": "paraphrase-multilingual-MiniLM-L12-v2",
         "offsetgroup": "0",
         "showlegend": false,
         "type": "bar",
         "x": [
          "KMeans"
         ],
         "xaxis": "x2",
         "y": [
          11.686611037402063
         ],
         "yaxis": "y2"
        },
        {
         "legendgroup": "all-MiniLM-L6-v2",
         "marker": {
          "color": "green"
         },
         "name": "all-MiniLM-L6-v2",
         "offsetgroup": "1",
         "showlegend": false,
         "type": "bar",
         "x": [
          "KMeans"
         ],
         "xaxis": "x2",
         "y": [
          11.082036006491075
         ],
         "yaxis": "y2"
        },
        {
         "legendgroup": "all-mpnet-base-v2",
         "marker": {
          "color": "yellow"
         },
         "name": "all-mpnet-base-v2",
         "offsetgroup": "2",
         "showlegend": false,
         "type": "bar",
         "x": [
          "KMeans"
         ],
         "xaxis": "x2",
         "y": [
          10.992938694384758
         ],
         "yaxis": "y2"
        },
        {
         "legendgroup": "paraphrase-multilingual-MiniLM-L12-v2",
         "marker": {
          "color": "blue"
         },
         "name": "paraphrase-multilingual-MiniLM-L12-v2",
         "offsetgroup": "0",
         "showlegend": false,
         "type": "bar",
         "x": [
          "DBSCAN"
         ],
         "xaxis": "x2",
         "y": [
          19.397135629689014
         ],
         "yaxis": "y2"
        },
        {
         "legendgroup": "all-MiniLM-L6-v2",
         "marker": {
          "color": "green"
         },
         "name": "all-MiniLM-L6-v2",
         "offsetgroup": "1",
         "showlegend": false,
         "type": "bar",
         "x": [
          "DBSCAN"
         ],
         "xaxis": "x2",
         "y": [
          19.468247012769822
         ],
         "yaxis": "y2"
        },
        {
         "legendgroup": "all-mpnet-base-v2",
         "marker": {
          "color": "yellow"
         },
         "name": "all-mpnet-base-v2",
         "offsetgroup": "2",
         "showlegend": false,
         "type": "bar",
         "x": [
          "DBSCAN"
         ],
         "xaxis": "x2",
         "y": [
          19.06166085517136
         ],
         "yaxis": "y2"
        },
        {
         "legendgroup": "paraphrase-multilingual-MiniLM-L12-v2",
         "marker": {
          "color": "blue"
         },
         "name": "paraphrase-multilingual-MiniLM-L12-v2",
         "offsetgroup": "0",
         "showlegend": false,
         "type": "bar",
         "x": [
          "HDBSCAN"
         ],
         "xaxis": "x2",
         "y": [
          13.842038102186649
         ],
         "yaxis": "y2"
        },
        {
         "legendgroup": "all-MiniLM-L6-v2",
         "marker": {
          "color": "green"
         },
         "name": "all-MiniLM-L6-v2",
         "offsetgroup": "1",
         "showlegend": false,
         "type": "bar",
         "x": [
          "HDBSCAN"
         ],
         "xaxis": "x2",
         "y": [
          15.953902106327948
         ],
         "yaxis": "y2"
        },
        {
         "legendgroup": "all-mpnet-base-v2",
         "marker": {
          "color": "yellow"
         },
         "name": "all-mpnet-base-v2",
         "offsetgroup": "2",
         "showlegend": false,
         "type": "bar",
         "x": [
          "HDBSCAN"
         ],
         "xaxis": "x2",
         "y": [
          14.060030256003799
         ],
         "yaxis": "y2"
        },
        {
         "legendgroup": "paraphrase-multilingual-MiniLM-L12-v2",
         "marker": {
          "color": "blue"
         },
         "name": "paraphrase-multilingual-MiniLM-L12-v2",
         "offsetgroup": "0",
         "showlegend": false,
         "type": "bar",
         "x": [
          "KMeans"
         ],
         "xaxis": "x3",
         "y": [
          1.2076629333208486
         ],
         "yaxis": "y3"
        },
        {
         "legendgroup": "all-MiniLM-L6-v2",
         "marker": {
          "color": "green"
         },
         "name": "all-MiniLM-L6-v2",
         "offsetgroup": "1",
         "showlegend": false,
         "type": "bar",
         "x": [
          "KMeans"
         ],
         "xaxis": "x3",
         "y": [
          1.7584293200726175
         ],
         "yaxis": "y3"
        },
        {
         "legendgroup": "all-mpnet-base-v2",
         "marker": {
          "color": "yellow"
         },
         "name": "all-mpnet-base-v2",
         "offsetgroup": "2",
         "showlegend": false,
         "type": "bar",
         "x": [
          "KMeans"
         ],
         "xaxis": "x3",
         "y": [
          1.8649800672226569
         ],
         "yaxis": "y3"
        },
        {
         "legendgroup": "paraphrase-multilingual-MiniLM-L12-v2",
         "marker": {
          "color": "blue"
         },
         "name": "paraphrase-multilingual-MiniLM-L12-v2",
         "offsetgroup": "0",
         "showlegend": false,
         "type": "bar",
         "x": [
          "DBSCAN"
         ],
         "xaxis": "x3",
         "y": [
          1.0413028358023237
         ],
         "yaxis": "y3"
        },
        {
         "legendgroup": "all-MiniLM-L6-v2",
         "marker": {
          "color": "green"
         },
         "name": "all-MiniLM-L6-v2",
         "offsetgroup": "1",
         "showlegend": false,
         "type": "bar",
         "x": [
          "DBSCAN"
         ],
         "xaxis": "x3",
         "y": [
          1.0061850904303877
         ],
         "yaxis": "y3"
        },
        {
         "legendgroup": "all-mpnet-base-v2",
         "marker": {
          "color": "yellow"
         },
         "name": "all-mpnet-base-v2",
         "offsetgroup": "2",
         "showlegend": false,
         "type": "bar",
         "x": [
          "DBSCAN"
         ],
         "xaxis": "x3",
         "y": [
          0.9756301165105754
         ],
         "yaxis": "y3"
        },
        {
         "legendgroup": "paraphrase-multilingual-MiniLM-L12-v2",
         "marker": {
          "color": "blue"
         },
         "name": "paraphrase-multilingual-MiniLM-L12-v2",
         "offsetgroup": "0",
         "showlegend": false,
         "type": "bar",
         "x": [
          "HDBSCAN"
         ],
         "xaxis": "x3",
         "y": [
          3.014103291175023
         ],
         "yaxis": "y3"
        },
        {
         "legendgroup": "all-MiniLM-L6-v2",
         "marker": {
          "color": "green"
         },
         "name": "all-MiniLM-L6-v2",
         "offsetgroup": "1",
         "showlegend": false,
         "type": "bar",
         "x": [
          "HDBSCAN"
         ],
         "xaxis": "x3",
         "y": [
          1.6828336406926234
         ],
         "yaxis": "y3"
        },
        {
         "legendgroup": "all-mpnet-base-v2",
         "marker": {
          "color": "yellow"
         },
         "name": "all-mpnet-base-v2",
         "offsetgroup": "2",
         "showlegend": false,
         "type": "bar",
         "x": [
          "HDBSCAN"
         ],
         "xaxis": "x3",
         "y": [
          1.9135988464150013
         ],
         "yaxis": "y3"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "silhouette",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "calinski_harabasz",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "davies_bouldin",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "arrowhead": 4,
          "ax": 0,
          "ay": 30,
          "showarrow": true,
          "text": "Maior Melhor",
          "x": 0.23,
          "xref": "paper",
          "y": 1,
          "yref": "paper"
         },
         {
          "arrowhead": 4,
          "ax": 0,
          "ay": 30,
          "showarrow": true,
          "text": "Maior Melhor",
          "x": 0.59,
          "xref": "paper",
          "y": 1,
          "yref": "paper"
         },
         {
          "arrowhead": 4,
          "ax": 0,
          "ay": -30,
          "showarrow": true,
          "text": "Menor Melhor",
          "x": 0.77,
          "xref": "paper",
          "y": 0.9,
          "yref": "paper"
         }
        ],
        "height": 600,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Comparação da qualidade de clustering com embeedings gerados em cada um dos modelos"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.2888888888888889
         ],
         "title": {
          "text": "Algoritmo"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.35555555555555557,
          0.6444444444444445
         ],
         "title": {
          "text": "Algoritmo"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.7111111111111111,
          1
         ],
         "title": {
          "text": "Algoritmo"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": ""
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Escolher o melhor modelo\n",
    "melhor_modelo = analise.escolher_melhor_modelo(resultados)\n",
    "print(f\"O melhor modelo é: {melhor_modelo}\")\n",
    "\n",
    "# Gerar o relatório de benchmarking (opcional)\n",
    "analise.generate_report(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "template_folder = \"source/template/\"\n",
    "os.listdir(os.path.join(str(root_folder),template_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarking_reports import BenchmarkReportGenerator\n",
    "try:\n",
    "    # Criar uma instância do BenchmarkReportGenerator\n",
    "    report_generator = BenchmarkReportGenerator(\"benchmark_report.html\") \n",
    "\n",
    "    # Gerar o relatório HTML\n",
    "    report_generator.generate_beckmarking_clustering_report(resultados, melhor_modelo)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao gerar relatório: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(template_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montar Camada de Pesquisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessar o tensor de embeddings para o modelo 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "best_embeddings_tensor = embeddings_dict.get('paraphrase-multilingual-MiniLM-L12-v2') # type: ignore\n",
    "\n",
    "# Exibir as dimensões do tensor\n",
    "if best_embeddings_tensor is not None:\n",
    "    print(\"Dimensões do tensor:\", best_embeddings_tensor.shape)\n",
    "else:\n",
    "    print(\"Modelo não encontrado no dicionário de embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "from git import Repo\n",
    "\n",
    "# Acessar o tensor de embeddings para o modelo 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "editais_embeddings = embeddings_dict.get('paraphrase-multilingual-MiniLM-L12-v2') # type: ignore\n",
    "\n",
    "# Carregar os currículos\n",
    "filename = \"input_curriculos.json\"\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "pathfilename = os.path.join(str(root_folder), \"_data\", \"out_json\",filename)\n",
    "with open(pathfilename, \"r\", encoding='utf-8') as f:\n",
    "    curriculos = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,curriculo in enumerate(curriculos):\n",
    "    print([x.get('Descrição') for x in curriculos[n].get('Linhas de Pesquisa')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,curriculo in enumerate(curriculos):\n",
    "    print([x.get('titulo') for x in curriculos[n].get('Produções').get('Artigos completos publicados em periódicos')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curriculos[1].get('Áreas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curriculos[1].get('Áreas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerar embeedings para currículos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Instanciar o modelo de linguagem (use o mesmo modelo usado para os editais)\n",
    "modelo = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')  # Substitua pelo seu modelo\n",
    "\n",
    "# Extrair o texto dos currículos\n",
    "curriculos_texto = []\n",
    "for curriculo in curriculos:\n",
    "    texto = \"\"\n",
    "    for key, value in curriculo.items():\n",
    "        if isinstance(value, str):\n",
    "            texto += value + \" \"\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, str):\n",
    "                    texto += item + \" \"\n",
    "                elif isinstance(item, dict):\n",
    "                    for subkey, subvalue in item.items():\n",
    "                        texto += str(subvalue) + \" \"\n",
    "    curriculos_texto.append(texto)\n",
    "\n",
    "# Gerar os embeddings dos currículos\n",
    "curriculos_embeddings = modelo.encode(curriculos_texto, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a similaridade do cosseno entre os embeddings dos editais e dos currículos\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similaridade = cosine_similarity(editais_embeddings.cpu().numpy(), curriculos_embeddings.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o grafo de conhecimento\n",
    "import networkx as nx\n",
    "\n",
    "# Criar um grafo direcionado\n",
    "grafo = nx.DiGraph()\n",
    "\n",
    "# Adicionar nós para os editais\n",
    "for i, edital_embedding in enumerate(editais_embeddings):\n",
    "    grafo.add_node(f\"edital_{i}\")\n",
    "\n",
    "# Adicionar nós para os currículos\n",
    "for i, curriculo_embedding in enumerate(curriculos_embeddings):\n",
    "    grafo.add_node(f\"curriculo_{i}\")\n",
    "\n",
    "# Adicionar arestas com base na similaridade (limiar de 0.25)\n",
    "limiar_similaridade = 0.25\n",
    "for i, edital_embedding in enumerate(editais_embeddings):\n",
    "    for j, curriculo_embedding in enumerate(curriculos_embeddings):\n",
    "        if similaridade[i, j] > limiar_similaridade:\n",
    "            grafo.add_edge(f\"edital_{i}\", f\"curriculo_{j}\", weight=similaridade[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar as comunidades (utilizando o algoritmo Louvain)\n",
    "\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "# Encontrar as comunidades\n",
    "comunidades = list(greedy_modularity_communities(grafo)) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exibir o grafo com Pyvis\n",
    "# from pyvis.network import Network\n",
    "\n",
    "# # Criar uma rede PyVis\n",
    "# net = Network(notebook=True, directed=True)\n",
    "\n",
    "# # Adicionar nós e arestas ao grafo PyVis\n",
    "# net.from_nx(grafo)\n",
    "\n",
    "# # Configurar a cor dos nós por comunidade\n",
    "# for i, comunidade in enumerate(comunidades):\n",
    "#     cor = f\"hsl({i * 360 / len(comunidades)}, 100%, 50%)\"\n",
    "#     for no in comunidade:\n",
    "#         net.get_node(no)[\"color\"] = cor\n",
    "\n",
    "# # Exibir o grafo\n",
    "# net.show(\"grafo_conhecimento.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recomendar editais\n",
    "def recomendar_editais(curriculo_id, grafo, similaridade, top_n=5):\n",
    "    \"\"\"\n",
    "    Recomenda os editais mais propícios para um currículo com base no grafo de conhecimento.\n",
    "    \"\"\"\n",
    "    editais_similares = []\n",
    "    for no in grafo.neighbors(curriculo_id):\n",
    "        editais_similares.append((no, grafo.get_edge_data(curriculo_id, no)['weight']))\n",
    "    editais_similares.sort(key=lambda x: x[1], reverse=True)\n",
    "    return editais_similares[:top_n]\n",
    "\n",
    "# Exemplo de recomendação para o currículo 0\n",
    "curriculo_id = \"curriculo_0\"\n",
    "editais_recomendados = recomendar_editais(curriculo_id, grafo, similaridade)\n",
    "print(f\"Editais recomendados para o currículo {curriculo_id}: {editais_recomendados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montagem Grafo de Conhecimento Artigos - Fomento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar embeeding de Artigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from googletrans import Translator\n",
    "from json import JSONDecodeError\n",
    "from git import Repo\n",
    "\n",
    "## Instanciar a classe para manipular modelos da biblioteca SenteceTransformer\n",
    "from gml_embeddings_analyser import EmbeddingsMulticriteriaAnalysis\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Definir os nomes de modelo do SentenceTransformer a serem comparados\n",
    "model_names = [\n",
    "    'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'all-MiniLM-L6-v2',\n",
    "    'all-mpnet-base-v2'\n",
    "]\n",
    "\n",
    "# Criar uma instância da classe EmbeddingsMulticriteriaAnalysis\n",
    "analise = EmbeddingsMulticriteriaAnalysis(\n",
    "    model_names=model_names,\n",
    "    models= [SentenceTransformer(model_name) for model_name in model_names]\n",
    ")\n",
    "\n",
    "## Carregar os embeddings previamente gerados\n",
    "embeddings_dict = analise.load_embeddings_dict(\"embeddings_dict_gpu.pt\")\n",
    "\n",
    "best_model_name = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "print(f\"Modelo escolhido para gerar embeedings: {best_model_name}\")\n",
    "\n",
    "# Acessar o tensor de embeddings gerados com modelo 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "editais_embeddings = embeddings_dict.get(best_model_name) # type: ignore\n",
    "\n",
    "# Exibir as dimensões do tensor\n",
    "if editais_embeddings is not None:\n",
    "    print(\"Dimensões do tensor:\", editais_embeddings.shape)\n",
    "else:\n",
    "    print(\"Tensor com embeddings de editais não encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kgnn import KGNN\n",
    "\n",
    "# Criar uma instância do KGNN\n",
    "kgnn = KGNN(\n",
    "    embedding_model_name=\"paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    neo4j_uri=\"bolt://localhost:7687\",\n",
    "    neo4j_user=\"neo4j\",\n",
    "    neo4j_password=\"password\"\n",
    ")\n",
    "\n",
    "# Carregar os currículos\n",
    "filename = \"input_curriculos.json\"\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "pathfilename = os.path.join(str(root_folder), \"_data\", \"out_json\",filename)\n",
    "with open(pathfilename, \"r\", encoding='utf-8') as f:\n",
    "    curriculos = json.load(f)\n",
    "\n",
    "# Criar subgrafos para cada um dos currículos\n",
    "for curriculo in curriculos:\n",
    "    try:\n",
    "        subgrafo = kgnn.criar_subgrafo_curriculo(curriculo)\n",
    "        kgnn.ingerir_subgrafo(subgrafo)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curriculos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "print(f\"Criar Label 'Pesquisador' com as propriedades:\")\n",
    "print(f\"  Label: 'Pesquisador'\")\n",
    "print(f\"  {curriculos[k].get('Identificação')}\")\n",
    "subdict_formacaoacademica = {'Formação Acadêmica': [x.get('Descrição') for x in curriculos[k].get('Formação').get('Acadêmica')]}\n",
    "print(f\"  {subdict_formacaoacademica}\")\n",
    "print(f\"  {curriculos[k].get('Áreas')}\")\n",
    "print(f\"  {[x.get('Instituição') for x in curriculos[k].get('Atuação Profissional')]}\")\n",
    "print(f\"  {curriculos[k].get('Linhas de Pesquisa')}\")\n",
    "print(f\"  {curriculos[k].get('ProjetosPesquisa')}\")\n",
    "print(f\"  {curriculos[k].get('ProjetosExtensão')}\")\n",
    "print(f\"  {curriculos[k].get('ProjetosDesenvolvimento')}\")\n",
    "print(f\"  {curriculos[k].get('Patentes e registros')}\")\n",
    "print(f\"  {curriculos[k].get('Bancas')}\")\n",
    "print(f\"  {curriculos[k].get('Orientações')}\")\n",
    "print(f\"  {curriculos[k].get('JCR2')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traduzir títulos para inglês e gerar os embeedings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "\n",
    "# Instanciar o modelo de linguagem (use o mesmo modelo usado para os editais)\n",
    "modelo = SentenceTransformer(best_model_name)\n",
    "\n",
    "# Instanciar o tradutor\n",
    "tradutor = Translator()\n",
    "\n",
    "# Extrair os títulos dos artigos publicados, traduzir para inglês (se necessário) \n",
    "# e gerar embeddings em lotes, incluindo tratamento de erros e títulos vazios\n",
    "artigos_embeddings = []\n",
    "artigos_titulos = []\n",
    "batch_size = 32\n",
    "\n",
    "for curriculo in tqdm(curriculos, desc=\"Processando currículos\"):\n",
    "    artigos = curriculo.get('Produções', {}).get('Artigos completos publicados em periódicos', [])\n",
    "    for i in tqdm(range(0, len(artigos), batch_size), desc=\"Processando artigos\", leave=False):\n",
    "        batch = artigos[i: i + batch_size]\n",
    "        titulos_batch = [artigo.get('titulo') for artigo in batch]  # Manter todos os títulos, mesmo os vazios\n",
    "\n",
    "        # Criar lista de títulos traduzidos, incluindo títulos vazios e ignorando erros\n",
    "        titulos_en = []\n",
    "        for titulo in titulos_batch:\n",
    "            if titulo:\n",
    "                try:\n",
    "                    idioma = detect(titulo)\n",
    "                    if idioma != 'en':\n",
    "                        titulo = tradutor.translate(titulo, dest='en').text # type: ignore\n",
    "                except (JSONDecodeError, Exception) as e:  # Capturar todas as exceções\n",
    "                    print(f\"Erro ao processar título: {e}\")\n",
    "                    # Opções para tratar o erro:\n",
    "                    # 1. Usar o título original: titulo = titulo\n",
    "                    # 2. Usar um título vazio: titulo = \"\"\n",
    "                    # 3. Ignorar o título: continue\n",
    "                    continue  # Ignorar o título com erro\n",
    "            else:\n",
    "                titulo = \"\"  # Usar um título vazio se o título original for None\n",
    "\n",
    "            titulos_en.append(titulo)  # Adicionar o título (traduzido ou original) à lista\n",
    "\n",
    "        # Gerar embeddings para os títulos em inglês em lote\n",
    "        if titulos_en:\n",
    "            try:\n",
    "                embeddings = modelo.encode(titulos_en, convert_to_tensor=True, batch_size=batch_size)\n",
    "                artigos_embeddings.append(embeddings)\n",
    "            except Exception as e:\n",
    "                print(f\"  Erro ao gerar embeddings: {e}\")\n",
    "                print(f\"  Título com problema: {titulo}\")\n",
    "\n",
    "# Concatenar os embeddings em um único tensor\n",
    "if artigos_embeddings:\n",
    "    artigos_embeddings = torch.cat(artigos_embeddings, dim=0)\n",
    "    print(f\"{len(curriculos)} processados com total de {len(artigos_embeddings)} embeedings de artigos gerados.\")\n",
    "    print(\"Dimensões do tensor:\", artigos_embeddings.shape)\n",
    "else:\n",
    "    print(\"Nenhum embedding de artigo foi gerado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --force-reinstall googletrans\n",
    "# !pip install --upgrade --force-reinstall googletrans==4.0.0-rc1 httpx==0.13.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes das traduções de frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funding_analyser import ENPreprocessor, BRPreprocessor\n",
    "\n",
    "# Criar uma instância do ENPreprocessor\n",
    "en_preprocessor = ENPreprocessor()\n",
    "\n",
    "# Frase em inglês para testar a tradução\n",
    "frase_portugues = \"Esta frase é em português.\"\n",
    "\n",
    "# Traduzir a frase para português\n",
    "traducao = en_preprocessor.translate_to_en([frase_portugues])[0]\n",
    "\n",
    "# Imprimir a tradução\n",
    "print(f\"Frase português: {frase_portugues}\")\n",
    "print(f\"Frase em inglês: {traducao}\")\n",
    "\n",
    "# Criar uma instância do BRPreprocessor\n",
    "br_preprocessor = BRPreprocessor()\n",
    "\n",
    "# Frase em inglês para testar a tradução\n",
    "frase_ingles = \"This is a test sentence.\"\n",
    "\n",
    "# Traduzir a frase para português\n",
    "traducao = br_preprocessor.translate_to_pt([frase_ingles])[0]\n",
    "\n",
    "# Imprimir a tradução\n",
    "print(f\"\\nFrase em inglês: {frase_ingles}\")\n",
    "print(f\"Frase português: {traducao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Preparar ambiente de desenvolvimento</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalações e testes de bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar bibliotecas de uso geral em cada ambiente virtual dos testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configurar canais e repositórios de bibliotecas\n",
    "# %conda config --add channels pypi\n",
    "# %conda config --add channels nvidia\n",
    "\n",
    "## instalar Spacy e Xformers\n",
    "# %conda uninstall pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch-nightly -c nvidia\n",
    "# %conda install --force-reinstall pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch-nightly -c nvidia\n",
    "# %conda install xformers\n",
    "# %conda install plotly\n",
    "# %conda install seaborn\n",
    "# %conda install nltk\n",
    "# %conda install -c conda-forge wordcloud\n",
    "# %conda install -c conda-forge notebook ipywidgets\n",
    "\n",
    "## Bliliotecas só disponíveis no Pip\n",
    "# %pip install sentence_transformers\n",
    "# %pip install py-cpuinfo\n",
    "\n",
    "## Instalar e testar biblioteca de gráficos Altair e Vega Datasets\n",
    "# !pip3 install altair vega_datasets\n",
    "# !pip3 install altair_viewer\n",
    "# !pip3 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Teste de instalação da bilbioteca altair\n",
    "# import altair as alt\n",
    "# from vega_datasets import data\n",
    "\n",
    "# # Criar um gráfico de exemplo\n",
    "# chart = alt.Chart(data.cars()).mark_point().encode(\n",
    "#     x='Horsepower',\n",
    "#     y='Miles_per_Gallon',\n",
    "#     tooltip=['Horsepower', 'Miles_per_Gallon']\n",
    "# ).interactive()\n",
    "\n",
    "# chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Instalações em ambientes variados</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar CUDA e CUDA Toolkit no Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Procedimento normal de instalação em Windows\n",
    "## Criar novo ambiente virtual a partir de janela do jupyter notebook\n",
    "# !conda create -n pytorch_env python=3.11\n",
    "# !conda activate pytorch_env\n",
    "\n",
    "### Configurar as Variáveis de Ambiente em Windows:\n",
    "## Para configurar ambiente do conda corretamente no seu sistema. O caminho para o executável do conda (conda.exe) deve estar incluído na variável de ambiente PATH.\n",
    "\n",
    "# No Painel de Controle do Windows:\n",
    "# Abra o menu Iniciar e procure por \"variáveis de ambiente\".\n",
    "# Clique em \"Editar as variáveis de ambiente do sistema\".\n",
    "# Na aba \"Avançado\", clique em \"Variáveis de Ambiente\".\n",
    "\n",
    "## Em \"Variáveis do sistema\", encontre a variável \"Path\" e clique em \"Editar\".\n",
    "# Adicione os seguintes caminhos, se ainda não estiverem presentes (substitua \"seu_usuario\" pelo seu nome de usuário):\n",
    "# C:\\Users\\seu_usuario\\anaconda3\n",
    "# C:\\Users\\seu_usuario\\anaconda3\\Scripts\n",
    "# C:\\Users\\seu_usuario\\anaconda3\\Library\\bin\n",
    "\n",
    "# !conda init\n",
    "\n",
    "## A partir da janela do terminal\n",
    "# Atualizar o anaconda para sua versão mais recente\n",
    "# conda update -n base -c defaults conda\n",
    "# conda update -n base -c defaults conda --force-reinstall\n",
    "\n",
    "# Se precisar de uma versão específica basta determinar o número da versão, por exemplo para 24.5.0\n",
    "# conda install conda=24.5.0\n",
    "\n",
    "# Para interagir diretamente no PowerShell é preciso ter permissão para isso, verificar no terminal com\n",
    "# Get-ExecutionPolicy\n",
    "\n",
    "# Se a política for Restricted, altere-a para RemoteSigned ou Unrestricted com o seguinte comando:\n",
    "# Set-ExecutionPolicy RemoteSigned -Scope CurrentUser\n",
    "\n",
    "# Usando direto no terminal para ativar o ambiente\n",
    "# conda activate pytorch_env\n",
    "# conda deactivate pytorch_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instalações pontuais de pacotes extra requirements.txt\n",
    "# !python.exe -m pip install --upgrade pip\n",
    "# !python3 -m pip install --upgrade pip\n",
    "# !pip3 install -r requirements.txt\n",
    "# !pip install requests beautifulsoup4 selenium pandas gitpython\n",
    "\n",
    "### Complementar instalação de modelos multilingues no SpaCy\n",
    "## Baixar modelos de de linguagem específica do SpaCy\n",
    "# !python -m spacy download pt_core_news_lg\n",
    "\n",
    "## Verificar modelos e versões instaladas no SpaCy\n",
    "# !python -m spacy validate\n",
    "\n",
    "# %pip install --upgrade ipython\n",
    "\n",
    "### Instalar extensão no VScode para renderizar mermaid\n",
    "# https://marketplace.visualstudio.com/items?itemName=bierner.markdown-mermaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Em caso de necessidade de upgrade ou reinstalação do PyTorch\n",
    "# !pip3 install --upgrade torchvision\n",
    "\n",
    "### Em caso de conflitos entre pacotes que impedem instalação\n",
    "## Exemplo: Instalar xformers com pip pode dar conflito com a bilioteca TBB\n",
    "# %pip show xformers\n",
    "# print()\n",
    "# %pip show TBB\n",
    "# %pip uninstall TBB # Se não funcionar deletar manualmente a biblioteca será reinstalada com xformers\n",
    "# %pip install xformers\n",
    "\n",
    "### Outras resoluções de conflito entre pacotes\n",
    "## 1. Limpar cache e atualizar versão do pip\n",
    "# !pip cache purge\n",
    "# !python.exe -m pip install --upgrade pip\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "## 2. Em caso de conflitos persistentes forçar atualização ou reinstalação de pacotes\n",
    "# !pip install --upgrade bottleneck\n",
    "# !python.exe -m pip install --upgrade --force-reinstall omegaconf\n",
    "\n",
    "## 3. Instalar xformers com conda pode gerenciar melhor conflitos\n",
    "%conda config --add channels pytorch\n",
    "%conda update -n base -c defaults conda\n",
    "%conda install -c conda-forge xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar instalação do PyTorch\n",
    "# Deve retornar True se o CUDA estiver disponível e a versão do cuDNN instlada\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.is_available())\n",
    "    print(torch.backends.cudnn.version())\n",
    "else:\n",
    "    print(\"CUDA não está disponível.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar CUDA e CUDA Toolkit no WSL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando se instala uma biblioteca no WSL, ela é instalada especificamente para o ambiente corrente. Isso permite ter uma versão de uma biblioteca instalada no Windows e uma versão diferente instalada no WSL, e elas não irão interferir uma na outra. Ao instalar bibliotecas no WSL, é recomendável usar o gerenciador de pacotes específico da distribuição (por exemplo, apt para distribuições baseadas em Debian/Ubuntu, pacman para Arch Linux, etc.). Isso garantirá que as bibliotecas sejam instaladas corretamente e que suas dependências sejam gerenciadas adequadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalar no sistema operacional PyTorch e CUDA Toolkit, acesse a página abeixo e escolha seus dados adequados\n",
    "\n",
    "https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No Terminal rodar com senha do sudo\n",
    "# sudo apt install python3-pip\n",
    "# sudo apt-get update\n",
    "# sudo apt-get upgrade\n",
    "\n",
    "## Depois siga as instruções oficiais da NVIDIA para instalar o CUDA Toolkit no WSL\n",
    "## Escolher a versão do CUDA que é compatível com a versão do PyTorch que você quer usar\n",
    "# https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=deb_local\n",
    "\n",
    "## O conjunto de instruções para uma instalação típica do WSL com Ubuntu é mais ou menos o seguinte:\n",
    "# wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin\n",
    "# sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "# wget https://developer.download.nvidia.com/compute/cuda/12.6.0/local_installers/cuda-repo-wsl-ubuntu-12-6-local_12.6.0-1_amd64.deb\n",
    "# sudo dpkg -i cuda-repo-wsl-ubuntu-12-6-local_12.6.0-1_amd64.deb\n",
    "# sudo cp /var/cuda-repo-wsl-ubuntu-12-6-local/cuda-*-keyring.gpg /usr/share/keyrings/\n",
    "# sudo apt-get update\n",
    "# sudo apt-get -y install cuda-toolkit-12-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para inserir os comandos direto pelo notebook seguir os passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "password = getpass.getpass('Senha sudo: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo {password} | sudo -S rm -rf /tmp/*\n",
    "!echo {password} | sudo -S apt autoremove\n",
    "!echo {password} | sudo -S apt clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo {password} | sudo -S apt install nvidia-cuda-toolkit -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo {password} | sudo -S mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://developer.download.nvidia.com/compute/cuda/12.6.0/local_installers/cuda-repo-wsl-ubuntu-12-6-local_12.6.0-1_amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo {password} | sudo -S dpkg -i cuda-repo-wsl-ubuntu-12-6-local_12.6.0-1_amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo {password} | sudo -S cp /var/cuda-repo-wsl-ubuntu-12-6-local/cuda-*-keyring.gpg /usr/share/keyrings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo {password} | sudo -S apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo {password} | sudo -S apt-get -y install cuda-toolkit-12-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar CUDA e CUDA Toolkit no Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar o Conda e driver da placa"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para Linux, no terminal rodar:\n",
    "sudo apt update\n",
    "sudo apt install libopenblas-dev\n",
    "\n",
    "## Instalar o Miniconda e criar o ambiente para RAPIDS\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
    "bash Miniconda3-latest-Linux-x86_64.sh\n",
    "conda create -n rapids-24.10 -c rapidsai -c conda-forge -c nvidia rapids=24.10 python=3.12 'cuda-version>=12.0,<=12.5'\n",
    "\n",
    "nano ~/.bashrc\n",
    "    Adicione o caminho à variável PATH:\n",
    "        export PATH=\"$PATH:~/miniconda3/bin\"\n",
    "    Pressione Ctrl + X, depois Y e Enter para salvar as alterações.\n",
    "source ~/.bashrc\n",
    "\n",
    "sudo apt install nvidia-driver-535\n",
    "sudo reboot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar CUDA Toolkit no Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme comandos a ser gerados em: https://developer.nvidia.com/cuda-downloads\n",
    "\n",
    "Exemplo para Linux:\n",
    "\n",
    "https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=24.04&target_type=deb_local"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-ubuntu2404.pin\n",
    "sudo mv cuda-ubuntu2404.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "wget https://developer.download.nvidia.com/compute/cuda/12.6.2/local_installers/cuda-repo-ubuntu2404-12-6-local_12.6.2-560.35.03-1_amd64.deb\n",
    "sudo dpkg -i cuda-repo-ubuntu2404-12-6-local_12.6.2-560.35.03-1_amd64.deb\n",
    "sudo cp /var/cuda-repo-ubuntu2404-12-6-local/cuda-*-keyring.gpg /usr/share/keyrings/\n",
    "sudo apt-get update\n",
    "sudo apt-get -y install cuda-toolkit-12-6"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Instalar conforme comandos a ser gerados em: https://pytorch.org/get-started/locally/\n",
    "\n",
    "Exemplo Linux: \n",
    "\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch-nightly -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "password = getpass.getpass('Senha sudo: ')\n",
    "\n",
    "!echo {password} | sudo -S rm -rf /tmp/*\n",
    "!echo {password} | sudo -S apt autoremove\n",
    "!echo {password} | sudo -S apt clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo {password} | sudo -S apt install nvidia-cuda-toolkit -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar o Pytorch para Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar o Spacy e GoogleTranslate no WSL ou Linux:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## No Terminal rodar com o Conda:\n",
    "# %conda install -c conda-forge spacy\n",
    "# %conda install -c conda-forge cupy\n",
    "# %conda install -c conda-forge spacy-transformers\n",
    "\n",
    "# ## Após isso rodar com o Pip:\n",
    "# %pip install spacy-lookups-data\n",
    "\n",
    "# ## Modelos mais precisos\n",
    "# # download dos modelos de linguagem\n",
    "# !python -m spacy download en_core_web_trf\n",
    "# !python -m spacy download xx_sent_ud_sm\n",
    "# !python -m spacy download pt_core_news_lg\n",
    "\n",
    "# ## Modelos menores\n",
    "# !python -m spacy download xx_ent_wiki_sm\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Carregar modelos com load\n",
    "# spacy.load('pt_core_news_lg')\n",
    "# spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# %conda install -c conda-forge spacy\n",
    "# %conda install -c conda-forge cupy\n",
    "# %pip install spacy_transformers\n",
    "# %pip install spacy-lookups-data\n",
    "# %pip install editdistance\n",
    "# %pip install contextualSpellCheck\n",
    "# %pip install langdetect\n",
    "\n",
    "# %pip install cython\n",
    "\n",
    "# !python -m spacy download xx_ent_wiki_sm\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en_core_web_lg\n",
    "# !python -m spacy download pt_core_news_sm\n",
    "\n",
    "# %pip install --upgrade sentence-transformers\n",
    "# %pip install --upgrade --no-deps sentence-transformers\n",
    "\n",
    "# %pip install transformers -U\n",
    "# %pip install seaborn==0.12.2\n",
    "\n",
    "## Resolução de conflitos de versões entre transformers e sentence-transformers\n",
    "# %pip uninstall transformers -y\n",
    "# %pip install transformers==4.34.0 # downgarade\n",
    "\n",
    "# %pip install transformers -U # Não funcionou\n",
    "# %pip install tokenizers==0.15.2 # downgarade\n",
    "# %pip install pyspellchecker\n",
    "\n",
    "# %pip show spacy_transformers\n",
    "# %pip show sentence-transformers\n",
    "\n",
    "# %pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Não instalar em ambientes mais recentes:\n",
    "# %pip install google-cloud-translate\n",
    "# %pip install googletrans==4.0.0-rc1\n",
    "# %pip show googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ver pipelines intalados\n",
    "# !pip install -U spacy\n",
    "!python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testar insalação para utilizar GPU\n",
    "import spacy\n",
    "\n",
    "# spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/home/mak/miniconda3/envs/rapids-24.10/bin/python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_trf\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlp.pipe_names)  # Should include 'spell_checker' if installed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_trf\n",
    "# !pip install transformers -U\n",
    "# !pip install spacy_transformers -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar RAPIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No Terminal intalar o RAPIDS versões mais atualizada em https://docs.rapids.ai/install\n",
    "## Criar ambiente e instalar o RAPIDS\n",
    "# conda create -n rapids-24.08 -c rapidsai -c conda-forge -c nvidia rapids=24.08 python=3.11 'cuda-version>=12.0,<=12.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verificar intalação do RAPIDS NVIDIA\n",
    "%conda list rapids\n",
    "%conda list cugraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Teste de cálculo em GPU\n",
    "import cudf\n",
    "print(cudf.Series([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reiniciar o Kernel e testar o ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda list torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda list xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda list TBB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caso CUDA ainda não disponível, verificar se há PyTorch CPU em vez de CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remover versões somente CPU para que seja possível CUDA ser habilitado\n",
    "# %conda uninstall pytorch torchvision torchaudio\n",
    "# %conda uninstall -y libtorch pytorch\n",
    "\n",
    "## Reinstalar versões compiladas para uso de GPU com CUDA\n",
    "## Estáveis\n",
    "%conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia\n",
    "## Ou Nightly\n",
    "# %conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch-nightly -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.randn(1, 1, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar PyTorch Geometric (pode conflitar PyTorch CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install pyg -c pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install pytorch-cluster -c pyg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testar o ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se o compulador CUDA está instalado\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verificar se o driver da placa GPU está instalado\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar a lista de ambientes virtuais locais\n",
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Listar os kernels instalados no ambiente local\n",
    "!jupyter kernelspec list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Desinstalar um kernel com problemas\n",
    "# jupyter kernelspec uninstall nome_do_kernel_problemático \n",
    "# jupyter kernelspec install --user --name nome_do_seu_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar a lista de repositórios confiáveis onde buscar bibliotecas\n",
    "%conda config --show channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Capacidades CUDA disponíveis: {torch.backends.cudnn.version()}\")\n",
    "else:\n",
    "    print(\"CUDA não está disponível.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar bibliotecas otimizadas para Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar o cuDNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O cuDNN é uma biblioteca de rotinas otimizadas para Deep Learning, e é essencial para o PyTorch aproveitar ao máximo o potencial da sua GPU. \n",
    "\n",
    "Instalar a biblioteca cuDNN clicando no botão \"Download cuDNN Library\" de acordo com seu sistema operacional Windows ou Linux, Arquitetura x86_64, Versão Tarball e CUDA Version 12 \n",
    "\n",
    "https://developer.nvidia.com/cudnn\n",
    "\n",
    "Ou fazer o download com o comando:\n",
    "\n",
    "    wget https://developer.download.nvidia.com/compute/cudnn/redist/cudnn/windows-x86_64/cudnn-windows-x86_64-9.2.1.18_cuda12-archive.zip\n",
    "\n",
    "Consultar compatibilidades em: \n",
    "\n",
    "https://docs.nvidia.com/deeplearning/cudnn/latest/reference/support-matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixar o cuDNN: Acesse a página de download do cuDNN no site da NVIDIA: https://developer.nvidia.com/cudnn\n",
    "\n",
    "1. Criar Conta (se necessário): Você precisará de uma conta de desenvolvedor da NVIDIA para fazer o download. Crie uma conta gratuitamente, se ainda não tiver uma.\n",
    "\n",
    "2. Escolher a versão do cuDNN que é compatível com o seu CUDA Toolkit 12.3. A página de download da NVIDIA fornecerá as opções corretas.\n",
    "\n",
    "3. Baixar o arquivo zip do cuDNN e extraia-o em um local de sua preferência.\n",
    "\n",
    "4. Copiar os seguintes arquivos da pasta extraída para a pasta de instalação do CUDA Toolkit:\n",
    "\n",
    "DLL:\n",
    "\n",
    "    Copie cudnn_cnn_infer64_8.dll (ou o nome do arquivo DLL correspondente à sua versão do cuDNN) para C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\\bin.\n",
    "\n",
    "Lib:\n",
    "\n",
    "    Copie cudnn_adv_infer64_8.lib (ou arquivo .lib correspondente) para C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\\lib\\x64.\n",
    "    Copie cudnn_adv_train64_8.lib (ou arquivo .lib correspondente) para C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\\lib\\x64.\n",
    "    Copie cudnn_cnn_infer64_8.lib (ou arquivo .lib correspondente) para C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\\lib\\x64.\n",
    "    Copie cudnn_cnn_train64_8.lib (ou arquivo .lib correspondente) para C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\\lib\\x64.\n",
    "\n",
    "Include:\n",
    "    Copie cudnn.h para C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\\include.\n",
    "\n",
    "5. Verificar a Instalação:\n",
    "\n",
    "Após copiar os arquivos, você pode verificar se o cuDNN foi instalado corretamente executando o seguinte código Python:\n",
    "\n",
    "    import torch\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(torch.backends.cudnn.version())\n",
    "    else:\n",
    "        print(\"CUDA não está disponível.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copiar arquivos contidos no arquivo zip do cuDNN baixado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da pasta bin do cuDNN:\n",
    "\n",
    "    cudnn_adv_infer64_9.dll\n",
    "    cudnn_cnn_infer64_9.dll\n",
    "\n",
    "Copiar para:\n",
    "\n",
    "    C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\\bin\n",
    "\n",
    "Da pasta include do cuDNN:\n",
    "\n",
    "    cudnn.h\n",
    "\n",
    "Copiar para:\n",
    "\n",
    "    C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\\include\n",
    "\n",
    "Da pasta lib/x64 do cuDNN:\n",
    "\n",
    "    Copie todos os arquivos .lib da pasta x64 do cuDNN para a pasta lib/x64 da sua instalação do CUDA:\n",
    "\n",
    "Copiar para:\n",
    "\n",
    "    C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\\lib\\x64\n",
    "\n",
    "Substitua v12.3 pela versão do CUDA que você tem instalada, se for diferente.\n",
    "\n",
    "Se a pasta lib/x64 do CUDA já contiver arquivos com o mesmo nome, você pode substituí-los pelos arquivos do cuDNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# cuda_bin_dir = r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\\bin\"\n",
    "# cuda_inc_dir = r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\\include\"\n",
    "# cuda_lib_dir = r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\\lib\\x64\"\n",
    "\n",
    "# arquivos_na_pasta = os.listdir(cuda_inc_dir)\n",
    "\n",
    "# for i in arquivos_na_pasta:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar compatibilidade Hardware/Software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install unidecode\n",
    "# %pip install --upgrade jupyter\n",
    "# %pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tqdm\n",
    "import torch\n",
    "import pynvml\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from git import Repo\n",
    "from tqdm.notebook import tqdm # Importando tqdm do notebook\n",
    "from sentence_transformers import SentenceTransformer\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"huggingface_hub\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCHINDUCTOR_FREEZING'] = '1'\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "\n",
    "## Sempre construir os caminhos usando os.path.join para compatibilidade WxL\n",
    "folder_utils = os.path.join(str(root_folder), 'utils')\n",
    "folder_domain = os.path.join(str(root_folder), 'source', 'domain')\n",
    "folder_data_input = os.path.join(str(root_folder), '_data', 'in_csv')\n",
    "folder_data_output = os.path.join(str(root_folder), '_data', 'out_json')\n",
    "\n",
    "## Adicionar pastas locais ao sys.path para importar pacotes criados localmente\n",
    "sys.path.append(folder_utils)\n",
    "sys.path.append(folder_domain)\n",
    "from competence_extraction import HardwareEvaluator, ProcessingCapacityEstimator\n",
    "from competence_extraction import EmbeddingModelEvaluator, ModelComparator, PlotlyResultVisualizer\n",
    "\n",
    "# !pip3 install py-cpuinfo\n",
    "hardware_evaluator = HardwareEvaluator()\n",
    "hardware_evaluator.print_hardware_info()\n",
    "\n",
    "# Estimativas de throughput\n",
    "estimator = ProcessingCapacityEstimator(hardware_evaluator)\n",
    "num_samples = 1000\n",
    "instructions_per_sample = 100\n",
    "cpu_throughput = estimator.estimate_cpu_throughput(num_samples, instructions_per_sample)\n",
    "cpu_parallel_throughput = estimator.estimate_cpu_parallel_throughput(num_samples, instructions_per_sample)\n",
    "num_operations = 1000 * 1000\n",
    "gpu_parallel_throughput = estimator.estimate_gpu_parallel_throughput(num_operations, \"FLOPS\")\n",
    "\n",
    "print(f\"\\nThroughput teórico single-threading estimado da CPU: {int(cpu_throughput)//1000000000:4} bilhões de operações/s\")\n",
    "print(f\"Throughput teórico multi-threadings estimado da CPU: {int(cpu_parallel_throughput)//1000000000:4} bilhões de operações/s\")\n",
    "print(f\"Throughput teórico multi-threadings estimado da GPU: {int(gpu_parallel_throughput)//1000000000:4} bilhões de operações/s\")\n",
    "\n",
    "# Verificação de compatibilidade PyTorch-GPU\n",
    "hardware_evaluator.check_pytorch_gpu_compatibility()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detectar hardware com nvidia-smi e pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --force-reinstall pynvml\n",
    "# import pynvml\n",
    "\n",
    "## Lista todos os atributos e métodos do módulo pynvml\n",
    "# all_attributes = dir(pynvml)\n",
    "\n",
    "## Filtra apenas os métodos (funções)\n",
    "# methods = [attr for attr in all_attributes if callable(getattr(pynvml, attr))]\n",
    "\n",
    "## Imprime os métodos\n",
    "# for method in methods:\n",
    "#     print(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "output = subprocess.check_output([\"nvidia-smi\", \"--query-gpu=name,compute_cap\", \"--format=csv,noheader\"]).decode(\"utf-8\").strip()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import pynvml\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "def detect_platform():\n",
    "    \"\"\"\n",
    "    Detects the operating system platform where the code is running, \n",
    "    distinguishing between Windows, Linux, WSL, and macOS.\n",
    "\n",
    "    Returns:\n",
    "        str: The name of the operating system platform.\n",
    "    \"\"\"\n",
    "\n",
    "    system = platform.system()\n",
    "    if system == \"Linux\":\n",
    "        # Verifica se está rodando no WSL\n",
    "        if \"microsoft\" in platform.uname().release.lower():\n",
    "            return \"WSL\"\n",
    "        else:\n",
    "            return \"Linux\"\n",
    "    elif system == \"Windows\":\n",
    "        return \"Windows\"\n",
    "    elif system == \"Darwin\":\n",
    "        return \"macOS\"\n",
    "    else:\n",
    "        return \"Unknown\"  # Plataforma desconhecida\n",
    "\n",
    "def detect_gpu_driver_version():\n",
    "    \"\"\"\n",
    "    Detects the version of the installed GPU driver.\n",
    "\n",
    "    Returns:\n",
    "        str: The GPU driver version or an error message if the detection fails.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        pynvml.nvmlInit()\n",
    "        driver_version = pynvml.nvmlSystemGetDriverVersion()\n",
    "        pynvml.nvmlShutdown()\n",
    "        return driver_version  # No need to decode\n",
    "\n",
    "    except pynvml.NVMLError as error:\n",
    "        return f\"Erro ao obter a versão do driver da GPU: {error}\"\n",
    "\n",
    "def detect_pytorch_and_geometric_versions():\n",
    "    \"\"\"\n",
    "    Detecta as versões do PyTorch e PyTorch Geometric, se estiverem instalados.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Uma tupla contendo as versões do PyTorch e PyTorch Geometric como strings,\n",
    "               ou None se alguma das bibliotecas não estiver instalada.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        import torch\n",
    "        # import torch_geometric\n",
    "\n",
    "        pytorch_version = torch.__version__\n",
    "        # pytorch_geometric_version = torch_geometric.__version__\n",
    "\n",
    "        # return pytorch_version, pytorch_geometric_version\n",
    "\n",
    "    except ImportError:\n",
    "        return None, None\n",
    "\n",
    "def detect_compatible_torch_versions():\n",
    "    \"\"\"\n",
    "    Detecta as versões do PyTorch compatíveis com a GPU instalada na máquina.\n",
    "\n",
    "    Returns:\n",
    "        list: Uma lista de strings contendo as versões mínimas do PyTorch \n",
    "              compatíveis com a compute capability da GPU.\n",
    "              Retorna uma lista vazia se a CUDA não estiver disponível.\n",
    "    \"\"\"\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA não está disponível. Não é possível verificar a compatibilidade com a GPU.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        gpu_compute_capability = f\"{pynvml.nvmlDeviceGetCudaComputeCapability(handle)[0]}.{pynvml.nvmlDeviceGetCudaComputeCapability(handle)[1]}\"\n",
    "        pynvml.nvmlShutdown()\n",
    "\n",
    "        # Dicionário de compatibilidade PyTorch-GPU (atualizado até agosto de 2024)\n",
    "        compatibility_dict = {\n",
    "            \"3.0\": (\"0.3.0\", \"Kepler\"),\n",
    "            \"3.5\": (\"0.4.0\", \"Kepler\"),\n",
    "            \"3.7\": (\"1.0.0\", \"Kepler\"),\n",
    "            \"5.0\": (\"1.2.0\", \"Maxwell\"),\n",
    "            \"5.2\": (\"1.3.0\", \"Maxwell\"),\n",
    "            \"6.0\": (\"1.4.0\", \"Pascal\"),\n",
    "            \"6.1\": (\"1.5.0\", \"Pascal\"),\n",
    "            \"7.0\": (\"1.6.0\", \"Volta\"),\n",
    "            \"7.5\": (\"1.7.0\", \"Turing\"),\n",
    "            \"8.0\": (\"1.8.0\", \"Ampere\"),\n",
    "            \"8.6\": (\"1.9.0\", \"Ampere\"),\n",
    "            \"8.9\": (\"1.12.0\", \"Ada Lovelace\"),\n",
    "            \"9.0\": (\"1.13.0\", \"Hopper\"),\n",
    "        }\n",
    "\n",
    "        compatible_versions = []\n",
    "        for compute_cap, (min_version, platform_name) in compatibility_dict.items():\n",
    "            if gpu_compute_capability >= compute_cap:\n",
    "                compatible_versions.append(min_version)\n",
    "\n",
    "        # Imprimir a plataforma detectada\n",
    "        if gpu_compute_capability in compatibility_dict:\n",
    "            detected_compatibility = compatibility_dict[gpu_compute_capability][0]\n",
    "            detected_platform = compatibility_dict[gpu_compute_capability][1]\n",
    "            print(f\"Computabilidade da GPU detectada: {detected_compatibility} | Plataforma NVIDIA {detected_platform}\")\n",
    "        else:\n",
    "            print(f\"Capacidade computacional da GPU detectada: {gpu_compute_capability}\") \n",
    "\n",
    "        return compatible_versions\n",
    "\n",
    "    except pynvml.NVMLError as error:\n",
    "        print(f\"Erro ao obter informações da GPU: {error}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_gpu_architecture():\n",
    "    \"\"\"\n",
    "    Obtém a arquitetura da GPU com base na compute capability.\n",
    "\n",
    "    Returns:\n",
    "        str: O nome da arquitetura da GPU ou \"Desconhecida\" se não for possível determinar.\n",
    "    \"\"\"\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        return \"Desconhecida\"  # CUDA não disponível\n",
    "\n",
    "    try:\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        cc_major, cc_minor = pynvml.nvmlDeviceGetCudaComputeCapability(handle)\n",
    "        compute_capability = f\"{cc_major}.{cc_minor}\"\n",
    "        pynvml.nvmlShutdown()\n",
    "\n",
    "        # Dicionário para mapear compute capability para arquitetura (atualizado)\n",
    "        compute_cap_to_architecture = {\n",
    "            \"3.0\": \"Kepler\",\n",
    "            \"3.5\": \"Kepler\",\n",
    "            \"3.7\": \"Kepler\",\n",
    "            \"5.0\": \"Maxwell\",\n",
    "            \"5.2\": \"Maxwell\",\n",
    "            \"6.0\": \"Pascal\",\n",
    "            \"6.1\": \"Pascal\",\n",
    "            \"7.0\": \"Volta\",\n",
    "            \"7.5\": \"Turing\",       # como a RTX 2080 Ti\n",
    "            \"8.0\": \"Ampere\",       # como a RTX 3080\n",
    "            \"8.6\": \"Ampere\",       # como a A100\n",
    "            \"8.9\": \"Ada Lovelace\", # como a RTX 4060, 4070, 4080 e 4090\n",
    "            \"9.0\": \"Hopper\",       # como a H100\n",
    "            \"11.0\": \"Blackwell\",   # Substituir 11.0 pela compute capability real da Blackwell quando for divugada\n",
    "        }\n",
    "\n",
    "        return compute_cap_to_architecture.get(compute_capability, \"Desconhecida\")\n",
    "\n",
    "    except pynvml.NVMLError as error:\n",
    "        print(f\"Erro ao obter informações da GPU: {error}\")\n",
    "        return \"Desconhecida\"\n",
    "\n",
    "\n",
    "def get_num_sms_via_nvidia_smi():\n",
    "    \"\"\"\n",
    "    Gets the number of Streaming Multiprocessors (SMs) on the GPU using nvidia-smi.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of SMs or 0 if the information is not available or an error occurs\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        output = subprocess.check_output([\"nvidia-smi\", \"--query-gpu=compute_cap\", \"--format=csv,noheader\"]).decode(\"utf-8\")\n",
    "        compute_cap = output.strip().split(\".\")[0]  # Extract the major compute capability version\n",
    "        return int(compute_cap) * 38  # Assuming 38 CUDA cores per SM\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao obter o número de SMs: {e}\")\n",
    "        return 0\n",
    "\n",
    "def get_tensor_cores_via_nvidia_smi():\n",
    "    \"\"\"\n",
    "    Gets the number of Tensor Cores by parsing nvidia-smi output and using \n",
    "    the `cuda_cores_per_sm` dictionary.\n",
    "\n",
    "    Returns:\n",
    "        int: The estimated number of Tensor Cores or 0 if the information is not available or an error occurs\n",
    "    \"\"\"\n",
    "    # Informações sobre CUDA Cores por SM para diferentes arquiteturas de GPU NVIDIA\n",
    "    cuda_cores_per_sm = {\n",
    "        \"Kepler\": 192,\n",
    "        \"Maxwell\": 128,\n",
    "        \"Pascal\": 128,\n",
    "        \"Volta\": 64,\n",
    "        \"Turing\": 64,\n",
    "        \"Ampere\": 64,\n",
    "        \"Ada Lovelace\": 128,\n",
    "        \"Hopper\": 128\n",
    "    }\n",
    "\n",
    "    # TO-DO: Pesquisar a quantidade de TensorCores de cada aruitetura\n",
    "    # Informações sobre Tensor Cores por SM para diferentes arquiteturas de GPU NVIDIA\n",
    "    tensor_cores_per_sm = {\n",
    "        \"Kepler\": 0,\n",
    "        \"Maxwell\": 0,\n",
    "        \"Pascal\": 4,\n",
    "        \"Volta\": 4,\n",
    "        \"Turing\": 4,\n",
    "        \"Ampere\": 8,\n",
    "        \"Ada Lovelace\": 12,\n",
    "        \"Hopper\": 12\n",
    "    }\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        return 0  # CUDA não disponível\n",
    "\n",
    "    try:\n",
    "        # Get GPU name and number of CUDA cores from nvidia-smi\n",
    "        output = subprocess.check_output([\"nvidia-smi\", \"--query-gpu=name,compute_cap\", \"--format=csv,noheader\"]).decode(\"utf-8\")\n",
    "        gpu_name, compute_cap = output.strip().split(\",\")\n",
    "        cuda_cores = int(compute_cap.split('.')[0].strip())*32\n",
    "\n",
    "        # Identify the GPU architecture\n",
    "        architecture = None\n",
    "        for arch in cuda_cores_per_sm:\n",
    "            if arch.lower() in gpu_name.lower():\n",
    "                architecture = arch\n",
    "                break\n",
    "\n",
    "        if architecture:\n",
    "            # Estimate the number of SMs based on CUDA cores per SM\n",
    "            num_sms = cuda_cores // cuda_cores_per_sm[architecture]\n",
    "\n",
    "            # Estimate Tensor Cores (may not be accurate for all architectures)\n",
    "            if architecture in tensor_cores_per_sm:\n",
    "                tensor_cores = num_sms * tensor_cores_per_sm[architecture]\n",
    "            else:\n",
    "                tensor_cores = 0\n",
    "\n",
    "            return tensor_cores\n",
    "        else:\n",
    "            print(f\"Arquitetura da GPU '{gpu_name}' não reconhecida. Não foi possível determinar o número de Tensor Cores.\")\n",
    "            return 0\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao obter informações da GPU usando nvidia-smi: {e}\")\n",
    "        return 0\n",
    "\n",
    "def get_tensor_cores():\n",
    "    \"\"\"\n",
    "    Obtém o número de Tensor Cores da GPU.\n",
    "\n",
    "    Returns:\n",
    "        int: Número de Tensor Cores ou 0 se a informação não estiver disponível ou ocorrer um erro.\n",
    "    \"\"\"\n",
    "    # Informações sobre CUDA Cores por SM para diferentes arquiteturas de GPU NVIDIA\n",
    "    cuda_cores_per_sm = {\n",
    "        \"Kepler\": 192,\n",
    "        \"Maxwell\": 128,\n",
    "        \"Pascal\": 128,\n",
    "        \"Volta\": 64,\n",
    "        \"Turing\": 64,\n",
    "        \"Ampere\": 64,\n",
    "        \"Ada Lovelace\": 128,\n",
    "        \"Hopper\": 128,\n",
    "        \"Blackwell\": 256 # Adicionado Blackwell, a arquitetura mais recente até agosto de 2024\n",
    "    }\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        return 0  # CUDA não disponível\n",
    "\n",
    "    try:\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "        # Obter o nome da GPU e a arquitetura\n",
    "        gpu_name = pynvml.nvmlDeviceGetName(handle)\n",
    "\n",
    "        # Obter a arquitetura da GPU a partir da saída do nvidia-smi\n",
    "        architecture = get_gpu_architecture()\n",
    "        print(f\"Arquitetura: {architecture}\")\n",
    "\n",
    "        # Informações sobre Tensor Cores para diferentes arquiteturas de GPU NVIDIA\n",
    "        tensor_cores_per_sm = {\n",
    "            \"Volta\": 8,         # Tensor Cores Volta (V100, Titan V)\n",
    "            \"Turing\": 4,        # Tensor Cores Turing (RTX 20 series, Quadro RTX series)\n",
    "            \"Ampere\": 4,        # Tensor Cores Ampere (RTX 30 series, A100, etc.)\n",
    "            \"Ada Lovelace\": 4,  # Tensor Cores Ada Lovelace (RTX 40 series)\n",
    "            \"Hopper\": 2,        # Tensor Cores Hopper (H100)\n",
    "            \"Blackwell\": 8      # Estimativa de Tensor Cores baseada em rumores sobre Blackwell (B100/B200)\n",
    "        }\n",
    "\n",
    "        conf_tensor_cores = {\n",
    "            \"RTX 4070 Super\": 224, # 4th Gen tensor cores\n",
    "            \"RTX 4500\": 240, # 4th Gen tensor cores\n",
    "            \"RTX 4070 Ti Super\": 264, # 4th Gen tensor cores\n",
    "            \"RTX 4080 Super\": 320, # 4th Gen tensor cores\n",
    "            \"RTX 4090\": 512, # 4th Gen tensor cores\n",
    "            \"RTX 4090 D\": 456, # 4th Gen tensor cores\n",
    "            \"RTX 5000\": 400, # 4th Gen tensor cores\n",
    "            \"RTX 6000\": 568, # 4th Gen tensor cores\n",
    "            \"A100\": 512, # tensor cores\n",
    "            \"H100\": 512, # tensor cores\n",
    "             \n",
    "        }\n",
    "        try:\n",
    "            pynvml.nvmlInit()\n",
    "            handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "            cc_major, cc_minor = pynvml.nvmlDeviceGetCudaComputeCapability(handle)\n",
    "            try:\n",
    "                num_sms = pynvml.nvmlDeviceGetVgpuMetadata(handle)\n",
    "            except:\n",
    "                num_sms = get_num_sms_via_nvidia_smi()\n",
    "            print(f\"Total de núcleos: {num_sms}\")\n",
    "        except Exception as e:\n",
    "            print('Erro ao tentar obter a quantidade de SMs')\n",
    "            print(e)\n",
    "            return 0\n",
    "\n",
    "        if architecture and num_sms:\n",
    "            total_cuda_cores = int(num_sms) * cuda_cores_per_sm[architecture] \n",
    "            \n",
    "            # Estimar o número de Tensor Cores (pode não ser preciso para todas as arquiteturas)\n",
    "            archs = [x.lower() for x in tensor_cores_per_sm.keys()]\n",
    "            if architecture.lower() in archs:\n",
    "                tensor_cores = int(num_sms) * tensor_cores_per_sm[architecture]\n",
    "            else:\n",
    "                # Para arquiteturas sem Tensor Cores dedicados, assumimos que não há\n",
    "                tensor_cores = 0  \n",
    "\n",
    "            return tensor_cores\n",
    "        else:\n",
    "            print(f\"Arquitetura da GPU '{architecture}' não reconhecida. Não foi possível determinar o número de Tensor Cores.\")\n",
    "            return 0\n",
    "\n",
    "    except pynvml.NVMLError as error:\n",
    "        print(f\"Erro ao obter informações da GPU: {error}\")\n",
    "        return 0\n",
    "\n",
    "    finally:\n",
    "        pynvml.nvmlShutdown()\n",
    "\n",
    "def get_num_sms():\n",
    "    \"\"\"\n",
    "    Obtém o número estimado de Streaming Multiprocessors (SMs) na GPU.\n",
    "\n",
    "    Returns:\n",
    "        int: O número estimado de SMs ou 0 se a informação não estiver disponível ou ocorrer um erro.\n",
    "    \"\"\"\n",
    "    # Informações sobre CUDA Cores por SM para diferentes arquiteturas de GPU NVIDIA\n",
    "    cuda_cores_per_sm = {\n",
    "        \"Kepler\": 192,\n",
    "        \"Maxwell\": 128,\n",
    "        \"Pascal\": 128,\n",
    "        \"Volta\": 64,\n",
    "        \"Turing\": 64,\n",
    "        \"Ampere\": 64,\n",
    "        \"Ada Lovelace\": 128,\n",
    "        \"Hopper\": 128\n",
    "    }\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        return 0  # CUDA não disponível\n",
    "\n",
    "    total_cuda_cores=0\n",
    "    \n",
    "    try:\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        gpu_name = pynvml.nvmlDeviceGetName(handle)\n",
    "\n",
    "        # Obter o número total de CUDA cores\n",
    "        try:\n",
    "            # total_cuda_cores = pynvml.nvmlDeviceGetNumGpuCores(handle)\n",
    "            # print(f\"Quantidade Total de núcleos: {total_cuda_cores}\")\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            print(f\"Não foi possível determinar a quantidade Total de núcleos da GPU '{gpu_name}' com pynvml.\")\n",
    "            print(f\"Usando estimativa com nvidia_smi.\")\n",
    "            total_cuda_cores = get_num_sms_via_nvidia_smi()\n",
    "            return total_cuda_cores\n",
    "\n",
    "        # Identificar a arquitetura da GPU\n",
    "        architecture = get_gpu_architecture()\n",
    "\n",
    "        if architecture:\n",
    "            # Consultar o dicionário para obter o número de CUDA cores por SM\n",
    "            cuda_cores_per_sm = cuda_cores_per_sm.get(architecture)\n",
    "\n",
    "            if cuda_cores_per_sm:\n",
    "                num_sms = total_cuda_cores // cuda_cores_per_sm\n",
    "                return num_sms\n",
    "            else:\n",
    "                print(f\"Arquitetura da GPU '{gpu_name}' não reconhecida. Não foi possível determinar o número de SMs.\")\n",
    "                return 0\n",
    "        else:\n",
    "            print(f\"Não foi possível determinar a arquitetura da GPU '{gpu_name}'. Não foi possível determinar o número de SMs.\")\n",
    "            return 0\n",
    "\n",
    "    except pynvml.NVMLError as error:\n",
    "        print(f\"Erro ao obter informações da GPU: {error}\")\n",
    "        return 0\n",
    "\n",
    "    finally:\n",
    "        pynvml.nvmlShutdown()\n",
    "\n",
    "\n",
    "def print_gpu_driver_info():\n",
    "    \"\"\"\n",
    "    Imprime informações detalhadas sobre o driver da GPU e a(s) GPU(s) instalada(s).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output = subprocess.check_output([\"nvidia-smi\", \"-q\"]).decode(\"utf-8\")\n",
    "        lines = output.splitlines()\n",
    "        sections = ['==============NVSMI LOG==============','PCIe Generation','Link Width','Bridge Chip','FB Memory Usage',\n",
    "                    'BAR1 Memory Usage','Utilization','Temperature','GPU Power Readings','Clocks','Max Clocks','Voltage']\n",
    "        interests = ['Driver Version','CUDA Version','Attached GPUs','Product Name','Product Architecture',\n",
    "                    'MultiGPU Board', 'Total', 'Free', 'Gpu', 'Memory','Graphics','SM','Memory','Video','Max','Current',\n",
    "                    'Tx Throughput','Rx Throughput','Power Draw','Max Power Limit','GPU Current Temp','GPU Max Operating Temp']\n",
    "\n",
    "        info_dict = {}\n",
    "        current_section = None\n",
    "        key=None\n",
    "        val=None\n",
    "\n",
    "        for i in lines:\n",
    "            if i == \"\" or i is None:\n",
    "                continue\n",
    "            if \":\" not in i and i is not None:\n",
    "                section = i.strip()\n",
    "                if section in sections:\n",
    "                    if section == \"==============NVSMI LOG==============\":\n",
    "                        section = 'General_Data'\n",
    "                    current_section = section\n",
    "                    info_dict[current_section] = {}  # Criar a estrutura aninhada para seção\n",
    "                    # print('-'*75)\n",
    "                    # print(f\"Seção: {section}\") # DEBUG\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                try:\n",
    "                    key = i.split(':',1)[0].strip()\n",
    "                    val = i.split(':',1)[1].strip()\n",
    "                    if val != \"N/A\" and val != \"Not Active\" and key in interests:\n",
    "                    # if val != \"N/A\" and val != \"Not Active\":\n",
    "                        # print(f\"Seção: {current_section:30} | Chave: {key:30} | Valor: {val}\") # DEBUG\n",
    "                        info_dict[current_section][key] = val\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro na linha {i} da seção {current_section} | Erro: {e}\")\n",
    "                    print(i)\n",
    "                    # print(f\"Seção: {current_section:30} | Chave: {key:30} | Valor: {val}\") # DEBUG\n",
    "                    continue\n",
    "\n",
    "        # Print the desired information, handling missing sections gracefully\n",
    "        print(\"\\nInformações do Driver e da(s) GPU(s):\")\n",
    "\n",
    "        list_keys=[]\n",
    "        [list_keys.extend(list(x.keys())) for x in info_dict.values()]\n",
    "\n",
    "        if 'Driver Version' in list_keys:\n",
    "            print(f\"  Driver Version: {info_dict['General_Data'].get('Driver Version')}\")\n",
    "        else:\n",
    "            print(\"  DriverVersion: Não encontrada\")\n",
    "\n",
    "        if 'CUDA Version' in list_keys:\n",
    "            print(f\"    CUDA Version: {info_dict['General_Data']['CUDA Version']}\")\n",
    "        else:\n",
    "            print(\"   CUDA Version: Não encontrada\")\n",
    "\n",
    "        if 'Attached GPUs' in list_keys:\n",
    "            gpu_count = int(info_dict['General_Data'].get('Attached GPUs'))\n",
    "        else:\n",
    "            gpu_count = 0\n",
    "            print(\"  Attached GPUs: Não encontrado\")\n",
    "\n",
    "        print(f\"   Attached GPUs: {gpu_count}\")\n",
    "\n",
    "        for i in range(gpu_count):\n",
    "            gpu_section = f\"GPU {i}\"\n",
    "            if gpu_section in info_dict:\n",
    "                print(f\"    GPU {i} - Product Name: {info_dict[gpu_section]['Product Name']}\")\n",
    "                print(f\"    GPU {i} - Product Architecture: {info_dict[gpu_section]['Architecture']}\")\n",
    "                print(f\"    GPU {i} - Accounting Mode Buffer Size: {info_dict[gpu_section]['Accounting Mode Buffer Size']}\")\n",
    "                print(f\"    GPU {i} - MultiGPU Board: {info_dict[gpu_section]['MultiGPU Board']}\")\n",
    "            else:\n",
    "                print(f\"    GPU {i} - Informações não encontradas\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao obter informações da GPU: {e}\")\n",
    "    \n",
    "    return info_dict\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "NVIDIA RTX A1000\n",
    "Graphics Processor\n",
    "GA107\n",
    " \n",
    "Cores\n",
    "2304\n",
    " \n",
    "TMUs\n",
    "72\n",
    " \n",
    "ROPs\n",
    "32\n",
    " \n",
    "Memory Size\n",
    "8 GB\n",
    " \n",
    "Memory Type\n",
    "GDDR6\n",
    " \n",
    "Bus Width\n",
    "128 bit\n",
    "\n",
    "NVIDIA GeForce RTX 4060 AD106\n",
    "Graphics Processor\n",
    "AD106\n",
    " \n",
    "Cores\n",
    "3072\n",
    " \n",
    "TMUs\n",
    "96\n",
    " \n",
    "ROPs\n",
    "48\n",
    " \n",
    "Memory Size\n",
    "8 GB\n",
    " \n",
    "Memory Type\n",
    "GDDR6\n",
    " \n",
    "Bus Width\n",
    "128 bit\n",
    "\n",
    "NVIDIA GeForce RTX 4070 SUPER\n",
    "Graphics Processor\n",
    "AD104\n",
    " \n",
    "Cores\n",
    "7168\n",
    " \n",
    "TMUs\n",
    "224\n",
    " \n",
    "ROPs\n",
    "80\n",
    " \n",
    "Memory Size\n",
    "12 GB\n",
    " \n",
    "Memory Type\n",
    "GDDR6X\n",
    " \n",
    "Bus Width\n",
    "192 bit\n",
    "\n",
    "NVIDIA RTX 2000 Ada Generation\n",
    "Graphics Processor\n",
    "AD107\n",
    " \n",
    "Cores\n",
    "2816\n",
    " \n",
    "TMUs\n",
    "88\n",
    " \n",
    "ROPs\n",
    "48\n",
    " \n",
    "Memory Size\n",
    "16 GB\n",
    " \n",
    "Memory Type\n",
    "GDDR6\n",
    " \n",
    "Bus Width\n",
    "128 bit\n",
    "\n",
    "NVIDIA GeForce RTX 5080\n",
    "Graphics Processor\n",
    "GB203\n",
    " \n",
    "Cores\n",
    "10752\n",
    " \n",
    "TMUs\n",
    "336\n",
    " \n",
    "ROPs\n",
    "128\n",
    " \n",
    "Memory Size\n",
    "16 GB\n",
    " \n",
    "Memory Type\n",
    "GDDR7\n",
    " \n",
    "Bus Width\n",
    "256 bit\n",
    "\n",
    "NVIDIA GeForce RTX 5090\n",
    "Graphics Processor\n",
    "GB202\n",
    " \n",
    "Cores\n",
    "20480\n",
    " \n",
    "TMUs\n",
    "640\n",
    " \n",
    "ROPs\n",
    "192\n",
    " \n",
    "Memory Size\n",
    "28 GB\n",
    " \n",
    "Memory Type\n",
    "GDDR7\n",
    " \n",
    "Bus Width\n",
    "448 bit\n",
    "\n",
    "NVIDIA H100 PCIe 80 GB\n",
    "Graphics Processor\n",
    "GH100\n",
    " \n",
    "Cores\n",
    "14592\n",
    " \n",
    "TMUs\n",
    "456\n",
    " \n",
    "ROPs\n",
    "24\n",
    " \n",
    "Memory Size\n",
    "80 GB\n",
    " \n",
    "Memory Type\n",
    "HBM2e\n",
    " \n",
    "Bus Width\n",
    "5120 bit\n",
    "\n",
    "NVIDIA H100 PCIe 96 GB\n",
    "Graphics Processor\n",
    "GH100\n",
    " \n",
    "Cores\n",
    "16896\n",
    " \n",
    "TMUs\n",
    "528\n",
    " \n",
    "ROPs\n",
    "24\n",
    " \n",
    "Memory Size\n",
    "96 GB\n",
    " \n",
    "Memory Type\n",
    "HBM3\n",
    " \n",
    "Bus Width\n",
    "5120 bit\n",
    "\n",
    "NVIDIA RTX 4000 Ada Generation\n",
    "Graphics Processor\n",
    "AD104\n",
    " \n",
    "Cores\n",
    "6144\n",
    " \n",
    "TMUs\n",
    "192\n",
    " \n",
    "ROPs\n",
    "80\n",
    " \n",
    "Memory Size\n",
    "20 GB\n",
    " \n",
    "Memory Type\n",
    "GDDR6\n",
    " \n",
    "Bus Width\n",
    "160 bit\n",
    "\n",
    "NVIDIA RTX 4500 Ada Generation\n",
    "Graphics Processor\n",
    "AD103\n",
    " \n",
    "Cores\n",
    "7680\n",
    " \n",
    "TMUs\n",
    "240\n",
    " \n",
    "ROPs\n",
    "80\n",
    " \n",
    "Memory Size\n",
    "24 GB\n",
    " \n",
    "Memory Type\n",
    "GDDR6\n",
    " \n",
    "Bus Width\n",
    "192 bit\n",
    "\n",
    "NVIDIA RTX 5000 Ada Generation\n",
    "Graphics Processor\n",
    "AD102\n",
    " \n",
    "Cores\n",
    "12800\n",
    " \n",
    "TMUs\n",
    "400\n",
    " \n",
    "ROPs\n",
    "176\n",
    " \n",
    "Memory Size\n",
    "32 GB\n",
    " \n",
    "Memory Type\n",
    "GDDR6\n",
    " \n",
    "Bus Width\n",
    "256 bit\n",
    "\n",
    "NVIDIA RTX 6000 Ada Generation\n",
    "Graphics Processor\n",
    "AD102\n",
    " \n",
    "Cores\n",
    "18176\n",
    " \n",
    "TMUs\n",
    "568\n",
    " \n",
    "ROPs\n",
    "192\n",
    " \n",
    "Memory Size\n",
    "48 GB\n",
    " \n",
    "Memory Type\n",
    "GDDR6\n",
    " \n",
    "Bus Width\n",
    "384 bit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gpu_architecture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_sms_via_nvidia_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tensor_cores_via_nvidia_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tensor_cores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_sms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_sms_via_nvidia_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tensor_cores = get_tensor_cores()\n",
    "if num_tensor_cores > 0:\n",
    "    print(f\"Número de Tensor Cores: {num_tensor_cores}\")\n",
    "else:\n",
    "    print(\"Não foi possível determinar o número de Tensor Cores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_name = detect_platform()\n",
    "print(f\"Plataforma de Sistema Operacional em uso: {platform_name}\")\n",
    "\n",
    "compatible_torch_versions = detect_compatible_torch_versions()\n",
    "if compatible_torch_versions:\n",
    "    print(f\"Versão mínima mais recente do PyTorch compatível: {compatible_torch_versions[-1]}\")\n",
    "else:\n",
    "    print(\"Não foi possível detectar versões compatíveis do PyTorch.\")\n",
    "\n",
    "driver_version = detect_gpu_driver_version()\n",
    "print(f\"Versão do driver da GPU instalado: {driver_version}\")\n",
    "\n",
    "# Imprimir o caminho completo para o interpretador Python em uso\n",
    "print(f\"\\nInterpretador Python: {sys.executable}\")\n",
    "\n",
    "# Imprimir o nome do ambiente conda ativo\n",
    "print(f\"Ambiente conda ativo: {os.environ.get('CONDA_DEFAULT_ENV')}\")\n",
    "\n",
    "pytorch_version, pytorch_geometric_version = detect_pytorch_and_geometric_versions() # type: ignore\n",
    "\n",
    "if pytorch_version and pytorch_geometric_version:\n",
    "    print(f\"Versão do PyTorch: {pytorch_version}\")\n",
    "    print(f\"Versão do PyTorch Geometric: {pytorch_geometric_version}\")\n",
    "else:\n",
    "    if not pytorch_version:\n",
    "        print(\"          PyTorch não está instalado no ambiente ativo.\")\n",
    "    if not pytorch_geometric_version:\n",
    "        print(\"PyTorch Geometric não está instalado no ambiente ativo.\")\n",
    "\n",
    "info_dict = print_gpu_driver_info()\n",
    "info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_keys=[]\n",
    "[list_keys.extend(list(x.keys())) for x in info_dict.values()]\n",
    "list_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict['General_Data'].get('Attached GPUs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "output = subprocess.check_output([\"nvidia-smi\", \"-q\"]).decode(\"utf-8\")\n",
    "lines = output.splitlines()\n",
    "sections = ['==============NVSMI LOG==============','PCIe Generation','Link Width','Bridge Chip','FB Memory Usage',\n",
    "            'BAR1 Memory Usage','Utilization','Temperature','GPU Power Readings','Clocks','Max Clocks','Voltage']\n",
    "interests = ['Driver Version','CUDA Version','Attached GPUs','Product Name','Product Brand','Product Architecture',\n",
    "             'MultiGPU Board', 'Total', 'Free', 'Gpu', 'Memory','Graphics','SM','Memory','Video','Max','Current',\n",
    "             'Tx Throughput','Rx Throughput','Power Draw','Max Power Limit','GPU Current Temp','GPU Max Operating Temp']\n",
    "for i in lines:\n",
    "    if i == \"\":\n",
    "        continue\n",
    "    if \":\" not in i:\n",
    "        section = i.strip()\n",
    "        if section in sections:\n",
    "            print('-'*75)\n",
    "            print(f\"Seção: {section}\")\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        try:\n",
    "            key = i.split(':',1)[0].strip()\n",
    "            val = i.split(':',1)[1].strip()\n",
    "            if val != \"N/A\" and val != \"Not Active\" and key in interests:\n",
    "            # if val != \"N/A\" and val != \"Not Active\":\n",
    "                print(f\"{key:30} | {val}\")\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Implementar Kernel CUDA</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A implementação do kernel CUDA para a vetorização de competências depende da escolha de arquitetura para o modelo. Para utilizar os embeedinds pré-treinados do modelo paraphrase-multilingual-mpnet-base-v2, foi preciso implementar um kernel otimizado que executa as seguintes etapas:\n",
    "\n",
    "1. Tokenizar: Dividir cada frase de competência em tokens (palavras ou subpalavras).\n",
    "\n",
    "2. Vetorizar: Converter cada token em um vetor de embedding usando o modelo pré-treinado.\n",
    "\n",
    "3. Codificar Sequência: Processar a sequência de embeddings usando as camadas do modelo (transformadores, camadas de pooling, etc.).\n",
    "\n",
    "4. Agregar (opcional): Se necessário, agregar os embeddings da sequência em um único vetor representativo da competência (por exemplo, usando a média ou o máximo dos embeddings).\n",
    "\n",
    "5. Armazenar embeedings: Armazenar os embeddings resultantes na memória da GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estratégias de Otimização de espaço de memória da GPU:\n",
    "\n",
    "Reduzir Dimensionalidade dos Embeddings: Para modelos com dimensões de embedding muito grandes (ex: 768), é possível otimizar cálculos usando modelos menores (ex: 128 ou 256). Isso reduz significativamente a quantidade de memória utilizada pela GPU. Modelos de menor dimensionalidade estão disponíveis no Hugging Face Model Hub, como, por exemplo, o \"paraphrase-MiniLM-L6-v2\" ou \"all-MiniLM-L6-v2\".\n",
    "\n",
    "Limpeza de Cache e Sincronização: Limpar o cache da GPU (torch.cuda.empty_cache()) e sincronizar operações CUDA (torch.cuda.synchronize()) é uma boa prática antes de cada iteração do loop no trecho \"for model_name in model_names:\"\n",
    "\n",
    "Processar em CPU: Se mesmo a redução do tamanho do modelo e do lote não for suficiente, pode-se processar os embeddings na CPU, o que torna execução mais lenta, mas evita a maioria dos erros de acesso à memória da GPU.\n",
    "\n",
    "Divisão dos Dados em Subconjuntos: Se você tiver um grande número de pesquisadores, divida os dados em subconjuntos menores e processe cada subconjunto separadamente.\n",
    "\n",
    "Uso de torch.utils.checkpoint: O PyTorch oferece a função torch.utils.checkpoint que permite trocar memória por tempo de computação. Ao ativar o checkpointing, o PyTorch recalculará partes do grafo computacional durante a retropropagação, em vez de armazenar todos os tensores intermediários na memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download pt_core_news_lg\n",
    "# !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GPU e CPU: A GPU (Unidade de Processamento Gráfico) é especializada em cálculos paralelizáveisos ideal para treinar modelos de aprendizado de máquina. \n",
    "Já a CPU (Unidade Central de Processamento) é mais versátil e lida com diversas tarefas, incluindo a execução do seu código.\n",
    "\n",
    "Transferência GPU/RAM: Para usar GPU durante o treinamento, é necessário mover os dados (tensores) para a memória da GPU.\n",
    "No entanto, outras bibliotecas, como o NumPy e o scikit-learn, geralmente esperam que os dados estejam na memória principal (RAM) acessível à CPU.\n",
    "Método .cpu(): O método .cpu() copia o tensor da memória da GPU para a memória principal, permitindo que você o use com o NumPy e outras bibliotecas que não suportam diretamente tensores na GPU.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pynvml\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "from git import Repo\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from competence_extraction import HardwareEvaluator, ProcessingCapacityEstimator\n",
    "from competence_extraction import EmbeddingModelEvaluator, ModelComparator, PlotlyResultVisualizer\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "def recommend_batch_size(model, model_name, X, evaluator, estimator, batch_sizes=[8, 16, 32, 64, 128]):\n",
    "    results = {}\n",
    "    gpu_memory_usage = []\n",
    "    gpu_utilization = []\n",
    "\n",
    "    # Inicializa o pynvml para monitorar a GPU\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    \n",
    "    for batch_size in tqdm(batch_sizes, desc=f\"Modelo: {model_name}\"):\n",
    "        print(f\"\\nBenchmarking e interpretação para batch size = {batch_size}\")\n",
    "\n",
    "        # Benchmark na CPU\n",
    "        cpu_time = evaluator.benchmark_model(model, X, 'cpu', batch_size=batch_size)\n",
    "\n",
    "        # Benchmark na GPU (se disponível) e transferência de dados\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "            try:\n",
    "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "                    gpu_time = evaluator.benchmark_model(model, X, device, batch_size=batch_size)\n",
    "            except RuntimeError as e:\n",
    "                if \"CUDA out of memory\" in str(e):\n",
    "                    print(f\"Erro de memória da GPU para o modelo {model_name} com batch size {batch_size}.\")\n",
    "                    gpu_time = float('inf')\n",
    "                    transfer_results = {batch_size: {'cpu_to_gpu': 0, 'gpu_to_cpu': 0}}\n",
    "                else:\n",
    "                    # Plotar o trace até o momento do erro\n",
    "                    print(f\"Erro ao processar o modelo {model} com batch size {batch_size}: {e}\")\n",
    "                    print(\"Trace até o momento do erro:\")\n",
    "                    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10)) # type: ignore\n",
    "                    raise e  # Repassar o erro após exibir o trace\n",
    "\n",
    "            # Extrair dados de tracing do profiler\n",
    "            trace_events = prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10) # type: ignore\n",
    "            print(trace_events)\n",
    "            # Gerar gráfico de tracing (exemplo)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.bar(trace_events.columns[0], trace_events.columns[1])\n",
    "            plt.xlabel(\"Evento\")\n",
    "            plt.ylabel(\"Tempo (ms)\")\n",
    "            plt.title(f\"Tracing da GPU para {model_name} (batch size={batch_size})\")\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            gpu_time = None\n",
    "            transfer_results = {batch_size: {'cpu_to_gpu': 0, 'gpu_to_cpu': 0}}\n",
    "\n",
    "        # Monitorar GPU\n",
    "        gpu_memory_usage.append(pynvml.nvmlDeviceGetMemoryInfo(handle).used / 1024**2)  # Em MB\n",
    "        gpu_utilization.append(pynvml.nvmlDeviceGetUtilizationRates(handle).gpu)\n",
    "\n",
    "        # Cálcular tempo total (incluindo transferência)\n",
    "        total_cpu_time = cpu_time\n",
    "        total_gpu_time = gpu_time + transfer_results[batch_size]['cpu_to_gpu'] + transfer_results[batch_size]['gpu_to_cpu'] if gpu_time is not None else float('inf')\n",
    "\n",
    "        best_device = \"gpu\" if total_gpu_time < total_cpu_time else \"cpu\"\n",
    "        best_time = min(total_cpu_time, total_gpu_time)\n",
    "\n",
    "        results[batch_size] = {\n",
    "            'cpu_time': cpu_time,\n",
    "            'gpu_time': gpu_time,\n",
    "            'transfer_time': transfer_results[batch_size]['cpu_to_gpu'] + transfer_results[batch_size]['gpu_to_cpu'],\n",
    "            'total_cpu_time': total_cpu_time,\n",
    "            'total_gpu_time': total_gpu_time,\n",
    "            'best_device': best_device,\n",
    "            'best_time': best_time,\n",
    "        }\n",
    "\n",
    "    # Finalizar o pynvml\n",
    "    pynvml.nvmlShutdown()\n",
    "\n",
    "    # Criar DataFrame com os resultados\n",
    "    df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    df['batch_size'] = df.index\n",
    "\n",
    "    # Visualizar com Altair\n",
    "    chart = alt.Chart(df.melt('batch_size', var_name='metric', value_name='time')).mark_line(point=True).encode(\n",
    "        x='batch_size:Q',\n",
    "        y='time:Q',\n",
    "        color='metric:N',\n",
    "        tooltip=['batch_size', 'metric', 'time']\n",
    "    ).properties(\n",
    "        title=f'Tempos de Processamento para o Modelo {model}'\n",
    "    ).interactive()\n",
    "\n",
    "    chart.save(f'tempos_processamento_{model.replace(\"/\", \"_\")}.json')\n",
    "\n",
    "    # Encontrar o melhor batch size\n",
    "    best_batch_size = df['best_time'].idxmin()\n",
    "\n",
    "    print(f\"\\nRecomendação para o modelo {model}:\")\n",
    "    print(f\"  Melhor batch size: {best_batch_size}\")\n",
    "    print(f\"  Dispositivo recomendado: {df.loc[best_batch_size, 'best_device']}\")\n",
    "    print(f\"  Tempo de processamento estimado: {df.loc[best_batch_size, 'best_time']:.4f} segundos por amostra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "from git import Repo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from competence_extraction import CompetenceExtraction\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Caminho para o arquivo de currículos\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "filename = os.path.join(\"_data\", \"in_csv\", \"docents_dict_list.json\")\n",
    "pathfilename = os.path.join(str(root_folder), filename)\n",
    "\n",
    "# Verificar se o arquivo existe\n",
    "if not os.path.exists(pathfilename):\n",
    "    raise FileNotFoundError(f\"Arquivo JSON não encontrado: {pathfilename}\")\n",
    "\n",
    "try:\n",
    "    with open(pathfilename, \"r\") as f:\n",
    "        curricula_data = json.load(f)\n",
    "except json.JSONDecodeError:\n",
    "    raise ValueError(f\"Erro ao decodificar o arquivo JSON: {pathfilename}\")\n",
    "\n",
    "competence_extractor = CompetenceExtraction(curricula_file=pathfilename)\n",
    "\n",
    "# Lista de modelos a serem avaliados\n",
    "model_names = [\n",
    "    \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "    \"sentence-transformers/LaBSE\",\n",
    "    \"sentence-transformers/distiluse-base-multilingual-cased-v1\"\n",
    "]\n",
    "\n",
    "curricula_file = os.path.join(str(root_folder), filename)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA não está disponível. Verifique a instalação e configuração da CUDA.\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(device)\n",
    "\n",
    "# Sincronizar as operações CUDA\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Limpar o cache da GPU\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "classifier = EmbeddingModelEvaluator(curricula_file, model_names)\n",
    "\n",
    "# Definir o estimador (modelo de classificação)\n",
    "estimator = LogisticRegression() \n",
    "\n",
    "# Benchmark e interpretação para diferentes tamanhos de lote\n",
    "batch_sizes = [8, 16, 32, 64, 128]\n",
    "for model_name in model_names:\n",
    "    try:\n",
    "        model = SentenceTransformer(model_name, device=device) # type: ignore\n",
    "        model, X, y = classifier.prepare_data_for_classification(model)\n",
    "\n",
    "        # Recomendar o tamanho de lote ideal\n",
    "        try:\n",
    "            recommend_batch_size(model, model_name, X, classifier, estimator, batch_sizes)\n",
    "        except:\n",
    "            print(\"Não foi possível recomendar um tamanho de bath_size automaticamente\")\n",
    "            continue\n",
    "    except RuntimeError as e:\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            print(f\"Erro de memória da GPU para o modelo {model_name}. Tente reduzir o tamanho do lote ou usar um modelo menor.\")\n",
    "        else:\n",
    "            print(f\"Erro ao processar o modelo {model_name}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratar erros comuns durante processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O erro mais comum ao rodar modelos na GPU tende a ser \"CUDA error: an illegal memory access was encountered\" indica que a GPU ainda está encontrando problemas para processar a quantidade de dados ou a complexidade do modelo. Como queremos rodar modelos locais, com limitação de hardware, devemos focar em estratégias para otimizar o uso da GPU e contornar esse problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Dados do Software\")\n",
    "print(f\"  Versão do PyTorch: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"     Versão do CUDA: {torch.__version__}\")\n",
    "    print(f\"    Versão do cuDNN: {torch.backends.cudnn.version()}\")\n",
    "    print(f\"    CUDA disponível: {torch.cuda.is_available()}\")\n",
    "else:\n",
    "    print(\"CUDA não disponível, não está configurado corretamente.\")\n",
    "\n",
    "print(f\"\\nDados do Compilador CUDA\")\n",
    "!nvcc --version\n",
    "\n",
    "print(f\"\\nDetalhes do PyTorch\")\n",
    "!pip3 show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nDetalhes da Memória ocupada na GPU\")\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_HOME\"] = \"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.3\"\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Alinhar competências às necessidades do CEIS</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executar tarefas do modelo em Suporte ao PDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisar dos dados de fomento - fase exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install pytorch::faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Carregar o arquivo CSV de editais em um dataframe cuDF\n",
    "df_fomento = cudf.read_csv('df_fomento_geral.csv')\n",
    "\n",
    "# Carregar os dados dos currículos dos pesquisadores (assumindo que já estejam em um dataframe cuDF)\n",
    "df_curriculos = cudf.read_json('docents_dict_list.json', lines=True)  # Ajuste conforme a estrutura do seu JSON\n",
    "\n",
    "# Inicializar o modelo de embeddings de texto\n",
    "model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2').to('cuda')\n",
    "\n",
    "# Gerar embeddings para os detalhes dos editais\n",
    "edital_embeddings = model.encode(df_fomento['detalhes'].tolist(), convert_to_tensor=True).cpu().numpy()\n",
    "\n",
    "# Criar um índice Faiss para busca eficiente\n",
    "index = faiss.IndexFlatL2(edital_embeddings.shape[1])\n",
    "index.add(edital_embeddings, 3) ## Verificar do que trata o segundo parâmetro ao certo\n",
    "\n",
    "def recomendar_fomento(competencias_pesquisador):\n",
    "    # Gerar embeddings para as competências do pesquisador\n",
    "    competencias_embedding = model.encode(competencias_pesquisador, convert_to_tensor=True).cpu().numpy()\n",
    "\n",
    "    # Realizar a busca de similaridade no índice Faiss\n",
    "    # Buscar os 10 editais mais similares\n",
    "    D, I = index.search(competencias_embedding.reshape(1, -1), 10, 3)  ## Verificar do que trata o segundo parâmetro ao certo\n",
    "\n",
    "    # Retornar os editais recomendados\n",
    "    return df_fomento.iloc[I[0]]\n",
    "\n",
    "# Exemplo de uso\n",
    "for _, pesquisador in df_curriculos.iterrows(): # type: ignore\n",
    "    competencias = pesquisador['competencias']  # Assumindo que as competências estejam em uma coluna 'competencias'\n",
    "    recomendacoes_fomento = recomendar_fomento(competencias)\n",
    "    print(f\"Recomendações de fomento para o pesquisador {pesquisador['nome']}:\")\n",
    "    print(recomendacoes_fomento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar classes do pacote\n",
    "from research_process_automation import QuestionFormulation, InteractiveFeedback, QuestionCriteriaEvaluator\n",
    "\n",
    "# Criar instância da classe QuestionFormulation\n",
    "question_formulator = QuestionFormulation()\n",
    "\n",
    "# Solicitar informações do usuário\n",
    "question_formulator.input_ideas()\n",
    "\n",
    "# Gerar a pergunta de pesquisa\n",
    "research_question = question_formulator.generate_question()\n",
    "print(\"PASSO 01: Questão de pesquisa\")\n",
    "print(research_question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolução de entidades com Ontologias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "class BioPortalAPI:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = '6e1ec84f-53df-45a3-9115-25d245caefb1'\n",
    "        self.base_url = \"https://data.bioontology.org/api\"\n",
    "\n",
    "    def search_entities(self, query, ontologies=None, max_results=10):\n",
    "        \"\"\"\n",
    "        Realiza uma busca por entidades no BioPortal.\n",
    "\n",
    "        Args:\n",
    "            query: Termo de busca.\n",
    "            ontologies: Lista de acrônimos de ontologias (opcional).\n",
    "            max_results: Número máximo de resultados (opcional).\n",
    "\n",
    "        Returns:\n",
    "            Lista de dicionários com informações sobre as entidades encontradas.\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}/search?q={query}&apikey={self.api_key}\"\n",
    "        if ontologies:\n",
    "            url += f\"&ontologies={','.join(ontologies)}\"\n",
    "        if max_results:\n",
    "            url += f\"&pagesize={max_results}\"\n",
    "\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"collection\"]\n",
    "        else:\n",
    "            raise Exception(f\"Erro na requisição: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Listar competências de cada currículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import spacy\n",
    "from git import Repo\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from competence_extraction import CompetenceExtraction\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "filename = os.path.join(\"_data\", \"in_csv\", \"docents_dict_list.json\")\n",
    "pathfilename = os.path.join(str(root_folder), filename)\n",
    "\n",
    "# Verificar se o arquivo existe\n",
    "if not os.path.exists(pathfilename):\n",
    "    raise FileNotFoundError(f\"Arquivo JSON não encontrado: {pathfilename}\")\n",
    "\n",
    "try:\n",
    "    with open(pathfilename, \"r\") as f:\n",
    "        curricula_data = json.load(f)\n",
    "except json.JSONDecodeError:\n",
    "    raise ValueError(f\"Erro ao decodificar o arquivo JSON: {pathfilename}\")\n",
    "\n",
    "competence_extractor = CompetenceExtraction(curricula_file=pathfilename)\n",
    "\n",
    "# Extrair e imprimir as competências de cada pesquisador\n",
    "for researcher_index, researcher_data in enumerate(curricula_data[:6]):\n",
    "    competences = competence_extractor.extract_competences(researcher_data)\n",
    "    processed_competences = competence_extractor.preprocess_competences(competences)\n",
    "    print(f\"\\nCompetências do pesquisador {researcher_index + 1}:\")\n",
    "    for competence in processed_competences:\n",
    "        print(f\"- {competence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualizar áreas de pesquisa de cada currículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "import os\n",
    "import warnings\n",
    "from git import Repo\n",
    "from competence_extraction import EmbeddingModelEvaluator, ModelComparator, PlotlyResultVisualizer\n",
    "from tqdm.notebook import tqdm # Importando tqdm do notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"huggingface_hub\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def load_curricula():\n",
    "    with open(curricula_file, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def extrair_areas(areas_dict):\n",
    "    lista_grdareas = []\n",
    "    lista_areas = []\n",
    "    lista_subareas = []\n",
    "    # Expressão regular corrigida para extrair as áreas\n",
    "    pattern = r'Grande área:\\s*(.*?)\\s*/\\s*Área:\\s*(.*?)\\s*(?:/ Subárea:\\s*(.*?)\\s*)?\\.'\n",
    "\n",
    "    for _, valor in areas_dict.items():\n",
    "        match = re.search(pattern, valor)\n",
    "        if match:\n",
    "            areas = {\n",
    "                'Grande Área': match.group(1).strip() if match.group(1) else None , \n",
    "                'Área': match.group(2).strip() if match.group(2) else None ,\n",
    "                'Subárea': match.group(3).strip() if match.group(3) else None  \n",
    "            }\n",
    "            lista_grdareas.append(areas.get('Grande Área'))\n",
    "            lista_areas.append(areas.get('Área'))\n",
    "            lista_subareas.append(areas.get('Subárea'))\n",
    "\n",
    "    return {'Grande Áreas': lista_grdareas, 'Áreas': lista_areas, 'Subáreas': lista_subareas}\n",
    "\n",
    "# Caminho para o arquivo de currículos\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "filename = os.path.join(\"_data\", \"in_csv\", \"docents_dict_list.json\")\n",
    "curricula_file = os.path.join(str(root_folder), filename)\n",
    "\n",
    "curricula_data = load_curricula()\n",
    "\n",
    "for researcher_data in curricula_data:\n",
    "    areas =  researcher_data.get('Áreas')\n",
    "    print(extrair_areas(areas).get('Áreas'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extrair competências do currículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Verificar se a CUDA está disponível\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA não está disponível.\")\n",
    "\n",
    "# Carregar um modelo pré-treinado\n",
    "model = SentenceTransformer('paraphrase-distilroberta-base-v2')\n",
    "\n",
    "# Dados de exemplo\n",
    "sentences = [\"Esta é uma frase de teste.\", \"Outra frase de exemplo.\"]\n",
    "\n",
    "# Codificar as frases\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from git import Repo\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from competence_extraction import EmbeddingModelEvaluator, ModelComparator, PlotlyResultVisualizer\n",
    "from tqdm.notebook import tqdm # Importando tqdm do notebook\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"huggingface_hub\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Lista de modelos a serem avaliados\n",
    "model_names = [\n",
    "    \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "    \"sentence-transformers/LaBSE\",\n",
    "    \"sentence-transformers/distiluse-base-multilingual-cased-v1\"\n",
    "]\n",
    "\n",
    "# Caminho para o arquivo de currículos\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "filename = os.path.join(\"_data\", \"in_csv\", \"docents_dict_list.json\")\n",
    "curricula_file = os.path.join(str(root_folder), filename)\n",
    "\n",
    "# Dados de validação (exemplo)\n",
    "validation_data = {\n",
    "    'similar': [\n",
    "        (\"machine learning\", \"deep learning\"),\n",
    "        (\"biologia molecular\", \"genética\")\n",
    "    ],\n",
    "    'dissimilar': [\n",
    "        (\"machine learning\", \"medicina\"),\n",
    "        (\"biologia molecular\", \"finanças\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA não está disponível. Verifique a instalação e configuração da CUDA.\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(device)\n",
    "\n",
    "# Limpar o cache da GPU\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Sincronizar as operações CUDA\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Verificar se o arquivo de currículos existe\n",
    "if not os.path.exists(curricula_file):\n",
    "    raise FileNotFoundError(f\"Arquivo JSON não encontrado: {curricula_file}\")\n",
    "\n",
    "# Escolha do tipo de avaliação\n",
    "use_cross_validation = True  # ou False\n",
    "classifier_name = \"LogisticRegression\"  # ou \"MultinomialNB\", \"SVC\", \"RandomForestClassifier\"\n",
    "\n",
    "# Criar o avaliador e comparar os modelos\n",
    "evaluator = EmbeddingModelEvaluator(curricula_file, model_names)\n",
    "\n",
    "# Usar validação cruzada com Regressão Logística default\n",
    "# results = evaluator.evaluate_models(validation_data, use_cross_validation=True)\n",
    "\n",
    "# Usar divisão em treinamento e teste com SVM\n",
    "results = evaluator.evaluate_models(validation_data, use_cross_validation=False, classifier_name=\"SVC\")\n",
    "\n",
    "comparator = ModelComparator(results)\n",
    "best_model, best_score = comparator.get_best_model()\n",
    "\n",
    "if best_model is not None:\n",
    "    print(f\"\\nO melhor modelo é: {best_model} com pontuação de {best_score:.4f}\")\n",
    "elif not results:\n",
    "    print(\"\\nNenhum modelo foi avaliado com sucesso.\")\n",
    "else:\n",
    "    print(\"\\nNão foi possível determinar o melhor modelo.\")\n",
    "\n",
    "# Visualizar os resultados\n",
    "visualizer = PlotlyResultVisualizer(results)\n",
    "visualizer.plot_similarity_distributions()\n",
    "if not use_cross_validation: # Plota a acurácia apenas se não for validação cruzada\n",
    "    visualizer.plot_accuracy_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from git import Repo\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import silhouette_score\n",
    "from competence_extraction import EmbeddingModelEvaluator, ModelComparator, PlotlyResultVisualizer\n",
    "\n",
    "def evaluate_embeddings(X, y, metric=cosine_similarity, n_splits=5):\n",
    "    scores = defaultdict(list)\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "        y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "        for i, area in enumerate(y_test):\n",
    "            area_idx = [j for j, a in enumerate(y_train) if a == area]\n",
    "            competence_embeddings = [X_train[j] for j in area_idx]\n",
    "            similarities = metric([X_test[i]], competence_embeddings)\n",
    "            scores['intra_class'].append(np.mean(similarities))\n",
    "            dissimilar_idx = [j for j, a in enumerate(y_train) if a != area]\n",
    "            dissimilar_embeddings = [X_train[j] for j in dissimilar_idx]\n",
    "            similarities = metric([X_test[i]], dissimilar_embeddings)\n",
    "            scores['inter_class'].append(np.mean(similarities))\n",
    "\n",
    "        scores['silhouette'].append(silhouette_score(X_train, y_train, metric=metric)) # type: ignore\n",
    "\n",
    "    results = {k: np.mean(v) for k, v in scores.items()}\n",
    "    results['std_dev_intra_class'] = np.std(scores['intra_class'])\n",
    "    results['std_dev_inter_class'] = np.std(scores['inter_class'])\n",
    "    results['std_dev_silhouette'] = np.std(scores['silhouette'])\n",
    "    return results\n",
    "\n",
    "model_names = [\n",
    "    \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "    \"sentence-transformers/LaBSE\",\n",
    "    \"sentence-transformers/distiluse-base-multilingual-cased-v1\",\n",
    "    # Adicione outros modelos aqui\n",
    "]\n",
    "\n",
    "# Caminho para o arquivo de currículos\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "filename = os.path.join(\"_data\", \"in_csv\", \"docents_dict_list.json\")\n",
    "curricula_file = os.path.join(str(root_folder), filename)\n",
    "\n",
    "classifier = EmbeddingModelEvaluator(curricula_file, model_names)\n",
    "\n",
    "# Defina o dispositivo (GPU se disponível, caso contrário CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Especifique a GPU correta (e.g., \"cuda:0\") se tiver várias\n",
    "    print(\"Usando GPU para processamento.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA não disponível, usando CPU.\")\n",
    "\n",
    "# Loop para avaliar os modelos\n",
    "for model_name in model_names:\n",
    "    # Limpeza de cache da GPU\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Redução do tamanho do lote\n",
    "    embeddings = model.encode(processed_competences, convert_to_tensor=True, batch_size=32)  # Tente um valor menor\n",
    "\n",
    "    # Carregue o modelo com o dispositivo especificado\n",
    "    model = SentenceTransformer(model_name, device=device) # type: ignore\n",
    "    X, y = classifier.prepare_data_for_classification(model) # type: ignore\n",
    "    score = evaluate_embeddings(X, y)\n",
    "    print(f\"Modelo: {model_name}, Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Escolher melhor vetorização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação individual do modelo de embeedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import spacy\n",
    "from git import Repo\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from competence_extraction import CompetenceExtraction\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "filename = os.path.join(\"_data\", \"in_csv\", \"docents_dict_list.json\")\n",
    "pathfilename = os.path.join(str(root_folder), filename)\n",
    "\n",
    "# Verificar se o arquivo existe\n",
    "if not os.path.exists(pathfilename):\n",
    "    raise FileNotFoundError(f\"Arquivo JSON não encontrado: {pathfilename}\")\n",
    "\n",
    "try:\n",
    "    with open(pathfilename, \"r\") as f:\n",
    "        curricula_data = json.load(f)\n",
    "except json.JSONDecodeError:\n",
    "    raise ValueError(f\"Erro ao decodificar o arquivo JSON: {pathfilename}\")\n",
    "\n",
    "competence_extractor = CompetenceExtraction(curricula_file=pathfilename)\n",
    "\n",
    "# Extrair e vetorizar as competências de todos os pesquisadores\n",
    "all_competences = []\n",
    "for researcher_index, researcher_data in enumerate(curricula_data):  # Itera sobre a lista\n",
    "    competences = competence_extractor.extract_competences(researcher_data)\n",
    "    processed_competences = competence_extractor.preprocess_competences(competences)\n",
    "    all_competences.extend(processed_competences)\n",
    "\n",
    "# Vetorizar as competências em lote\n",
    "competence_vectors = competence_extractor.vectorize_competences(all_competences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(competence_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Suponha que você tenha uma lista de pares de competências semelhantes e não semelhantes\n",
    "similar_pairs    = [(\"machine learning\", \"deep learning\"), (\"biologia molecular\", \"genética\")]\n",
    "dissimilar_pairs = [(\"machine learning\", \"medicina\"), (\"biologia molecular\", \"finanças\")]\n",
    "\n",
    "# Calcule a similaridade de cosseno entre os embeddings dos pares\n",
    "for pair in similar_pairs + dissimilar_pairs:\n",
    "    embedding1 = competence_extractor.vectorize_competences([pair[0]])\n",
    "    embedding2 = competence_extractor.vectorize_competences([pair[1]])\n",
    "    similarity = cosine_similarity(embedding1, embedding2)[0][0]\n",
    "    print(f\"Similaridade entre '{pair[0]}' e '{pair[1]}': {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação comparativa entre os modelos de embeedings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas de Avaliação: As métricas utilizadas (similaridade média e acurácia) outras métricas de acordo com necessidade.\n",
    "\n",
    "Dados de Validação: Os dados de validação fornecidos são apenas exemplos. \n",
    "\n",
    "Os dados precisam ser reais e representativos para avaliar os modelos de forma adequada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lista de modelos a serem avaliados (atualizada)\n",
    "# model_names = [\"sentence-transformers/distiluse-base-multilingual-cased-v2\", \n",
    "#                \"bert-base-multilingual-cased\", \n",
    "#                \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"]\n",
    "\n",
    "# model_names = [\n",
    "#     \"sentence-transformers/distiluse-base-multilingual-cased-v2\", \n",
    "#     \"bert-base-uncased\",  # Modelo compatível com xFormers\n",
    "#     \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "# ]\n",
    "\n",
    "# Lista de modelos a serem avaliados\n",
    "# model_names = [\"distiluse-base-multilingual-cased-v2\",\n",
    "#                 \"bert-base-multilingual-cased\", \n",
    "#                 \"paraphrase-multilingual-mpnet-base-v2\"] ## Nome antigo não mais disponível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpustat\n",
    "\n",
    "gpu_stats = gpustat.GPUStatCollection.new_query()\n",
    "print(gpu_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export CUDA_LAUNCH_BLOCKING=1  # No Linux/macOS\n",
    "!set CUDA_LAUNCH_BLOCKING=1  # No Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Limpeza de memória após a avaliação de cada modelo\n",
    "# del model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from git import Repo\n",
    "\n",
    "from competence_extraction import EmbeddingModelEvaluator, ModelComparator, PlotlyResultVisualizer\n",
    "from tqdm.notebook import tqdm # Importando tqdm do notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"huggingface_hub\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Lista de modelos a serem avaliados\n",
    "model_names = [\n",
    "    \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "    \"sentence-transformers/LaBSE\",\n",
    "    \"sentence-transformers/distiluse-base-multilingual-cased-v1\"\n",
    "]\n",
    "\n",
    "# Caminho para o arquivo de currículos\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "filename = os.path.join(\"_data\", \"in_csv\", \"docents_dict_list.json\")\n",
    "curricula_file = os.path.join(str(root_folder), filename)\n",
    "\n",
    "# Dados de validação (exemplo)\n",
    "validation_data = {\n",
    "    'similar': [\n",
    "        (\"machine learning\", \"deep learning\"),\n",
    "        (\"biologia molecular\", \"genética\")\n",
    "    ],\n",
    "    'dissimilar': [\n",
    "        (\"machine learning\", \"medicina\"),\n",
    "        (\"biologia molecular\", \"finanças\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Verificar se o arquivo de currículos existe\n",
    "if not os.path.exists(curricula_file):\n",
    "    raise FileNotFoundError(f\"Arquivo JSON não encontrado: {curricula_file}\")\n",
    "\n",
    "# Escolha do tipo de avaliação\n",
    "use_cross_validation = True  # ou False\n",
    "classifier_name = \"LogisticRegression\"  # ou \"MultinomialNB\", \"SVC\", \"RandomForestClassifier\"\n",
    "\n",
    "# Criar o avaliador e comparar os modelos\n",
    "evaluator = EmbeddingModelEvaluator(curricula_file, model_names)\n",
    "\n",
    "# Usar validação cruzada com Regressão Logística default\n",
    "# results = evaluator.evaluate_models(validation_data, use_cross_validation=True)\n",
    "\n",
    "# Usar divisão em treinamento e teste com SVM\n",
    "# results = evaluator.evaluate_models(validation_data, use_cross_validation=False, classifier_name=\"SVC\")\n",
    "results = evaluator.evaluate_models(validation_data, use_cross_validation=False, classifier_name=\"MultinomialNB\")\n",
    "\n",
    "comparator = ModelComparator(results)\n",
    "best_model, best_score = comparator.get_best_model()\n",
    "\n",
    "if best_model is not None:\n",
    "    print(f\"\\nO melhor modelo é: {best_model} com pontuação de {best_score:.4f}\")\n",
    "elif not results:\n",
    "    print(\"\\nNenhum modelo foi avaliado com sucesso.\")\n",
    "else:\n",
    "    print(\"\\nNão foi possível determinar o melhor modelo.\")\n",
    "\n",
    "# Visualizar os resultados\n",
    "visualizer = PlotlyResultVisualizer(results)\n",
    "visualizer.plot_similarity_distributions()\n",
    "if not use_cross_validation: # Plota a acurácia apenas se não for validação cruzada\n",
    "    visualizer.plot_accuracy_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from git import Repo\n",
    "\n",
    "from competence_extraction import EmbeddingModelEvaluator, ModelComparator, PlotlyResultVisualizer\n",
    "# from tqdm.notebook import tqdm # Importando tqdm do notebook\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"huggingface_hub\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# # Lista de modelos a serem avaliados\n",
    "# model_names = [\n",
    "#     \"sentence-transformers/distiluse-base-multilingual-cased-v2\",\n",
    "#     \"bert-base-multilingual-cased\",\n",
    "#     \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "# ]\n",
    "\n",
    "# Lista de modelos a serem avaliados (atualizada)\n",
    "model_names = [\n",
    "    \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "    \"sentence-transformers/LaBSE\",\n",
    "    \"sentence-transformers/distiluse-base-multilingual-cased-v1\"\n",
    "]\n",
    "\n",
    "\n",
    "# Caminho para o arquivo de currículos\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "filename = os.path.join(\"_data\", \"in_csv\", \"docents_dict_list.json\")\n",
    "curricula_file = os.path.join(str(root_folder), filename)\n",
    "\n",
    "# Dados de validação (exemplo)\n",
    "validation_data = {\n",
    "    'similar': [\n",
    "        (\"machine learning\", \"deep learning\"),\n",
    "        (\"biologia molecular\", \"genética\")\n",
    "    ],\n",
    "    'dissimilar': [\n",
    "        (\"machine learning\", \"medicina\"),\n",
    "        (\"biologia molecular\", \"finanças\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Verificar se o arquivo de currículos existe\n",
    "if not os.path.exists(curricula_file):\n",
    "    raise FileNotFoundError(f\"Arquivo JSON não encontrado: {curricula_file}\")\n",
    "\n",
    "# Criar o avaliador e comparar os modelos\n",
    "evaluator = EmbeddingModelEvaluator(curricula_file, model_names)\n",
    "results = evaluator.evaluate_models(validation_data)\n",
    "\n",
    "comparator = ModelComparator(results)\n",
    "best_model, best_score = comparator.get_best_model()\n",
    "\n",
    "if best_model is not None:\n",
    "    print(f\"\\nO melhor modelo é: {best_model} com pontuação de {best_score:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNão foi possível determinar o melhor modelo devido à falta de dados para validação cruzada.\")\n",
    "\n",
    "# Visualizar os resultados\n",
    "visualizer = PlotlyResultVisualizer(results)\n",
    "visualizer.plot_similarity_distributions()\n",
    "visualizer.plot_accuracy_comparison()  # Comentar esta linha se não houver resultados de validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmarking em Gerar Embeedings de Competências em PDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lime\n",
    "\n",
    "# # Lista de modelos a serem avaliados\n",
    "# model_names = [\n",
    "#     \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "#     \"sentence-transformers/distiluse-base-multilingual-cased-v1\",\n",
    "#     \"sentence-transformers/LaBSE\"\n",
    "# ]\n",
    "\n",
    "# # Caminho para o arquivo de currículos\n",
    "# repo = Repo(search_parent_directories=True)\n",
    "# root_folder = repo.working_tree_dir\n",
    "# filename = os.path.join(\"_data\", \"in_csv\", \"docents_dict_list.json\")\n",
    "# curricula_file = os.path.join(str(root_folder), filename)\n",
    "\n",
    "# # Dispositivo de processamento\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Instanciando as classes de avaliação\n",
    "# hardware_evaluator = HardwareEvaluator()\n",
    "# estimator = ProcessingCapacityEstimator(hardware_evaluator)\n",
    "# classifier = EmbeddingModelEvaluator(curricula_file, model_names)\n",
    "\n",
    "# # Tamanhos de lote para testar\n",
    "# batch_sizes = [8, 16, 32, 64, 128]\n",
    "\n",
    "# # Dicionário para armazenar os resultados da avaliação\n",
    "# results = {}\n",
    "\n",
    "# # Realizar benchmarks e recomendações\n",
    "# for model_name in model_names:\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.empty_cache()\n",
    "#         torch.cuda.synchronize()\n",
    "#         print('='*125)\n",
    "#         print(f'MODELO PRÉ-TREINADO: {model_name}')\n",
    "#         try:\n",
    "#             # Limpar a memória da GPU antes de carregar o modelo\n",
    "#             torch.cuda.empty_cache() \n",
    "\n",
    "#             # Monitorar o uso de memória antes e depois de carregar o modelo\n",
    "#             print(f\"Memória ocupada na GPU  antes de carregar o modelo: {np.round(torch.cuda.memory_allocated() / 1024**2,2):>8} MB\")\n",
    "#             model = SentenceTransformer(model_name, device=device) #type: ignore\n",
    "#             print(f\"Memória ocupada na GPU depois de carregar o modelo: {np.round(torch.cuda.memory_allocated() / 1024**2,2):>8} MB\")\n",
    "#             print('-'*125)\n",
    "\n",
    "#             # Preparar os dados para classificação (passe o objeto 'model')\n",
    "#             X, y = classifier.prepare_data_for_classification(model) # type: ignore\n",
    "\n",
    "#             # Converter X e y para arrays NumPy, movendo os tensores para a CPU primeiro\n",
    "#             if isinstance(X, list):\n",
    "#                 X = np.array([tensor.cpu().numpy() for tensor in X]) \n",
    "#             if isinstance(y, list):\n",
    "#                 y = np.array(y) \n",
    "\n",
    "#             # Dividir os dados em conjuntos de treinamento e teste\n",
    "#             X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "#             # Escolha do classificador (adaptado para lidar com dados desbalanceados ou uma classe)\n",
    "#             unique_classes = np.unique(y_train)\n",
    "#             if len(unique_classes) == 1:\n",
    "#                 # Se houver apenas uma classe, use um algoritmo de detecção de anomalias\n",
    "#                 clf = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)  # Ou IsolationForest, LocalOutlierFactor\n",
    "#                 clf.fit(X_train)\n",
    "#                 y_pred = clf.predict(X_test)\n",
    "#                 # Converter as previsões para 0 (normal) ou 1 (anomalia)\n",
    "#                 y_pred = [0 if pred == 1 else 1 for pred in y_pred]\n",
    "#                 # Como estamos em um cenário de detecção de anomalias, \n",
    "#                 # assumimos que a classe minoritária (ou única) é a anomalia (classe 1)\n",
    "#                 y_test = [1 if label == unique_classes[0] else 0 for label in y_test] \n",
    "#             else:\n",
    "#                 # Se houver mais de uma classe, use um classificador robusto a dados desbalanceados\n",
    "#                 clf = LogisticRegression(class_weight='balanced', max_iter=1000)  # Ou outro classificador adequado\n",
    "#                 clf.fit(X_train, y_train)\n",
    "#                 y_pred = clf.predict(X_test)\n",
    "\n",
    "#             # Avaliar o modelo\n",
    "#             report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "#             # Explicabilidade com LIME\n",
    "#             explainer = lime.lime_text.LimeTextExplainer(class_names=clf.classes_)\n",
    "#             idx = 0  # Escolha um exemplo para explicar\n",
    "#             exp = explainer.explain_instance(X_test[idx], clf.predict_proba, num_features=10)\n",
    "#             print(f\"Explicação para a instância {idx}:\")\n",
    "#             print(exp.as_list())\n",
    "\n",
    "#             # Armazenar os resultados\n",
    "#             results[model_name] = {\n",
    "#                 'report': report,\n",
    "#                 'explainer': explainer  # Armazene o objeto explainer para uso posterior\n",
    "#             }\n",
    "#         except RuntimeError as e:\n",
    "#             if \"CUDA out of memory\" in str(e):\n",
    "#                 print(f\"Erro de memória da GPU para o modelo {model_name}. Tente reduzir o tamanho do lote ou usar um modelo menor.\")\n",
    "#             else:\n",
    "#                 print(f\"\\n  Erro ao processar o modelo {model_name}\")\n",
    "#                 print(f\"  {e}\")\n",
    "#     else:\n",
    "#         print('GPU não configurada corretamente, CUDA indisponível')\n",
    "\n",
    "# if results:\n",
    "#     # Comparar os modelos e escolher o melhor\n",
    "#     best_model = max(results, key=lambda k: results[k]['report']['macro avg']['f1-score'])\n",
    "#     print(f\"\\nO melhor modelo é: {best_model}\")\n",
    "#     print(results[best_model]['report'])\n",
    "# else:\n",
    "#     print('Não foi possível ler os resultados para realizar as comparações de desempenho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gml_benchmark\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import time\n",
    "\n",
    "# # Carregar os dados do currículo usando sua classe CompetenceExtraction\n",
    "# repo = Repo(search_parent_directories=True)\n",
    "# root_folder = repo.working_tree_dir\n",
    "# filename = os.path.join(\"_data\", \"in_csv\", \"docents_dict_list.json\")\n",
    "# pathfilename = os.path.join(str(root_folder), filename)\n",
    "\n",
    "# # Verificar se o arquivo existe\n",
    "# if not os.path.exists(pathfilename):\n",
    "#     raise FileNotFoundError(f\"Arquivo JSON não encontrado: {pathfilename}\")\n",
    "\n",
    "# try:\n",
    "#     with open(pathfilename, \"r\") as f:\n",
    "#         curricula_data = json.load(f)\n",
    "# except json.JSONDecodeError:\n",
    "#     raise ValueError(f\"Erro ao decodificar o arquivo JSON: {pathfilename}\")\n",
    "\n",
    "# competence_extractor = CompetenceExtraction(curricula_file=pathfilename)\n",
    "# curricula_data = competence_extractor.load_curricula()\n",
    "# competences = []\n",
    "# for researcher_data in curricula_data:\n",
    "#     competences.extend(competence_extractor.extract_competences(researcher_data))\n",
    "# processed_competences = competence_extractor.preprocess_competences(competences)\n",
    "\n",
    "# # Defina o número de clusters desejado para a classificação\n",
    "# num_clusters = 5  # Ou ajuste conforme necessário\n",
    "\n",
    "# # Defina a operação de benchmarking (geração de embeddings e classificação)\n",
    "# def embedding_generation_and_classification(graph, model, data, num_clusters):\n",
    "#     embeddings = gml_benchmark.generate_embeddings(model, data)\n",
    "\n",
    "#     if isinstance(graph, torch_geometric.data.Data):\n",
    "#         graph.x = embeddings\n",
    "#     elif isinstance(graph, dgl.DGLGraph):\n",
    "#         graph.ndata['feat'] = embeddings\n",
    "\n",
    "#     node_similarity = gml_benchmark.calculate_node_similarity(embeddings)\n",
    "#     edge_similarity = gml_benchmark.calculate_edge_similarity(graph)\n",
    "\n",
    "#     node_labels = gml_benchmark.classify_nodes(embeddings, num_clusters)\n",
    "#     edge_labels = gml_benchmark.classify_edges(edge_similarity, num_clusters)\n",
    "\n",
    "# # Lista de modelos a serem avaliados (mesma do código anterior)\n",
    "# model_names = [\n",
    "#     \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "#     \"sentence-transformers/distiluse-base-multilingual-cased-v1\",\n",
    "#     \"sentence-transformers/LaBSE\"\n",
    "# ]\n",
    "\n",
    "# # Dispositivo de processamento\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Benchmarking\n",
    "# results = {}\n",
    "# for model_name in model_names:\n",
    "#     print('-' * 125)\n",
    "#     print(f'MODELO PRÉ-TREINADO: {model_name}')\n",
    "\n",
    "#     try:\n",
    "#         # Carregar o modelo pré-treinado\n",
    "#         model = SentenceTransformer(model_name, device=device) # type: ignore\n",
    "\n",
    "#         # Criar os grafos (implemente as funções de criação de grafo)\n",
    "#         pyg_graph = gml_benchmark.create_pytorch_geometric_graph([], [])  # Substitua [] pelos seus dados de aresta\n",
    "#         dgl_graph = gml_benchmark.create_dgl_graph([], [])            # Substitua [] pelos seus dados de aresta\n",
    "\n",
    "#         # Realizar o benchmarking\n",
    "#         pyg_time = gml_benchmark.benchmark_operation(\n",
    "#             pyg_graph, \"PyTorch Geometric\",\n",
    "#             lambda graph: embedding_generation_and_classification(graph, model, processed_competences, num_clusters)\n",
    "#         )\n",
    "#         dgl_time = gml_benchmark.benchmark_operation(\n",
    "#             dgl_graph, \"DGL\",\n",
    "#             lambda graph: embedding_generation_and_classification(graph, model, processed_competences, num_clusters)\n",
    "#         )\n",
    "\n",
    "#         # Armazenar os resultados\n",
    "#         results[model_name] = {\"PyTorch Geometric\": pyg_time, \"DGL\": dgl_time}\n",
    "\n",
    "#     except RuntimeError as e:\n",
    "#         if \"CUDA out of memory\" in str(e):\n",
    "#             print(f\"Erro de memória da GPU para o modelo {model_name}. Tente reduzir o tamanho do lote ou usar um modelo menor.\")\n",
    "#         else:\n",
    "#             print(f\"Erro ao processar o modelo {model_name}: {e}\")\n",
    "\n",
    "# # Plotar os resultados\n",
    "# gml_benchmark.plot_benchmark_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gerar o modelo grafo inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install networkx\n",
    "# !pip install matplotlib\n",
    "# !pip3 install selenium\n",
    "# !pip3 install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('../../templates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from IPython.display import IFrame\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# from pathlib import Path\n",
    "# def find_repo_root(path='.', depth=10):\n",
    "#         ''' \n",
    "#         Busca o arquivo .git e retorna string com a pasta raiz do repositório.\n",
    "#         '''\n",
    "#         # Prevenir recursão infinita limitando a profundidade\n",
    "#         if depth < 0:\n",
    "#             return None\n",
    "#         path = Path(path).absolute()\n",
    "#         if (path / '.git').is_dir():\n",
    "#             return path\n",
    "#         # Corrigido para usar LattesScraper.find_repo_root para chamada recursiva\n",
    "#         return find_repo_root(path.parent, depth-1)\n",
    "\n",
    "import os\n",
    "from git import Repo\n",
    "\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "# data_folder = os.path.join(str(root_folder),\"_data\",\"in_pdf\")\n",
    "\n",
    "# Criar o grafo\n",
    "G = nx.Graph()\n",
    "\n",
    "# Adicionar nós (dominios, processos e entidades)\n",
    "dominios = [\"Pesquisar\", \"Desenvolver\", \"Inovar\"]\n",
    "processos = [\"P001\", \"P002\", \"P003\", \"P004\", \"P005\", \"P006\", \"P007\", \"P008\", \"P009\"]\n",
    "entidades = {\n",
    "    \"P001\": [\"Dores\", \"Desejos\", \"Desafios\"],\n",
    "    \"P002\": [\"Temas\", \"Tópicos\", \"Assuntos\"],\n",
    "    \"P003\": [\"Atitudes\", \"Experiências\", \"Habilidades\"],\n",
    "    \"P004\": [\"Papeis\", \"Tempo\", \"Orçamentos\"],\n",
    "    \"P005\": [\"Projetos\", \"Processos\", \"Programas\"],\n",
    "    \"P006\": [\"Ensaios\", \"Equipamentos\", \"Ambientes\"],\n",
    "    \"P007\": [\"Aplicação\", \"Solução\", \"Produto-Serviço\"],\n",
    "    \"P008\": [\"Modelos\", \"Protótipos\", \"Empreendimentos\"],\n",
    "    \"P009\": [\"Indicadores\", \"Evidências\", \"Mensuração\"]\n",
    "}\n",
    "\n",
    "# Criar visualização dos nós de acordo com a estrutura de dados\n",
    "for macroprocesso in dominios:\n",
    "    G.add_node(macroprocesso, type=\"macroprocesso\")\n",
    "\n",
    "for processo in processos:\n",
    "    G.add_node(processo, type=\"processo\")\n",
    "\n",
    "for processo, entidades_list in entidades.items():\n",
    "    for entidade in entidades_list:\n",
    "        G.add_node(entidade, type=\"entidade\")\n",
    "\n",
    "# Adicionar arestas (relacionamentos)\n",
    "for macroprocesso in dominios:\n",
    "    for i in range(1, 4):\n",
    "        G.add_edge(macroprocesso, f\"P00{i + 3*(dominios.index(macroprocesso))}\")\n",
    "\n",
    "for processo, entidades_list in entidades.items():\n",
    "    for entidade in entidades_list:\n",
    "        G.add_edge(processo, entidade)\n",
    "\n",
    "# (Opcional) Adicionar relacionamentos entre entidades, para formar Demanda, Faturamento, Lucro, Reinvestimento... etc\n",
    "# G.add_edge(\"Dores\", \"Desejos\")\n",
    "\n",
    "# Calcular distâncias, definir cores, tamanhos e tamanhos de fonte\n",
    "node_distances = {}\n",
    "for macroprocesso in dominios:\n",
    "    for node, distance in nx.shortest_path_length(G, source=macroprocesso).items():\n",
    "        node_distances[node] = distance\n",
    "\n",
    "cores_base = {\"macroprocesso\": \"#007BFF\", \"processo\": \"#28A745\", \"entidade\": \"#FFC107\"}\n",
    "node_colors = {}\n",
    "node_sizes = {}\n",
    "node_font_sizes = {}  # Dicionário para armazenar os tamanhos de fonte\n",
    "for node in G.nodes():\n",
    "    node_type = G.nodes[node][\"type\"]\n",
    "    cor_base = cores_base[node_type]\n",
    "    alpha = max(0, 255 - 25 * node_distances[node])\n",
    "    node_colors[node] = f\"{cor_base}{alpha:02X}\"\n",
    "\n",
    "    # Definir tamanhos e tamanhos de fonte com base na distância\n",
    "    tamanho_base = {\"macroprocesso\": 50, \"processo\": 30, \"entidade\": 15}\n",
    "    font_size_base = {\"macroprocesso\": 42, \"processo\": 28, \"entidade\": 18}  # Tamanhos de fonte iniciais\n",
    "    node_sizes[node] = tamanho_base[node_type] - 5 * node_distances[node]\n",
    "    node_font_sizes[node] = font_size_base[node_type] - node_distances[node]  # Reduzir 1 pixel por passo\n",
    "\n",
    "# Configurar o PyVis (notebook=False para renderizar na célula)\n",
    "net = Network(notebook=False, width=\"100%\", height=\"1200px\", bgcolor=\"#ffffff\", font_color=\"black\") # type: ignore\n",
    "net.barnes_hut()\n",
    "\n",
    "# Adicionar nós e arestas ao PyVis\n",
    "for node in G.nodes():\n",
    "    net.add_node(node, label=node, color=node_colors[node], title=G.nodes[node][\"type\"], \n",
    "                 size=node_sizes[node], font={\"size\": node_font_sizes[node], \"color\": \"black\"})  # Adicionar tamanho da fonte\n",
    "\n",
    "for edge in G.edges():\n",
    "    weight = 1\n",
    "    net.add_edge(*edge, value=weight)\n",
    "\n",
    "# Configurar o ForceAtlas2\n",
    "net.options.physics.solver = \"forceAtlas2Based\"\n",
    "net.options.physics.forceAtlas2Based = { # type: ignore\n",
    "    \"gravitationalConstant\": -50,\n",
    "    \"centralGravity\": 0.01,\n",
    "    \"springLength\": 100,\n",
    "    \"springConstant\": 0.08,\n",
    "    \"damping\": 0.4,\n",
    "    \"avoidOverlap\": 1\n",
    "}\n",
    "\n",
    "driver_path = None\n",
    "try:\n",
    "    # Caminho para o chromedriver no sistema local\n",
    "    if platform.system() == \"Windows\":\n",
    "        driver_path=os.path.join(str(root_folder),'chromedriver','chromedriver.exe')\n",
    "    else:\n",
    "        driver_path=os.path.join(str(root_folder),'chromedriver','chromedriver')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"Não foi possível estabelecer uma conexão, verifique o chromedriver\")\n",
    "    print(e)\n",
    "\n",
    "# print(driver_path)\n",
    "# service = Service(driver_path)\n",
    "# driver = webdriver.Chrome(service=service)\n",
    "# driver.get(\"grafo_interativo.html\")\n",
    "\n",
    "# Adicionar controles interativos (opcional)\n",
    "net.show_buttons(filter_=['physics'])\n",
    "# Adicionar estilo inline para fundo branco\n",
    "net.html = net.html.replace(\"<body>\", '<body style=\"background-color: white;\">')\n",
    "\n",
    "# Salvar o HTML na pasta templates\n",
    "template_dir = os.path.join(str(root_folder),'templates')\n",
    "pathfilename = os.path.join(template_dir,\"grafo_interativo.html\")\n",
    "net.save_graph(pathfilename)\n",
    "\n",
    "print(f\"Grafo interativo salvo em: {pathfilename}\")\n",
    "# Renderizar na célula do Jupyter Notebook\n",
    "# net.show(\"'../../templates'grafo_interativo.html\")  # Definir fundo branco ao salvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Renderizar grafo no Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "net = Network(notebook=True, \n",
    "              width=\"100%\", \n",
    "              height=\"1200px\", \n",
    "              bgcolor=\"#ffffff\", \n",
    "              font_color=\"black\") # type: ignore\n",
    "\n",
    "IFrame(src='http://127.0.0.1:5000/grafo_interativo.html', width='100%', height='800px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renderizar grafo em HTML na célula do Jupyter Notebook\n",
    "from IPython.display import IFrame\n",
    "IFrame(src=\"grafo_interativo.html\", width=\"100%\", height=\"600px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Tarefas para monitorar políticas públicas</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obter dados de Protocolos e Diretrizes Clínicas vigentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocolos clínicos vigentes no site do Ministério da Saúde\n",
    "\n",
    "Fonte de dados para extração de protocolos: https://www.gov.br/saude/pt-br/assuntos/pcdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protocolos clínicos vigentes no site do CONITEC\n",
    "Fonte de dados para extração de protocolos: https://www.gov.br/conitec/pt-br/assuntos/avaliacao-de-tecnologias-em-saude/protocolos-clinicos-e-diretrizes-terapeuticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baixar Protocolos e Diretrizes Clínicas do Site do MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_protocol import SaudeGovDataExtractor\n",
    "\n",
    "extractor = SaudeGovDataExtractor(\"https://www.gov.br/saude/pt-br/assuntos/pcdt\")\n",
    "df_docs, sucessos, erros = extractor.download_pdfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs[:60] # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitorar fluxos e fontes de dados no CONITEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fluxo elaboração/atualização de Protocolos e Diretrizes\n",
    "https://www.gov.br/conitec/pt-br/assuntos/avaliacao-de-tecnologias-em-saude/pcdt-em-elaboracao-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fluxo de Incorporação de Tecnologia no SUS\n",
    "https://www.gov.br/conitec/pt-br/assuntos/fluxo-de-incorporacao-de-tecnologias-no-sus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitorar Tecnologias discutidas no CONITEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.gov.br/conitec/pt-br/assuntos/avaliacao-de-tecnologias-em-saude/monitoramento-de-tecnologias-em-saude#MHT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acompanhar Publicações Diretrizes Clínicas CONITEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.gov.br/conitec/pt-br/assuntos/noticias/2024/abril/atualizacao-anual-de-diretrizes-clinicas-pelo-ministerio-da-saude-segue-criterios-de-priorizacao-e-considera-encaminhamento-de-areas-tecnicas\n",
    "\n",
    "https://www.gov.br/conitec/pt-br/@@search?SearchableText=Diretrizes%20Cl%C3%ADnicas\n",
    "\n",
    "https://www.gov.br/conitec/pt-br/midias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd, os, re, sys, time, json, subprocess\n",
    "\n",
    "## Configurar exibição do pandas para melhor visualizar os dados\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('colheader_justify', 'left')\n",
    "pd.set_option('display.max_rows', 600)\n",
    "\n",
    "def find_repo_root(path='.', depth=10):\n",
    "    ''' \n",
    "    Busca o arquivo .git e retorna string com a pasta raiz do repositório\n",
    "    '''\n",
    "    # Prevent infinite recursion by limiting depth\n",
    "    if depth < 0:\n",
    "        return None\n",
    "    path = Path(path).absolute()\n",
    "    if (path / '.git').is_dir():\n",
    "        return path\n",
    "    return find_repo_root(str(path.parent), depth-1)\n",
    "\n",
    "delay = 10\n",
    "\n",
    "## Definir a pasta de base do repositório local\n",
    "base_repo_dir = find_repo_root()\n",
    "\n",
    "## Sempre construir os caminhos usando os.path.join para compatibilidade WxL\n",
    "folder_utils = os.path.join(str(base_repo_dir), 'utils')\n",
    "folder_domain = os.path.join(str(base_repo_dir), 'source', 'domain')\n",
    "folder_data_input = os.path.join(str(base_repo_dir), '_data', 'in_csv')\n",
    "folder_data_output = os.path.join(str(base_repo_dir), '_data', 'out_json')\n",
    "\n",
    "## Adicionar pastas locais ao sys.path para importar pacotes criados localmente\n",
    "sys.path.append(folder_utils)\n",
    "sys.path.append(folder_domain)\n",
    "from environment_setup import EnvironmentSetup\n",
    "from chromedriver_manager import ChromeDriverManager\n",
    "from neo4j_persister import Neo4jPersister\n",
    "from lattes_scrapper import JSONFileManager, LattesScraper, HTMLParser, SoupParser, GetQualis, ArticlesCounter, DictToHDF5, attribute_to_be_non_empty\n",
    "from extract_protocol import SaudeGovDataExtractor\n",
    "# from scraper_pasteur import PasteurScraper\n",
    "# from scraper_sucupira import SucupiraScraper\n",
    "# from scraper_sucupira_edge import SucupiraScraperEdge\n",
    "\n",
    "t00 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from git import Repo\n",
    "from extract_protocol import SaudeGovDataExtractor\n",
    "\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "extractor = SaudeGovDataExtractor(\"https://www.gov.br/saude/pt-br/assuntos/pcdt\")\n",
    "links = extractor.get_links()\n",
    "if links:\n",
    "    print(f'{len(links)} links extraídos')\n",
    "\n",
    "## Visualizar links para documentos de protocolos e diretrizes\n",
    "# for link in links:\n",
    "#     filename = os.path.join(str(root_folder),\"_data\",\"in_pdf\", link.split(\"/\")[-1])\n",
    "#     if '#' in filename:\n",
    "#         filename = filename.split('#')[0]\n",
    "#     print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Tarefas para obter dados de Inovação no Mundo</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desempenho em Inovação no mundo e no Brasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A medição da inovação em nível mundial é um campo importante para entender como diferentes nações estão progredindo em termos de capacidade e sucesso em inovação. Uma das iniciativas mais conhecidas neste campo é o Global Innovation Index (GII).\n",
    "\n",
    "O GII é um ranking anual publicado pela World Intellectual Property Organization (WIPO) em parceria com a INSEAD e outras instituições, como a Cornell University. Iniciado em 2007, o índice é baseado em dados subjetivos e objetivos obtidos de várias fontes, incluindo a International Telecommunication Union, o World Bank e o World Economic Forum. O GII classifica os países com base em dois sub-índices: o Innovation Input Index e o Innovation Output Index, compostos por cinco e dois pilares, respectivamente, cada um descrevendo um atributo da inovação.\n",
    "\n",
    "Além do GII, há outras iniciativas semelhantes, como o International Innovation Index, que medem o nível de inovação de um país. Este índice é produzido em conjunto pelo Boston Consulting Group (BCG), pela National Association of Manufacturers (NAM) e pelo Manufacturing Institute (MI), o afiliado de pesquisa apartidária da NAM.\n",
    "\n",
    "Cada um desses índices oferece uma perspectiva única sobre a inovação em nível de país, ajudando governos, formuladores de políticas e acadêmicos a entender as tendências de inovação e a identificar áreas para melhoria e investimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "for i in range(0,20):\n",
    "    print(math.factorial(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.linspace(1, 100, 100)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Valores de entrada (tamanho do problema) - ajustados\n",
    "n = np.linspace(1, 100, 100)\n",
    "\n",
    "# Cálculo das complexidades\n",
    "O_1 = np.ones(n.shape)\n",
    "O_log_n = np.log2(n)\n",
    "O_n = n\n",
    "O_n_log_n = n * np.log2(n)\n",
    "O_n_squared = n**2\n",
    "O_2_n = 2**n-1\n",
    "max_factorial_visible = 120  # Valor máximo para o cálculo do fatorial 6!=120\n",
    "O_n_factorial = np.array([math.factorial(int(i)) if i <= max_factorial_visible else np.nan for i in n])\n",
    "\n",
    "# Exibir O_n_factorial em notação científica\n",
    "for valor in O_n_factorial[:max_factorial_visible + 1]:\n",
    "    print(f\"{valor}\")\n",
    "\n",
    "# Criar um DataFrame para os dados a serem exibidos\n",
    "df = pd.DataFrame({'n': n[:max_factorial_visible + 1], 'O(n!)': O_n_factorial[:max_factorial_visible + 1]})\n",
    "\n",
    "# Criar o gráfico de linha\n",
    "chart = alt.Chart(df).mark_line(point=True).encode(  # Adicionamos point=True para mostrar os pontos\n",
    "    x=alt.X('n:Q', axis=alt.Axis(labelAngle=-45, format='.2f')),  # Formato com 4 casas decimais\n",
    "    y=alt.Y('O(n!)', scale=alt.Scale(type='log')),\n",
    "    tooltip=['n', 'O(n!)']\n",
    ").properties(\n",
    "    title='Valores de O(n!) até n = 20',\n",
    "    height=400,\n",
    "    width=800,\n",
    ").interactive()\n",
    "\n",
    "# Exibir o gráfico\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Valores de entrada (tamanho do problema) - ajustados\n",
    "n = np.linspace(1, 100, 100)\n",
    "\n",
    "# Cálculo das complexidades\n",
    "O_1 = np.ones(n.shape)\n",
    "O_log_n = np.log2(n)\n",
    "O_n = n\n",
    "O_n_log_n = n * np.log2(n)\n",
    "O_n_squared = n**2\n",
    "O_2_n = 2**n - 1\n",
    "\n",
    "# Calcular O(n!) até um ponto visível\n",
    "max_factorial = 100  # Valor máximo de n para o qual O(n!) é visível no gráfico\n",
    "O_n_factorial = np.array([math.factorial(int(i)) if i <= max_factorial_visible else np.nan for i in n])\n",
    "\n",
    "# Paleta de cores similar à imagem de referência\n",
    "colors = ['darkgreen', 'green', 'orange', 'gold', 'red', 'darkblue', 'purple']\n",
    "\n",
    "# Criar o gráfico Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Adicionar as curvas ao gráfico, usando cores personalizadas\n",
    "fig.add_trace(go.Scatter(x=n, y=O_1, mode='lines', name='O(1)', line=dict(color=colors[0], width=2)))\n",
    "fig.add_trace(go.Scatter(x=n, y=O_log_n, mode='lines', name='O(log n)', line=dict(color=colors[1], width=2)))\n",
    "fig.add_trace(go.Scatter(x=n, y=O_n, mode='lines', name='O(n)', line=dict(color=colors[2], width=2)))\n",
    "fig.add_trace(go.Scatter(x=n, y=O_n_log_n, mode='lines', name='O(n log n)', line=dict(color=colors[3], width=2)))\n",
    "fig.add_trace(go.Scatter(x=n, y=O_n_squared, mode='lines', name='O(n²)', line=dict(color=colors[4], width=2)))\n",
    "fig.add_trace(go.Scatter(x=n, y=O_2_n, mode='lines', name='O(2ⁿ)', line=dict(color=colors[5], width=2)))\n",
    "fig.add_trace(go.Scatter(x=n[:max_factorial + 1], y=O_n_factorial[:max_factorial + 1], mode='lines', name='O(n!)', line=dict(color=colors[6], width=2)))\n",
    "\n",
    "# Configuração do layout do gráfico\n",
    "fig.update_layout(\n",
    "    title='Comparação de Complexidades Algorítmicas (Big O)',\n",
    "    xaxis_title='Tamanho dos Dados de Entrada (n)',\n",
    "    yaxis_title='Tempo de Execução em escala logarítmica (em operações)',\n",
    "    yaxis_type='log',\n",
    "    yaxis=dict(range=[-0.04, 2]),  # Escala logarítmica com limite definido para y\n",
    "    xaxis=dict(range=[1, 20]),  # Escala linear com limite definido para x\n",
    "    showlegend=False,\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(l=50, r=50, t=80, b=50),\n",
    ")\n",
    "\n",
    "# Função para calcular as posições das anotações\n",
    "def calculate_annotations(fig):\n",
    "    annotations = []\n",
    "    x_end = fig.layout.xaxis.range[1] * 0.95  \n",
    "    for i, trace in enumerate(fig.data):\n",
    "        # Encontrar o índice do valor de x mais próximo de x_end\n",
    "        idx = np.abs(trace.x - x_end).argmin()\n",
    "\n",
    "        # Se o valor de y for NaN, usar o último valor válido antes de x_end\n",
    "        if np.isnan(trace.y[idx]):\n",
    "            valid_indices = np.where(~np.isnan(trace.y) & (trace.x <= x_end))[0]\n",
    "            if len(valid_indices) > 0:\n",
    "                idx = valid_indices[-1]\n",
    "\n",
    "        x = trace.x[idx]\n",
    "        y = trace.y[idx]\n",
    "\n",
    "        # Calcular a posição da anotação no eixo y, considerando a escala logarítmica, exceto para O(1)\n",
    "        if trace.name == 'O(n log n)':\n",
    "            y_annotation = 1.95\n",
    "        if trace.name == \"O(n)\":\n",
    "            y_annotation = 1.35\n",
    "            x_annotation = x\n",
    "        if trace.name == \"O(log n)\":\n",
    "            y_annotation = 0.7\n",
    "            x_annotation = x-0.4\n",
    "        if trace.name == \"O(1)\":\n",
    "            y_annotation = 0.05\n",
    "            x_annotation = x\n",
    "        if trace.name == \"O(n²)\":\n",
    "            y_annotation = 2\n",
    "            x_annotation = 10\n",
    "        if trace.name == \"O(2ⁿ)\":\n",
    "            y_annotation = 2\n",
    "            x_annotation = 6.7\n",
    "        if trace.name == \"O(n!)\":\n",
    "            y_annotation = 2\n",
    "            x_annotation = 5\n",
    "\n",
    "        annotations.append(\n",
    "            dict(\n",
    "                x=x_annotation,\n",
    "                y=y_annotation,\n",
    "                text=trace.name,\n",
    "                showarrow=False,\n",
    "                xanchor='left' if trace.name != 'O(n log n)' else 'center',  # Ajustar o alinhamento para O(n log n)\n",
    "                yanchor='middle',  # Centralizar o rótulo na vertical\n",
    "                font=dict(size=12, color=colors[i], family='Arial'),  # Usar a cor correspondente da paleta\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return annotations\n",
    "\n",
    "# Calcular e adicionar as anotações\n",
    "fig.update_layout(annotations=calculate_annotations(fig))\n",
    "\n",
    "# Exibir o gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Valores de entrada (tamanho do problema) - ajustados\n",
    "n = np.linspace(1, 100, 1000)\n",
    "\n",
    "# Cálculo das complexidades\n",
    "O_1 = np.ones(n.shape)\n",
    "O_log_n = np.log2(n)\n",
    "O_n = n\n",
    "O_n_log_n = n * np.log2(n)\n",
    "O_n_squared = n**2\n",
    "O_2_n = 2**n - 1\n",
    "\n",
    "# Cálculo da complexidade O(n!) para inteiros até max_factorial_visible\n",
    "max_factorial_visible = 100\n",
    "n_int = np.arange(1, max_factorial_visible + 1)  # Valores inteiros de 1 a max_factorial_visible\n",
    "O_n_factorial_int = np.array([math.factorial(i) for i in n_int])\n",
    "\n",
    "# Interpolação para valores fracionários\n",
    "O_n_factorial = np.array([math.gamma(i + 1) for i in n])\n",
    "\n",
    "# Paleta de cores similar à imagem de referência\n",
    "colors = ['darkgreen', 'green', 'gold', 'orange', 'red', 'darkblue', 'black']\n",
    "\n",
    "# Criar o gráfico Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Adicionar as curvas ao gráfico, usando cores personalizadas\n",
    "fig.add_trace(go.Scatter(x=n, y=O_1, mode='lines', name='O(1)', line=dict(color=colors[0], width=4)))\n",
    "fig.add_trace(go.Scatter(x=n, y=O_log_n, mode='lines', name='O(log n)', line=dict(color=colors[1], width=4)))\n",
    "fig.add_trace(go.Scatter(x=n, y=O_n, mode='lines', name='O(n)', line=dict(color=colors[2], width=4)))\n",
    "fig.add_trace(go.Scatter(x=n, y=O_n_log_n, mode='lines', name='O(n log n)', line=dict(color=colors[3], width=4)))\n",
    "fig.add_trace(go.Scatter(x=n, y=O_n_squared, mode='lines', name='O(n²)', line=dict(color=colors[4], width=4)))\n",
    "fig.add_trace(go.Scatter(x=n, y=O_2_n, mode='lines', name='O(2ⁿ)', line=dict(color=colors[5], width=4)))\n",
    "fig.add_trace(go.Scatter(x=n[:max_factorial_visible + 1], y=O_n_factorial[:max_factorial_visible + 1], \n",
    "    mode='lines', name='O(n!)', line=dict(color=colors[6], width=4)))\n",
    "\n",
    "# Configuração do layout do gráfico\n",
    "fig.update_layout(\n",
    "    title='Comparação de Complexidades Assintótica dos Algoritmos (Big O)',\n",
    "    xaxis_title='Tamanho dos Dados de Entrada (n)',\n",
    "    yaxis_title='Tempo de Execução em escala logarítmica (em operações)',\n",
    "    yaxis_type='log',\n",
    "    xaxis=dict(\n",
    "        range=[1, 20],          # Escala linear com limite definido para x\n",
    "        gridcolor='lightgray',  # Cor mais clara para a grade\n",
    "        gridwidth=0.25,         # Largura menor para a grade\n",
    "        showgrid=True,\n",
    "        griddash='dot',\n",
    "    ),  \n",
    "    yaxis=dict(\n",
    "        range=[-0.04, 2],       # Escala logarítmica com limite definido para y\n",
    "        gridcolor='lightgray',  \n",
    "        gridwidth=0.25,\n",
    "        showgrid=True,\n",
    "        griddash='dot',\n",
    "        # tickformat=\".0e\",     # Formatar os ticks em notação científica com expoente inteiro\n",
    "        # tickformat=\",d\"         # Formatar os ticks como números inteiros com separador de milhar\n",
    "        tickvals=[1, 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000],  # Valores dos ticks\n",
    "        ticktext=['1', '10', '100', '1,000', '10,000', '100,000', '1,000,000', '10,000,000', '100,000,000']  # Rótulos em números inteiros\n",
    "\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(l=25, r=50, t=80, b=50),\n",
    ")\n",
    "\n",
    "# Função para calcular as posições das anotações\n",
    "def calculate_annotations(fig):\n",
    "    annotations = []\n",
    "    x_end = fig.layout.xaxis.range[1] * 0.95  \n",
    "    for i, trace in enumerate(fig.data):\n",
    "        # Encontrar o índice do valor de x mais próximo de x_end\n",
    "        idx = np.abs(trace.x - x_end).argmin()\n",
    "\n",
    "        # Se o valor de y for NaN, usar o último valor válido antes de x_end\n",
    "        if np.isnan(trace.y[idx]):\n",
    "            valid_indices = np.where(~np.isnan(trace.y) & (trace.x <= x_end))[0]\n",
    "            if len(valid_indices) > 0:\n",
    "                idx = valid_indices[-1]\n",
    "\n",
    "        x = trace.x[idx]\n",
    "        y = trace.y[idx]\n",
    "\n",
    "        # Calcular a posição da anotação no eixo y, considerando a escala logarítmica, exceto para O(1)\n",
    "        if trace.name == 'O(n log n)':\n",
    "            y_annotation = 1.95\n",
    "        if trace.name == \"O(n)\":\n",
    "            y_annotation = 1.4\n",
    "            x_annotation = x+0.75\n",
    "        if trace.name == \"O(log n)\":\n",
    "            y_annotation = 0.7\n",
    "            x_annotation = x+0.75\n",
    "        if trace.name == \"O(1)\":\n",
    "            y_annotation = 0.075\n",
    "            x_annotation = x+0.75\n",
    "        if trace.name == \"O(n²)\":\n",
    "            y_annotation = 1.95\n",
    "            x_annotation = 11.4\n",
    "        if trace.name == \"O(2ⁿ)\":\n",
    "            y_annotation = 1.95\n",
    "            x_annotation = 8\n",
    "        if trace.name == \"O(n!)\":\n",
    "            y_annotation = 1.95\n",
    "            x_annotation = 4.75         \n",
    "\n",
    "        annotations.append(\n",
    "            dict(\n",
    "                x=x_annotation,\n",
    "                y=y_annotation,\n",
    "                text=trace.name,\n",
    "                showarrow=False,\n",
    "                xanchor='right',\n",
    "                yanchor='middle',\n",
    "                font=dict(size=20, color='black', family='Arial'),  # Usar a cor correspondente da paleta\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return annotations\n",
    "\n",
    "# Calcular e adicionar as anotações\n",
    "fig.update_layout(annotations=calculate_annotations(fig),\n",
    "    shapes=[\n",
    "        # Região verde (diagonal até um pouco acima de O(log n))\n",
    "        dict(\n",
    "            type=\"path\",\n",
    "            path=f\"M 0, {10**fig.layout.yaxis.range[0]} L 20, {O_log_n[-1]} L 20, {10**fig.layout.yaxis.range[0]} Z\", # type: ignore\n",
    "            fillcolor=\"lightgreen\",\n",
    "            opacity=0.3,\n",
    "            line_width=0,\n",
    "            layer='below' # para que as curvas fiquem por cima\n",
    "        ),\n",
    "        # Região amarela (diagonal até um pouco acima de O(n log n))\n",
    "        dict(\n",
    "            type=\"path\",\n",
    "            path=f\"M 0, {10**fig.layout.yaxis.range[0]} L 20, {O_n_log_n[-1]-5} L 20, {O_log_n[-1]} Z\", # type: ignore\n",
    "            fillcolor=\"yellow\",\n",
    "            opacity=0.3,\n",
    "            line_width=0,\n",
    "            layer='below' # para que as curvas fiquem por cima\n",
    "        ),\n",
    "        # Região vermelha (diagonal até o topo do gráfico)\n",
    "        dict(\n",
    "            type=\"path\",\n",
    "            # path=f\"M 0, {10**fig.layout.yaxis.range[0]} L 20, {10**fig.layout.yaxis.range[1]} L 0, {10**fig.layout.yaxis.range[1]} Z\",\n",
    "            path=f\"M 20, {O_n_log_n[-1] - 5} L 0, {10**(int(np.log10(O_n_log_n[-1])) + 1)} L 0, {10**fig.layout.yaxis.range[0]} Z\", # type: ignore\n",
    "            fillcolor=\"red\",\n",
    "            opacity=0.3,\n",
    "            line_width=0,\n",
    "            layer='below'  # para que as curvas fiquem por cima\n",
    "        ),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "# Exibir o gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histórico no Global Innovation Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pathfilename = os.path.join(folder_data_input, 'gii_history_data.csv')\n",
    "df_gii = pd.read_csv(pathfilename)\n",
    "\n",
    "def calculate_percentages(df_gii):\n",
    "    df_avaliacao = pd.DataFrame(columns=['Ano', 'Participantes', 'Above Brazil', 'Below Brazil', 'Above Brazil (%)', 'Below Brazil (%)'])\n",
    "    \n",
    "    for year in df_gii['Ano'].unique():\n",
    "        df_year = df_gii[df_gii['Ano'] == year]\n",
    "        total_countries = df_year['Países Participantes'].values[0]\n",
    "        brazil_position = df_year['Colocação do Brasil'].values[0]\n",
    "        above_brazil = brazil_position - 1\n",
    "        below_brazil = total_countries - brazil_position\n",
    "        \n",
    "        above_percent = (above_brazil / total_countries) * 100\n",
    "        below_percent = (below_brazil / total_countries) * 100\n",
    "        \n",
    "        df_avaliacao = pd.concat([df_avaliacao, pd.DataFrame({'Ano': [year], 'Participantes': [total_countries], 'Above Brazil': [above_brazil], 'Below Brazil': [below_brazil], 'Above Brazil (%)': [above_percent], 'Below Brazil (%)': [below_percent]})], ignore_index=True)\n",
    "    \n",
    "    return df_avaliacao\n",
    "\n",
    "# Call the function to create df_avaliacao\n",
    "df_avaliacao = calculate_percentages(df_gii)\n",
    "df_avaliacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create a figure with secondary y-axis for the line plots\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add stacked bars for 'Below Brazil (%)' and 'Above Brazil (%)'\n",
    "fig.add_trace(\n",
    "    go.Bar(x=df_avaliacao['Ano'], \n",
    "           y=df_avaliacao['Below Brazil (%)'], \n",
    "           name='Below Brazil (%)'),\n",
    "           secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=df_avaliacao['Ano'], \n",
    "           y=df_avaliacao['Above Brazil (%)'], \n",
    "           name='Above Brazil (%)'),\n",
    "           secondary_y=False,\n",
    ")\n",
    "\n",
    "# Correct the data label positions for each segment of the stacked bars\n",
    "for index, row in df_avaliacao.iterrows():\n",
    "    # Position for label of 'Above Brazil (%)'\n",
    "    position_above = row['Below Brazil (%)'] + row['Above Brazil (%)'] / 2\n",
    "    fig.add_annotation(\n",
    "        x=row['Ano'], y=position_above,\n",
    "        text=f\"{row['Above Brazil (%)']:.1f}%\",\n",
    "        showarrow=False, font=dict(color='white')\n",
    "    )\n",
    "\n",
    "    # Position for label of 'Below Brazil (%)'\n",
    "    position_below = row['Below Brazil (%)'] / 2\n",
    "    fig.add_annotation(\n",
    "        x=row['Ano'], y=position_below,\n",
    "        text=f\"{row['Below Brazil (%)']:.1f}%\",\n",
    "        showarrow=False, font=dict(color='white')\n",
    "    )\n",
    "\n",
    "# Update layout for stacked bars\n",
    "fig.update_layout(barmode='stack')\n",
    "\n",
    "# Add line for total number of participants\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df_avaliacao['Ano'], \n",
    "               y=df_avaliacao['Participantes'], \n",
    "               name='Total Participants', \n",
    "               mode='lines+markers+text', \n",
    "               text=df_avaliacao['Participantes'], \n",
    "               textposition=\"top center\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Add line for Brazil's performance, but on the primary y-axis\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df_avaliacao['Ano'], \n",
    "               y=df_avaliacao['Below Brazil (%)'], \n",
    "               name='Brazil Performance', \n",
    "               mode='lines+markers', \n",
    "               line=dict(color='yellow', \n",
    "                         dash='dot')),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "# Update the bar colors\n",
    "fig.update_traces(\n",
    "    selector=dict(name='Above Brazil (%)'),\n",
    "    marker=dict(color='orange')\n",
    ")\n",
    "fig.update_traces(\n",
    "    selector=dict(name='Below Brazil (%)'),\n",
    "    marker=dict(color='blue')\n",
    ")\n",
    "\n",
    "# Update the line trace for total number of participants to have a thickness of 4\n",
    "fig.update_traces(\n",
    "    selector=dict(name='Total Participants'),\n",
    "    line=dict(width=2)\n",
    ")\n",
    "\n",
    "# Update the line trace for Brazil's performance to have a thickness of 4\n",
    "fig.update_traces(\n",
    "    selector=dict(name='Brazil Performance'),\n",
    "    line=dict(width=6)\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "vr_max = max(df_avaliacao['Participantes']) * 1.1\n",
    "fig.update_layout(\n",
    "    title='Performance Comparison: Brazil vs. Other Countries',\n",
    "    height=600,\n",
    "    yaxis=dict(title='Percentage', range=[0, vr_max]),  # Extending primary y-axis range\n",
    "    yaxis2=dict(title='Total Participants', overlaying='y', side='right', range=[0, vr_max])\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickvals=df_avaliacao['Ano'])\n",
    "\n",
    "# Re-render the chart\n",
    "fig.show(renderer=\"notebook\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Gerar análises no domínio PDI para o CEIS</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Analisar similaridade tópicos - questões pesquisa</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd, os, re, sys, time, json, subprocess\n",
    "\n",
    "## Configurar exibição do pandas para melhor visualizar os dados\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('colheader_justify', 'left')\n",
    "pd.set_option('display.max_rows', 600)\n",
    "\n",
    "def find_repo_root(path='.', depth=10):\n",
    "    ''' \n",
    "    Busca o arquivo .git e retorna string com a pasta raiz do repositório\n",
    "    '''\n",
    "    # Prevent infinite recursion by limiting depth\n",
    "    if depth < 0:\n",
    "        return None\n",
    "    path = Path(path).absolute()\n",
    "    if (path / '.git').is_dir():\n",
    "        return path\n",
    "    return find_repo_root(str(path.parent), depth-1)\n",
    "\n",
    "delay = 10\n",
    "\n",
    "## Definir a pasta de base do repositório local\n",
    "base_repo_dir = find_repo_root()\n",
    "\n",
    "## Construir os caminhos usando os.path.join para compatibilidade WxL\n",
    "folder_utils = os.path.join(str(base_repo_dir), 'utils')\n",
    "folder_domain = os.path.join(str(base_repo_dir), 'source', 'domain')\n",
    "folder_data_input = os.path.join(str(base_repo_dir), '_data', 'in_csv')\n",
    "folder_data_output = os.path.join(str(base_repo_dir), '_data', 'out_json')\n",
    "\n",
    "## Adicionar pastas locais ao sys.path para importar pacotes criados localmente\n",
    "sys.path.append(folder_utils)\n",
    "sys.path.append(folder_domain)\n",
    "# from scraper_pasteur import PasteurScraper\n",
    "# from scraper_sucupira import SucupiraScraper\n",
    "# from scraper_sucupira_edge import SucupiraScraperEdge\n",
    "from environment_setup import EnvironmentSetup\n",
    "from chromedriver_manager import ChromeDriverManager\n",
    "from neo4j_persister import Neo4jPersister\n",
    "from lattes_scrapper import JSONFileManager, LattesScraper, HTMLParser, SoupParser, GetQualis, ArticlesCounter, DictToHDF5, attribute_to_be_non_empty\n",
    "\n",
    "t00 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(folder_data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Carregar dados dos produtos prioritários, equipamentos e questões de pesquisa\n",
    "curr_pathfilename = os.path.join(folder_data_input,'docents_dict_list.json')\n",
    "with open(curr_pathfilename, 'r', encoding='utf-8') as f:\n",
    "    curriculos = json.load(f)\n",
    "\n",
    "prod_pathfilename = os.path.join(folder_data_output,'matriz_ceis.json')\n",
    "with open(prod_pathfilename, 'r', encoding='utf-8') as f:\n",
    "    matriz_produtos = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(curriculos)} currículos carregados')\n",
    "# [x.get('Áreas') for x in curriculos]\n",
    "produtos = [produto.get('nome') for bloco in matriz_produtos.get('blocos', []) for produto in bloco.get('produtos', [])]\n",
    "print(f'{len(produtos)} produtos carregados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install vega\n",
    "# !jupyter nbextension install --sys-prefix --py vega\n",
    "# !jupyter nbextension enable --sys-prefix --py vega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_validator import *\n",
    "\n",
    "# Exemplo de uso (substituir pelos dados reais)\n",
    "y_true = [[\"A\", \"B\"], [\"B\"], [\"A\", \"C\"]]\n",
    "y_pred = [[\"A\"], [\"B\", \"C\"], [\"A\", \"B\"]]\n",
    "classes = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "# Probabilidades aqui\n",
    "y_proba = [[0.8, 0.7, 0.3], [0.2, 0.9, 0.5], [0.6, 0.8, 0.4]]\n",
    "\n",
    "\n",
    "validar_modelo(y_true, y_pred, y_proba, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Criar grafo de conhecimento</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict = []\n",
    "equipamentos = [...]\n",
    "questoes_pesquisa = [...]\n",
    "produtos_prioritarios = []\n",
    "\n",
    "# Criar o grafo heterogêneo\n",
    "G = nx.Graph()\n",
    "\n",
    "# Adicionar nós e arestas para pesquisadores\n",
    "for pesquisador in curriculos:\n",
    "    G.add_node(pesquisador['Identificação']['ID Lattes'], type=\"pesquisador\", **pesquisador)  # Adicionar atributos do currículo\n",
    "    \n",
    "    # Conectar pesquisador às suas áreas de atuação\n",
    "    for area in pesquisador['Áreas'].values():\n",
    "        G.add_node(area, type=\"area\")\n",
    "        G.add_edge(pesquisador['Identificação']['ID Lattes'], area)\n",
    "\n",
    "    # Conectar pesquisador às suas publicações\n",
    "    for publicacao in pesquisador['Produções']['Artigos completos publicados em periódicos']:\n",
    "        G.add_node(publicacao['titulo'], type=\"publicacao\")\n",
    "        G.add_edge(pesquisador['Identificação']['ID Lattes'], publicacao['titulo'])\n",
    "\n",
    "    # Conectar pesquisador a projetos\n",
    "    for pesquisador in curriculos:\n",
    "        for tipo_projeto in [\"ProjetosPesquisa\", \"ProjetosExtensão\", \"ProjetosDesenvolvimento\", \"ProjetosOutros\"]:\n",
    "            if tipo_projeto in pesquisador:\n",
    "                for projeto in pesquisador[tipo_projeto]:\n",
    "                    G.add_node(projeto['titulo_projeto'], type=\"projeto\")\n",
    "                    G.add_edge(pesquisador['Identificação']['ID Lattes'], projeto['titulo_projeto'])\n",
    "\n",
    "    # Conectar pesquisador a equipamentos\n",
    "    # (Assumindo que você tem uma lista de equipamentos mencionados nos currículos)\n",
    "    equipamentos_citados = []  # Preencha com os nomes dos equipamentos mencionados nos currículos\n",
    "    for pesquisador in curriculos:\n",
    "        for equipamento in equipamentos_citados:\n",
    "            if equipamento in pesquisador['Atuação Profissional'][0]['Descrição']:  # Exemplo: busca na descrição da atuação profissional\n",
    "                G.add_edge(pesquisador['Identificação']['ID Lattes'], equipamento)\n",
    "\n",
    "    # Conectar pesquisador a questões de pesquisa\n",
    "    # (Assumindo que você tem uma lista de questões de pesquisa e um método para associá-las aos pesquisadores)\n",
    "    for pesquisador in curriculos:\n",
    "        for questao in questoes_pesquisa:\n",
    "            if pesquisador_tem_interesse_na_questao(pesquisador, questao):  # inferência do interesse\n",
    "                G.add_edge(pesquisador['Identificação']['ID Lattes'], questao['descricao']) # type: ignore\n",
    "\n",
    "    # TO-DO\n",
    "    def calculate_similarity(pesquisador, list_dict):\n",
    "        \n",
    "        similarity=0\n",
    "        return similarity\n",
    "    \n",
    "    # TO-DO\n",
    "    def extract_topicos(questao, topico_pesquisa):\n",
    "        \n",
    "        lista_topicos=[]\n",
    "        return lista_topicos    \n",
    "\n",
    "    # Função para inferir o interesse do pesquisador em uma questão\n",
    "    def pesquisador_tem_interesse_na_questao(pesquisador, questao):\n",
    "        # Analise o currículo do pesquisador (áreas de atuação, publicações, projetos, etc.)\n",
    "        # e compare com a descrição da questão de pesquisa para determinar o interesse\n",
    "        # Retorna True se houver interesse, False caso contrário\n",
    "        topicos_pesquisador = extract_topicos(pesquisador, list_dict)\n",
    "        interesses_pesquisador = []\n",
    "        flag_interesse = False\n",
    "        threshold = 0.8\n",
    "        for i in topicos_pesquisador:\n",
    "            similarity = calculate_similarity(questao, i)\n",
    "            if similarity >= threshold:\n",
    "                interesses_pesquisador.append(questao)\n",
    "                flag_interesse = True\n",
    "\n",
    "        return flag_interesse\n",
    "\n",
    "\n",
    "# Adicionar nós e arestas para produtos prioritários, equipamentos e questões de pesquisa\n",
    "for produto in produtos_prioritarios:\n",
    "    G.add_node(produto['nome'], type=\"produto\", **produto)  # Adicionar atributos do produto (nome, descrição, área, etc.)\n",
    "\n",
    "    # Conectar produto às suas áreas (assumindo que o produto tem uma lista de áreas)\n",
    "    for area in produto.get('areas', []):  # Usar get() para evitar KeyError se 'areas' não existir\n",
    "        G.add_edge(produto['nome'], area)\n",
    "\n",
    "# Adicionar nós e arestas para equipamentos\n",
    "for equipamento in equipamentos:\n",
    "    G.add_node(equipamento['nome'], type=\"equipamento\", **equipamento)  # type: ignore # Adicionar atributos do equipamento\n",
    "\n",
    "    # Conectar equipamento às suas áreas (assumindo que o equipamento tem uma lista de áreas)\n",
    "    for area in equipamento.get('areas', []): # type: ignore\n",
    "        G.add_edge(equipamento['nome'], area) # type: ignore\n",
    "\n",
    "# Adicionar nós e arestas para questões de pesquisa\n",
    "for questao in questoes_pesquisa:\n",
    "    G.add_node(questao['descricao'], type=\"questao_pesquisa\", **questao)  # type: ignore # Adicionar atributos da questão\n",
    "\n",
    "    # Conectar questão de pesquisa às suas áreas (assumindo que a questão tem uma lista de áreas)\n",
    "    for area in questao.get('areas', []): # type: ignore\n",
    "        G.add_edge(questao['descricao'], area) # type: ignore\n",
    "\n",
    "# Adicionar nós e arestas para equipamentos\n",
    "for equipamento in equipamentos:\n",
    "    G.add_node(equipamento['nome'], type=\"equipamento\", **equipamento)  # type: ignore # Adicionar atributos do equipamento\n",
    "\n",
    "    # Conectar equipamento às suas áreas (assumindo que o equipamento tem uma lista de áreas)\n",
    "    if 'areas' in str(equipamento):  # Verificar se o equipamento possui áreas associadas\n",
    "        for area in equipamento['areas']: # type: ignore\n",
    "            if area in G.nodes:  # Verificar se a área já existe no grafo\n",
    "                G.add_edge(equipamento['nome'], area) # type: ignore\n",
    "            else:\n",
    "                # Se a área não existir, você pode decidir se quer adicioná-la como um novo nó\n",
    "                # G.add_node(area, type=\"area\")  \n",
    "                # G.add_edge(equipamento['nome'], area)\n",
    "                print(f\"Área '{area}' não encontrada para o equipamento '{equipamento['nome']}'.\") # type: ignore\n",
    "    else:\n",
    "        print(f\"Equipamento '{equipamento['nome']}' não possui áreas associadas.\") # type: ignore\n",
    "\n",
    "# Adicionar nós e arestas para questões de pesquisa\n",
    "for questao in questoes_pesquisa:\n",
    "    G.add_node(questao['descricao'], type=\"questao_pesquisa\", **questao)  # type: ignore # Adicionar atributos da questão\n",
    "\n",
    "    # Conectar questão de pesquisa às suas áreas\n",
    "    if 'areas' in str(questao):  # Verificar se a questão possui áreas associadas\n",
    "        for area in questao['areas']: # type: ignore\n",
    "            if area in G.nodes:  # Verificar se a área já existe no grafo\n",
    "                G.add_edge(questao['descricao'], area) # type: ignore\n",
    "            else:\n",
    "                # Se a área não existir, você pode decidir se quer adicioná-la como um novo nó\n",
    "                # G.add_node(area, type=\"area\")  \n",
    "                # G.add_edge(questao['descricao'], area)\n",
    "                print(f\"Área '{area}' não encontrada para a questão de pesquisa '{questao['descricao']}'.\") # type: ignore\n",
    "    else:\n",
    "        print(f\"Questão de pesquisa '{questao['descricao']}' não possui áreas associadas.\") # type: ignore\n",
    "\n",
    "# Análise 1: Agrupamento de Pesquisadores\n",
    "# Extrair características textuais dos currículos (ex: usando TF-IDF)\n",
    "# Exemplo usando a descrição da formação acadêmica\n",
    "corpus = [pesquisador['Formação']['Acadêmica'][0]['Descrição'] for pesquisador in curriculos]  \n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Calcular similaridade entre pesquisadores (ex: usando cosseno)\n",
    "similarity_matrix = cosine_similarity(X)\n",
    "\n",
    "# Aplicar algoritmo de agrupamento (ex: DBSCAN)\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "clustering = DBSCAN(eps=0.3, min_samples=2).fit(similarity_matrix)\n",
    "labels = clustering.labels_\n",
    "\n",
    "# Adicionar atributo 'cluster' aos nós dos pesquisadores\n",
    "for i, pesquisador in enumerate(curriculos):\n",
    "    G.nodes[pesquisador['Identificação']['ID Lattes']]['cluster'] = labels[i]\n",
    "\n",
    "\n",
    "# Análise 2: Agrupamento de Questões de Pesquisa\n",
    "# Extrair características textuais das questões de pesquisa (ex: usando TF-IDF)\n",
    "corpus_questoes = [questao['descricao'] for questao in questoes_pesquisa] # type: ignore\n",
    "vectorizer_questoes = TfidfVectorizer()\n",
    "X_questoes = vectorizer_questoes.fit_transform(corpus_questoes)\n",
    "\n",
    "# Calcular similaridade entre questões (ex: usando cosseno)\n",
    "similarity_matrix_questoes = cosine_similarity(X_questoes)\n",
    "\n",
    "# Aplicar algoritmo de agrupamento (ex: K-Means)\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 5  # Defina o número de clusters desejado\n",
    "clustering_questoes = KMeans(n_clusters=n_clusters).fit(similarity_matrix_questoes)\n",
    "labels_questoes = clustering_questoes.labels_\n",
    "\n",
    "# Adicionar atributo 'cluster' aos nós das questões de pesquisa\n",
    "for i, questao in enumerate(questoes_pesquisa):\n",
    "    G.nodes[questao['descricao']]['cluster'] = labels_questoes[i] # type: ignore\n",
    "\n",
    "# Análise 3: Recomendação de Projetos (exemplo simplificado)\n",
    "def recomendar_projetos(pesquisador_id):\n",
    "    pesquisador_areas = list(G.neighbors(pesquisador_id))  # Obter áreas do pesquisador\n",
    "    projetos_recomendados = []\n",
    "    for projeto_id in G.nodes:\n",
    "        if G.nodes[projeto_id]['type'] == \"projeto\":\n",
    "            projeto_areas = list(G.neighbors(projeto_id))\n",
    "            if set(pesquisador_areas) & set(projeto_areas):  # Verificar se há áreas em comum\n",
    "                projetos_recomendados.append(projeto_id)\n",
    "    return projetos_recomendados\n",
    "\n",
    "# Análise 4: Detecção de Oportunidades\n",
    "def detectar_oportunidades(G, produtos_prioritarios, top_n=5):\n",
    "    areas_importantes = {}\n",
    "    for produto in produtos_prioritarios:\n",
    "        for area in G.neighbors(produto['nome']):\n",
    "            areas_importantes[area] = areas_importantes.get(area, 0) + 1\n",
    "\n",
    "    # Ponderar pela concentração de pesquisadores e questões de pesquisa\n",
    "    for area in areas_importantes:\n",
    "        pesquisadores_na_area = len([n for n in G.neighbors(area) if G.nodes[n]['type'] == \"pesquisador\"])\n",
    "        questoes_na_area = len([n for n in G.neighbors(area) if G.nodes[n]['type'] == \"questao_pesquisa\"])\n",
    "        areas_importantes[area] *= (pesquisadores_na_area + questoes_na_area)\n",
    "\n",
    "    # Ordenar áreas por importância\n",
    "    areas_importantes = dict(sorted(areas_importantes.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    return list(areas_importantes.keys())[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))\n",
    "print(stopwords.words('portuguese'))\n",
    "print(stopwords.words('italian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade httpx\n",
    "# !pip install --upgrade httpcore\n",
    "# !pip install --upgrade googletrans==4.0.0-rc1\n",
    "# !pip install deep-translator\n",
    "\n",
    "import nltk\n",
    "print(nltk.data.find(\"corpora/stopwords\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_path = nltk.data.find(\"corpora/stopwords\")\n",
    "stopwords_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install deep_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import json\n",
    "from langdetect import detect\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from deep_translator import GoogleTranslator  # Import the Googletrans library\n",
    "\n",
    "def identify_researcher_topics(data, fields, translate=False, target_language='en'):\n",
    "    \"\"\"\n",
    "    Identifies the top 3 research topics of a researcher based on their Lattes CV data.\n",
    "\n",
    "    Args:\n",
    "        data: A dictionary containing the researcher's Lattes CV data.\n",
    "        fields: A list of field names to be used for topic identification.\n",
    "\n",
    "    Returns:\n",
    "        A list of the top 3 research topics.\n",
    "    \"\"\"\n",
    "\n",
    "    def translate_text(text, target_language):\n",
    "        \"\"\"\n",
    "        Translates the text to the target language using Google Translate.\n",
    "        \"\"\"\n",
    "        translated = GoogleTranslator(source='auto', target=target_language).translate(text)\n",
    "        return translated\n",
    "\n",
    "    def extract_text_from_fields(data, fields, corpus):\n",
    "        \"\"\"\n",
    "        Recursively extracts text from the specified fields in the data dictionary.\n",
    "        \"\"\"\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                if key in fields:\n",
    "                    if isinstance(value, list):\n",
    "                        for item in value:\n",
    "                            corpus.append(item.get(\"Descricao\", \"\") + item.get(\"titulo\", \"\"))\n",
    "                    else:\n",
    "                        corpus.append(str(value))  # Convert non-string values to string\n",
    "                else:\n",
    "                    extract_text_from_fields(value, fields, corpus)\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                extract_text_from_fields(item, fields, corpus)\n",
    "\n",
    "    # def preprocess_text(text, target_language='en'):\n",
    "    #     \"\"\"\n",
    "    #     Preprocesses the text by tokenizing, removing stopwords and proper nouns, translating, and removing punctuation.\n",
    "    #     \"\"\"\n",
    "    #     # Tokenize the text\n",
    "    #     words = nltk.word_tokenize(text.lower())\n",
    "\n",
    "    #     # Remove stopwords in the original language (if available)\n",
    "    #     source_language = detect(text)\n",
    "    #     try:\n",
    "    #         words = [word for word in words if word not in stopwords.words(source_language) and not word.istitle()]\n",
    "    #     except OSError:\n",
    "    #         print(f\"Warning: Stopwords not found for language '{source_language}'. Skipping stopword removal.\")\n",
    "\n",
    "    #     # Translate the text (if it's not already in the target language)\n",
    "    #     if target_language != 'auto' and source_language != target_language:\n",
    "    #         translator = GoogleTranslator(source=source_language, target=target_language)\n",
    "    #         text = translator.translate(text)\n",
    "\n",
    "    #         # Tokenize the translated text\n",
    "    #         words = nltk.word_tokenize(text.lower())\n",
    "\n",
    "    #         # Remove stopwords in the target language\n",
    "    #         words = [word for word in words if word not in stopwords.words(target_language)]\n",
    "\n",
    "    #     # Remove punctuation and numbers\n",
    "    #     words = [re.sub(r'[^\\w\\s]', '', word) for word in words if not word.isdigit()]\n",
    "\n",
    "    #     return \" \".join(words)\n",
    "\n",
    "    def preprocess_text(text, target_language='en'):\n",
    "        \"\"\"\n",
    "        Preprocesses the text by tokenizing, removing stopwords and proper nouns, translating, and removing punctuation.\n",
    "        \"\"\"\n",
    "        # Tokenize the text\n",
    "        words = nltk.word_tokenize(text.lower())\n",
    "\n",
    "        # Remove stopwords in the original language (if available)\n",
    "        source_language = detect(text)\n",
    "        stopwords_path = nltk.data.find(\"corpora/stopwords\")\n",
    "        # stopwords_path = os.path.join(os.getenv('APPDATA'), 'Roaming', 'nltk_data', 'corpora', 'stopwords')  # Get stopwords path\n",
    "        if os.path.exists(os.path.join(str(stopwords_path), source_language)):\n",
    "            with open(os.path.join(str(stopwords_path), source_language), 'r', encoding='utf-8') as f:\n",
    "                stop_words = set(f.read().splitlines())\n",
    "            words = [word for word in words if word not in stop_words and not word.istitle()]\n",
    "\n",
    "        # Translate the text (if it's not already in the target language)\n",
    "        if target_language != 'auto' and source_language != target_language:\n",
    "            translator = GoogleTranslator(source=source_language, target=target_language)\n",
    "            text = translator.translate(text)\n",
    "\n",
    "            # Tokenize the translated text\n",
    "            words = nltk.word_tokenize(text.lower())\n",
    "\n",
    "            # Remove stopwords in the target language\n",
    "            with open(os.path.join(str(stopwords_path), target_language), 'r', encoding='utf-8') as f:\n",
    "                stop_words = set(f.read().splitlines())\n",
    "            words = [word for word in words if word not in stop_words]\n",
    "\n",
    "        # Remove punctuation and numbers\n",
    "        words = [re.sub(r'[^\\w\\s]', '', word) for word in words if not word.isdigit()]\n",
    "\n",
    "        return \" \".join(words)\n",
    "\n",
    "    # Concatenate text from specified fields\n",
    "    corpus = []\n",
    "    extract_text_from_fields(data, fields, corpus)\n",
    "\n",
    "    # Preprocess the corpus\n",
    "    corpus = [preprocess_text(text) for text in corpus]\n",
    "\n",
    "    # Vectorize the text using TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Apply LDA for topic modeling\n",
    "    lda = LatentDirichletAllocation(n_components=7, random_state=0)\n",
    "    lda.fit(X)\n",
    "\n",
    "    # Get the top words for each topic\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    top_words = []\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        top_words.append([feature_names[i] for i in topic.argsort()[:-4:-1]])\n",
    "\n",
    "    return top_words\n",
    "\n",
    "pathfilename = os.path.join(folder_data_input,'docents_dict_list.json')\n",
    "with open(pathfilename, 'r', encoding='utf-8') as file:\n",
    "    docents_data = json.load(file)\n",
    "    print(f'{len(docents_data)} currículos carregados')\n",
    "\n",
    "# fields_to_use = [\"Formação Acadêmica\", \"Atuação Profissional\", \"Produções\"]\n",
    "fields_to_use = [\"titulo\"]\n",
    "\n",
    "for researcher in docents_data:\n",
    "    topics = identify_researcher_topics(researcher, fields_to_use)\n",
    "    print(f\"Principais tópicos de interesse para {researcher['Identificação']['Nome']}:\")\n",
    "    for i, topic in enumerate(topics):\n",
    "        print(f\"  Tópico {i+1}: {', '.join(topic)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso\n",
    "oportunidades = detectar_oportunidades(G, produtos_prioritarios)\n",
    "print(\"Áreas de oportunidade:\", oportunidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo\n",
    "import requests\n",
    "\n",
    "# Cabeçalhos para a requisição\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "    \"Accept\": \"application/json\",\n",
    "}\n",
    "\n",
    "import http.client\n",
    "import ssl\n",
    "\n",
    "# Cria um contexto SSL sem verificação de certificado\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "conn = http.client.HTTPSConnection(\"api-comexstat.mdic.gov.br\", context=context)\n",
    "# conn = http.client.HTTPSConnection(\"api-comexstat.mdic.gov.br\")\n",
    "\n",
    "conn.request(\"GET\", \"/cities/filters?language=en\")\n",
    "\n",
    "res = conn.getresponse()\n",
    "data = res.read()\n",
    "\n",
    "print(data.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "import pandas as pd\n",
    "import ssl\n",
    "\n",
    "# Cria um contexto SSL sem verificação de certificado (NÃO RECOMENDADO PARA PRODUÇÃO)\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "# Função para fazer a requisição com tratamento de erro RETORNA OBJETO BYTES\n",
    "# def fazer_requisicao(conn, endpoint, method=\"GET\", params=None, body=None):\n",
    "#     try:\n",
    "#         # Cabeçalhos para a requisição\n",
    "#         headers = {\n",
    "#             \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "#             \"Accept\": \"application/json\",\n",
    "#         }\n",
    "#         conn.request(method, endpoint, body=body, headers=headers)\n",
    "#         res = conn.getresponse()\n",
    "#         data = res.read()\n",
    "#         return json.loads(data.decode(\"utf-8\"))\n",
    "#     except Exception as e:\n",
    "#         print(f\"Erro na requisição: {e}\")\n",
    "#         return None\n",
    "\n",
    "# Função para fazer a requisição com tratamento de erro e decodificação de bytes\n",
    "def fazer_requisicao(conn, endpoint, method=\"GET\", params=None, body=None):\n",
    "    try:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\",\n",
    "            \"Accept\": \"application/json\",\n",
    "        }\n",
    "        conn.request(method, endpoint, body=body, headers=headers)\n",
    "        res = conn.getresponse()\n",
    "\n",
    "        # Lê os dados da resposta como bytes\n",
    "        data = res.read()  \n",
    "\n",
    "        # Decodifica os bytes para uma string UTF-8\n",
    "        data_str = data.decode(\"utf-8\")  \n",
    "\n",
    "        # Converte a string JSON para um dicionário Python\n",
    "        return json.loads(data_str)  \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na requisição: {e}\")\n",
    "        return None\n",
    "\n",
    "# Conexão com a API\n",
    "conn = http.client.HTTPSConnection(\"api-comexstat.mdic.gov.br\", context=context)\n",
    "\n",
    "# Endpoint para obter os anos disponíveis\n",
    "anos_url = \"/cities/dates/years\"\n",
    "anos_response = fazer_requisicao(conn, anos_url)\n",
    "\n",
    "# Inicializa as variáveis com valores padrão\n",
    "ano_inicial = 1997  # Ano inicial padrão\n",
    "ano_final = 2024   # Ano final padrão (ou o ano atual)\n",
    "\n",
    "if anos_response:\n",
    "    if anos_response.get('success', False):  # Verifica se a requisição foi bem-sucedida\n",
    "        if 'data' in anos_response and 'min' in anos_response['data'] and 'max' in anos_response['data']:\n",
    "            ano_inicial = int(anos_response['data']['min'])\n",
    "            ano_final = int(anos_response['data']['max'])\n",
    "        else:\n",
    "            print(\"Erro: As chaves 'data', 'min' e/ou 'max' não foram encontradas na resposta da API.\")\n",
    "    else:\n",
    "        print(f\"Erro na requisição para obter os anos: {anos_response}\")\n",
    "else:\n",
    "    print(\"Erro na requisição para obter os anos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anos_response['data']['min']) # type: ignore\n",
    "print(anos_response['data']['max']) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.request(\"GET\", \"/cities/filters?language=en\")\n",
    "\n",
    "res = conn.getresponse()\n",
    "data = res.read()\n",
    "\n",
    "print(data.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint para obter os valores do filtros disponíveis na API\n",
    "endpoint = \"/cities/filters\"\n",
    "filters_params = {\"language\": \"pt\"}\n",
    "filters_response = fazer_requisicao(conn, endpoint, params=filters_params)\n",
    "filters_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtros = [x['filter'] for x in filters_response.get('data').get('list')] # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_options_filters(api_filter):\n",
    "    # Cria um contexto SSL sem verificação de certificado\n",
    "    context = ssl._create_unverified_context()\n",
    "    conn = http.client.HTTPSConnection(\"api-comexstat.mdic.gov.br\", context=context)\n",
    "    conn.request(\"GET\", f\"/general/filters/{api_filter}?language=pt\")\n",
    "\n",
    "    res = conn.getresponse()\n",
    "    # print(f'objeto       res: {type(res)}')\n",
    "    data = res.read()\n",
    "    # print(f'objeto      data: {type(data)}')\n",
    "    data_str = data.decode(\"utf-8\")\n",
    "    # print(f'objeto  data_str: {type(data_str)}')\n",
    "    data_json = json.loads(data_str)\n",
    "    # print(f'objeto data_json: {type(data_json)}')\n",
    "    try:\n",
    "        results = [x.get('text') for x in data_json.get('data')[0]]\n",
    "        print(f'{len(results):>4} resultados para filtro {api_filter}')\n",
    "    except Exception as e:\n",
    "        print(f'     Erro ao buscar dados para filtro {api_filter}: {e}')\n",
    "    return [results][0]\n",
    "\n",
    "todos_campos_filtro={}\n",
    "for n,i in enumerate(filtros):\n",
    "    try:\n",
    "        todos_campos_filtro[i] = get_options_filters(i)\n",
    "    except Exception as e:\n",
    "        print(f'     Filtro {i} não disponível na API. Erro: {e}')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unicos=[]\n",
    "[unicos.append(x) for x in todos_campos_filtro['economicBlock'] if x not in unicos]\n",
    "unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unicos=[]\n",
    "[unicos.append(x) for x in todos_campos_filtro['state'] if x not in unicos]\n",
    "unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_interesse = [\n",
    "    'VI - Produtos das indústrias químicas ou indústrias conexas', \n",
    "    'XVIII - Instrumentos e aparelhos de ótica, fotografia ou cinematografia, medida, controle ou de precisão; Instrumentos e aparelhos médico-cirúrgicos; Relógios e aparelhos semelhantes; Instrumentos musicais; Suas partes e acessórios',\n",
    "    'XX - Mercadorias e produtos diversos',\n",
    "    'XXII - Transações especiais'\n",
    "    ]\n",
    "\n",
    "chapter_interesse = [\n",
    "    '28 - Produtos químicos inorgânicos; compostos inorgânicos ou orgânicos de metais preciosos, de elementos radioativos, de metais das terras raras ou de isótopos',\n",
    "    '29 - Produtos químicos orgânicos',\n",
    "    '30 - Produtos farmacêuticos',\n",
    "    '35 - Matérias albuminóides; produtos à base de amidos ou de féculas modificados; colas; enzimas',\n",
    "    '38 - Produtos diversos das indústrias químicas',\n",
    "    ]\n",
    "\n",
    "heading_interesse = [\n",
    "    '2801 - Flúor, cloro, bromo e iodo',\n",
    "    '2802 - Enxofre sublimado ou precipitado; enxofre coloidal',\n",
    "    '2803 - Carbono (negros-de-carbono e outras formas não compreendidas em outras posições)',\n",
    "    '2804 - Hidrogénio, gases raros e outros elementos não metálicos',\n",
    "    '2805 - Metais alcalinos ou alcalino-terrosos; metais de terras raras, escândio e ítrio, mesmo misturados ou ligados entre si; mercúrio',\n",
    "    '2806 - Cloreto de hidrogénio (ácido clorídrico); ácido clorossulfúrico',\n",
    "    '2807 - Ácido sulfúrico e ácido sulfúrico fumante (oleum)',\n",
    "    '2808 - Ácido nítrico; ácidos sulfonítricos',\n",
    "    '2809 - Pentóxido de difosfóro; ácido fosfórico; ácidos polifosfóricos, de constituição química definida ou não',\n",
    "    '2810 - Óxidos de boro; ácidos bóricos',\n",
    "    '2811 - Outros ácidos inorgânicos e outros compostos oxigenados inorgânicos dos elementos não metálicos',\n",
    "    '2812 - Halogenetos e oxialogenetos dos elementos não metálicos',\n",
    "    '2813 - Sulfuretos dos elementos não metálicos; trissulfureto de fósforo comercial',\n",
    "    '2814 - Amoníaco anidro ou em solução aquosa (amónia)',\n",
    "    '2815 - Hidróxido de sódio (soda cáustica); hidróxido de potássio (potassa cáustica); peróxidos de sódio ou de potássio',\n",
    "    '2816 - Hidróxido e peróxido de magnésio; óxidos, hidróxidos e peróxidos, de estrôncio ou de bário',\n",
    "    '2817 - Óxido de zinco; peróxido de zinco',\n",
    "    '2818 - Corindo artificial, quimicamente definido ou não; óxido de alumínio; hidróxido de alumínio',\n",
    "    '2819 - Óxidos e hidróxidos de crómio',\n",
    "    '2820 - Óxidos de manganés',\n",
    "    '2821 - Óxidos e hidróxidos de ferro; terras corantes contendo, em peso, 70\\xa0% ou mais de ferro combinado, expresso em Fe2O3',\n",
    "    '2822 - Óxidos e hidróxidos de cobalto, inclusive os comerciais',\n",
    "    '2823 - Óxidos de titânio',\n",
    "    '2824 - Óxidos de chumbo; mínio (zarcão) e mínio-laranja (mine-orange)',\n",
    "    '2825 - Hidrazina e hidroxilamina, e seus sais inorgânicos; outras bases inorgânicas; outros óxidos, hidróxidos e peróxidos, de metais',\n",
    "    '2826 - Fluoretos; fluorossilicatos, fluoroaluminatos e outros sais complexos de flúor',\n",
    "    '2827 - Cloretos, oxicloretos e hidroxicloretos; brometos e oxibrometos; iodetos e oxiiodetos',\n",
    "    '2828 - Hipocloritos; hipoclorito de cálcio comercial; cloritos; hipobromitos',\n",
    "    '2829 - Cloratos e percloratos; bromatos e perbromatos; iodatos e periodatos',\n",
    "    '2830 - Sulfuretos; polissulfuretos, de constituição química definida ou não',\n",
    "    '2831 - Ditionites e sulfoxilatos',\n",
    "    '2832 - Sulfitos; tiosulfatos',\n",
    "    '2833 - Sulfatos; alúmenes; peroxosulfatos (persulfatos)',\n",
    "    '2834 - Nitritos; nitratos',\n",
    "    '2835 - Fosfinatos (hipofosfitos), fosfonatos (fosfitos) e fosfatos; polifosfatos, de constituição química definida ou não:',\n",
    "    '2836 - Carbonatos; peroxocarbonatos (percarbonatos); carbonato de amónio comercial contendo carbamato de amónio',\n",
    "    '2837 - Cianetos, oxicianetos e cianetos complexos',\n",
    "    '2838 - Fulminatos, cianatos e tiocianatos',\n",
    "    '2839 - Silicatos; silicatos dos metais alcalinos comerciais',\n",
    "    '2840 - Boratos; peroxoboratos (perboratos)',\n",
    "    '2841 - Sais dos ácidos oxometálicos ou peroxometálicos',\n",
    "    '2842 - Outros sais dos ácidos ou peroxoácidos inorgânicos (incluindo aluminossilicatos de constituição química definida ou não), exceto azidas',\n",
    "    '2843 - Metais preciosos no estado coloidal; compostos inorgânicos ou orgânicos de metais preciosos, de constituição química definida ou não; amálgamas de metais preciosos',\n",
    "    '2844 - Elementos químicos radioactivos e isótopos radioactivos (incluídos os elementos químicos e isótopos cindíveis ou férteis), e seus compostos; misturas e resíduos contendo esses produtos',\n",
    "    '2845 - Isótopos não incluídos na posição\\xa02844; seus compostos inorgânicos ou orgânicos, de constituição química definida ou não',\n",
    "    '2846 - Compostos, inorgânicos ou orgânicos, dos metais das terras raras, de ítrio ou de escândio ou das misturas destes metais',\n",
    "    '2847 - Peróxido de hidrogênio (água oxigenada), mesmo solidificado com ureia',\n",
    "    '2848 - Fosfetos, exceto ferrofósforos, quimicamente definidos ou não',\n",
    "    '2849 - Carbonetos de constituição química definida ou não',\n",
    "    '2850 - Hidretos, nitretos, azidas, silicietos e boretos, quimicamente definidos ou não',\n",
    "    '2851 - Compostos inorgânicos nesoi: liq ar: amálgamas nesoi',\n",
    "    '2852 - Compostos, inorgânicos ou orgânicos, de mercúrio, de constituição química definida ou não, exceto as amálgamas',\n",
    "    '2853 - Outros compostos inorgânicos (incluídas as águas destiladas, de condutibilidade ou de igual grau de pureza); ar líquido (incluído o ar líquido cujos gases raros foram eliminados); ar comprimido; amálgamas, exceto de metais preciosos.',\n",
    "    '2901 - Hidrocarbonetos acíclicos',\n",
    "    '2902 - Hidrocarbonetos cíclicos',\n",
    "    '2903 - Derivados halogenados dos hidrocarbonetos',\n",
    "    '2904 - Derivados sulfonados, nitrados ou nitrosados dos hidrocarbonetos, mesmo halogenados',\n",
    "    '2905 - Álcoois acíclicos e seus derivados halogenados, sulfonados, nitrados ou nitrosados',\n",
    "    '2906 - Álcoois cíclicos e seus derivados halogenados, sulfonados, nitrados ou nitrosados',\n",
    "    '2907 - Fenóis; fenóis-álcoois',\n",
    "    '2908 - Derivados halogenados, sulfonados, nitrados ou nitrosados dos fenóis ou dos fenóis-álcoois',\n",
    "    '2909 - Éteres, éteres-álcoois, éteres-fenóis, éteres-álcoois-fenóis, peróxidos de álcoois, peróxidos de éteres, peróxidos de cetonas (de constituição química definida ou não), e seus derivados halogenados, sulfonados, nitrados ou nitrosados',\n",
    "    '2910 - Epóxidos, epoxi-álcoois, epoxi-fenóis e epoxi-éteres, com três átomos no ciclo, e seus derivados halogenados, sulfonados, nitrados ou nitrosados',\n",
    "    '2911 - Acetais, semi-acetais, mesmo contendo outras funções oxigenadas, e seus derivados halogenados, sulfonados, nitrados ou nitrosados',\n",
    "    '2912 - Aldeídos, mesmo contendo outras funções oxigenadas; polímeros cíclicos dos aldeídos; paraformaldeído',\n",
    "    '2913 - Derivados halogenados, sulfonados, nitrados ou nitrosados dos produtos da posição 2912',\n",
    "    '2914 - Cetonas e quinonas, mesmo contendo outras funções oxigenadas, e seus derivados halogenados, sulfonados, nitratos ou nitrosados',\n",
    "    '2915 - Ácidos monocarboxílicos acíclicos saturados e seus anidridos, halogenetos, peróxidos e peroxiácidos; seus derivados halogenados, sulfonados, nitrados ou nitrosados',\n",
    "    '2916 - Ácidos monocarboxílicos acíclicos não saturados e ácidos monocarboxílicos cíclicos, seus anidridos, halogenetos, peróxidos e peroxiácidos; seus derivados halogenados, sulfonados, nitrados ou nitrosados',\n",
    "    '2917 - Ácidos policarboxílicos, seus anidridos, halogenetos, peróxidos e peroxiácidos; seus derivados halogenados, sulfonados, nitrados ou nitrosados',\n",
    "    '2918 - Ácidos carboxílicos contendo funções oxigenadas suplementares e seus anidridos, halogenetos, peróxidos e peroxiácidos; seus derivados halogenados, sulfonados, nitrados ou nitrosados',\n",
    "    '2919 - Ésteres fosfóricos e seus sais, incluindo os lactofosfatos; seus derivados halogenados, sulfonados, nitrados ou nitrosados',\n",
    "    '2920 - Ésteres de outros ácidos inorgânicos de não-metais (exceto os ésteres de halogenetos de hidrogénio) e seus sais; seus derivados halogenados, sulfonados, nitrados ou nitrosados',\n",
    "    '2921 - Compostos de função amina',\n",
    "    '2922 - Compostos aminados de funções oxigenadas',\n",
    "    '2923 - Sais e hidróxidos de amónio quaternários; lecitinas e outros fosfoaminolípidos, de constitução química definida ou não',\n",
    "    '2924 - Compostos de função carboxiamida; compostos de função amida do ácido carbónico',\n",
    "    '2925 - Compostos de função carboxiimida (incluindo a sacarina e seus sais) ou de função imina',\n",
    "    '2926 - Compostos de função nitrilo',\n",
    "    '2927 - Compostos diazóicos, azóicos e azóxicos',\n",
    "    '2928 - Derivados orgânicos da hidrazina e hidroxilamina',\n",
    "    '2929 - Compostos de outras funções azotadas (nitrogenadas)',\n",
    "    '2930 - Tiocompostos orgânicos',\n",
    "    '2931 - Outros compostos organo-inorgânicos',\n",
    "    '2932 - Compostos heterocíclicos exclusivamente de hetero-átomo(s) de oxigénio',\n",
    "    '2933 - Compostos heterocíclicos, exclusivamente de hetero-átomo(s) de azoto (nitrogénio)',\n",
    "    '2934 - Ácidos nucleicos e seus sais, de constituição química definida ou não; outros compostos heterocíclicos',\n",
    "    '2935 - Sulfonamidas',\n",
    "    '2936 - Provitaminas e vitaminas, naturais ou sintéticas (incluídos os concentrados naturais), bem como os seus derivados utilizados principalmente como vitaminas, misturados ou não entre si, mesmo em quaisquer soluções',\n",
    "    '2937 - Hormonas, prostaglandinas, tromboxanos e leucotrienos, naturais ou reproduzidos por síntese; seus derivados e análogos estruturais, incluindo os polipéptidos de cadeia modificada, utilizados principalmente como hormonas',\n",
    "    '2938 - Heterósidos, naturais ou sintéticos, seus sais, éteres, ésteres e outros derivados',\n",
    "    '2939 - Alcalóides vegetais, naturais ou sintéticos, seus sais, éteres, ésteres e outros derivados',\n",
    "    '2940 - Açúcares quimicamente puros, exceto sacarose, lactose, maltose, glicose e frutose; seus éteres e ésteres e seus sais',\n",
    "    '2941 - Antibióticos',\n",
    "    '2942 - Outros compostos orgânicos',\n",
    "    '3001 - Glândulas e outros órgãos para usos opoterápicos, dessecados, mesmo em pó; extractos de glândulas ou de outros órgãos ou das suas secreções, para usos opoterápicos; heparina e seus sais; outras substâncias humanas ou animais preparadas para fins terapêuti',\n",
    "    '3002 - Sangue humano; sangue animal preparado para usos terapêuticos, profilácticos ou de diagnóstico; anti-soros, outras fracções do sangue, produtos imunológicos modificados, mesmo obtidos por via biotecnológica; vacinas, toxinas, culturas de microrganismos (e',\n",
    "    '3003 - Medicamentos (exceto os produtos das posições\\xa03002, 3005\\xa0ou\\xa03006) constituídos por produtos misturados entre si, preparados para fins terapêuticos ou profilácticos, mas não apresentados em doses nem acondicionados para venda a retalho',\n",
    "    '3004 - Medicamentos (exceto os produtos das posições\\xa03002, 3005\\xa0ou\\xa03006) constituídos por produtos misturados ou não misturados, preparados para fins terapêuticos ou profilácticos, apresentados em doses (incluindo os destinados a serem administrados por via sub',\n",
    "    '3005 - Pastas (ouates), gazes, ataduras e artigos análogos (por exemplo: pensos, esparadrapos, sinapismos), impregnados ou recobertos de substâncias farmacêuticas ou acondicionados para venda a retalho para usos medicinais, cirúrgicos, dentários ou veterinários',\n",
    "    '3006 - Preparações e artigos farmacêuticos indicados na Nota\\xa04\\xa0do presente capítulo',\n",
    "    '3501 - Caseínas, caseinatos e outros derivados das caseínas; colas de caseína',\n",
    "    '3502 - Albuminas (incluídos os concentrados de várias proteínas de soro de leite, contendo, em peso calculado sobre matéria seca, mais de\\xa080\\xa0% de proteínas do soro de leite), albuminatos e outros derivados das albuminas',\n",
    "    '3503 - Gelatinas e seus derivados; ictiocola e outras colas de origem animal, exceto cola de caseína',\n",
    "    '3504 - Peptonas e seus derivados; outras matérias protéicas e seus derivados; pó de peles',\n",
    "    '3505 - Dextrina e outros amidos e féculas modificados (por exemplo: amidos e féculas pré-gelatinizados ou esterificados); colas à base de amidos ou de féculas, de dextrina ou de outros amidos ou féculas modificados',\n",
    "    '3506 - Colas e outros adesivos preparados, não especificados nem compreendidos em outras posições; produtos de qualquer espécie utilizados como colas ou adesivos, acondicionados para venda a retalho como colas ou adesivos, com peso líquido não superior a\\xa01\\xa0kg',\n",
    "    '3507 - Enzimas; enzimas preparadas não especificadas nem compreendidas em outras posições',\n",
    "    '3821 - Meios de cultura preparados para o desenvolvimento e a manutenção de microrganismos (incluindo os vírus e os organismos similares) ou de células vegetais, humanas ou animais',\n",
    "    '3822 - Reagentes de diagnóstico ou de laboratório, em qualquer suporte ou preparados, exceto os das posições 3002 ou 3006; materiais de referência certificados',\n",
    "    '3823 - Ácidos gordos monocarboxílicos industriais; óleos ácidos de refinação; alcoóis gordos industriais',\n",
    "    '3824 - Aglutinantes preparados para moldes ou para núcleos de fundição; produtos químicos e preparações das indústrias químicas ou das indústrias conexas (incluídos os constituídos por misturas de produtos naturais), não especificados nem compreendidos noutras p',\n",
    "    '3825 - Produtos residuais das indústrias químicas ou das indústrias conexas, não especificados nem compreendidos em outras posições; resíduos municipais; lamas de depuração; outros resíduos mencionados na Nota\\xa06 do presente capítulo',\n",
    "    '3901 - Polímeros de etileno, em formas primárias',\n",
    "    '3902 - Polímeros de propileno ou de outras olefinas, em formas primárias',\n",
    "    '3903 - Polímeros de estireno, em formas primárias',\n",
    "    '3904 - Polímeros de cloreto de vinilo ou de outras olefinas halogenadas, em formas primárias',\n",
    "    '3905 - Polímeros de acetato de vinilo ou de outros ésteres de vinilo, em formas primárias; outros polímeros de vinilo, em formas primárias',\n",
    "    '3906 - Polímeros acrílicos, em formas primárias',\n",
    "    '3907 - Poliacetais, outros poliéteres e resinas epóxidas, em formas primárias; policarbonatos, resinas alquídicas, poliésteres alílicos e outros poliésteres, em formas primárias',\n",
    "    '3908 - Poliamidas em formas primárias',\n",
    "    '3909 - Resinas amínicas, resinas fenólicas e poliuretanos, em formas primárias',\n",
    "    '3910 - Silicones, em formas primárias',\n",
    "    '8417 - Fornos industriais ou de laboratório, incluídos os incineradores, não elétricos',\n",
    "    '8418 - Refrigeradores, congeladores (freezers) e outro material, máquinas e aparelhos para a produção de frio, com equipamento eléctrico ou outro; bombas de calor, excluídas as máquinas e aparelhos de ar condicionado da posição 8415',\n",
    "    '8419 - Aparelhos e dispositivos, mesmo aquecidos electricamente (exceto fornos e outros aparelhos da posição 8514), para tratamento de matérias por meio de operações que impliquem mudança de temperatura, tais como o aquecimento, cozimento, torrefacção, destilaç',\n",
    "    '8420 - Calandras e laminadores, exceto os destinados ao tratamento de metais ou vidro, e seus cilindros',\n",
    "    '8421 - Centrifugadores, incluídos os secadores centrífugos, aparelhos para filtrar ou depurar líquidos ou gases',\n",
    "    '8423 - Aparelhos e instrumentos de pesagem, incluídas as básculas e balanças para verificar peças fabricadas, excluídas as balanças sensíveis a pesos não superiores a 5 cg; pesos para quaisquer balanças',\n",
    "    '8471 - Máquinas automáticas para processamento de dados e suas unidades; leitores magnéticos ou ópticos, máquinas para registar dados em suporte sob forma codificada, e máquinas para processamento desses dados, não especificadas nem compreendidas em outras posiç',\n",
    "    '8472 - Outras máquinas e aparelhos de escritório [por exemplo: duplicadores hectográficos ou a stencil, máquinas para imprimir endereços, distribuidores automáticos de papel-moeda, máquinas para seleccionar, contar ou empacotar moedas, afiadores (apontadores) me',\n",
    "    '9011 - Microscópios ópticos, incluídos os microscópios para fotomicrografia, cinefotomicrografia ou microprojecção',\n",
    "    '9012 - Microscópios, exceto ópticos; difractógrafos',\n",
    "    '9013 - Dispositivos de cristais líquidos que não constituam artigos compreendidos mais especificamente em outras posições; lasers, exceto díodos laser; outros aparelhos e instrumentos de óptica, não especificados nem compreendidos em outras posições do presente',\n",
    "    '9016 - Balanças sensíveis a pesos >= 5 cg, com ou sem pesos',\n",
    "    '9021 - Artigos e aparelhos ortopédicos, incluídas as cintas e fundas médico-cirúrgicas e as muletas; talas, goteiras e outros artigos e aparelhos para fracturas; artigos e aparelhos de prótese; aparelhos para facilitar a audição dos surdos e outros aparelhos par',\n",
    "    '9022 - Aparelhos de raios X e aparelhos que utilizem as radiações alfa, beta ou gama, mesmo para usos médicos, cirúrgicos, odontológicos ou veterinários, incluídos os aparelhos de radiofotografia ou de radioterapia, os tubos de raios X e outros dispositivos gera',\n",
    "    '9023 - Instrumentos, aparelhos e modelos, concebidos para demonstração (por exemplo, no ensino e nas exposições), não suscetíveis de outros usos',\n",
    "    '9024 - Máquinas e aparelhos para ensaios de dureza, tracção, compressão, elasticidade e de outras propriedades mecânicas de materiais (por exemplo: metais, madeira, têxteis, papel, plásticos)',\n",
    "    '9025 - Densímetros, areómetros, pesa-líquidos e instrumentos flutuantes semelhantes, termómetros, pirómetros, barómetros, higrómetros e psicrómetros, registadores ou não, mesmo combinados entre si',\n",
    "    '9026 - Instrumentos e aparelhos para medida ou controlo do caudal (vazão), do nível, da pressão ou de outras características variáveis dos líquidos ou gases (por exemplo: medidores de caudal, indicadores de nível, manómetros, contadores de calor), exceto os ins',\n",
    "    '9027 - Instrumentos e aparelhos para análises físicas ou químicas (por exemplo: polarímetros, refractómetros, espectrómetros, analisadores de gases ou de fumos); instrumentos e aparelhos para ensaios de viscosidade, porosidade, dilatação, tensão superficial ou s',\n",
    "    '9028 - Contadores de gases, de líquidos ou de electricidade, incluídos os aparelhos para a sua aferição',\n",
    "    '9029 - Outros contadores (por exemplo: contadores de voltas, contadores de produção, taxímetros, totalizadores de caminho percorrido, podómetros); indicadores de velocidade e tacómetros, exceto os das posições 9014 ou 9015; estroboscópios',\n",
    "    '9030 - Osciloscópios, analisadores de espectro e outros instrumentos e aparelhos para medida ou controlo de grandezas elétricas; instrumentos e aparelhos para medida ou detecção de radiações alfa, beta, gama, X, cósmicas ou outras radiações ionizantes',\n",
    "    '9031 - Instrumentos, aparelhos e máquinas de medida ou controlo, não especificados nem compreendidos em outras posições do presente capítulo; projectores de perfis',\n",
    "    '9032 - Instrumentos e aparelhos para regulação ou controlo, automáticos',\n",
    "    '9033 - Partes e acessórios não especificados nem compreendidos noutras posições do presente Capítulo, para máquinas, aparelhos, instrumentos ou artigos do Capítulo 90',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "\n",
    "context = ssl._create_unverified_context()\n",
    "conn = http.client.HTTPSConnection(\"api-comexstat.mdic.gov.br\", context=context)\n",
    "conn.request(\"GET\", \"/tables/ncm/02042200\")\n",
    "\n",
    "res = conn.getresponse()\n",
    "data = res.read()\n",
    "\n",
    "print(data.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "\n",
    "context = ssl._create_unverified_context()\n",
    "conn = http.client.HTTPSConnection(\"api-comexstat.mdic.gov.br\", context=context)\n",
    "conn.request(\"GET\", \"/tables/ncm?language=pt\")\n",
    "\n",
    "res = conn.getresponse()\n",
    "data = res.read()\n",
    "\n",
    "print(data.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interesse = []\n",
    "# f = filtros[0]\n",
    "# print(f)\n",
    "# for n,i in enumerate(todos_campos_filtro.get(f)):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Endpoint para obter os valores por filtro disponíveis na API\n",
    "# # Lista os valores disponíveis para um filtro específico. Exemplos de como acessar os valores possíveis por diferentes filtros:\n",
    "# # Países: /general/filters/country?language=pt\n",
    "# # Blocos Econômicos: /general/filters/economicBlock?language=pt\n",
    "# # Seções (do Sistema Harmonizado - SH): /general/filters/section?language=pt\n",
    "# # NCM (Nomenclatura Comum do Mercosul): /general/filters/ncm?language=pt\n",
    "\n",
    "# import http.client\n",
    "\n",
    "# # Cria um contexto SSL sem verificação de certificado\n",
    "# context = ssl._create_unverified_context()\n",
    "# conn = http.client.HTTPSConnection(\"api-comexstat.mdic.gov.br\", context=context)\n",
    "# conn.request(\"GET\", \"/general/filters/heading?language=pt\")\n",
    "\n",
    "# res = conn.getresponse()\n",
    "# print(f'objeto       res: {type(res)}')\n",
    "# data = res.read()\n",
    "# print(f'objeto      data: {type(data)}')\n",
    "# data_str = data.decode(\"utf-8\")\n",
    "# print(f'objeto  data_str: {type(data_str)}')\n",
    "# data_json = json.loads(data_str)\n",
    "# print(f'objeto data_json: {type(data_json)}')\n",
    "\n",
    "# Lista de campos no filtro heading\n",
    "# heading_list = [y.get('text') for y in data_json.get('data')[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de campos no filtro chapter\n",
    "campos = ['country', 'economicBlock', 'state', 'city', 'heading', 'chapter', 'section']\n",
    "filter='economicBlock'\n",
    "api_filters = ['']\n",
    "list_country = get_options_filters('country')\n",
    "list_economicBlock = get_options_filters('economicBlock')\n",
    "list_state = get_options_filters('state')\n",
    "list_heading = get_options_filters('heading')\n",
    "list_chapter = get_options_filters('chapter')\n",
    "list_section = get_options_filters('section')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Inicializa a lista de NCMs de saúde com valores padrão\n",
    "# ncms_saude = []  # Lista vazia caso a requisição falhe\n",
    "\n",
    "# if ncm_response:\n",
    "#     ncms = ncm_response.json()\n",
    "#     # Filtrar os NCMs relacionados à saúde (exemplo)\n",
    "#     ncms_saude = [ncm['id'] for ncm in ncms if ncm['desc'].startswith(\"Medicamentos\")]\n",
    "\n",
    "# # Endpoint para consulta dos dados\n",
    "# consulta_url = \"/cities\"\n",
    "\n",
    "# # Parâmetros da consulta (exemplo)\n",
    "# params = {\n",
    "#     \"flow\": [\"export\", \"import\"],\n",
    "#     \"monthDetail\": False,\n",
    "#     \"period\": {\"from\": f\"{ano_inicial}-01\", \"to\": f\"{ano_final}-12\"},\n",
    "#     \"filters\": [{\"filter\": \"ncm\", \"values\": ncms_saude}],\n",
    "#     \"details\": [\"ncm\"],\n",
    "#     \"metrics\": [\"metricFOB\"],\n",
    "# }\n",
    "\n",
    "# # Realiza a consulta\n",
    "# response = fazer_requisicao(conn, consulta_url, params=params)\n",
    "\n",
    "# if response:\n",
    "#     data = response\n",
    "#     df = pd.DataFrame(data['data'])\n",
    "\n",
    "#     # Calcula o déficit por ano e NCM\n",
    "#     df_pivot = df.pivot_table(\n",
    "#         index=[\"year\", \"ncm\"], columns=\"flow\", values=\"metricFOB\", aggfunc=\"sum\"\n",
    "#     )\n",
    "#     df_pivot[\"deficit\"] = df_pivot[\"import\"] - df_pivot[\"export\"]\n",
    "\n",
    "#     # Salva os resultados em um arquivo CSV\n",
    "#     df_pivot.to_csv(\"deficit_balanca_comercial_saude.csv\")\n",
    "\n",
    "#     print(\"Dados salvos com sucesso!\")\n",
    "\n",
    "# # Fecha a conexão\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # Inicializa a lista de NCMs de saúde com valores padrão\n",
    "# # com lista vazia caso a requisição falhe\n",
    "# ncms_saude = []  \n",
    "# ncm_response = []\n",
    "\n",
    "# if ncm_response:\n",
    "#     ncms = ncm_response.json()\n",
    "#     # Filtrar os NCMs relacionados à saúde (exemplo)\n",
    "#     ncms_saude = [ncm['id'] for ncm in ncms if ncm['desc'].startswith(\"Medicamentos\")]\n",
    "#     print(ncms_saude)\n",
    "\n",
    "# # Endpoint para consulta dos dados\n",
    "# consulta_url = \"https://api-comexstat.mdic.gov.br/cities\"\n",
    "\n",
    "# # Parâmetros da consulta (exemplo)\n",
    "# params = {\n",
    "#     \"flow\": [\"export\", \"import\"],\n",
    "#     \"monthDetail\": False,\n",
    "#     \"period\": {\"from\": f\"{ano_inicial}-01\", \"to\": f\"{ano_final}-12\"},\n",
    "#     \"filters\": [{\"filter\": \"ncm\", \"values\": ncms_saude}],\n",
    "#     \"details\": [\"ncm\"],\n",
    "#     \"metrics\": [\"metricFOB\"],\n",
    "# }\n",
    "\n",
    "# # Realiza a consulta\n",
    "# response = fazer_requisicao(consulta_url, json=params)\n",
    "\n",
    "# if response:\n",
    "#     data = response.json()\n",
    "#     df = pd.DataFrame(data)\n",
    "\n",
    "#     # # Calcula o déficit por ano e NCM\n",
    "#     # df_pivot = df.pivot_table(\n",
    "#     #     index=[\"coAno\", \"ncm\"], columns=\"flow\", values=\"metricFOB\", aggfunc=\"sum\"\n",
    "#     # )\n",
    "#     # df_pivot[\"deficit\"] = df_pivot[\"import\"] - df_pivot[\"export\"]\n",
    "\n",
    "#     # # Salva os resultados em um arquivo CSV\n",
    "#     # df_pivot.to_csv(\"deficit_balanca_comercial_saude.csv\")\n",
    "\n",
    "#     # print(\"Dados salvos com sucesso!\")\n",
    "# for i in df['data'].items():\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ncm_response = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Gerar ilustrações para modelos pré-treinados</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir parâmetros adequado para trabalhar com tensores na GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O parâmetro return_tensors=\"pt\" em funções como o tokenizer do Hugging Face Transformers indica que você deseja que o tokenizador retorne os resultados da tokenização como tensores PyTorch.\n",
    "\n",
    "PyTorch é uma biblioteca popular de aprendizado de máquina que usa tensores como sua estrutura de dados principal.\n",
    "Por que usar return_tensors=\"pt\"?\n",
    "\n",
    "Tensores são estruturas de dados multidimensionais semelhantes a arrays NumPy, mas com a capacidade de serem processados ​​em GPUs para acelerar cálculos numéricos.\n",
    "\n",
    "A maioria dos modelos do Hugging Face Transformers são implementados em PyTorch. Ao usar return_tensors=\"pt\", você garante que os resultados da tokenização estejam no formato correto para serem alimentados diretamente nesses modelos.\n",
    "\n",
    "Se houver uma GPU dsiponivel, os tensores PyTorch podem ser movidos para a GPU para aproveitar sua capacidade de processamento paralelo e acelerar os cálculos.\n",
    "\n",
    "Alternativas\n",
    "\n",
    "return_tensors=\"tf\": Retorna os resultados como tensores do TensorFlow, outra biblioteca popular de aprendizado de máquina.\n",
    "\n",
    "return_tensors=\"np\": Retorna os resultados como arrays NumPy, que são úteis para algumas operações de pré-processamento ou análise, mas geralmente não são tão eficientes em GPUs quanto os tensores PyTorch.\n",
    "\n",
    "return_tensors=None (padrão): Retorna os resultados como listas de Python, que são mais fáceis de entender e manipular, mas podem ser menos eficientes para alimentar modelos de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"This is a test sentence.\"\n",
    "\n",
    "# Tokenização com tensores PyTorch\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "sentence1 = \"This is a test sentence.\"\n",
    "sentence2 = \"How are you?\"\n",
    "\n",
    "# Tokenização com duas sentenças\n",
    "inputs = tokenizer([sentence1, sentence2], return_tensors=\"pt\", padding=True)\n",
    "\n",
    "for i,j in inputs.items():\n",
    "    print(f\"{i:>15}: {j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation_en_to_pt\", model=\"unicamp-dl/translation-en-pt-t5\")\n",
    "print(translator.tokenizer.model_max_length) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificar pilelines do Spacy para PLN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Carregar o modelo en_core_web_trf\n",
    "nlp_en = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# Imprimir os nomes dos pipes disponíveis no modelo\n",
    "print(nlp_en.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificar informações básicas para modelos do Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR\n",
    "    subgraph Input [Input]\n",
    "    end\n",
    "\n",
    "    subgraph Embeddings\n",
    "        word_embeddings([\"word_embeddings\"])\n",
    "        position_embeddings([\"position_embeddings\"])\n",
    "        token_type_embeddings([\"token_type_embeddings\"])\n",
    "        LayerNorm([\"LayerNorm\"])\n",
    "        Dropout([\"Dropout\"])\n",
    "    end\n",
    "    \n",
    "    Input --> Embeddings\n",
    "\n",
    "    subgraph Encoder [Encoder]\n",
    "        BertLayers[12 x BertLayer]\n",
    "    end\n",
    "\n",
    "    Embeddings --> Encoder\n",
    "\n",
    "    subgraph Pooler [Pooler]\n",
    "        dense(( Linear ))\n",
    "        activation(( Tanh ))\n",
    "    end\n",
    "\n",
    "    Encoder --> Pooler\n",
    "    \n",
    "    subgraph BertLayer\n",
    "        BertAttention\n",
    "        BertIntermediate\n",
    "        BertOutput\n",
    "        LayerNorm_output([\"LayerNorm\"])\n",
    "        Dropout_output([\"Dropout\"])\n",
    "    end\n",
    "\n",
    "    subgraph BertAttention\n",
    "        SelfAttention\n",
    "        output\n",
    "    end\n",
    "\n",
    "    BertLayer --> BertAttention\n",
    "    BertLayer --> BertIntermediate\n",
    "    \n",
    "    subgraph BertSelfAttention\n",
    "        query(( Linear ))\n",
    "        key(( Linear ))\n",
    "        value(( Linear ))\n",
    "        Dropout([\"Dropout\"])\n",
    "    end\n",
    "\n",
    "    BertAttention --> BertSelfAttention\n",
    "\n",
    "    subgraph BertSelfOutput\n",
    "        dense(( Linear ))\n",
    "        LayerNorm([\"LayerNorm\"])\n",
    "        Dropout([\"Dropout\"])\n",
    "    end\n",
    "\n",
    "    BertSelfAttention --> BertSelfOutput\n",
    "\n",
    "    subgraph BertIntermediate\n",
    "        dense(( Linear ))\n",
    "        intermediate_act_fn(( GELUActivation ))\n",
    "    end\n",
    "\n",
    "    BertSelfOutput --> BertIntermediate\n",
    "\n",
    "    subgraph BertOutput\n",
    "        dense(( Linear ))\n",
    "        LayerNorm([\"LayerNorm\"])\n",
    "        Dropout([\"Dropout\"])\n",
    "    end\n",
    "\n",
    "    %% BertLayers --> BertLayer\n",
    "    \n",
    "    BertAttention -.-> BertSelfOutput  \n",
    "    BertSelfOutput --> LayerNorm_output\n",
    "    LayerNorm_output --> Dropout_output\n",
    "    Dropout_output --> BertLayer \n",
    "    BertLayer -.-> BertOutput \n",
    "    \n",
    "    BertIntermediate --> GELUActivation\n",
    "    BertIntermediate --> BertOutput\n",
    "    BertSelfAttention --> query\n",
    "    BertSelfAttention --> key\n",
    "    BertSelfAttention --> value\n",
    "    BertSelfAttention --> Dropout\n",
    "    \n",
    "    Pooler --> Tanh\n",
    "    Tanh --> pooler_output(( pooler_output ))\n",
    "\n",
    "    BertOutput --> dense\n",
    "    BertOutput --> LayerNorm\n",
    "    BertOutput --> Dropout\n",
    "    BertOutput --> last_hidden_state(( last_hidden_state ))\n",
    "    BertOutput --> hidden_states(( hidden_states ))\n",
    "    BertAttention --> attentions(( attentions ))\n",
    "\n",
    "    %% Embeddings - vertical arrangement\n",
    "    word_embeddings --> position_embeddings\n",
    "    position_embeddings --> token_type_embeddings\n",
    "    token_type_embeddings --> LayerNorm\n",
    "    LayerNorm --> Dropout\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir o nome de cada camada\n",
    "for name, module in model.named_modules():\n",
    "    print(name)\n",
    "\n",
    "# Acessar uma camada específica\n",
    "first_layer = model.get_encoder().layer[0]\n",
    "print(first_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mermaid_diagram_ok(model):\n",
    "    \"\"\"\n",
    "    Generates a Mermaid diagram representing the structure of a Hugging Face model, \n",
    "    collapsing repetitive layers into shapes with layer count and using rounded rectangles for internal layers.\n",
    "\n",
    "    Args:\n",
    "        model: The Hugging Face model to be analyzed.\n",
    "    \"\"\"\n",
    "\n",
    "    diagram = \"graph LR\\n\"\n",
    "    layer_counts = {}\n",
    "\n",
    "    root_nome_name = f\"{model.__class__.__name__}\"\n",
    "\n",
    "    # Adicionar o nó raiz que representa o modelo\n",
    "    diagram += f\"    {root_nome_name}{{ {root_nome_name} }}\\n\"\n",
    "\n",
    "    # Função recursiva para percorrer a estrutura do modelo \n",
    "    def add_nodes_and_connections(module, parent_name=\"\"):\n",
    "        nonlocal diagram, layer_counts\n",
    "        for name, child_module in module.named_children():\n",
    "            current_layer_type = child_module.__class__.__name__\n",
    "            node_name = parent_name + \".\" + name if parent_name else name\n",
    "\n",
    "            ## Elementos filhos repetitivos dentro de um pai, mas precisa detectar dinamicamente o nome do elemento\n",
    "            layer_counts[current_layer_type] = layer_counts.get(current_layer_type, 0) + 1\n",
    "\n",
    "            if layer_counts[current_layer_type] == 1:\n",
    "                # Use rounded rectangle for single occurrences or non-repetitive layers\n",
    "                diagram += f\"    {node_name}{ (current_layer_type) }\\n\"\n",
    "                diagram += f\"    {parent_name} --> {node_name}\\n\"\n",
    "\n",
    "            add_nodes_and_connections(child_module, node_name)\n",
    "\n",
    "    add_nodes_and_connections(model)\n",
    "\n",
    "    # Adicionar formas para camadas repetitivas com contagem e retângulos para camadas internas\n",
    "    named_children = list(model.named_children())\n",
    "    for layer_type, count in layer_counts.items():\n",
    "        if count > 1:\n",
    "            diagram += f\"    subgraph {layer_type}s\\n\"\n",
    "            diagram += f\"        {layer_type}x{count}[\\\"{count} x {layer_type}\\\"]\\n\"  \n",
    "            diagram += \"    end\\n\"\n",
    "            diagram += f\"    {model.__class__.__name__} --> {layer_type}s\\n\"\n",
    "\n",
    "            # Conectar a forma ao componente subsequente se não for o último filho\n",
    "            if count < len(named_children): \n",
    "                diagram += f\"    {layer_type}s --> {named_children[count][0]}\\n\"\n",
    "        else:\n",
    "            try:\n",
    "                parent_name = root_nome_name\n",
    "                first_child_name = layer_type\n",
    "                # add_nodes_and_connections(model)\n",
    "            except:\n",
    "                first_child_name = None\n",
    "            print(parent_name, first_child_name)\n",
    "\n",
    "    return diagram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import re\n",
    "\n",
    "def generate_mermaid_diagram(model):\n",
    "    \"\"\"\n",
    "    Generates a Mermaid diagram representing the structure of a Hugging Face model, \n",
    "    collapsing repetitive layers into shapes with layer count and using rounded rectangles for internal layers.\n",
    "\n",
    "    Args:\n",
    "        model: The Hugging Face model to be analyzed.\n",
    "    \"\"\"\n",
    "\n",
    "    diagram = \"graph LR\\n\"\n",
    "    layer_counts = {}\n",
    "    parent_shapes = {}\n",
    "\n",
    "    # Add the root node representing the model\n",
    "    diagram += f\"    {model.__class__.__name__}{{ {model.__class__.__name__} }}\\n\"\n",
    "\n",
    "    # Recursive function to traverse the model structure \n",
    "    def add_nodes_and_connections(module, parent_name=\"\"):\n",
    "        nonlocal diagram, layer_counts, parent_shapes\n",
    "        for name, child_module in module.named_children():\n",
    "            current_layer_type = child_module.__class__.__name__\n",
    "\n",
    "            # Sanitize the node name more aggressively to be Mermaid-compatible\n",
    "            node_name = re.sub(r'[^a-zA-Z0-9_-]', '_', parent_name + \".\" + name if parent_name else name).strip()\n",
    "            # Replace consecutive underscores with a single underscore\n",
    "            node_name = re.sub(r'_+', '_', node_name)\n",
    "\n",
    "            layer_counts[node_name] = layer_counts.get(node_name, 0) + 1\n",
    "\n",
    "            # Always add nodes to the diagram\n",
    "            diagram += f\"    {node_name}(( {current_layer_type} ))\\n\"\n",
    "\n",
    "            # If this is the first child of its parent, create a subgraph for the parent\n",
    "            if layer_counts[node_name] == 1 and parent_name:\n",
    "                if parent_name not in parent_shapes:\n",
    "                    # Sanitize the parent name as well\n",
    "                    parent_name = re.sub(r'[^a-zA-Z0-9_-]', '_', parent_name).strip()\n",
    "                    parent_name = re.sub(r'_+', '_', parent_name)\n",
    "                    diagram += f\"    subgraph {parent_name}\\n\"\n",
    "                    parent_shapes[parent_name] = True\n",
    "\n",
    "            diagram += f\"    {parent_name} --> {node_name}\\n\"\n",
    "\n",
    "            add_nodes_and_connections(child_module, node_name)\n",
    "\n",
    "            # If this is the last child of its parent, close the subgraph if it was opened\n",
    "            if layer_counts[node_name] == len(list(module.named_children())) and parent_name in parent_shapes:\n",
    "                diagram += \"    end\\n\"\n",
    "\n",
    "    add_nodes_and_connections(model)\n",
    "\n",
    "    # Add shapes for repetitive layers with count and rounded rectangles for internal layers\n",
    "    named_children = list(model.named_children())\n",
    "    for layer_type, count in layer_counts.items():\n",
    "        if count > 1:\n",
    "            parent_name = \".\".join(layer_type.split(\".\")[:-1])\n",
    "            # Sanitize the parent name\n",
    "            parent_name = re.sub(r'[^a-zA-Z0-9_-]', '_', parent_name).strip()\n",
    "            parent_name = re.sub(r'_+', '_', parent_name)\n",
    "\n",
    "            diagram = diagram.replace(f\"    subgraph {parent_name}\\n\", \n",
    "                                      f\"    subgraph {parent_name} [{count} x {layer_type.split('.')[-1]}]\\n\")\n",
    "\n",
    "            # Connect the grandparent to the shape\n",
    "            grandparent_name = \".\".join(parent_name.split(\".\")[:-1]) \n",
    "            if grandparent_name:\n",
    "                diagram += f\"    {grandparent_name} --> {parent_name}\\n\"\n",
    "\n",
    "            # Connect the shape to the subsequent component if it's not the last child\n",
    "            if any(name.startswith(parent_name + \".\") for name in layer_counts):\n",
    "                next_component = next(name for name in layer_counts if name.startswith(parent_name + \".\"))\n",
    "                diagram += f\"    {parent_name} --> {next_component}\\n\"\n",
    "\n",
    "    return diagram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar o código Mermaid\n",
    "mermaid_code = generate_mermaid_diagram_ok(model)\n",
    "print(mermaid_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar o código Mermaid\n",
    "mermaid_code = generate_mermaid_diagram(model)\n",
    "print(mermaid_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir o diagrama usando Markdown\n",
    "from IPython.display import Markdown\n",
    "display(Markdown(f\"```mermaid\\n{mermaid_code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` mermaid\n",
    "graph TD\n",
    "    BertModel{{BertModel}} --> embeddings{{BertEmbeddings}} --> embeddings --> embeddings(BertEmbeddings) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` mermaid\n",
    "graph TD\n",
    "    BertModel{{BertModel}} --> embeddings{{BertEmbeddings}} --> embeddings --> embeddings((BertEmbeddings)) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "print(model)\n",
    "print()\n",
    "print(model.config)\n",
    "\n",
    "# Imprimir o nome de cada camada\n",
    "for name, module in model.named_modules():\n",
    "    print(name)\n",
    "\n",
    "# Acessar uma camada específica\n",
    "print(f\"\\nBusca por camada específica no modelo HF:\")\n",
    "camada = \"get_encoder\"\n",
    "try:\n",
    "    first_layer = model.camada().layer[0]\n",
    "    print(first_layer)\n",
    "except:\n",
    "    print(f\"  Modelo {model_name} não possui camada de {camada}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entradas de referência:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entradas de citações para referências:\n",
    "\n",
    "@book{gil2022comoelaborarprojetosdepesquisa,\n",
    "  title={Como Elaborar Projetos de Pesquisa},\n",
    "  author={Gil, Antonio Carlos},\n",
    "  edition={7},\n",
    "  publisher={Atlas},\n",
    "  year={2022}\n",
    "}\n",
    "\n",
    "@book{popper1934logic,\n",
    "  title={A Lógica da Pesquisa Científica},\n",
    "  author={Popper, Karl},\n",
    "  year={1934}\n",
    "}\n",
    "\n",
    "@misc{IEP2023Popper,\n",
    "  author = {Internet Encyclopedia of Philosophy},\n",
    "  title = {Karl Popper: Political Philosophy},\n",
    "  year = {2023},\n",
    "  howpublished = {\\url{https://iep.utm.edu/popp-pol/}},\n",
    "  note = {Acesso em: 01/01/2024}\n",
    "}\n",
    "\n",
    "@phdthesis{Broderick1984,\n",
    "  author = {David Gregory Broderick},\n",
    "  title = {Objectivity: Thomas Aquinas and Karl Popper},\n",
    "  school = {Boston College},\n",
    "  year = {1984}\n",
    "}\n",
    "\n",
    "@article{CRYFUNavara2023,\n",
    "  author = {Grupo Ciencia, Razón y Fe (CRYF)},\n",
    "  title = {The Ethical Roots of Karl Popper's Epistemology},\n",
    "  journal = {Universidad de Navarra},\n",
    "  year = {2023},\n",
    "  url = {https://www.unav.edu/web/ciencia-razon-y-fe/poppers-epistemology}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bases de Dados:\n",
    "\n",
    "@misc{arxiv,\n",
    "  title = {{arXiv}},\n",
    "  url = {https://arxiv.org}\n",
    "}\n",
    "\n",
    "@misc{core,\n",
    "  title = {{CORE}},\n",
    "  url = {https://core.ac.uk}\n",
    "}\n",
    "\n",
    "@misc{doaj,\n",
    "  title = {{Directory of Open Access Journals (DOAJ)}},\n",
    "  url = {https://doaj.org}\n",
    "}\n",
    "\n",
    "@misc{googlescholar,\n",
    "  title = {{Google Scholar}},\n",
    "  url = {https://scholar.google.com}\n",
    "}\n",
    "\n",
    "@misc{openaire,\n",
    "  title = {{OpenAIRE}},\n",
    "  url = {https://www.openaire.eu}\n",
    "}\n",
    "\n",
    "@misc{pubmedcentral,\n",
    "  title = {{PubMed Central}},\n",
    "  url = {https://www.ncbi.nlm.nih.gov/pmc/}\n",
    "}\n",
    "\n",
    "@misc{ssrn,\n",
    "  title = {{Social Science Research Network (SSRN)}},\n",
    "  url = {https://www.ssrn.com}\n",
    "}\n",
    "\n",
    "@misc{scienceopen,\n",
    "  title = {{ScienceOpen}},\n",
    "  url = {https://www.scienceopen.com}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editoras com políticas de OA:\n",
    "\n",
    "@misc{springernature,\n",
    "  title = {{Springer Nature}},\n",
    "  url = {https://www.springernature.com}\n",
    "}\n",
    "\n",
    "@misc{oup,\n",
    "  title = {{Oxford University Press (OUP)}},\n",
    "  url = {https://academic.oup.com}\n",
    "}\n",
    "\n",
    "@misc{frontiers,\n",
    "  title = {{Frontiers}},\n",
    "  url = {https://www.frontiersin.org}\n",
    "}\n",
    "\n",
    "@misc{wiley,\n",
    "  title = {{Wiley}},\n",
    "  url = {https://www.wiley.com}\n",
    "}\n",
    "\n",
    "@misc{plos,\n",
    "  title = {{Public Library of Science (PLOS)}},\n",
    "  url = {https://www.plos.org}\n",
    "}\n",
    "\n",
    "@misc{hindawi,\n",
    "  title = {{Hindawi}},\n",
    "  url = {https://www.hindawi.com}\n",
    "}\n",
    "\n",
    "@misc{mdpi,\n",
    "  title = {{MDPI AG}},\n",
    "  url = {https://www.mdpi.com}\n",
    "}\n",
    "\n",
    "@misc{informa,\n",
    "  title = {{Informa PLC}},\n",
    "  url = {https://www.informa.com}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GII\n",
    "@misc{GII-WIPO,\n",
    "      title = {Global Innovation Index - WIPO Series},\n",
    "      abstract = {The Global Innovation Index (GII) ranks the innovation performance of some 131 countries and economies around the world, based on 80+ indicators. Co-published by WIPO, Cornell University and INSEAD, the report provides an annual ranking of the innovation capabilities and performance of economies around the world.},\n",
    "      {url = https://www.wipo.int/publications/en/series/index.jsp?id=129}\n",
    "}\n",
    "\n",
    "@misc{GII-2011,\n",
    "  title = {Global Innovation Index 2011 - Accelerating Growth and Development},\n",
    "  url = {https://www.wipo.int/publications/en/details.jsp?id=274&plang=EN}\n",
    "}\n",
    "\n",
    "@misc{GII-2012,\n",
    "  title = {Global Innovation Index 2012 - Stronger Innovation Linkages for Global Growth},\n",
    "  url = {https://www.wipo.int/publications/en/details.jsp?id=247&plang=EN}\n",
    "}\n",
    "\n",
    "@misc{GII-2013,\n",
    "  title = {Global Innovation Index 2013 - The Local Dynamics of Innovation},\n",
    "  url = {https://www.wipo.int/publications/en/details.jsp?id=368&plang=EN}\n",
    "}\n",
    "\n",
    "@misc{GII-2014,\n",
    "  title = {Global Innovation Index 2014 - The Human Factor in Innovation},\n",
    "  url = {https://www.wipo.int/publications/en/details.jsp?id=3254&plang=EN}\n",
    "}\n",
    "\n",
    "@misc{GII-2015,\n",
    "  title = {Global Innovation Index 2015 - Effective Innovation Policies for Development},\n",
    "  url = {https://www.wipo.int/publications/en/details.jsp?id=3978&plang=EN}\n",
    "}\n",
    "\n",
    "@misc{GII-2016,\n",
    "  title = {Global Innovation Index 2016 - Winning with Global Innovation},\n",
    "  url = {https://www.wipo.int/publications/en/details.jsp?id=4064&plang=EN}\n",
    "}\n",
    "\n",
    "@misc{GII-2017,\n",
    "  title = {Global Innovation Index 2017 - Innovation Feeding the World},\n",
    "  url = {https://www.wipo.int/publications/en/details.jsp?id=4193&plang=EN}\n",
    "}\n",
    "\n",
    "@misc{GII-2018,\n",
    "  title = {Global Innovation Index 2018 - Energizing the World with Innovation},\n",
    "  url = {https://www.wipo.int/publications/en/details.jsp?id=4330&plang=EN}\n",
    "}\n",
    "\n",
    "@misc{GII-2019,\n",
    "  title = {Global Innovation Index 2019 - Creating Healthy Lives — The Future of Medical Innovation},\n",
    "  url = {https://www.wipo.int/publications/en/details.jsp?id=4434&plang=EN}\n",
    "}\n",
    "\n",
    "@article{40579,\n",
    "      author = {Cornell University.},\n",
    "      url = {http://tind.wipo.int/record/40579},\n",
    "      title = {Global Innovation Index 2019 - Executive version.},\n",
    "      abstract = {The Global Innovation Index 2019 provides detailed metrics  about the innovation performance of 129 countries and  economies around the world. Its 80 indicators explore a  broad vision of innovation, including political  environment, education, infrastructure and business  sophistication. The GII 2019 analyzes the medical  innovation landscape of the next decade, looking at how  technological and non-technological medical innovation will  transform the delivery of healthcare worldwide. It also  explores the role and dynamics of medical innovation as it  shapes the future of healthcare, and the potential  influence this may have on economic growth. Chapters of the  report provide more details on this year’s theme from  academic, business, and particular country perspectives  from leading experts and decision makers.},\n",
    "      doi = {https://doi.org/10.34667/tind.40579},\n",
    "      recid = {40579},\n",
    "      pages = {214 pages ;},\n",
    "}\n",
    "\n",
    "@article{35279,\n",
    "      url = {http://tind.wipo.int/record/35279},\n",
    "      title = {Índice Global de inovação de 2019 - PRINCIPAIS  RESULTADOS.},\n",
    "      abstract = {Criar Vidas Sadias - O Futuro da Inovação Médica.},\n",
    "      doi = {https://doi.org/10.34667/tind.35279},\n",
    "      recid = {35279},\n",
    "      pages = {20 pages ;},\n",
    "}\n",
    "\n",
    "@misc{GII-2020,\n",
    "  title = {Global Innovation Index 2020 - Who Will Finance Innovation?},\n",
    "  url = {https://www.wipo.int/publications/en/details.jsp?id=4514&plang=EN}\n",
    "}\n",
    "\n",
    "@misc{GII-2021,\n",
    "  title = {Global Innovation Index 2021 - Tracking Innovation through the COVID-19 Crisis},\n",
    "  url = {https://www.wipo.int/publications/en/details.jsp?id=4560&plang=EN}\n",
    "}\n",
    "\n",
    "@article{46620,\n",
    "      url = {http://tind.wipo.int/record/46620},\n",
    "      title = {Índice Global de Inovação 2022 : Resumo executivo.},\n",
    "      abstract = {O Índice Global da Inovação 2022 (IGI) analisa as  tendências globais no campo da inovação em um cenário  marcado pela pandemia de COVID-19 em curso, por um  crescimento desacelerado da produtividade e pelo surgimento  de novos desafios. O IGI revela as economias mais  inovadoras do mundo, classificando o desempenho em  inovação de 132 economias, destacando seus pontos fortes  e fracos em matéria de inovação e identificando lacunas  em suas métricas de inovação. Esta edição de 2022 tem  como foco o efeito da inovação sobre a produtividade e o  bem-estar da sociedade ao longo das próximas décadas.},\n",
    "      doi = {https://doi.org/10.34667/tind.46620},\n",
    "      recid = {46620},\n",
    "      pages = {28 pages :},\n",
    "}\n",
    "\n",
    "@misc{GII-2022,\n",
    "  title = {Global Innovation Index 2022 - What is the future of innovation driven growth?},\n",
    "  url = {https://www.wipo.int/publications/en/details.jsp?id=4622&plang=EN}\n",
    "}\n",
    "\n",
    "@misc{GII-2023,\n",
    "  title = {Global Innovation Index 2023},\n",
    "  url = {https://www.globalinnovationindex.org/gii-2023}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar ou apontar para local atual do Spacy para PLN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar instalação desnecessária quando o Spacy já está instalado no Windows onde o WSL está rodando, é possível apontar para o diretório do spaCy instalado no Windows a partir do WSL para evitar uma nova instalação e economizar espaço em disco. \n",
    "\n",
    "No WSL, o sistema de arquivos do Windows é montado em /mnt/c. Portanto, para navegar até o diretório c:\\.spacy no WSL, você pode mudar para o diretório com o seguinte comando no Terminal do WSL:\n",
    "\n",
    "Para que o comando import spacy funcione corretamente no WSL sem precisar reinstalar o spaCy, você deve colocar o link simbólico dentro do diretório onde o Python do WSL procura por pacotes instalados. Geralmente, esse diretório é:\n",
    "\n",
    "    /home/<seu_nome_de_usuario>/.local/lib/python<versão>/site-packages/\n",
    "\n",
    "Para criar um link simbólico no WSL no diretório adequado para apontar para o spaCy no Windows executamos o seguinte comando:\n",
    "\n",
    "Bash\n",
    "\n",
    "    ln -s /mnt/c/Users/<seu_nome_de_usuario>/.spacy /path/to/spacy/in/wsl\n",
    "    \n",
    "No meu caso aqui, para criar dentro do diretório do ambiente virtual que desejo usar o Spacy, por exemplo, ficou:\n",
    "\n",
    "    ln -s /mnt/c/.spacy /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages/spacy\n",
    "\n",
    "Para remover o link usar:\n",
    "\n",
    "    unlink /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages/spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import translate\n",
    "# def translate_pt_to_en(text):\n",
    "#     translate_client = translate.TranslationServiceClient()\n",
    "#     parent = \"projects/seu-projeto-id/locations/global\" \n",
    "#     response = translate_client.translate_text(\n",
    "#         request={\n",
    "#             \"parent\": parent,\n",
    "#             \"contents\": [text],\n",
    "#             \"mime_type\": \"text/plain\",\n",
    "#             \"source_language_code\": \"pt\",\n",
    "#             \"target_language_code\": \"en\",\n",
    "#         }\n",
    "#     )\n",
    "#     return response.translations[0].translated_text\n",
    "#\n",
    "# def translate_to_pt(text):\n",
    "#     translate_client = translate.TranslationServiceClient()\n",
    "#     parent = \"projects/seu-projeto-id/locations/global\"  # Substitua 'seu-projeto-id' pelo ID real do seu projeto\n",
    "#     response = translate_client.translate_text(\n",
    "#         request={\n",
    "#             \"parent\": parent,\n",
    "#             \"contents\": [text],\n",
    "#             \"mime_type\": \"text/plain\",\n",
    "#             \"target_language_code\": \"pt\",  # Traduzir para português\n",
    "#         }\n",
    "#     )\n",
    "#     return response.translations[0].translated_text\n",
    "\n",
    "    # # 0. Distribuição do número de palavras-chave por edital (neste caso é inútil pois montei com apenas uma palavra-chave)\n",
    "    # # Verificar valores únicos na coluna 'palavras-chave'\n",
    "    # print(df_fomento['palavras-chave'].unique().to_pandas()) \n",
    "\n",
    "    # # Normalizar caracteres Unicode e substituir valores especiais por NaN (on CPU)\n",
    "    # pd_series = df_fomento['palavras-chave'].to_pandas()\n",
    "    # pd_series = pd_series.astype(str).map(\n",
    "    #     lambda x: unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8')\n",
    "    # )\n",
    "    # pd_series = pd_series.str.replace(r'^\\s*$', '', regex=True) \n",
    "    # pd_series = pd_series.fillna('')\n",
    "\n",
    "    # # Aplicar str.split(',') e str.len() no Pandas\n",
    "    # pd_series_split = pd_series.str.split(',')\n",
    "    # pd_series_len = pd_series_split.str.len()\n",
    "\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # sns.histplot(pd_series_len, kde=True)  # Passar a Series do Pandas para o Seaborn\n",
    "    # plt.title('Distribuição do Número de Palavras-chave por Edital')\n",
    "    # plt.xlabel('Número de Palavras-chave')\n",
    "    # plt.ylabel('Frequência')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import time\n",
    "# import cudf\n",
    "# import nltk\n",
    "# import torch\n",
    "# import spacy\n",
    "# import string\n",
    "# import logging\n",
    "# import unicodedata\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import contextualSpellCheck\n",
    "\n",
    "# from transformers.tokenization_utils_base import TruncationStrategy\n",
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "# from transformers import pipeline, TranslationPipeline\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# from spacy.tokens import Doc, Token\n",
    "# from spacy.language import Language\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# from nltk.corpus import stopwords\n",
    "# from collections import Counter\n",
    "# from googletrans import Translator\n",
    "# from wordcloud import WordCloud\n",
    "# from langdetect import detect\n",
    "# from git import Repo\n",
    "# from tqdm.notebook import tqdm\n",
    "# tqdm.pandas()\n",
    "\n",
    "# def detect_language(text):\n",
    "#     try:\n",
    "#         return detect(text)\n",
    "#     except langdetect.lang_detect_exception.LangDetectException:\n",
    "#         return 'unknown'\n",
    "\n",
    "# def translate_to_pt(texts):\n",
    "#     try:\n",
    "#         # Tradução usando o modelo Hugging Face\n",
    "#         inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "#         outputs = model.generate(**inputs)\n",
    "#         translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "#         return translations\n",
    "#     except Exception as e:\n",
    "#         print(f\"Erro na tradução: {e}\")\n",
    "#         return texts\n",
    "\n",
    "# # Função de pré-processamento otimizada para GPU\n",
    "# def gpu_preprocess_text(text):\n",
    "#     # Carregar as stopwords em inglês\n",
    "#     stop_words_en = set(stopwords.words('english'))\n",
    "\n",
    "#     # Adicionar as stopwords personalizadas em inglês\n",
    "#     stop_words_en.update([\"must\", \"due\", \"track\", \"may\", \"non\", \"year\", \"apply\", \"prepare\", \"era\", \"eligibility\",\n",
    "#                           \"funded value\", \"deadline\", \"application form\", \"description\", \"homepage\", \"Name\",\n",
    "#                           \"address\", \"phone\", \"Fax\", \"e-mail\", \"email\", \"contact\", \"home page\", \"home\", \"page\"])\n",
    "\n",
    "#     # Traduzir o texto para português (se necessário) em lote\n",
    "#     try:\n",
    "#         # logging.info(\"Traduzindo texto para o português (se necessário)...\")\n",
    "#         text_translated = translate_to_pt([text])[0] if detect_language(text) != 'pt' else text\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Erro na tradução: {e}\")\n",
    "#         return []\n",
    "\n",
    "#     # Converter para minúsculas e remover pontuação\n",
    "#     # logging.info(\"Limpando e normalizando o texto...\")\n",
    "#     text_translated = text_translated.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "#     # Truncar o texto traduzido se for muito longo\n",
    "#     max_length = 512  # Ajuste conforme necessário\n",
    "#     text_translated = text_translated[:max_length]\n",
    "\n",
    "#     # Aplicar o corretor ortográfico e lematizar em inglês em lote (usando pipe do spaCy)\n",
    "#     # logging.info(\"Processando o texto com spaCy...\")\n",
    "#     with nlp_en.disable_pipes('ner'):  # Desabilitar NER para economizar memória da GPU\n",
    "#         docs = nlp_en.pipe([text_translated], batch_size=64) \n",
    "\n",
    "#     for doc in docs:\n",
    "#         words_en = [token.lemma_.lower() if token.text.lower() not in [\"institute\", \"institution\", \"institutional\"] else \"institution\"\n",
    "#                     for token in doc \n",
    "#                     if token.is_alpha and not token.is_stop and token.lemma_.lower() not in stop_words_en]\n",
    "\n",
    "#     return words_en  \n",
    "\n",
    "# # Configurar o logging (opcional)\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# # Load the transformer-based Portuguese and English models \n",
    "# nlp_pt = spacy.load(\"pt_core_news_sm\")  \n",
    "# nlp_en = spacy.load(\"en_core_web_trf\") \n",
    "\n",
    "# # Add the contextual spell checker to the English pipeline \n",
    "# contextualSpellCheck.add_to_pipe(nlp_en)\n",
    "\n",
    "# # Load the translation pipeline\n",
    "# translator = pipeline(\"translation\", model=\"unicamp-dl/translation-pt-en-t5\") \n",
    "\n",
    "# # Certifique-se de que `detect_language(text)` está definida em algum lugar do seu código\n",
    "# # Medir tempo para pré-processar (remover sw, traduzir para português, lematizar) sem cuGrpah mas já usando GPU\n",
    "# start_time = time.time()\n",
    "# # Aplicar a função de pré-processamento à coluna 'texto_para_embedding' em lotes, com barra de progresso\n",
    "# all_words = df_fomento['texto_para_embedding'].to_pandas().progress_apply(gpu_preprocess_text) \n",
    "# end_time = time.time()\n",
    "# time_com = end_time - start_time\n",
    "# print(f\"Tempos para pré-processar usando mais a GPU:\") \n",
    "# print(f\"Carregando o modelo diretamente na GPU: {time_com:>.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definir a função de pré-processamento \n",
    "# def br_preprocess_text(text):\n",
    "#     # Carregar as stopwords em português\n",
    "#     stop_words_pt = set(stopwords.words('portuguese'))\n",
    "\n",
    "#     # Adicionar as stopwords personalizadas em português\n",
    "#     stop_words_pt.update([\"deve\", \"devido\", \"acompanhar\", \"pode\", \"não\", \"ano\", \"aplicar\", \"preparar\", \"era\", \"elegibilidade\",\n",
    "#                        \"valorfinanciado\", \"datalimite\", \"formuláriodesolicitacao\", \"descrição\", \"homepage\", \"nome\",\n",
    "#                        \"endereço\", \"telefone\", \"fax\", \"e-mail\", \"contato\", \"home page\", \"casa\", \"página\"])\n",
    "\n",
    "#     # Traduzir o texto para português (se necessário)\n",
    "#     try:\n",
    "#         if detect_language(text) != 'pt':\n",
    "#             # logging.info(\"Traduzindo texto para o português...\")\n",
    "#             text_translated = translator(text, src_lang = \"auto\", tgt_lang=\"pt\")[0]['translation_text']\n",
    "#         else: \n",
    "#             text_translated = text \n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Erro na tradução: {e}\")\n",
    "#         return [] \n",
    "\n",
    "#     # Converter para minúsculas e remover pontuação\n",
    "#     # logging.info(\"Limpando e normalizando o texto...\")\n",
    "#     text_translated = text_translated.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "#     # Truncar o texto traduzido se for muito longo\n",
    "#     max_length = 512 \n",
    "#     text_translated = text_translated[:max_length]\n",
    "\n",
    "#     # Aplicar o corretor ortográfico (se disponível para português)\n",
    "#     # logging.info(\"Aplicando o corretor ortográfico...\")\n",
    "#     # doc_pt_spell_check = nlp_pt(text_translated)\n",
    "#     # text_corrected = doc_pt_spell_check._.outcome_spellCheck \n",
    "\n",
    "#     # Lematizar em português\n",
    "#     # logging.info(\"Lematizando o texto...\")\n",
    "#     doc_pt = nlp_pt(text_translated)\n",
    "#     words_pt = [token.lemma_.lower() \n",
    "#                 for token in doc_pt \n",
    "#                 if token.is_alpha and not token.is_stop and token.lemma_.lower() not in stop_words_pt \n",
    "#                 and not (token.pos_ == \"PROPN\" and token.text.lower() not in stop_words_pt)]\n",
    "\n",
    "#     return words_pt\n",
    "\n",
    "# # Configurar o logging (opcional)\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# # Carregar o modelo de tradução e o tokenizador do Hugging Face\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"unicamp-dl/translation-pt-en-t5\")\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"unicamp-dl/translation-pt-en-t5\")\n",
    "\n",
    "# # Move the Hugging Face model to the GPU\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# if device == 'cuda':\n",
    "#     print(f\"Caregando modelo para GPU...\")\n",
    "# else:\n",
    "#     print(f\"GPU indisponível, usando aoenas CPU...\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Load the transformer-based English model\n",
    "# nlp_en = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# # Add the contextual spell checker to the pipeline\n",
    "# contextualSpellCheck.add_to_pipe(nlp_en)\n",
    "\n",
    "# # Medir tempo para pré-processar (remocer sw, traduzir para português, lematizar) sem cuGrpah mas já usando GPU\n",
    "# start_time = time.time()\n",
    "# # Aplicar a função de pré-processamento à coluna 'texto_para_embedding' em lotes\n",
    "# all_words = df_fomento['texto_para_embedding'].to_pandas().apply(br_preprocess_text)\n",
    "# end_time = time.time()\n",
    "# time_sem = end_time - start_time\n",
    "# print(f\"Tempos para pré-processar usando GPU somente indiretamente:\") \n",
    "# print(f\"Sem carregar o modelo diretamente na GPU: {time_sem:>.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cudf\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import unicodedata\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import contextualSpellCheck\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from spacy.tokens import Doc, Token\n",
    "from spacy.language import Language\n",
    "# from googletrans import Translator\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from git import Repo\n",
    "import logging\n",
    "\n",
    "# Configurar o logging (opcional)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def translate_to_pt(text):\n",
    "#     translator = Translator()\n",
    "#     try:\n",
    "#         translation = translator.translate(text, dest='pt')\n",
    "#         return translation.text\n",
    "#     except Exception as e:\n",
    "#         print(f\"Erro na tradução: {e}\")\n",
    "#         return text \n",
    "\n",
    "# def translate_pt_to_en(text):\n",
    "#     translator = Translator()\n",
    "#     try:\n",
    "#         translation = translator.translate(text, src='pt', dest='en')\n",
    "#         return translation.text\n",
    "#     except Exception as e:\n",
    "#         print(f\"Erro na tradução: {e}\")\n",
    "#         return text\n",
    "\n",
    "# # Carregar os modelos de língua portuguesa e inglesa do spaCy\n",
    "# # nlp_pt = spacy.load('pt_core_news_sm')\n",
    "# # nlp_en = spacy.load('en_core_web_lg')\n",
    "\n",
    "# # Load the transformer-based English model\n",
    "# nlp_en = spacy.load(\"en_core_web_trf\") \n",
    "\n",
    "# # Add the contextual spell checker to the pipeline\n",
    "# contextualSpellCheck.add_to_pipe(nlp_en)\n",
    "\n",
    "# # Definir a função de pré-processamento (recebendo stop_words como argumento)\n",
    "# def cpu_preprocess_text(text):\n",
    "#     # Carregar as stopwords em inglês\n",
    "#     stop_words_en = set(stopwords.words('english'))\n",
    "\n",
    "#     # Adicionar as stopwords personalizadas em inglês\n",
    "#     stop_words_en.update([\"must\", \"due\", \"track\", \"may\", \"non\", \"year\", \"apply\", \"prepare\", \"era\", \"eligibility\",\n",
    "#                        \"funded value\", \"deadline\", \"application form\", \"description\", \"homepage\", \"Name\",\n",
    "#                        \"address\", \"phone\", \"Fax\", \"e-mail\", \"email\", \"contact\", \"home page\", \"home\", \"page\"])\n",
    "\n",
    "#     # Traduzir o texto de português para inglês\n",
    "#     try:\n",
    "#         logging.info(\"Pre-processar termos (traduzir para o inglês, corrigir ortografia e lematizar)...\")\n",
    "#         text_translated = translate_pt_to_en(text)\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Erro na tradução: {e}\")\n",
    "#         return []\n",
    "\n",
    "#     # Converter para minúsculas e remover pontuação\n",
    "#     text_translated = text_translated.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "#     # Truncate the translated text if it's too long\n",
    "#     max_length = 512  \n",
    "#     text_translated = text_translated[:max_length]\n",
    "\n",
    "#     # Aplicar o corretor ortográfico contextual\n",
    "#     doc_en_spell_check = nlp_en(text_translated)\n",
    "#     text_corrected = doc_en_spell_check._.outcome_spellCheck # Usando a extensão correta do contextualSpellCheck\n",
    "\n",
    "#     # Lematizar em inglês\n",
    "#     doc_en = nlp_en(text_corrected)\n",
    "#     words_en = [token.lemma_.lower() if token.text.lower() not in [\"institute\", \"institution\", \"institutional\"] else \"institution\"\n",
    "#                 for token in doc_en \n",
    "#                 if token.is_alpha and not token.is_stop and token.lemma_.lower() not in stop_words_en]\n",
    "\n",
    "#     return words_en\n",
    "\n",
    "# def analisar_dados_fomento(all_words):\n",
    "#     \"\"\"\n",
    "#     Realiza análises exploratórias nos dados de oportunidades de fomento.\n",
    "\n",
    "#     Args:\n",
    "#         arquivo_csv: Caminho para o arquivo CSV contendo os dados de fomento.\n",
    "#     \"\"\"\n",
    "#     # Contar a frequência das palavras\n",
    "#     word_counts = Counter(word for words in all_words for word in words)\n",
    "\n",
    "#     # Obter as palavras mais frequentes\n",
    "#     top_words = word_counts.most_common(20)\n",
    "\n",
    "#     # Plotar um gráfico de barras com as palavras mais frequentes\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.bar(*zip(*top_words))\n",
    "#     plt.title('Palavras Mais Frequentes (sem Stopwords e com Lematização)')\n",
    "#     plt.xlabel('Palavra')\n",
    "#     plt.ylabel('Frequência')\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.show()\n",
    "\n",
    "#     # Criar uma nuvem de palavras\n",
    "#     wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_counts)\n",
    "\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.imshow(wordcloud, interpolation='bilinear')\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "#     # 2. Visualização dos embeddings em 2D usando PCA\n",
    "#     pca = PCA(n_components=2)\n",
    "#     embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
    "#     plt.title('Visualização dos Embeddings (PCA)')\n",
    "#     plt.xlabel('Componente Principal 1')\n",
    "#     plt.ylabel('Componente Principal 2')\n",
    "#     plt.show()\n",
    "\n",
    "#     # 3. Visualização dos embeddings em 2D usando t-SNE\n",
    "#     tsne = TSNE(n_components=2, perplexity=30, learning_rate=200)\n",
    "#     embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
    "#     plt.title('Visualização dos Embeddings (t-SNE)')\n",
    "#     plt.xlabel('Dimensão 1')\n",
    "#     plt.ylabel('Dimensão 2')\n",
    "#     plt.show()\n",
    "\n",
    "# analisar_dados_fomento()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, HTML\n",
    "\n",
    "# def generate_mermaid_diagram_v0(model):\n",
    "#     \"\"\"\n",
    "#     Gera um diagrama Mermaid representando a estrutura de um modelo Hugging Face.\n",
    "\n",
    "#     Args:\n",
    "#         model: O modelo Hugging Face a ser analisado.\n",
    "\n",
    "#     Returns:\n",
    "#         Uma string contendo o código Mermaid para o diagrama.\n",
    "#     \"\"\"\n",
    "\n",
    "#     diagram = \"graph LR\\n\"\n",
    "\n",
    "#     # Adicionar o nó raiz representando o modelo\n",
    "#     diagram += f\"    {model.__class__.__name__}{{ {model.__class__.__name__} }}\\n\"\n",
    "\n",
    "#     # Função recursiva para percorrer a estrutura do modelo e adicionar nós e conexões ao diagrama\n",
    "#     def add_nodes_and_connections(module, parent_name=\"\"):\n",
    "#         nonlocal diagram\n",
    "#         for name, child_module in module.named_children():\n",
    "#             node_name = parent_name + \".\" + name if parent_name else name\n",
    "#             diagram += f\"    {node_name}{{ {child_module.__class__.__name__} }}\\n\"\n",
    "#             diagram += f\"    {parent_name} --> {node_name}\\n\"\n",
    "#             add_nodes_and_connections(child_module, node_name)\n",
    "\n",
    "#     # Chamar a função recursiva para construir o diagrama\n",
    "#     add_nodes_and_connections(model)\n",
    "\n",
    "#     return diagram\n",
    "\n",
    "# def generate_mermaid_diagram_v1(model):\n",
    "#     \"\"\"\n",
    "#     Generates a Mermaid diagram representing the structure of a Hugging Face model, \n",
    "#     collapsing repetitive layers.\n",
    "\n",
    "#     Args:\n",
    "#         model: The Hugging Face model to be analyzed.\n",
    "#     \"\"\"\n",
    "\n",
    "#     diagram = \"graph LR\\n\"\n",
    "#     prev_layer_type = None\n",
    "#     layer_count = 0\n",
    "\n",
    "#     # Add the root node representing the model\n",
    "#     diagram += f\"    {model.__class__.__name__}{{ {model.__class__.__name__} }}\\n\"\n",
    "\n",
    "#     # Recursive function to traverse the model structure and add nodes and connections to the diagram\n",
    "#     def add_nodes_and_connections(module, parent_name=\"\"):\n",
    "#         nonlocal diagram, prev_layer_type, layer_count\n",
    "#         for name, child_module in module.named_children():\n",
    "#             current_layer_type = child_module.__class__.__name__\n",
    "#             node_name = parent_name + \".\" + name if parent_name else name\n",
    "\n",
    "#             if current_layer_type == prev_layer_type:\n",
    "#                 layer_count += 1\n",
    "#             else:\n",
    "#                 if layer_count > 1:\n",
    "#                     diagram += f\"    {parent_name}.{prev_layer_type}_...(...):::same\\n\"  # Add ellipses for repetitive layers\n",
    "#                 prev_layer_type = current_layer_type\n",
    "#                 layer_count = 1\n",
    "#                 diagram += f\"    {node_name}{{ {current_layer_type} }}\\n\"\n",
    "#                 diagram += f\"    {parent_name} --> {node_name}\\n\"\n",
    "\n",
    "#             add_nodes_and_connections(child_module, node_name)\n",
    "\n",
    "#         # Handle remaining repetitive layers at the end of a module\n",
    "#         if layer_count > 1:\n",
    "#             diagram += f\"    {parent_name}.{prev_layer_type}_...(...):::same\\n\"\n",
    "\n",
    "#     # Call the recursive function to build the diagram\n",
    "#     add_nodes_and_connections(model)\n",
    "\n",
    "#     # # Encapsulate the Mermaid code in an HTML block for rendering in Jupyter Notebook\n",
    "#     # html_code = f\"\"\"\n",
    "#     # <div class=\"mermaid\">\n",
    "#     # {diagram}\n",
    "#     # </div>\n",
    "#     # \"\"\"\n",
    "\n",
    "#     # # Display the diagram in the Jupyter Notebook cell\n",
    "#     # display(HTML(html_code))\n",
    "\n",
    "#     return diagram\n",
    "\n",
    "# def generate_mermaid_diagram_v2(model):\n",
    "#     \"\"\"\n",
    "#     Generates a Mermaid diagram representing the structure of a Hugging Face model, \n",
    "#     collapsing repetitive layers into shapes.\n",
    "\n",
    "#     Args:\n",
    "#         model: The Hugging Face model to be analyzed.\n",
    "#     \"\"\"\n",
    "\n",
    "#     diagram = \"graph LR\\n\"\n",
    "#     prev_layer_type = None\n",
    "#     layer_count = 0\n",
    "#     shape_id = 0  # To keep track of unique shape IDs\n",
    "\n",
    "#     # Add the root node representing the model\n",
    "#     diagram += f\"    {model.__class__.__name__}{{ {model.__class__.__name__} }}\\n\"\n",
    "\n",
    "#     # Recursive function to traverse the model structure and add nodes and connections to the diagram\n",
    "#     def add_nodes_and_connections(module, parent_name=\"\"):\n",
    "#         nonlocal diagram, prev_layer_type, layer_count, shape_id\n",
    "#         for name, child_module in module.named_children():\n",
    "#             current_layer_type = child_module.__class__.__name__\n",
    "#             node_name = parent_name + \".\" + name if parent_name else name\n",
    "\n",
    "#             if current_layer_type == prev_layer_type:\n",
    "#                 layer_count += 1\n",
    "#             else:\n",
    "#                 if layer_count > 1:\n",
    "#                     # Create a shape to group repetitive layers\n",
    "#                     shape_id += 1\n",
    "#                     diagram += f\"    subgraph shape{shape_id} [{prev_layer_type} x {layer_count}]\\n\"\n",
    "#                     diagram += f\"        {parent_name}.{prev_layer_type}_0[\\\"{prev_layer_type} 0\\\"]\\n\"\n",
    "#                     diagram += f\"        {parent_name}.{prev_layer_type}_...[\\\" ... \\\"]\\n\"\n",
    "#                     diagram += f\"        {parent_name}.{prev_layer_type}_{layer_count - 1}[\\\"{prev_layer_type} {layer_count - 1}\\\"]\\n\"\n",
    "#                     diagram += \"    end\\n\"\n",
    "#                     diagram += f\"    {parent_name} --> shape{shape_id}\\n\"\n",
    "#                 else:\n",
    "#                     diagram += f\"    {node_name}{{ {current_layer_type} }}\\n\"\n",
    "#                     diagram += f\"    {parent_name} --> {node_name}\\n\"\n",
    "\n",
    "#                 prev_layer_type = current_layer_type\n",
    "#                 layer_count = 1\n",
    "\n",
    "#             add_nodes_and_connections(child_module, node_name)\n",
    "\n",
    "#         # Handle remaining repetitive layers at the end of a module\n",
    "#         if layer_count > 1:\n",
    "#             shape_id += 1\n",
    "#             diagram += f\"    subgraph shape{shape_id} [{prev_layer_type} x {layer_count}]\\n\"\n",
    "#             diagram += f\"        {parent_name}.{prev_layer_type}_0[\\\"{prev_layer_type} 0\\\"]\\n\"\n",
    "#             diagram += f\"        {parent_name}.{prev_layer_type}_...[\\\" ... \\\"]\\n\"\n",
    "#             diagram += f\"        {parent_name}.{prev_layer_type}_{layer_count - 1}[\\\"{prev_layer_type} {layer_count - 1}\\\"]\\n\"\n",
    "#             diagram += \"    end\\n\"\n",
    "#             diagram += f\"    {parent_name} --> shape{shape_id}\\n\"\n",
    "\n",
    "#     # Call the recursive function to build the diagram\n",
    "#     add_nodes_and_connections(model)\n",
    "\n",
    "#     # # Encapsulate the Mermaid code in an HTML block for rendering in Jupyter Notebook\n",
    "#     # html_code = f\"\"\"\n",
    "#     # <div class=\"mermaid\">\n",
    "#     # {diagram}\n",
    "#     # </div>\n",
    "#     # \"\"\"\n",
    "\n",
    "#     # # Display the diagram in the Jupyter Notebook cell\n",
    "#     # display(HTML(html_code))\n",
    "\n",
    "#     return diagram\n",
    "\n",
    "# def generate_mermaid_diagram_v3_4_5(model):\n",
    "#     \"\"\"\n",
    "#     Generates a Mermaid diagram representing the structure of a Hugging Face model, \n",
    "#     collapsing repetitive layers into shapes with numbered instances.\n",
    "\n",
    "#     Args:\n",
    "#         model: The Hugging Face model to be analyzed.\n",
    "#     \"\"\"\n",
    "\n",
    "#     diagram = \"graph LR\\n\"\n",
    "#     layer_counts = {}  # To keep track of layer counts for each type\n",
    "\n",
    "#     # Add the root node representing the model\n",
    "#     diagram += f\"    {model.__class__.__name__}{{ {model.__class__.__name__} }}\\n\"\n",
    "\n",
    "#     # Recursive function to traverse the model structure and add nodes and connections to the diagram\n",
    "#     def add_nodes_and_connections(module, parent_name=\"\"):\n",
    "#         nonlocal diagram, layer_counts\n",
    "#         for name, child_module in module.named_children():\n",
    "#             current_layer_type = child_module.__class__.__name__\n",
    "#             node_name = parent_name + \".\" + name if parent_name else name\n",
    "\n",
    "#             # Count occurrences of each layer type\n",
    "#             layer_counts[current_layer_type] = layer_counts.get(current_layer_type, 0) + 1\n",
    "\n",
    "#             # If this is the first occurrence of this layer type, add it to the diagram\n",
    "#             if layer_counts[current_layer_type] == 1:\n",
    "#                 diagram += f\"    {node_name}{{ {current_layer_type} }}\\n\"\n",
    "#                 diagram += f\"    {parent_name} --> {node_name}\\n\"\n",
    "\n",
    "#             add_nodes_and_connections(child_module, node_name)\n",
    "\n",
    "#     # Call the recursive function to build the diagram\n",
    "#     add_nodes_and_connections(model)\n",
    "\n",
    "#     # Add shapes for repetitive layers\n",
    "#     named_children = list(model.named_children())\n",
    "#     for layer_type, count in layer_counts.items():\n",
    "#         if count > 1:\n",
    "#             diagram += f\"    subgraph {layer_type}s [x{count}]\\n\"\n",
    "#             for i in range(count):\n",
    "#                 diagram += f\"        {layer_type}_{i}{{ {layer_type} {i} }}\\n\"\n",
    "#             diagram += \"    end\\n\"\n",
    "#             # Connect the parent to the first layer in the shape \n",
    "#             diagram += f\"    {model.__class__.__name__} --> {layer_type}_0\\n\"\n",
    "            \n",
    "#             # Connect the last layer to the subsequent component only if it exists\n",
    "#             if count < len(named_children):  # Check if there's a subsequent component\n",
    "#                 diagram += f\"    {layer_type}_{count - 1} --> {named_children[count][0]}\\n\"\n",
    "\n",
    "#     # # Encapsulate the Mermaid code in an HTML block for rendering in Jupyter Notebook\n",
    "#     # html_code = f\"\"\"\n",
    "#     # <div class=\"mermaid\">\n",
    "#     # {diagram}\n",
    "#     # </div>\n",
    "#     # \"\"\"\n",
    "\n",
    "#     # # Display the diagram in the Jupyter Notebook cell\n",
    "#     # display(HTML(html_code))\n",
    "\n",
    "#     return diagram\n",
    "\n",
    "# from IPython.display import display, HTML\n",
    "\n",
    "# def generate_mermaid_diagram(model):\n",
    "#     \"\"\"\n",
    "#     Generates a Mermaid diagram representing the structure of a Hugging Face model, \n",
    "#     collapsing repetitive layers into shapes with layer count and using rounded rectangles for internal layers.\n",
    "\n",
    "#     Args:\n",
    "#         model: The Hugging Face model to be analyzed.\n",
    "#     \"\"\"\n",
    "\n",
    "#     diagram = \"graph LR\\n\"\n",
    "#     layer_counts = {}\n",
    "\n",
    "#     # Add the root node representing the model\n",
    "#     diagram += f\"    {model.__class__.__name__}{{ {model.__class__.__name__} }}\\n\"\n",
    "\n",
    "#     # Recursive function to traverse the model structure \n",
    "#     def add_nodes_and_connections(module, parent_name=\"\"):\n",
    "#         nonlocal diagram, layer_counts\n",
    "#         for name, child_module in module.named_children():\n",
    "#             current_layer_type = child_module.__class__.__name__\n",
    "#             node_name = parent_name + \".\" + name if parent_name else name\n",
    "\n",
    "#             layer_counts[current_layer_type] = layer_counts.get(current_layer_type, 0) + 1\n",
    "\n",
    "#             if layer_counts[current_layer_type] == 1:\n",
    "#                 # Use rounded rectangle for single occurrences or non-repetitive layers\n",
    "#                 diagram += f\"    {node_name}(( {current_layer_type} ))\\n\"\n",
    "#                 diagram += f\"    {parent_name} --> {node_name}\\n\"\n",
    "\n",
    "#             add_nodes_and_connections(child_module, node_name)\n",
    "\n",
    "#     add_nodes_and_connections(model)\n",
    "\n",
    "#     # Add shapes for repetitive layers with count and rounded rectangles for internal layers\n",
    "#     named_children = list(model.named_children())\n",
    "#     for layer_type, count in layer_counts.items():\n",
    "#         if count > 1:\n",
    "#             diagram += f\"    subgraph {layer_type}s\\n\"\n",
    "#             diagram += f\"        {layer_type}x{count}[\\\"{count} x {layer_type}\\\"]\\n\"  \n",
    "#             diagram += \"    end\\n\"\n",
    "#             diagram += f\"    {model.__class__.__name__} --> {layer_type}s\\n\"\n",
    "            \n",
    "#             if count < len(named_children): \n",
    "#                 diagram += f\"    {layer_type}s --> {named_children[count][0]}\\n\"\n",
    "\n",
    "#     # # Encapsulate the Mermaid code in an HTML block for rendering in Jupyter Notebook\n",
    "#     # html_code = f\"\"\"\n",
    "#     # <div class=\"mermaid\">\n",
    "#     # {diagram}\n",
    "#     # </div>\n",
    "#     # \"\"\"\n",
    "\n",
    "#     # # Display the diagram in the Jupyter Notebook cell\n",
    "#     # display(HTML(html_code))\n",
    "    \n",
    "#     return diagram\n",
    "\n",
    "# from IPython.display import display, HTML\n",
    "\n",
    "# def generate_mermaid_diagram(model):\n",
    "#     \"\"\"\n",
    "#     Generates a Mermaid diagram representing the structure of a Hugging Face model,\n",
    "#     collapsing repetitive layers into shapes with layer count and using rounded\n",
    "#     rectangles for internal layers.\n",
    "\n",
    "#     Args:\n",
    "#         model: The Hugging Face model to be analyzed.\n",
    "#     \"\"\"\n",
    "\n",
    "#     diagram = \"graph LR\\n\"\n",
    "#     layer_counts = {}\n",
    "\n",
    "#     # Add the root node representing the model\n",
    "#     diagram += f\"    {model.__class__.__name__}{{ {model.__class__.__name__} }}\\n\"\n",
    "\n",
    "#     # Recursive function to traverse the model structure\n",
    "#     def add_nodes_and_connections(module, parent_name=\"\"):\n",
    "#         nonlocal diagram, layer_counts\n",
    "#         for name, child_module in module.named_children():\n",
    "#             current_layer_type = child_module.__class__.__name__\n",
    "#             node_name = parent_name + \".\" + name if parent_name else name\n",
    "\n",
    "#             layer_counts[current_layer_type] = layer_counts.get(current_layer_type, 0) + 1\n",
    "\n",
    "#             if layer_counts[current_layer_type] == 1:\n",
    "#                 # Use rounded rectangle for single occurrences or non-repetitive layers\n",
    "#                 diagram += f\"    {node_name}{ (current_layer_type) }\\n\"\n",
    "#                 diagram += f\"    {parent_name} --> {node_name}\\n\"\n",
    "\n",
    "#             add_nodes_and_connections(child_module, node_name)\n",
    "\n",
    "#     add_nodes_and_connections(model)\n",
    "\n",
    "#     # Add shapes for repetitive layers with count and rounded rectangles for internal layers\n",
    "#     named_children = list(model.named_children())\n",
    "#     for layer_type, count in layer_counts.items():\n",
    "#         if count > 1:\n",
    "#             diagram += f\"    subgraph {layer_type}s\\n\"\n",
    "#             diagram += f\"        {layer_type}x{count}[\\\"{count} x {layer_type}\\\"]\\n\"  \n",
    "#             diagram += \"    end\\n\"\n",
    "#             diagram += f\"    {model.__class__.__name__} --> {layer_type}s\\n\"\n",
    "\n",
    "#             # Connect the shape to the subsequent component if it's not the last child\n",
    "#             if count < len(named_children): \n",
    "#                 diagram += f\"    {layer_type}s --> {named_children[count][0]}\\n\"\n",
    "\n",
    "#     # # Encapsulate the Mermaid code in an HTML block for rendering in Jupyter Notebook\n",
    "#     # html_code = f\"\"\"\n",
    "#     # <div class=\"mermaid\">\n",
    "#     # {diagram}\n",
    "#     # </div>\n",
    "#     # \"\"\"\n",
    "\n",
    "#     # # Display the diagram in the Jupyter Notebook cell\n",
    "#     # display(HTML(html_code))\n",
    "\n",
    "#     return diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versões antigas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from git import Repo\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# from gml_unsupervised_learning_tools import DataPreprocessor\n",
    "# from gml_unsupervised_learning_tools import EmbeddingEvaluator\n",
    "# from funding_analyser import FundingEmbeddingGenerator\n",
    "\n",
    "# # Criar uma instância do FundingEmbeddingGenerator\n",
    "# embedding_generator = FundingEmbeddingGenerator()\n",
    "\n",
    "# try:\n",
    "#     # Criar a coluna 'texto_para_embedding' no dataframe df_fomento usando cuDF (se disponível)\n",
    "#     df_fomento = embedding_generator.create_embedding_column(use_cudf=True)\n",
    "# except:\n",
    "#     # Ou, criar a coluna 'texto_para_embedding' sem usar cuDF, usando apenas Pandas\n",
    "#     df_fomento = embedding_generator.create_embedding_column(use_cudf=False)\n",
    "\n",
    "# # Define the model names and the models you want to compare\n",
    "# model_names = [\n",
    "#     'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "#     'all-MiniLM-L6-v2'\n",
    "#     # Add more model names here if needed\n",
    "# ]\n",
    "\n",
    "# models = [\n",
    "#     SentenceTransformer(model_name)\n",
    "#     for model_name in model_names\n",
    "# ]\n",
    "\n",
    "# # Create an instance of EmbeddingEvaluator\n",
    "# benchmark = EmbeddingEvaluator(model_names, models, df_fomento) \n",
    "\n",
    "# # Gere o relatório de benchmarking\n",
    "# benchmark.generate_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking de pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, cudf\n",
    "from funding_analyser import FundingEmbeddingGenerator\n",
    "\n",
    "df_fomento = pd.DataFrame()\n",
    "\n",
    "# Criar uma instância do EmbeddingGenerator\n",
    "embedding_generator = FundingEmbeddingGenerator()\n",
    "\n",
    "# Criar a coluna 'texto_para_embedding' no dataframe df_fomento usando cuDF (se disponível)\n",
    "try:\n",
    "    df_fomento = embedding_generator.create_embedding_column(use_cudf=True)\n",
    "except:\n",
    "    # Ou, criar a coluna 'texto_para_embedding' sem usar cuDF, usando apenas Pandas\n",
    "    df_fomento = embedding_generator.create_embedding_column(use_cudf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funding_analyser import ENPreprocessor\n",
    "\n",
    "# Criar instâncias do pré-processador\n",
    "en_preprocessor = ENPreprocessor()\n",
    "\n",
    "# Medir tempo pré-processar em lotes (remover sw, traduzir p/inglês, corrigir ortografia e lematizar)\n",
    "start_time = time.time()\n",
    "all_words_en = df_fomento['texto_para_embedding'].to_pandas().progress_apply(en_preprocessor.preprocess_text)  # type: ignore\n",
    "end_time = time.time()\n",
    "time_en = end_time - start_time\n",
    "print(f\"Tempo de execução da função en_preprocessor: {time_en:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funding_analyser import BRPreprocessor\n",
    "\n",
    "# Criar instância do pré-processador\n",
    "br_preprocessor = BRPreprocessor()\n",
    "\n",
    "# Medir tempo para pré-processar sem usar processamento em lotes (remover sw, traduzir p/português, lematizar)\n",
    "start_time = time.time()\n",
    "all_words_br = df_fomento['texto_para_embedding'].to_pandas().progress_apply(br_preprocessor.preprocess_text) # type: ignore\n",
    "end_time = time.time()\n",
    "time_br = end_time - start_time\n",
    "print(f\"Tempo de execução da função br_preprocess_text: {time_br:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in all_words_en[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in all_words_br[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking de geração de embeedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarking - Geração de embeddings sem batches\n",
    "start_time = time.time()\n",
    "embeddings_sem_batch = embedding_generator.generate_embeddings(df_fomento)\n",
    "end_time = time.time()\n",
    "tempo_sem_batch = end_time - start_time\n",
    "print(f\"Tempo de execução sem batches: {tempo_sem_batch:.2f} segundos\")\n",
    "\n",
    "# Benchmarking - Geração de embeddings com batches\n",
    "start_time = time.time()\n",
    "embeddings_com_batch = embedding_generator.generate_embeddings_batch(df_fomento)\n",
    "end_time = time.time()\n",
    "tempo_com_batch = end_time - start_time\n",
    "print(f\"Tempo de execução com batches: {tempo_com_batch:.2f} segundos\")\n",
    "\n",
    "# Comparar os resultados (opcional)\n",
    "if np.allclose(embeddings_sem_batch, embeddings_com_batch):\n",
    "    print(\"Os embeddings gerados são iguais.\")\n",
    "else:\n",
    "    print(\"Os embeddings gerados são diferentes. Verifique a implementação.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medir tempo de execução da função original\n",
    "start_time = time.time()\n",
    "all_words_original = df_fomento['texto_para_embedding'].to_pandas().apply(cpu_preprocess_text) # type: ignore\n",
    "original_time = time.time() - start_time\n",
    "print(f\"Tempo de execução da função original: {original_time} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medir tempo de execução da função otimizada\n",
    "start_time = time.time()\n",
    "all_words_optimized = df_fomento['texto_para_embedding'].to_pandas().apply(gpu_preprocess_text) # type: ignore\n",
    "optimized_time = time.time() - start_time\n",
    "print(f\"Tempo de execução da função otimizada: {optimized_time} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# 1. Carregar o dataframe df_fomento (carregado e processado anteriormente)\n",
    "df_fomento = pdf\n",
    "\n",
    "# 2. Criar um grafo vazio\n",
    "G = nx.Graph()\n",
    "\n",
    "# 3. Obter todas as chaves únicas\n",
    "all_keys = set()\n",
    "for keys in df_fomento['detalhes'].map(lambda x: x.keys()):\n",
    "    all_keys.update(keys)\n",
    "\n",
    "# 4. Iterar sobre as linhas do dataframe\n",
    "for index, row in df_fomento.iterrows():\n",
    "    # 5. Criar um nó com o índice da linha como ID\n",
    "    G.add_node(index)\n",
    "\n",
    "    # 6. Adicionar as propriedades do dicionário ao nó\n",
    "    for key in all_keys:\n",
    "        G.nodes[index][key] = row['detalhes'].get(key, None)  # Usar None para chaves ausentes\n",
    "\n",
    "# 7. Exibir informações sobre o grafo\n",
    "print(\"Número de nós:\", G.number_of_nodes())\n",
    "print(\"Número de arestas:\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fomento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Converter a coluna 'detalhes' para dicionários\n",
    "def convert_to_dict(text):\n",
    "    try:\n",
    "        return ast.literal_eval(text)\n",
    "    except ValueError:\n",
    "        return None  # Ou {} se preferir um dicionário vazio para entradas inválidas\n",
    "\n",
    "df_fomento['detalhes'] = df_fomento['detalhes'].astype(str).apply(convert_to_dict)\n",
    "\n",
    "# 3. Criar um grafo vazio\n",
    "G = nx.Graph()\n",
    "\n",
    "# 4. Obter todas as chaves únicas\n",
    "all_keys = set()\n",
    "for detalhes in df_fomento['detalhes']:\n",
    "    if detalhes:  # Verificar se detalhes é um dicionário válido\n",
    "        all_keys.update(detalhes.keys())\n",
    "\n",
    "# 5-8. Iterar, criar nós e adicionar propriedades\n",
    "for index, row in df_fomento.iterrows():\n",
    "    detalhes = row['detalhes']\n",
    "    G.add_node(index)\n",
    "    for key in all_keys:\n",
    "        G.nodes[index][key] = detalhes.get(key, None)\n",
    "\n",
    "# 9. Exibir informações sobre o grafo\n",
    "print(\"Número de nós:\", G.number_of_nodes())\n",
    "print(\"Número de arestas:\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fomento.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[y for y in x.keys()] for x in df_fomento['detalhes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fomento.iloc[0]['financiadora']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "cols_geninfo = ['financiadora','titulo','palavras-chave']\n",
    "cols_details = ['elegibilidade','descricao','valorfinanciado','datalimite']\n",
    "cols_moreinf = ['formasolicitacao']\n",
    "id=1\n",
    "w = 125\n",
    "\n",
    "for id,_ in enumerate(df_fomento.index):\n",
    "    print('-'*125)\n",
    "    print(f\"{cols_geninfo[-1].upper():>15}: {df_fomento.iloc[id][cols_geninfo[-1]].upper()} | {df_fomento.iloc[id][cols_geninfo[0]]}\")\n",
    "    for j in cols_details:\n",
    "        print(f\"{j.upper():>15}: {df_fomento['detalhes'][id][j]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in df_fomento['detalhes'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fomento['detalhes'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Analisar dos dados de fomento - fase exploratória</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similaridade semântica por similaridade de cossenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "from cuml.cluster import KMeans, DBSCAN, HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import networkx as nx\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "from scipy.spatial.distance import cosine\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def cosine_similarity_torch(a, b):\n",
    "  \"\"\"\n",
    "  Calcula a similaridade cosseno entre dois tensores a e b.\n",
    "\n",
    "  Args:\n",
    "      a: Primeiro tensor (torch.Tensor).\n",
    "      b: Segundo tensor (torch.Tensor).\n",
    "\n",
    "  Returns:\n",
    "      A similaridade cosseno entre os tensores a e b (um tensor com um único valor entre 0 e 1).\n",
    "  \"\"\"\n",
    "  return 1 - F.cosine_similarity(a, b, dim=0)\n",
    "\n",
    "def cosine_similarity_array(a, b):\n",
    "  \"\"\"\n",
    "  Calcula a similaridade cosseno entre dois vetores a e b.\n",
    "\n",
    "  Args:\n",
    "      a: Primeiro vetor (numpy array).\n",
    "      b: Segundo vetor (numpy array).\n",
    "\n",
    "  Returns:\n",
    "      A similaridade cosseno entre os vetores a e b (um valor entre 0 e 1).\n",
    "  \"\"\"\n",
    "  return 1 - cosine(a, b)\n",
    "\n",
    "# Criar nova coluna 'texto_para_embedding' combinando as informações desejadas\n",
    "def extrair_texto_para_embedding(row):\n",
    "    detalhes = row['detalhes']\n",
    "    texto = \"\"\n",
    "    if detalhes:\n",
    "        texto += detalhes.get('elegibilidade', '') + ' ' + detalhes.get('descricao', '')\n",
    "    texto += ' ' + row['palavras-chave']\n",
    "    return texto\n",
    "\n",
    "# Carregar o dataframe df_fomento (carregado e processado anteriormente)\n",
    "df_fomento = pdf\n",
    "\n",
    "# Preparar Dados\n",
    "model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2').to('cuda')\n",
    "\n",
    "# Combinar informações relevantes em um único texto\n",
    "df_fomento['texto_para_embedding'] = df_fomento.apply(extrair_texto_para_embedding, axis=1)\n",
    "\n",
    "# Gerar embeddings de texto na GPU\n",
    "embeddings = model.encode(df_fomento['texto_para_embedding'].tolist(), convert_to_tensor=True, device='cuda')\n",
    "embeddings = embeddings.cpu().numpy()\n",
    "\n",
    "# Função para calcular a similaridade cosseno\n",
    "def cosine_similarity(a, b):\n",
    "    return 1 - cosine(a, b)\n",
    "\n",
    "# Benchmark e Agrupamento em Comunidades\n",
    "algorithms = {\n",
    "    'KMeans': KMeans(n_clusters=5, init='k-means++', random_state=42),\n",
    "    'DBSCAN': DBSCAN(eps=0.5, min_samples=5),\n",
    "    'HDBSCAN': HDBSCAN(min_cluster_size=5, min_samples=2)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, algorithm in algorithms.items():\n",
    "    start_time = time.time()\n",
    "    clusters = algorithm.fit_predict(embeddings)\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    # Criar Arestas no Grafo (dentro do loop para cada algoritmo)\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Obter todas as chaves únicas dos dicionários em 'detalhes'\n",
    "    all_keys = set()\n",
    "    for detalhes in df_fomento['detalhes']:\n",
    "        if detalhes:\n",
    "            all_keys.update(detalhes.keys())\n",
    "\n",
    "    similarity_threshold = 0.7\n",
    "\n",
    "    # Adicionar nós e arestas ao grafo\n",
    "    for i in range(len(embeddings)):\n",
    "        # Criar um nó com o índice da linha como ID e adicionar as propriedades do dicionário\n",
    "        G.add_node(i, **df_fomento.iloc[i]['detalhes'])\n",
    "\n",
    "        for j in range(i + 1, len(embeddings)):\n",
    "            if clusters[i] == clusters[j]:\n",
    "                similarity = cosine_similarity(embeddings[i], embeddings[j])\n",
    "                if similarity > similarity_threshold:\n",
    "                    G.add_edge(i, j, weight=similarity)\n",
    "\n",
    "    # Calcular métricas de avaliação\n",
    "    partition = {node: cluster for node, cluster in enumerate(clusters)}\n",
    "\n",
    "    # Converter clusters escalares em listas\n",
    "    communities = [[c] if isinstance(c, np.int32) else c for c in partition.values()] # type: ignore\n",
    "\n",
    "    # Remover clusters vazios\n",
    "    communities = [c for c in communities if c]\n",
    "\n",
    "    # Verificar se 'communities' é uma partição válida antes de calcular a modularidade\n",
    "    if nx.algorithms.community.is_partition(G, communities):\n",
    "        modularity = nx.algorithms.community.modularity(G, communities)\n",
    "    else:\n",
    "        print(f\"Aviso: {name} gerou uma partição inválida. Modularidade não será calculada.\")\n",
    "        modularity = None  # Ou outro valor padrão, como 0 ou -1\n",
    "\n",
    "    results[name] = {\n",
    "        'execution_time': execution_time,\n",
    "        'modularity': modularity,\n",
    "    }\n",
    "\n",
    "# Plotar Resultados\n",
    "fig = go.Figure()\n",
    "for name, result in results.items():\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[name],\n",
    "        y=[result['execution_time']],\n",
    "        text=[f\"Tempo: {result['execution_time']:.2f}s<br>Modularidade: {result['modularity']:.3f}\"],\n",
    "        textposition='auto',\n",
    "        name=name\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Benchmark de Algoritmos de Agrupamento',\n",
    "    xaxis_title='Algoritmo',\n",
    "    yaxis_title='Tempo de Execução (segundos)'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medir tempo para calcular Pagerank\n",
    "# We now have data as edge pairs\n",
    "# create a Graph using the source (src) and destination (dst) vertex pairs\n",
    "# G = cugraph.Graph()\n",
    "# G.from_cudf_edgelist(gdf, source='src', destination='dst')\n",
    "\n",
    "# # Let's now get the PageRank score of each vertex by calling cugraph.pagerank\n",
    "# df_page = cugraph.pagerank(G)\n",
    "\n",
    "# # Let's look at the top 10 PageRank Score\n",
    "# df_page.sort_values('pagerank', ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
