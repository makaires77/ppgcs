{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interação Inteligente para PDI de tecnologias para o CEIS/SUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O spaCy separa os modelos de linguagem dos seus componentes principais para permitir uma instalação mais flexível e eficiente. Após a instalação da biblioteca SpaCy no seu ambiente atual, para instalar os modelos específicos que deseja usar para cada idioma executar o comando a seguir para baixar e instalar o modelo 'pt_core_news_lg' no seu ambiente atual:\n",
    "\n",
    "    python -m spacy download pt_core_news_lg \n",
    "\n",
    "O spaCy oferece outros modelos em português, como o 'pt_core_news_sm' (menor e mais rápido) e modelos treinados com transformers (pt_core_news_trf). Você pode explorar esses modelos se precisar de diferentes recursos ou tamanhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt-core-news-lg==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.7.0/pt_core_news_lg-3.7.0-py3-none-any.whl (568.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.2/568.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from pt-core-news-lg==3.7.0) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.12.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (72.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-lg==3.7.0) (0.1.2)\n",
      "Installing collected packages: pt-core-news-lg\n",
      "Successfully installed pt-core-news-lg-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "# %pip install neo4j\n",
    "# %pip show spacy\n",
    "!python -m spacy download pt_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;1m✘ No compatible package found for 'pt_core_news_trf' (spaCy v3.7.5)\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt_core_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def mapear_elementos_modulo(nome_arquivo):\n",
    "    \"\"\"\n",
    "    Mapeia e imprime as classes, métodos e funções dentro de um arquivo Python.\n",
    "\n",
    "    Args:\n",
    "        nome_arquivo: O nome do arquivo .py a ser analisado.\n",
    "    \"\"\"\n",
    "\n",
    "    # Importar o módulo dinamicamente\n",
    "    modulo = __import__(nome_arquivo.replace(\".py\", \"\"))\n",
    "\n",
    "    # Obter todos os membros do módulo\n",
    "    membros = inspect.getmembers(modulo)\n",
    "\n",
    "    # Filtrar e imprimir classes, métodos e funções\n",
    "    for nome, elemento in membros:\n",
    "        if inspect.isclass(elemento):\n",
    "            print(f\"Classe: {nome}\")\n",
    "            for nome_metodo, metodo in inspect.getmembers(elemento, inspect.isfunction):\n",
    "                if nome_metodo.startswith(\"__\"):  # Ignorar métodos especiais\n",
    "                    continue\n",
    "                print(f\"  Método: {nome_metodo}\")\n",
    "        elif inspect.isfunction(elemento):\n",
    "            if nome.startswith(\"__\"):  # Ignorar funções especiais\n",
    "                continue\n",
    "            print(f\"Função: {nome}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe: AnaliseGrafo\n",
      "  Método: analisar_distribuicao_graus\n",
      "  Método: calcular_densidade_grafo\n",
      "  Método: visualizar_distribuicao_graus\n",
      "Classe: ExplosaoSubgrafos\n",
      "  Método: apresentar_subgrafo\n",
      "  Método: recuperar_subgrafo\n",
      "Classe: FontesDados\n",
      "  Método: consultar_fontes\n",
      "Classe: GraphDatabase\n",
      "Classe: InteracaoUsuario\n",
      "  Método: gerar_consulta_neo4j\n",
      "  Método: interagir_com_pesquisador\n",
      "Classe: MapeamentoEntidades\n",
      "  Método: mapear_entidades\n",
      "  Método: mapear_entidades_gpu\n",
      "  Método: sugerir_novas_entidades\n",
      "  Método: sugerir_novas_entidades_gpu\n",
      "Classe: ProcessamentoLinguagemNatural\n",
      "  Método: processar_questao_pesquisa\n",
      "Classe: RecomendacaoProjetos\n",
      "  Método: recomendar_projetos\n",
      "Classe: SentenceTransformer\n",
      "  Método: _apply\n",
      "  Método: _call_impl\n",
      "  Método: _create_model_card\n",
      "  Método: _encode_multi_process_worker\n",
      "  Método: _eval_during_training\n",
      "  Método: _first_module\n",
      "  Método: _get_backward_hooks\n",
      "  Método: _get_backward_pre_hooks\n",
      "  Método: _get_item_by_idx\n",
      "  Método: _get_name\n",
      "  Método: _get_scheduler\n",
      "  Método: _last_module\n",
      "  Método: _load_auto_model\n",
      "  Método: _load_from_state_dict\n",
      "  Método: _load_sbert_model\n",
      "  Método: _maybe_warn_non_full_backward_hook\n",
      "  Método: _named_members\n",
      "  Método: _register_load_state_dict_pre_hook\n",
      "  Método: _register_state_dict_hook\n",
      "  Método: _replicate_for_data_parallel\n",
      "  Método: _save_checkpoint\n",
      "  Método: _save_to_state_dict\n",
      "  Método: _slow_forward\n",
      "  Método: _text_length\n",
      "  Método: _wrapped_call_impl\n",
      "  Método: add_module\n",
      "  Método: append\n",
      "  Método: apply\n",
      "  Método: bfloat16\n",
      "  Método: buffers\n",
      "  Método: children\n",
      "  Método: compile\n",
      "  Método: cpu\n",
      "  Método: cuda\n",
      "  Método: double\n",
      "  Método: encode\n",
      "  Método: encode_multi_process\n",
      "  Método: eval\n",
      "  Método: evaluate\n",
      "  Método: extend\n",
      "  Método: extra_repr\n",
      "  Método: fit\n",
      "  Método: float\n",
      "  Método: forward\n",
      "  Método: get_buffer\n",
      "  Método: get_extra_state\n",
      "  Método: get_max_seq_length\n",
      "  Método: get_parameter\n",
      "  Método: get_sentence_embedding_dimension\n",
      "  Método: get_sentence_features\n",
      "  Método: get_submodule\n",
      "  Método: gradient_checkpointing_enable\n",
      "  Método: half\n",
      "  Método: insert\n",
      "  Método: ipu\n",
      "  Método: load\n",
      "  Método: load_state_dict\n",
      "  Método: modules\n",
      "  Método: mtia\n",
      "  Método: named_buffers\n",
      "  Método: named_children\n",
      "  Método: named_modules\n",
      "  Método: named_parameters\n",
      "  Método: old_fit\n",
      "  Método: parameters\n",
      "  Método: pop\n",
      "  Método: push_to_hub\n",
      "  Método: register_backward_hook\n",
      "  Método: register_buffer\n",
      "  Método: register_forward_hook\n",
      "  Método: register_forward_pre_hook\n",
      "  Método: register_full_backward_hook\n",
      "  Método: register_full_backward_pre_hook\n",
      "  Método: register_load_state_dict_post_hook\n",
      "  Método: register_load_state_dict_pre_hook\n",
      "  Método: register_module\n",
      "  Método: register_parameter\n",
      "  Método: register_state_dict_post_hook\n",
      "  Método: register_state_dict_pre_hook\n",
      "  Método: requires_grad_\n",
      "  Método: save\n",
      "  Método: save_pretrained\n",
      "  Método: save_to_hub\n",
      "  Método: set_extra_state\n",
      "  Método: set_pooling_include_prompt\n",
      "  Método: set_submodule\n",
      "  Método: share_memory\n",
      "  Método: smart_batching_collate\n",
      "  Método: start_multi_process_pool\n",
      "  Método: state_dict\n",
      "  Método: stop_multi_process_pool\n",
      "  Método: to\n",
      "  Método: to_empty\n",
      "  Método: tokenize\n",
      "  Método: train\n",
      "  Método: truncate_sentence_embeddings\n",
      "  Método: type\n",
      "  Método: xpu\n",
      "  Método: zero_grad\n",
      "Função: r2_score\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "nome_arquivo = \"analisar_pdi_ceis_sus_grafo.py\"\n",
    "mapear_elementos_modulo(nome_arquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrair entidades e relacionamentos de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from tika import parser  # Para extrair texto de PDFs\n",
    "from bs4 import BeautifulSoup  # Para analisar HTML\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Conectar ao banco de dados Neo4j\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))\n",
    "\n",
    "# Carregar o JSON\n",
    "with open(\"dados_pesquisa_biotecnologia.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Criar nós e relacionamentos no Neo4j\n",
    "with driver.session() as session:\n",
    "    for node in data[\"nodes\"]:\n",
    "        session.run(\n",
    "            \"CREATE (n:%s {name: $name, legislação: $legislação})\" % node[\"label\"],\n",
    "            **node[\"properties\"]\n",
    "        )\n",
    "\n",
    "    for relationship in data[\"relationships\"]:\n",
    "        session.run(\n",
    "            \"MATCH (s {name: $source_name}), (t {name: $target_name}) \"\n",
    "            \"CREATE (s)-[:%s]->(t)\" % relationship[\"type\"],\n",
    "            source_name=relationship[\"source\"],\n",
    "            target_name=relationship[\"target\"]\n",
    "        )\n",
    "\n",
    "driver.close()\n",
    "\n",
    "# Carregar o modelo de linguagem português do spaCy (certificar antes que o modelo já está instalado para funcionar)\n",
    "nlp = spacy.load(\"pt_core_news_lg\") \n",
    "\n",
    "def extrair_informacoes_documento(caminho_documento):\n",
    "    \"\"\"\n",
    "    Extrai informações de um documento em HTML ou PDF e retorna um dicionário com entidades e relacionamentos.\n",
    "    Limitado inicialmente no MVP para sujeitos e objetos diretos mediados por verbos\n",
    "    \"\"\"\n",
    "\n",
    "    # Extrair o texto do documento (adapte para outros formatos se necessário)\n",
    "    if caminho_documento.endswith(\".pdf\"):\n",
    "        raw_text = parser.from_file(caminho_documento)[\"content\"]\n",
    "    elif caminho_documento.endswith(\".html\"):\n",
    "        with open(caminho_documento, \"r\", encoding=\"utf-8\") as f:\n",
    "            html_content = f.read()\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        raw_text = soup.get_text()\n",
    "    else:\n",
    "        raise ValueError(\"Formato de arquivo não suportado\")\n",
    "\n",
    "    # Processar o texto com spaCy\n",
    "    doc = nlp(raw_text)\n",
    "\n",
    "    # Extrair entidades e relacionamentos (adaptar regras de acordo com o tipo de documento)\n",
    "    entidades = []\n",
    "    relacionamentos = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        # Identificar possíveis atividades e documentos\n",
    "        for token in sent:\n",
    "            if token.pos_ == \"NOUN\" and token.dep_ in [\"nsubj\", \"dobj\"]:  # sujeito ou objeto direto\n",
    "                entidades.append({\"id\": token.text, \"label\": \"Atividade\" if token.dep_ == \"nsubj\" else \"Documento\"})\n",
    "\n",
    "        # Identificar possíveis relacionamentos entre atividades e documentos\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"ROOT\" and token.head.pos_ == \"VERB\":  # verbo principal da frase\n",
    "                sujeito = [child for child in token.children if child.dep_ == \"nsubj\"]\n",
    "                objeto = [child for child in token.children if child.dep_ == \"dobj\"]\n",
    "                if sujeito and objeto:\n",
    "                    relacionamentos.append({\n",
    "                        \"source\": sujeito[0].text,\n",
    "                        \"target\": objeto[0].text,\n",
    "                        \"type\": \"REQUER\"  # Adapte o tipo de relacionamento conforme necessário\n",
    "                    })\n",
    "\n",
    "    # Construir o JSON de saída\n",
    "    dados_json = {\n",
    "        \"nodes\": entidades,\n",
    "        \"relationships\": relacionamentos\n",
    "    }\n",
    "\n",
    "    return dados_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso\n",
    "caminho_documento = \"caminho/para/seu/documento.pdf\"  # ou .html\n",
    "dados_extraidos = extrair_informacoes_documento(caminho_documento)\n",
    "dados_extraidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o JSON em um arquivo\n",
    "with open(\"dados_extraidos.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dados_extraidos, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliar Similaridades Semânticas por métricas diversas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Neo4j oferece algoritmos de similaridade diretamente em suas consultas Cypher, o que pode ser mais eficiente em alguns casos do que calcular as similaridades em Python e depois ordená-las. \n",
    "\n",
    "A escolha da métrica de similaridade ideal dependerá do seu caso de uso específico e das características dos seus dados. É fundamental entender as particularidades de cada métrica para interpretar corretamente os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "from sentence_transformers import SentenceTransformer, util # Para calcular similaridade semântica\n",
    "\n",
    "# Conectar ao banco de dados Neo4j\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))\n",
    "\n",
    "# Carregar o modelo de similaridade semântica (escolha um modelo adequado)\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2') \n",
    "\n",
    "def calcular_similaridade_euclidiana(caminho_json):\n",
    "    \"\"\"\n",
    "    Calcula a similaridade euclidiana entre entidades em um arquivo JSON local e entidades\n",
    "    existentes no banco de dados Neo4j, retornando um índice ordenado de similaridade.\n",
    "    \"\"\"\n",
    "\n",
    "    # Carregar o JSON local\n",
    "    with open(caminho_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        dados_json = json.load(f)\n",
    "\n",
    "    # Extrair entidades do JSON local\n",
    "    entidades_locais = [node[\"properties\"][\"name\"] for node in dados_json[\"nodes\"]]\n",
    "\n",
    "    # Consultar entidades e seus embeddings no Neo4j (assumindo que você já armazenou os embeddings)\n",
    "    with driver.session() as session:\n",
    "        resultado = session.run(\"MATCH (n) RETURN n.name AS name, n.embedding AS embedding\")\n",
    "        entidades_neo4j = [(registro[\"name\"], registro[\"embedding\"]) for registro in resultado]\n",
    "\n",
    "    # Calcular similaridade euclidiana usando Cypher\n",
    "    indice_ordenado = []\n",
    "    for entidade_local in entidades_locais:\n",
    "        embedding_local = model.encode(entidade_local, convert_to_tensor=True).tolist()[0]  # Converter para lista\n",
    "        query = f\"\"\"\n",
    "            WITH point({embedding_local}) AS p1\n",
    "            UNWIND $embeddings AS p2\n",
    "            RETURN p2.name AS name, distance(p1, point(p2.embedding)) AS distance\n",
    "            ORDER BY distance\n",
    "        \"\"\"\n",
    "        params = {\"embeddings\": entidades_neo4j}\n",
    "        resultado = session.run(query, params)\n",
    "\n",
    "        for registro in resultado:\n",
    "            indice_ordenado.append({\n",
    "                \"entidade_local\": entidade_local,\n",
    "                \"entidade_neo4j\": registro[\"name\"],\n",
    "                \"similaridade\": 1 / (1 + registro[\"distance\"])  # Converter distância em similaridade\n",
    "            })\n",
    "\n",
    "    indice_ordenado.sort(key=lambda x: x[\"similaridade\"], reverse=True)\n",
    "\n",
    "    return indice_ordenado\n",
    "\n",
    "def calcular_similaridade_jaccard(caminho_json):\n",
    "    \"\"\"\n",
    "    Calcula a similaridade de Jaccard entre entidades em um arquivo JSON local e entidades\n",
    "    existentes no banco de dados Neo4j, retornando um índice ordenado de similaridade.\n",
    "    \"\"\"\n",
    "\n",
    "    # Carregar o JSON local\n",
    "    with open(caminho_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        dados_json = json.load(f)\n",
    "\n",
    "    # Extrair entidades do JSON local\n",
    "    entidades_locais = [node[\"properties\"][\"name\"] for node in dados_json[\"nodes\"]]\n",
    "\n",
    "    # Consultar entidades e seus embeddings no Neo4j (assumindo que você já armazenou os embeddings)\n",
    "    with driver.session() as session:\n",
    "        resultado = session.run(\"MATCH (n) RETURN n.name AS name, n.embedding AS embedding\")\n",
    "        entidades_neo4j = [(registro[\"name\"], registro[\"embedding\"]) for registro in resultado]\n",
    "\n",
    "    # Calcular similaridade de Jaccard usando Cypher (requer converter embeddings para strings)\n",
    "    indice_ordenado = []\n",
    "    for entidade_local in entidades_locais:\n",
    "        embedding_local_str = ','.join(map(str, model.encode(entidade_local, convert_to_tensor=True).tolist()[0]))\n",
    "        query = f\"\"\"\n",
    "            WITH split($embedding_local, ',') AS s1\n",
    "            UNWIND $embeddings AS e2\n",
    "            WITH s1, e2, split(e2.embedding, ',') AS s2\n",
    "            RETURN e2.name AS name, \n",
    "                   toFloat(size(apoc.coll.intersection(s1, s2))) / toFloat(size(apoc.coll.union(s1, s2))) AS similarity\n",
    "            ORDER BY similarity DESC\n",
    "        \"\"\"\n",
    "        params = {\"embedding_local\": embedding_local_str, \"embeddings\": entidades_neo4j}\n",
    "        resultado = session.run(query, params)\n",
    "\n",
    "        for registro in resultado:\n",
    "            indice_ordenado.append({\n",
    "                \"entidade_local\": entidade_local,\n",
    "                \"entidade_neo4j\": registro[\"name\"],\n",
    "                \"similaridade\": registro[\"similarity\"]\n",
    "            })\n",
    "\n",
    "    return indice_ordenado\n",
    "\n",
    "def calcular_similaridade_entidades(caminho_json, algoritmo_similaridade=\"cosine\"):\n",
    "    \"\"\"\n",
    "    Calcula, por um algoritmo definido, a similaridade semântica entre entidades em um arquivo JSON local e entidades\n",
    "    existentes no banco de dados Neo4j, retornando um índice ordenado de similaridade.\n",
    "    \"\"\"\n",
    "\n",
    "    # Carregar o JSON local\n",
    "    with open(caminho_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        dados_json = json.load(f)\n",
    "\n",
    "    # Extrair entidades do JSON local\n",
    "    entidades_locais = [node[\"properties\"][\"name\"] for node in dados_json[\"nodes\"]]\n",
    "\n",
    "    # Consultar entidades existentes no Neo4j\n",
    "    with driver.session() as session:\n",
    "        resultado = session.run(\"MATCH (n) RETURN n.name AS name\")\n",
    "        entidades_neo4j = [registro[\"name\"] for registro in resultado]\n",
    "\n",
    "    # Calcular embeddings das entidades (representações vetoriais)\n",
    "    embeddings_locais = model.encode(entidades_locais, convert_to_tensor=True)\n",
    "    embeddings_neo4j = model.encode(entidades_neo4j, convert_to_tensor=True)\n",
    "\n",
    "    # Calcular similaridade (escolha o algoritmo desejado)\n",
    "    if algoritmo_similaridade == \"cosine\":\n",
    "        similaridades = util.cos_sim(embeddings_locais, embeddings_neo4j)\n",
    "    # Adicione outros algoritmos de similaridade aqui, se necessário\n",
    "\n",
    "    # Criar um índice ordenado de similaridade\n",
    "    indice_ordenado = []\n",
    "    for i, entidade_local in enumerate(entidades_locais):\n",
    "        for j, entidade_neo4j in enumerate(entidades_neo4j):\n",
    "            indice_ordenado.append({\n",
    "                \"entidade_local\": entidade_local,\n",
    "                \"entidade_neo4j\": entidade_neo4j,\n",
    "                \"similaridade\": similaridades[i][j].item()  # Converter tensor para valor numérico\n",
    "            })\n",
    "\n",
    "    indice_ordenado.sort(key=lambda x: x[\"similaridade\"], reverse=True)\n",
    "\n",
    "    return indice_ordenado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo por similaridade euclidiana\n",
    "caminho_json = \"caminho/para/seu/arquivo.json\"\n",
    "calcular_similaridade_euclidiana(caminho_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo por similaridade de Jaccard\n",
    "caminho_json = \"caminho/para/seu/arquivo.json\"\n",
    "calcular_similaridade_jaccard(caminho_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo por similaridade de cossenos\n",
    "caminho_json = \"caminho/para/seu/arquivo.json\"\n",
    "algoritmo = \"cosine\"  # ou outro algoritmo de similaridade disponível\n",
    "resultados = calcular_similaridade_entidades(caminho_json, algoritmo)\n",
    "\n",
    "# Imprimir os resultados\n",
    "for resultado in resultados:\n",
    "    print(f\"Entidade local: {resultado['entidade_local']}\")\n",
    "    print(f\"Entidade Neo4j: {resultado['entidade_neo4j']}\")\n",
    "    print(f\"Similaridade: {resultado['similaridade']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para recomendar a métrica mais adequada para calcular a similaridade semântica entre entidades e relacionamentos em grafos no Neo4j, precisamos analisar as características dos dados e a topologia dos grafos envolvidos. Para análise genérica inicial, ainda desconsiderando dados e estrutura de algum grafo específicos, utilizamos um método baseado em informações sobre o tipo de dados e a estrutura do grafo inferidos pelo texto da questão de pesquisa fornecida pelo usuário para fazer a recomendação, juntamente com uma breve explicação da escolha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import networkx as nx  # Para análise de grafos\n",
    "import numpy as np\n",
    "import cupy as cp  # Para cálculos em GPU (se disponível)\n",
    "from collections import Counter\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Conectar ao banco de dados Neo4j\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"your_password\"))\n",
    "\n",
    "def calcular_densidade_grafo(grafo_neo4j):\n",
    "    \"\"\"\n",
    "    Calcula a densidade do grafo Neo4j.\n",
    "    \"\"\"\n",
    "\n",
    "    with driver.session() as session:\n",
    "        resultado = session.run(\"\"\"\n",
    "            MATCH (n) \n",
    "            WITH count(n) AS num_nodes, \n",
    "                 sum(size((n)--()))/2 AS num_edges \n",
    "            RETURN toFloat(num_edges) / (toFloat(num_nodes) * (toFloat(num_nodes) - 1) / 2) AS density\n",
    "        \"\"\")\n",
    "        densidade = resultado.single()[\"density\"]\n",
    "\n",
    "    return densidade\n",
    "\n",
    "def analisar_distribuicao_graus(grafo_neo4j):\n",
    "    \"\"\"\n",
    "    Analisa a distribuição de graus do grafo Neo4j e retorna \"power_law\" se a distribuição seguir\n",
    "    aproximadamente uma lei de potência, ou \"other\" caso contrário.\n",
    "    \"\"\"\n",
    "\n",
    "    with driver.session() as session:\n",
    "        resultado = session.run(\"MATCH (n) RETURN size((n)--()) AS degree\")\n",
    "        graus = [registro[\"degree\"] for registro in resultado]\n",
    "\n",
    "    # Converter para NumPy array para cálculos mais rápidos\n",
    "    graus_np = np.array(graus)\n",
    "\n",
    "    # Opcional: usar CuPy para cálculos em GPU, se disponível\n",
    "    if cp.cuda.is_available():\n",
    "        graus_np = cp.asarray(graus_np)\n",
    "\n",
    "    # Calcular histograma e analisar a distribuição\n",
    "    histograma, _ = np.histogram(graus_np, bins='auto')\n",
    "\n",
    "    # Filtrar zeros do histograma e calcular logaritmos\n",
    "    graus_nao_zero = np.where(histograma > 0)[0]\n",
    "    log_graus = np.log10(graus_nao_zero + 1)  # Adicionar 1 para evitar log(0)\n",
    "    log_freqs = np.log10(histograma[graus_nao_zero])\n",
    "\n",
    "    # Ajustar uma reta aos dados em escala log-log\n",
    "    coeficientes = np.polyfit(log_graus, log_freqs, 1)\n",
    "\n",
    "    # Calcular o coeficiente de determinação R²\n",
    "    y_pred = np.polyval(coeficientes, log_graus)\n",
    "    r2 = r2_score(log_freqs, y_pred)\n",
    "\n",
    "    # Definir um limiar para o R² e retornar True ou False\n",
    "    limiar_r2 = 0.9  # Ajuste conforme necessário\n",
    "    if r2 >= limiar_r2:\n",
    "        return \"power_law\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "def identificar_tipos_relacionamentos(grafo_neo4j):\n",
    "    \"\"\"\n",
    "    Identifica os tipos de relacionamentos presentes no grafo Neo4j e retorna \"homogeneos\"\n",
    "    se houver poucos tipos distintos, ou \"heterogeneos\" caso contrário.\n",
    "    \"\"\"\n",
    "\n",
    "    with driver.session() as session:\n",
    "        resultado = session.run(\"MATCH ()-[r]->() RETURN distinct type(r) AS tipo\")\n",
    "        tipos = [registro[\"tipo\"] for registro in resultado]\n",
    "\n",
    "    if len(tipos) <= 3:  # Adapte o limiar conforme necessário\n",
    "        return \"homogeneos\"\n",
    "    else:\n",
    "        return \"heterogeneos\"\n",
    "\n",
    "def calcular_tamanho_vocabulario(dados_json, grafo_neo4j):\n",
    "    \"\"\"\n",
    "    Calcula o tamanho do vocabulário combinado das entidades no JSON e no grafo Neo4j.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extrair entidades do JSON local (igual ao exemplo anterior)\n",
    "    entidades_locais = [node[\"properties\"][\"name\"] for node in dados_json[\"nodes\"]]\n",
    "\n",
    "    # Consultar entidades existentes no Neo4j (igual ao exemplo anterior)\n",
    "    with driver.session() as session:\n",
    "        resultado = session.run(\"MATCH (n) RETURN n.name AS name\")\n",
    "        entidades_neo4j = [registro[\"name\"] for registro in resultado]\n",
    "\n",
    "    # Combinar e contar palavras únicas\n",
    "    vocabulario = Counter(entidades_locais + entidades_neo4j)\n",
    "    tamanho_vocabulario = len(vocabulario)\n",
    "\n",
    "    return tamanho_vocabulario\n",
    "\n",
    "def recomendar_metrica(dados_json, grafo_neo4j):\n",
    "    \"\"\"\n",
    "    Analisa as características dos dados e do grafo para recomendar a métrica \n",
    "    de similaridade semântica mais adequada.\n",
    "\n",
    "    Args:\n",
    "        dados_json: Dados no formato JSON a serem comparados com o grafo.\n",
    "        grafo_neo4j: Objeto representando o grafo no Neo4j.\n",
    "\n",
    "    Returns:\n",
    "        Uma tupla contendo a métrica recomendada e uma breve explicação da escolha.\n",
    "    \"\"\"\n",
    "\n",
    "    # Analisar características dos dados e do grafo (código hipotético)\n",
    "    densidade_grafo = calcular_densidade_grafo(grafo_neo4j)\n",
    "    distribuicao_graus = analisar_distribuicao_graus(grafo_neo4j)\n",
    "    tipos_relacionamentos = identificar_tipos_relacionamentos(grafo_neo4j)\n",
    "    tamanho_vocabulario = calcular_tamanho_vocabulario(dados_json, grafo_neo4j)\n",
    "\n",
    "    # Lógica de decisão para recomendar a métrica (código hipotético)\n",
    "    if densidade_grafo > 0.5 and distribuicao_graus == \"power_law\":\n",
    "        metrica_recomendada = \"cosine\"\n",
    "        explicacao = \"Grafo denso com distribuição de graus em lei de potência sugere similaridade baseada em contexto. A distância de cossenos é eficaz em capturar relações semânticas em grafos densos e complexos, onde o contexto das entidades é crucial.\"\n",
    "    elif tamanho_vocabulario < 1000 and tipos_relacionamentos == \"homogeneos\":\n",
    "        metrica_recomendada = \"euclidean\"\n",
    "        explicacao = \"Vocabulário pequeno e relacionamentos homogêneos indicam que a distância euclidiana pode ser suficiente. A distância euclidiana é uma métrica simples e eficiente para calcular a similaridade entre vetores em espaços de baixa dimensão, o que pode ser o caso quando o vocabulário é limitado.\"\n",
    "    else:\n",
    "        metrica_recomendada = \"jaccard\"\n",
    "        explicacao = \"Em outros casos, a similaridade de Jaccard pode ser uma boa opção geral, especialmente quando a presença ou ausência de características é mais importante do que a magnitude das diferenças. A similaridade de Jaccard é útil para comparar conjuntos de elementos, como palavras-chave ou atributos, e é menos sensível a variações na frequência dos termos.\"\n",
    "\n",
    "    return metrica_recomendada, explicacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interação com usuários com utilização de PLN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Froam criados métodos em Python que utilizam processamento de linguagem natural (PLN) para interagir com pesquisadores, permitindo que eles expressem suas questões de pesquisa em linguagem natural e recebam sugestões de entidades e relacionamentos relevantes para serem explorados no grafo Neo4j. O sistema também permitirá que os pesquisadores refinem suas consultas, incluindo ou modificando entidades e relacionamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Carregar o modelo de linguagem português do spaCy\n",
    "nlp = spacy.load(\"pt_core_news_lg\")\n",
    "\n",
    "# Conectar ao banco de dados Neo4j\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))\n",
    "\n",
    "def processar_questao_pesquisa(questao):\n",
    "    \"\"\"\n",
    "    Processa a questão de pesquisa do usuário utilizando PLN e retorna entidades e \n",
    "    relacionamentos relevantes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Analisar a questão com spaCy\n",
    "    doc = nlp(questao)\n",
    "\n",
    "    # Extrair entidades e relacionamentos (adapte as regras conforme necessário)\n",
    "    entidades = [ent.text for ent in doc.ents]\n",
    "    relacionamentos = [(child.text, child.dep_) for token in doc for child in token.children if child.dep_ in [\"nsubj\", \"dobj\"]]\n",
    "\n",
    "    return entidades, relacionamentos\n",
    "\n",
    "def gerar_consulta_neo4j(entidades, relacionamentos):\n",
    "    \"\"\"\n",
    "    Gera uma consulta Cypher para o Neo4j com base nas entidades e relacionamentos extraídos.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construir a consulta (adapte a lógica conforme a estrutura do seu grafo)\n",
    "    match_clause = \"MATCH \"\n",
    "    where_clause = \"WHERE \"\n",
    "    for entidade in entidades:\n",
    "        match_clause += f\"(n{entidades.index(entidade)}:Entidade {{nome: '{entidade}'}})\"\n",
    "        if entidade != entidades[-1]:\n",
    "            match_clause += \", \"\n",
    "\n",
    "    for relacionamento in relacionamentos:\n",
    "        sujeito, tipo_relacionamento = relacionamento\n",
    "        match_clause += f\"-[r{relacionamentos.index(relacionamento)}:{tipo_relacionamento}]->\"\n",
    "\n",
    "    consulta = match_clause + \" \" + where_clause + \" RETURN *\"\n",
    "\n",
    "    return consulta\n",
    "    \n",
    "def interagir_com_pesquisador():\n",
    "    \"\"\"\n",
    "    Realiza a interação com o pesquisador, permitindo que ele refine sua consulta.\n",
    "    \"\"\"\n",
    "\n",
    "    entidades = []\n",
    "    relacionamentos = []\n",
    "\n",
    "    while True:\n",
    "        questao = input(\"Digite sua questão de pesquisa ou 'sair' para encerrar: \")\n",
    "        if questao.lower() == 'sair':\n",
    "            break\n",
    "\n",
    "        if not entidades and not relacionamentos:  # Primeira iteração\n",
    "            entidades, relacionamentos = processar_questao_pesquisa(questao)\n",
    "\n",
    "            # Mapear entidades e sugerir novas se necessário\n",
    "            entidades_mapeadas, entidades_nao_encontradas = MapeamentoEntidades.mapear_entidades(entidades, driver)\n",
    "            if entidades_nao_encontradas:\n",
    "                sugestoes_entidades = MapeamentoEntidades.sugerir_novas_entidades(entidades_nao_encontradas)\n",
    "                print(\"\\nAlgumas entidades não foram encontradas no modelo. Sugestões:\")\n",
    "                for sugestao in sugestoes_entidades:\n",
    "                    print(f\"- {sugestao['entidade_nao_encontrada']}: {', '.join(sugestao['sugestoes'])}\")\n",
    "\n",
    "                # Adicionar as sugestões à lista de entidades (opcional)\n",
    "                # entidades.extend([sugestao[\"entidade_nao_encontrada\"] for sugestao in sugestoes_entidades])\n",
    "\n",
    "        else:\n",
    "            novas_entidades, novos_relacionamentos = processar_questao_pesquisa(questao)\n",
    "            entidades.extend(novas_entidades)\n",
    "            relacionamentos.extend(novos_relacionamentos)\n",
    "\n",
    "        print(\"\\nEntidades identificadas:\")\n",
    "        for entidade in entidades:\n",
    "            print(f\"- {entidade}\")\n",
    "\n",
    "        print(\"\\nRelacionamentos identificados:\")\n",
    "        for relacionamento in relacionamentos:\n",
    "            print(f\"- {relacionamento[0]} ({relacionamento[1]})\")\n",
    "\n",
    "        consulta = gerar_consulta_neo4j(entidades, relacionamentos)\n",
    "        print(\"\\nConsulta gerada:\")\n",
    "        print(consulta)\n",
    "\n",
    "        # Executar a consulta no Neo4j e apresentar os resultados\n",
    "        with driver.session() as session:\n",
    "            resultado = session.run(consulta)\n",
    "\n",
    "            # Verificar se há resultados\n",
    "            if resultado.peek() is None:\n",
    "                print(\"\\nNenhum resultado encontrado para a consulta.\")\n",
    "            else:\n",
    "                print(\"\\nResultados da consulta:\")\n",
    "                for registro in resultado:\n",
    "                    # Apresentar os nós e relacionamentos encontrados\n",
    "                    for node in registro.values():\n",
    "                        if isinstance(node, Node):\n",
    "                            print(f\"Nó: {node['nome']} (tipo: {list(node.labels)[0]})\")\n",
    "                        elif isinstance(node, Relationship):\n",
    "                            print(f\"Relacionamento: {node.start_node['nome']} -[{node.type}]-> {node.end_node['nome']}\")\n",
    "\n",
    "        while True:\n",
    "            resposta = input(\"\\nDeseja explorar mais detalhes sobre alguma entidade ou relacionamento, ou realizar uma busca entre entidades? (s/n): \")\n",
    "            if resposta.lower() != \"s\":\n",
    "                break\n",
    "\n",
    "            opcao = input(\"Digite 'detalhar' para explorar uma entidade/relacionamento existente, ou 'buscar' para realizar uma busca entre entidades, ou 'adicionar' para sugerir novas entidades/relacionamentos: \")\n",
    "\n",
    "            if opcao.lower() == 'detalhar':\n",
    "                print(\"Entidades e relacionamentos atuais:\")\n",
    "                for i, entidade in enumerate(entidades):\n",
    "                    print(f\"{i+1}. Entidade: {entidade}\")\n",
    "                for i, relacionamento in enumerate(relacionamentos):\n",
    "                    print(f\"{i+len(entidades)+1}. Relacionamento: {relacionamento[0]} ({relacionamento[1]})\")\n",
    "\n",
    "                indice_elemento = int(input(\"Digite o número do elemento a ser explorado: \")) - 1\n",
    "\n",
    "                if indice_elemento < len(entidades):\n",
    "                    entidade_selecionada = entidades[indice_elemento]\n",
    "                    # Explosão do subgrafo\n",
    "                    subgrafo = ExplosaoSubgrafos.recuperar_subgrafo(entidade_selecionada)\n",
    "                    ExplosaoSubgrafos.apresentar_subgrafo(subgrafo)\n",
    "\n",
    "                    # Recomendações (opcional, dependendo da sua implementação)\n",
    "                    recomendacoes = RecomendacaoProjetos.gerar_recomendacoes(entidades, relacionamentos, subgrafo)\n",
    "                    for recomendacao in recomendacoes:\n",
    "                        print(f\"- {recomendacao['projeto']}\")\n",
    "                        print(f\"  Justificativa: {recomendacao['justificativa']}\")\n",
    "                        print(f\"  Fontes: {recomendacao['fontes']}\\n\")\n",
    "\n",
    "                else:\n",
    "                    relacionamento_selecionado = relacionamentos[indice_elemento - len(entidades)]\n",
    "                    # ... (implementação para detalhar um relacionamento, se aplicável)\n",
    "                    print(f\"Relacionamento selecionado:\\n {relacionamento_selecionado}\")\n",
    "                    print()\n",
    "\n",
    "            elif opcao.lower() == 'buscar':\n",
    "                print(\"Entidades atuais:\")\n",
    "                for i, entidade in enumerate(entidades):\n",
    "                    print(f\"{i+1}. {entidade}\")\n",
    "\n",
    "                indice_inicio = int(input(\"Digite o número da entidade de início da busca: \")) - 1\n",
    "                indice_fim = int(input(\"Digite o número da entidade de fim da busca: \")) - 1\n",
    "\n",
    "                entidade_inicio = entidades[indice_inicio]\n",
    "                entidade_fim = entidades[indice_fim]\n",
    "\n",
    "                # Consulta para encontrar caminhos entre as entidades\n",
    "                consulta_caminhos = f\"\"\"\n",
    "                    MATCH path = (inicio:Entidade {{nome: '{entidade_inicio}'}})-[*]-(fim:Entidade {{nome: '{entidade_fim}'}})\n",
    "                    RETURN path\n",
    "                \"\"\"\n",
    "\n",
    "                with driver.session() as session:\n",
    "                    resultado_caminhos = session.run(consulta_caminhos)\n",
    "\n",
    "                    # Apresentar os caminhos encontrados\n",
    "                    if resultado_caminhos.peek() is None:\n",
    "                        print(\"\\nNenhum caminho encontrado entre as entidades.\")\n",
    "                    else:\n",
    "                        print(\"\\nCaminhos encontrados:\")\n",
    "                        for registro in resultado_caminhos:\n",
    "                            caminho = registro[\"path\"]\n",
    "                            print(caminho)\n",
    "\n",
    "            elif opcao.lower() == 'adicionar':\n",
    "                questao_adicional = input(\"Digite a questão de pesquisa que as novas entidades/relacionamentos devem abordar: \")\n",
    "                novas_entidades, novos_relacionamentos = ProcessamentoLinguagemNatural.processar_questao_pesquisa(questao_adicional)\n",
    "\n",
    "                # Apresentar as sugestões ao usuário para confirmação\n",
    "                print(\"\\nSugestões de entidades:\")\n",
    "                for entidade in novas_entidades:\n",
    "                    print(f\"- {entidade}\")\n",
    "\n",
    "                print(\"\\nSugestões de relacionamentos:\")\n",
    "                for relacionamento in novos_relacionamentos:\n",
    "                    print(f\"- {relacionamento[0]} ({relacionamento[1]})\")\n",
    "\n",
    "                confirmacao = input(\"\\nDeseja adicionar estas sugestões ao modelo? (s/n): \")\n",
    "                if confirmacao.lower() == 's':\n",
    "                    # Persistir as sugestões no Neo4j\n",
    "                    with driver.session() as session:\n",
    "                        for entidade in novas_entidades:\n",
    "                            session.run(\"\"\"\n",
    "                                MERGE (e:SugestaoEntidade {nome: $nome})\n",
    "                                ON CREATE SET e.data_criacao = datetime()\n",
    "                            \"\"\", nome=entidade)\n",
    "\n",
    "                        for relacionamento in novos_relacionamentos:\n",
    "                            sujeito, tipo_relacionamento = relacionamento\n",
    "                            session.run(\"\"\"\n",
    "                                MERGE (s:SugestaoEntidade {nome: $sujeito})\n",
    "                                ON CREATE SET s.data_criacao = datetime()\n",
    "                                MERGE (r:SugestaoRelacionamento {tipo: $tipo})\n",
    "                                ON CREATE SET r.data_criacao = datetime()\n",
    "                                MERGE (s)-[:TEM_SUGESTAO]->(r)\n",
    "                            \"\"\", sujeito=sujeito, tipo=tipo_relacionamento)\n",
    "\n",
    "                    print(\"Sugestões de entidades e relacionamentos adicionadas ao banco de dados.\")\n",
    "                else:\n",
    "                    print(\"Sugestões descartadas.\")\n",
    "\n",
    "                break \n",
    "\n",
    "            else:\n",
    "                print(\"Opção inválida. Digite 'detalhar', 'buscar' ou 'adicionar'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar a interação\n",
    "interagir_com_pesquisador()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estruturação da Lógica de Detalhamento Sucessivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificar Entidades e Relacionamentos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O módulo de processamento de linguagem natural (PLN) continuará sendo utilizado para extrair entidades e relacionamentos das questões de pesquisa dos usuários.\n",
    "No entanto, precisaremos adaptar as regras de extração para identificar termos e conceitos específicos do domínio de PDI em saúde e do CEIS.\n",
    "Podemos utilizar técnicas de reconhecimento de entidades nomeadas (NER) e mineração de terminologia para aprimorar a identificação de entidades relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapear fenômenos no CEIS para o Modelo de Grafo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As entidades e relacionamentos extraídos pela PLN são mapeados para o modelo de grafo, começando pelo nível de maior abstração.\n",
    "\n",
    "Quando uma entidade não está presente no modelo atual, o sistema informa o usuário a lacuna nos dados e pode sugerir entidades relacionadas (por similaridade semântica) ou e oferece a possibilidade de incluir a nova entidade no modelo.\n",
    "\n",
    "Os relacionamentos identificados guiam a navegação pelo grafo, expandindo os subgrafos relevantes para níveis de detalhamento maiores, conforme necessário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detalhar sucessivamente por explosão em Subgrafos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lógica de detalhamento sucessivo foi implementada através da explosão de subgrafos.\n",
    "\n",
    "Quando o usuário deseja mais detalhes sobre uma determinada entidade ou relacionamento, o sistema consulta o Neo4j para recuperar os nós e relacionamentos filhos associados a essa entidade no próximo nível de detalhamento.\n",
    "\n",
    "Os novos subgrafos são apresentados ao usuário, permitindo que ele explore o modelo em diferentes níveis de granularidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interagir por meio de Recomendações Contrafactuais Explanáveis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fornecer recomendações diversas, tais como recomendar estratégias para possíveis projetos de PDI, o sistema utiliza algoritmos de análise de grafos e mineração de dados para identificar padrões, tendências e oportunidades no CEIS.\n",
    "\n",
    "As recomendações são explanáveis, ou seja, o sistema fornece ao usuário as razões e evidências contrafactuais que justificam cada sugestão, com base nos dados do grafo e em fontes externas confiáveis, previamente inseridas por meio de curadoria humana.\n",
    "\n",
    "A similaridade semântica entre as entidades e relacionamentos da consulta do usuário e os elementos do grafo é utilizada para personalizar as recomendações e garantir sua relevância."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes e Métodos Adicionais:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapeamentoEntidades: Classe responsável por mapear as entidades extraídas pela PLN para o modelo de grafo e sugerir novas entidades quando necessário.\n",
    "\n",
    "ExplosaoSubgrafos: Classe responsável por realizar a consulta ao Neo4j para recuperar os subgrafos filhos de uma entidade e apresentá-los ao usuário.\n",
    "\n",
    "RecomendacaoProjetos: Classe responsável por analisar o grafo e gerar recomendações explanáveis sobre possíveis projetos de PDI, utilizando dados do grafo e fontes externas.\n",
    "\n",
    "FontesDados: Classe ou módulo para gerenciar as fontes de dados externas (artigos científicos, bases de dados governamentais, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
