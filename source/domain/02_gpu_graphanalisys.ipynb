{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python.exe -m pip install --upgrade pip\n",
    "# %pip install -U pip\n",
    "\n",
    "# !conda clean --all\n",
    "# !conda update --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash-attn\n",
      "  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n",
      "     ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 0.5/2.6 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.6/2.6 MB 9.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [6 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\marco\\AppData\\Local\\Temp\\pip-install-qisf9hpf\\flash-attn_150799254ada4f2897b283febe5196da\\setup.py\", line 21, in <module>\n",
      "          import torch\n",
      "      ModuleNotFoundError: No module named 'torch'\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "%pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDados do ambiente local\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    "print(f\"\\nDados do ambiente local\")\n",
    "# !nvcc --version\n",
    "def verificar_versoes():\n",
    "    \"\"\"Verifica e exibe as versões  da GPU, do Python e bibliotecas CUDA instaladas no sistema.\"\"\"\n",
    "\n",
    "    # Versão do Python\n",
    "    python_version = sys.version.split()[0]\n",
    "    print(f\"   Versão Python: {python_version}\")\n",
    "    print(f\"  Versão PyTorch: {torch.__version__}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  Versão do CUDA: {torch.version.cuda}\")\n",
    "        print(f\" Versão do cuDNN: {torch.backends.cudnn.version()}\")\n",
    "    else:\n",
    "        print(\"CUDA não disponível, não está configurado corretamente.\")\n",
    "\n",
    "    # Versão do CUDA (usando nvcc)\n",
    "    try:\n",
    "        cuda_version = subprocess.check_output([\"nvcc\", \"--version\"])\n",
    "        cuda_version_l3 = [' '.join(cuda_version.decode(\"utf-8\").strip().split(\"\\n\")[-2].split(',')[1:])][0].strip()\n",
    "        cuda_version_l4 = cuda_version.decode(\"utf-8\").strip().split(\"\\n\")[-1]\n",
    "        print(f\"    CUDA Toolkit: {cuda_version_l3}\")\n",
    "        print(f\"      Build nvcc: {cuda_version_l4}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"nvcc não encontrado. CUDA pode não estar instalado ou configurado corretamente.\")\n",
    "\n",
    "# Chamando a função para verificar as versões\n",
    "verificar_versoes()\n",
    "\n",
    "print(f\"\\nDetalhes da biblioteca PyTorch\")\n",
    "!pip3 show torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução 01: Sem mecanismo de atenção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "# Carregar modelo e tokenizer pré-treinados\n",
    "model_name = \"bert-base-uncased\"  # Escolha o modelo desejado\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(\"cuda\")  # Mover para GPU\n",
    "\n",
    "# Textos de entrada (exemplo)\n",
    "texts = [\n",
    "    \"This is a sentence about natural language processing.\",\n",
    "    \"Another sentence about NLP.\",\n",
    "    \"An unrelated sentence about dogs.\"\n",
    "]\n",
    "\n",
    "# Pré-processamento\n",
    "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Medir tempo de execução\n",
    "start_time = time.time()\n",
    "\n",
    "# Embedding\n",
    "with torch.no_grad():\n",
    "    embeddings = model(**encoded_input)[\"pooler_output\"].cpu().numpy()\n",
    "\n",
    "# Cálculo de similaridade\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Matriz de similaridade:\")\n",
    "print(similarity_matrix)\n",
    "\n",
    "print(f\"Tempo de execução: {end_time - start_time:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução 02: Com mecanismo de atenção\n",
    "\n",
    "A versão do CUDA precisa ser compatível com a Flash Attention. A Flash Attention foi introduzida no PyTorch 2.0 e requer CUDA 11.8 ou superior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda uninstall pytorch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar o ambiente pelo Terminal:\n",
    "### Sempre atualizar versões mais recentes em https://pytorch.org/\n",
    "\n",
    "    conda create -n pytorch_env python=3.11\n",
    "    conda activate pytorch_env\n",
    "    conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch-nightly -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda config --add channels conda-forge\n",
    "# !conda config --add channels rapidsai\n",
    "# !conda config --add channels nvidia\n",
    "\n",
    "# %conda install -c rapidsai -c nvidia -c conda-forge pylibcugraph=24.6.1 cudatoolkit=12.5\n",
    "# %conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch-nightly -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamando a função para verificar as versões\n",
    "verificar_versoes()\n",
    "\n",
    "print(f\"\\nDetalhes da biblioteca PyTorch\")\n",
    "!pip3 show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "url = \"https://data.rapids.ai/cugraph/datasets/cit-Patents.csv\"\n",
    "df = pd.read_csv(url, sep=\" \", names=[\"src\", \"dst\"], dtype=\"int32\")\n",
    "G = nx.from_pandas_edgelist(df, source=\"src\", target=\"dst\")\n",
    "\n",
    "%time result = nx.betweenness_centrality(G, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Criar um grafo aleatório\n",
    "G = nx.gnp_random_graph(10, 0.3)\n",
    "\n",
    "# Definir um layout\n",
    "pos = nx.spring_layout(G) # Outras opções: circular_layout, spectral_layout, etc.\n",
    "\n",
    "# Desenhar o grafo com personalizações\n",
    "nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=500, font_size=10, font_color='black', width=2, edge_color='gray')\n",
    "\n",
    "# Mostrar o grafo\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimativas de tempo de execução \n",
    "\n",
    "Considerando detecção de características do grafo e recursos computacionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular e exibir o número de nós e arestas\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "print(\"Número de nós:\", num_nodes)\n",
    "print(\"Número de arestas:\", num_edges)\n",
    "\n",
    "# Calcular e exibir a densidade do grafo\n",
    "density = nx.density(G)\n",
    "print(\"Densidade do grafo:\", density)\n",
    "\n",
    "# Obter informações de hardware\n",
    "cpu_count = psutil.cpu_count(logical=True)\n",
    "ram_gb = psutil.virtual_memory().total / (1024 ** 3)\n",
    "\n",
    "# Estimar o tempo de execução (modelo simplificado)\n",
    "k = 10  # Valor de k usado no cálculo da centralidade\n",
    "estimated_time = (num_nodes * num_edges * density * k) / (cpu_count * ram_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar o comando e medir o tempo de execução\n",
    "# %time result = nx.betweenness_centrality(G, k=10)\n",
    "\n",
    "# Exibir o tempo estimado e o tempo real de execução\n",
    "print(\"Tempo estimado:\", estimated_time)\n",
    "print(\"Tempo real:\", _ # A variável mágica '_' contém o tempo de execução do último comando %)\n",
    "\n",
    "# Visualizar a distribuição da centralidade betweenness\n",
    "betweenness_data = pd.DataFrame(list(result.items()), columns=['Node', 'Betweenness Centrality'])\n",
    "\n",
    "chart = alt.Chart(betweenness_data).mark_bar().encode(\n",
    "    x=alt.X('Node:N', sort='-y'),\n",
    "    y=alt.Y('Betweenness Centrality:Q'),\n",
    "    tooltip=['Node', 'Betweenness Centrality']\n",
    ").properties(\n",
    "    title='Distribuição da Centralidade Betweenness'\n",
    ").interactive()\n",
    "\n",
    "chart.save('betweenness_centrality_distribution.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import timeit\n",
    "import altair as alt\n",
    "\n",
    "# Carregar o dataframe a partir da URL\n",
    "url = \"https://data.rapids.ai/cugraph/datasets/cit-Patents.csv\"\n",
    "df = pd.read_csv(url, sep=\" \", names=[\"src\", \"dst\"], dtype=\"int32\")\n",
    "\n",
    "# Criar o grafo a partir do dataframe\n",
    "G = nx.from_pandas_edgelist(df, source=\"src\", target=\"dst\")\n",
    "\n",
    "# Calcular e exibir o número de nós e arestas\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "print(\"Número de nós:\", num_nodes)\n",
    "print(\"Número de arestas:\", num_edges)\n",
    "\n",
    "# Calcular e exibir a densidade do grafo\n",
    "density = nx.density(G)\n",
    "print(\"Densidade do grafo:\", density)\n",
    "\n",
    "# Executar o comando e medir o tempo de execução usando timeit\n",
    "start_time = timeit.default_timer()\n",
    "result = nx.betweenness_centrality(G, k=10)\n",
    "end_time = timeit.default_timer()\n",
    "actual_time = end_time - start_time\n",
    "\n",
    "# Exibir o tempo real de execução\n",
    "print(\"Tempo real:\", actual_time)\n",
    "\n",
    "# Visualizar a distribuição da centralidade betweenness\n",
    "betweenness_data = pd.DataFrame(list(result.items()), columns=['Node', 'Betweenness Centrality'])\n",
    "\n",
    "chart = alt.Chart(betweenness_data).mark_bar().encode(\n",
    "    x=alt.X('Node:N', sort='-y'),\n",
    "    y=alt.Y('Betweenness Centrality:Q'),\n",
    "    tooltip=['Node', 'Betweenness Centrality']\n",
    ").properties(\n",
    "    title='Distribuição da Centralidade Betweenness'\n",
    ").interactive()\n",
    "\n",
    "chart.save('betweenness_centrality_distribution.json')\n",
    "\n",
    "# Exibir a distribuição da centralidade betweenness em formato tabular, ordenada de forma decrescente\n",
    "betweenness_data_sorted = betweenness_data.sort_values(by='Betweenness Centrality', ascending=False)\n",
    "print(betweenness_data_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G)  # Outras opções: circular_layout, spectral_layout, etc.\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install -c rapidsai -c nvidia pylibcugraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip3 install --extra-index-url https://pypi.nvidia.com/pylibcugraph-cu12 pylibcugraph_cu12-24.6.1-cp311-cp311-manylinux_2_28_x86_64.whl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beakerx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
