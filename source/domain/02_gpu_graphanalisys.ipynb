{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Utilizando como gerenciador de pacotes o Conda\n",
    "# !conda clean --all\n",
    "# %conda update --all\n",
    "\n",
    "## Utilizando como gerenciador de pacotes o PIP\n",
    "# !python.exe -m pip install --upgrade pip\n",
    "%pip install -U pip\n",
    "\n",
    "# %pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dados do ambiente local\n",
      "   Versão Python: 3.11.9\n",
      "  Versão PyTorch: 2.2.2\n",
      "CUDA não disponível, não está configurado corretamente.\n",
      "    CUDA Toolkit: release 12.5  V12.5.40\n",
      "      Build nvcc: Build cuda_12.5.r12.5/compiler.34177558_0\n",
      "\n",
      "Detalhes da biblioteca PyTorch\n",
      "Name: torch\n",
      "Version: 2.2.2\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /home/mak/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: contextualSpellCheck, curated-transformers, EasyNMT, sentence-transformers, spacy-curated-transformers, spacy-transformers, torchaudio, torchvision, torchviz\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    "print(f\"\\nDados do ambiente local\")\n",
    "# !nvcc --version\n",
    "def verificar_versoes():\n",
    "    \"\"\"Verifica e exibe as versões  da GPU, do Python e bibliotecas CUDA instaladas no sistema.\"\"\"\n",
    "\n",
    "    # Versão do Python\n",
    "    python_version = sys.version.split()[0]\n",
    "    print(f\"   Versão Python: {python_version}\")\n",
    "    print(f\"  Versão PyTorch: {torch.__version__}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  Versão do CUDA: {torch.version.cuda}\")\n",
    "        print(f\" Versão do cuDNN: {torch.backends.cudnn.version()}\")\n",
    "    else:\n",
    "        print(\"CUDA não disponível, não está configurado corretamente.\")\n",
    "\n",
    "    # Versão do CUDA (usando nvcc)\n",
    "    try:\n",
    "        cuda_version = subprocess.check_output([\"nvcc\", \"--version\"])\n",
    "        cuda_version_l3 = [' '.join(cuda_version.decode(\"utf-8\").strip().split(\"\\n\")[-2].split(',')[1:])][0].strip()\n",
    "        cuda_version_l4 = cuda_version.decode(\"utf-8\").strip().split(\"\\n\")[-1]\n",
    "        print(f\"    CUDA Toolkit: {cuda_version_l3}\")\n",
    "        print(f\"      Build nvcc: {cuda_version_l4}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"nvcc não encontrado. CUDA pode não estar instalado ou configurado corretamente.\")\n",
    "\n",
    "# Chamando a função para verificar as versões\n",
    "verificar_versoes()\n",
    "\n",
    "print(f\"\\nDetalhes da biblioteca PyTorch\")\n",
    "!pip3 show torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução 01: Sem mecanismo de atenção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "# Carregar modelo e tokenizer pré-treinados\n",
    "model_name = \"bert-base-uncased\"  # Escolha o modelo desejado\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(\"cuda\")  # Mover para GPU\n",
    "\n",
    "# Textos de entrada (exemplo)\n",
    "texts = [\n",
    "    \"This is a sentence about natural language processing.\",\n",
    "    \"Another sentence about NLP.\",\n",
    "    \"An unrelated sentence about dogs.\"\n",
    "]\n",
    "\n",
    "# Pré-processamento\n",
    "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Medir tempo de execução\n",
    "start_time = time.time()\n",
    "\n",
    "# Embedding\n",
    "with torch.no_grad():\n",
    "    embeddings = model(**encoded_input)[\"pooler_output\"].cpu().numpy()\n",
    "\n",
    "# Cálculo de similaridade\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Matriz de similaridade:\")\n",
    "print(similarity_matrix)\n",
    "\n",
    "print(f\"Tempo de execução: {end_time - start_time:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução 02: Com mecanismo de atenção\n",
    "\n",
    "A versão do CUDA precisa ser compatível com a Flash Attention. A Flash Attention foi introduzida no PyTorch 2.0 e requer CUDA 11.8 ou superior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - pypi\n",
      " - conda-forge\n",
      " - pytorch\n",
      " - defaults\n",
      " - rapidsai\n",
      " - nvidia\n",
      " - pytorch-nightly\n",
      " - pyg\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/mak/miniconda3/envs/rapids-24.08\n",
      "\n",
      "  removed specs:\n",
      "    - pytorch\n",
      "    - torchaudio\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "  aom-3.6.1-h59595ed_0\n",
      "  blas-1.0-mkl\n",
      "  cpuonly-2.0-0\n",
      "  ffmpeg-4.4.2-gpl_hdf48244_113\n",
      "  gmp-6.3.0-hac33072_2\n",
      "  gmpy2-2.1.5-py311hc4f1f91_1\n",
      "  gnutls-3.7.9-hb077bed_0\n",
      "  lame-3.100-h166bdaf_1003\n",
      "  libdrm-2.4.123-hb9d3cd8_0\n",
      "  libidn2-2.3.7-hd590300_0\n",
      "  libpciaccess-0.18-hd590300_0\n",
      "  libtasn1-4.19.0-h166bdaf_0\n",
      "  libunistring-0.9.10-h7f98852_0\n",
      "  libva-2.21.0-h4ab18f5_2\n",
      "  libvpx-1.13.1-h59595ed_0\n",
      "  llvm-openmp-15.0.7-h0cdce71_0\n",
      "  mpc-1.3.1-hfe3b2da_0\n",
      "  mpfr-4.2.1-h38ae2d0_2\n",
      "  mpmath-1.2.1-py311_0\n",
      "  nettle-3.9.1-h7ab15ed_0\n",
      "  openh264-2.3.1-hcb278e6_2\n",
      "  p11-kit-0.24.1-hc5aa10d_0\n",
      "  pyg-2.5.2-py311_torch_2.2.0_cpu\n",
      "  pytorch-2.2.2-py3.11_cpu_0\n",
      "  pytorch-mutex-1.0-cpu\n",
      "  svt-av1-1.4.1-hcb278e6_0\n",
      "  sympy-1.13.2-pypyh2585a3b_103\n",
      "  torchaudio-2.2.2-py311_cpu\n",
      "  torchvision-0.17.2-py311_cpu\n",
      "  x264-1!164.3095-h166bdaf_2\n",
      "  x265-3.5-h924138e_3\n",
      "  xorg-fixesproto-5.0-h7f98852_1002\n",
      "  xorg-libxfixes-5.0.3-h7f98852_1004\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  torchtriton        pytorch-nightly::torchtriton-3.0.0+de~ --> pkgs/main::torchtriton-2.3.0-cuda123py311hdb19cb5_0 \n",
      "\n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    }
   ],
   "source": [
    "# !conda uninstall pytorch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar o ambiente pelo Terminal:\n",
    "### Sempre atualizar versões mais recentes em https://pytorch.org/\n",
    "\n",
    "    conda create -n pytorch_env python=3.11\n",
    "    conda activate pytorch_env\n",
    "    conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch-nightly -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda config --add channels conda-forge\n",
    "# !conda config --add channels rapidsai\n",
    "# !conda config --add channels nvidia\n",
    "\n",
    "\n",
    "# %conda install -c rapidsai -c nvidia -c conda-forge pylibcugraph=24.6.1 cudatoolkit=12.5\n",
    "# %conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch-nightly -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'verificar_versoes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Chamando a função para verificar as versões\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mverificar_versoes\u001b[49m()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDetalhes da biblioteca PyTorch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip3 show torch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'verificar_versoes' is not defined"
     ]
    }
   ],
   "source": [
    "# Chamando a função para verificar as versões\n",
    "verificar_versoes()\n",
    "\n",
    "print(f\"\\nDetalhes da biblioteca PyTorch\")\n",
    "!pip3 show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "url = \"https://data.rapids.ai/cugraph/datasets/cit-Patents.csv\"\n",
    "df = pd.read_csv(url, sep=\" \", names=[\"src\", \"dst\"], dtype=\"int32\")\n",
    "G = nx.from_pandas_edgelist(df, source=\"src\", target=\"dst\")\n",
    "\n",
    "%time result = nx.betweenness_centrality(G, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Criar um grafo aleatório\n",
    "G = nx.gnp_random_graph(10, 0.3)\n",
    "\n",
    "# Definir um layout\n",
    "pos = nx.spring_layout(G) # Outras opções: circular_layout, spectral_layout, etc.\n",
    "\n",
    "# Desenhar o grafo com personalizações\n",
    "nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=500, font_size=10, font_color='black', width=2, edge_color='gray')\n",
    "\n",
    "# Mostrar o grafo\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimativas de tempo de execução \n",
    "\n",
    "Considerando detecção de características do grafo e recursos computacionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular e exibir o número de nós e arestas\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "print(\"Número de nós:\", num_nodes)\n",
    "print(\"Número de arestas:\", num_edges)\n",
    "\n",
    "# Calcular e exibir a densidade do grafo\n",
    "density = nx.density(G)\n",
    "print(\"Densidade do grafo:\", density)\n",
    "\n",
    "# Obter informações de hardware\n",
    "cpu_count = psutil.cpu_count(logical=True)\n",
    "ram_gb = psutil.virtual_memory().total / (1024 ** 3)\n",
    "\n",
    "# Estimar o tempo de execução (modelo simplificado)\n",
    "k = 10  # Valor de k usado no cálculo da centralidade\n",
    "estimated_time = (num_nodes * num_edges * density * k) / (cpu_count * ram_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar o comando e medir o tempo de execução\n",
    "# %time result = nx.betweenness_centrality(G, k=10)\n",
    "\n",
    "# Exibir o tempo estimado e o tempo real de execução\n",
    "print(\"Tempo estimado:\", estimated_time)\n",
    "print(\"Tempo real:\", _ # A variável mágica '_' contém o tempo de execução do último comando %)\n",
    "\n",
    "# Visualizar a distribuição da centralidade betweenness\n",
    "betweenness_data = pd.DataFrame(list(result.items()), columns=['Node', 'Betweenness Centrality'])\n",
    "\n",
    "chart = alt.Chart(betweenness_data).mark_bar().encode(\n",
    "    x=alt.X('Node:N', sort='-y'),\n",
    "    y=alt.Y('Betweenness Centrality:Q'),\n",
    "    tooltip=['Node', 'Betweenness Centrality']\n",
    ").properties(\n",
    "    title='Distribuição da Centralidade Betweenness'\n",
    ").interactive()\n",
    "\n",
    "chart.save('betweenness_centrality_distribution.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import timeit\n",
    "import altair as alt\n",
    "\n",
    "# Carregar o dataframe a partir da URL\n",
    "url = \"https://data.rapids.ai/cugraph/datasets/cit-Patents.csv\"\n",
    "df = pd.read_csv(url, sep=\" \", names=[\"src\", \"dst\"], dtype=\"int32\")\n",
    "\n",
    "# Criar o grafo a partir do dataframe\n",
    "G = nx.from_pandas_edgelist(df, source=\"src\", target=\"dst\")\n",
    "\n",
    "# Calcular e exibir o número de nós e arestas\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "print(\"Número de nós:\", num_nodes)\n",
    "print(\"Número de arestas:\", num_edges)\n",
    "\n",
    "# Calcular e exibir a densidade do grafo\n",
    "density = nx.density(G)\n",
    "print(\"Densidade do grafo:\", density)\n",
    "\n",
    "# Executar o comando e medir o tempo de execução usando timeit\n",
    "start_time = timeit.default_timer()\n",
    "result = nx.betweenness_centrality(G, k=10)\n",
    "end_time = timeit.default_timer()\n",
    "actual_time = end_time - start_time\n",
    "\n",
    "# Exibir o tempo real de execução\n",
    "print(\"Tempo real:\", actual_time)\n",
    "\n",
    "# Visualizar a distribuição da centralidade betweenness\n",
    "betweenness_data = pd.DataFrame(list(result.items()), columns=['Node', 'Betweenness Centrality'])\n",
    "\n",
    "chart = alt.Chart(betweenness_data).mark_bar().encode(\n",
    "    x=alt.X('Node:N', sort='-y'),\n",
    "    y=alt.Y('Betweenness Centrality:Q'),\n",
    "    tooltip=['Node', 'Betweenness Centrality']\n",
    ").properties(\n",
    "    title='Distribuição da Centralidade Betweenness'\n",
    ").interactive()\n",
    "\n",
    "chart.save('betweenness_centrality_distribution.json')\n",
    "\n",
    "# Exibir a distribuição da centralidade betweenness em formato tabular, ordenada de forma decrescente\n",
    "betweenness_data_sorted = betweenness_data.sort_values(by='Betweenness Centrality', ascending=False)\n",
    "print(betweenness_data_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G)  # Outras opções: circular_layout, spectral_layout, etc.\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install -c rapidsai -c nvidia pylibcugraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip3 install --extra-index-url https://pypi.nvidia.com/pylibcugraph-cu12 pylibcugraph_cu12-24.6.1-cp311-cp311-manylinux_2_28_x86_64.whl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beakerx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
