{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>ML, DL e GML para classificação de texto</b>\n",
    "## Avaliando evolução da aprendizagem supervisionada\n",
    "### Do básico em ML, DL com RNN, até DL com Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação do passo a passo inicial para preparar o ambiente:\n",
    "\n",
    "- Importar sys: Importa o módulo sys para acessar o executável do Python.\n",
    "\n",
    "- Criar o ambiente virtual:\n",
    "!{sys.executable} -m venv meu_ambiente: Executa o comando python -m venv meu_ambiente no terminal do sistema operacional, criando um ambiente virtual chamado \"meu_ambiente\". Substitua \"meu_ambiente\" pelo nome desejado para o seu ambiente.\n",
    "\n",
    "- Atualizar o pip:\n",
    "!{sys.executable} -m pip install --upgrade pip: Atualiza o pip dentro do novo ambiente virtual para garantir que você tenha a versão mais recente.\n",
    "\n",
    "- Instalar as dependências:\n",
    "!meu_ambiente\\Scripts\\pip.exe install -r requirements.txt: Executa o comando pip install -r requirements.txt dentro do ambiente virtual, instalando todas as dependências listadas no arquivo requirements.txt. Certifique-se de que o arquivo requirements.txt esteja no mesmo diretório do seu notebook.\n",
    "\n",
    "- Após a execução:\n",
    "\n",
    "- Ativar o ambiente: Para usar o ambiente virtual recém-criado, você precisa ativá-lo. No Jupyter Notebook, você pode fazer isso reiniciando o kernel e selecionando o novo ambiente na lista de kernels disponíveis.\n",
    "Verificar a instalação: Após ativar o ambiente, você pode verificar se os pacotes foram instalados corretamente executando !pip list em uma célula do notebook.\n",
    "\n",
    "Observações:\n",
    "\n",
    "Nome do ambiente: Substitua \"meu_ambiente\" pelo nome desejado para o seu ambiente virtual.\n",
    "\n",
    "Caminho do arquivo: Certifique-se de que o caminho para o arquivo requirements.txt esteja correto. Se o arquivo estiver em um diretório diferente, ajuste o caminho no comando de instalação.\n",
    "\n",
    "Permissões: Se você encontrar problemas de permissão durante a criação do ambiente ou a instalação dos pacotes, tente executar o Jupyter Notebook como administrador.\n",
    "\n",
    "Outras ferramentas: Se você preferir usar o conda para criar o ambiente virtual e instalar os pacotes, pode adaptar o código acima para usar os comandos conda em vez dos comandos venv e pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m venv py12\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!py12\\Scripts\\pip.exe install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Executar no terminal a instalação dos pacotes básicos\n",
    "# conda install -p c:\\Users\\marcos.aires\\ppgcs\\.conda ipykernel --update-deps --force-reinstall\n",
    "\n",
    "## Intalar o PyTorch conforme comandos obtidos em https://pytorch.org/get-started/locally/\n",
    "## Se o ambiente não possui GPU a seguinte linha de comando é suficiente:\n",
    "# %conda install pytorch torchvision torchaudio cpuonly -c pytorch-nightly\n",
    "\n",
    "## Se o ambiente possui uma GPU selecionar de acordo com os drivers CUDA respectivos, por exemplo:\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch-nightly -c nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenção e preparação dos dados (dataset e pré-processamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mA execução de células com '.conda (Python 3.12.4)' requer o pacote ipykernel.\n",
      "\u001b[1;31mExecute o seguinte comando para instalar \"ipykernel\" no ambiente do Python. \n",
      "\u001b[1;31mComando: \"conda install -p c:\\Users\\marcos.aires\\ppgcs\\.conda ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "## Atualizar o gerenciador de pacotes no terminal\n",
    "# python.exe -m pip install --upgrade pip --user\n",
    "\n",
    "# %pip show torch\n",
    "# %pip install torch -U\n",
    "\n",
    "## Verificar a versão instalada da biblioteca Transformers\n",
    "# %pip show transformers\n",
    "# %pip install --upgrade transformers\n",
    "# %pip install transformers\n",
    "\n",
    "## Atualizar dependências da biblioteca em caso de conflitos ao importar\n",
    "# %pip install transformers -U\n",
    "\n",
    "## Instalar a biblioteca sentence-transformers se ainda não estiver instalada\n",
    "%pip install --upgrade --force-reinstall sentence_transformers\n",
    "\n",
    "## Exemplo de conflito de dependências:\n",
    "# ImportError: tokenizers>=0.19,<0.20 is required for a normal functioning of this module, but found tokenizers==0.10.3.\n",
    "# Try: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main\n",
    "\n",
    "# %pip show numpy\n",
    "# %pip install --upgrade numpy\n",
    "# %pip install --upgrade --force-reinstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --force-reinstall --no-deps scipy==1.10.1\n",
    "%pip install scipy==1.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaxNLocator\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Carregue um modelo de embedding pré-treinado\n",
    "model_name = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Definir o dispositivo de cálculo como a GPU se disponível\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model = model.to(device) # Mova o modelo para dispositivo de cálculo\n",
    "\n",
    "# Carregar os dados\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import sklearn.metrics as skmetrics\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "# Carregar os subconjuntos de dados de treinamento e teste do dataset para dataframe\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Ler os nomes das classes disponíveis no dataset de treinamento\n",
    "newsgroups_train.target_names\n",
    "\n",
    "# Pré-processar os dados, removendo símbolos ou dados que não interessam ou atrapalham o processamento do texto\n",
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "  # Remover nomes, e-mails e palavras estranhas dos pontos de dados do dataset newsgroups.data\n",
    "  newsgroup_dataset.data = [re.sub(r'[\\w\\.-]+@[\\w\\.-]+', '', d) for d in newsgroup_dataset.data] # Remover email\n",
    "  newsgroup_dataset.data = [re.sub(r\"\", \"\", d) for d in newsgroup_dataset.data] # Remover names\n",
    "  newsgroup_dataset.data = [d.replace(\"From: \", \"\") for d in newsgroup_dataset.data] # Remover \"From: \"\n",
    "  newsgroup_dataset.data = [d.replace(\"\\nSubject: \", \"\") for d in newsgroup_dataset.data] # Remover \"\\nSubject: \"\n",
    "\n",
    "  # Definir um limite máximo para extensão de cada entrada de texto em 5.000 caracteres\n",
    "  newsgroup_dataset.data = [d[0:5000] if len(d) > 5000 else d for d in newsgroup_dataset.data]\n",
    "\n",
    "  # Popular os pontos de dados a estudar em uma estrutura de dataframe\n",
    "  df_processed = pd.DataFrame(newsgroup_dataset.data, columns=['Text'])\n",
    "  df_processed['Label'] = newsgroup_dataset.target\n",
    "  \n",
    "  # Corresponder cada rótulo ao índice de nome de destino\n",
    "  df_processed['Class Name'] = ''\n",
    "  for idx, row in df_processed.iterrows():\n",
    "    df_processed.at[idx, 'Class Name'] = newsgroup_dataset.target_names[row['Label']]\n",
    "\n",
    "  return df_processed\n",
    "\n",
    "# Aplicar função de pré-processamento ao conjuntos de dados de treinamento e teste\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montagem dos conjuntos de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "    # Agrupa por 'Label' e amostra 'num_samples' de cada grupo,\n",
    "    # excluindo as colunas de agrupamento da operação apply\n",
    "    df = (\n",
    "        df.groupby('Label', as_index=False)\n",
    "        .apply(lambda x: x.sample(num_samples), include_groups=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Filtra apenas as classes que contêm 'classes_to_keep' em 'Class Name'\n",
    "    df_filtered = df[df['Class Name'].str.contains(classes_to_keep)].copy() \n",
    "\n",
    "    # Garante que 'Class Name' seja do tipo category e remapeia os códigos\n",
    "    df_filtered['Class Name'] = df_filtered['Class Name'].astype('category')\n",
    "    df_filtered['Encoded Label'] = df_filtered['Class Name'].cat.codes\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# Defina os parâmetros de amostragem\n",
    "TRAIN_NUM_SAMPLES = 100\n",
    "TEST_NUM_SAMPLES = 25\n",
    "CLASSES_TO_KEEP = 'sci' # Class name should contain 'sci' in it to keep science categories\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "\n",
    "df_train.value_counts('Class Name')\n",
    "df_test.value_counts('Class Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentativa de carregar o modelo para GPU (se disponível)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar um modelo de embedding pré-treinado\n",
    "# Escolher um modelo mais adequado às necessidades do problema em análise\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Certifique-se de que você tem uma GPU disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device) # Mova o modelo para dispositivo de cálculo\n",
    "\n",
    "## Em caso de indisponibilidade de GPU local pode-se usar em Cloud por API\n",
    "# API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "# genai.configure(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de embeedings GPU local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(model, df):\n",
    "    # Codifique as frases em embeddings usando o modelo\n",
    "    embeddings = model.encode(df['Text'].tolist(), convert_to_tensor=True, device=device)\n",
    "    \n",
    "    # Converta os embeddings para uma lista de listas e armazene no DataFrame\n",
    "    df['Embeddings'] = embeddings.tolist()\n",
    "    return df\n",
    "\n",
    "# Crie os embeddings localmente\n",
    "df_train = create_embeddings(model, df_train)\n",
    "df_test = create_embeddings(model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construção do Modelo de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o modelo de classificação em PyTorch\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Derive o tamanho do embedding\n",
    "embedding_size = len(df_train['Embeddings'].iloc[0])\n",
    "\n",
    "# Crie o modelo\n",
    "classifier = ClassificationModel(embedding_size, len(df_train['Class Name'].unique())).to(device)\n",
    "print(classifier) \n",
    "\n",
    "# Defina a função de perda e o otimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir da versão 1.7 do PyTorch, a chamada optimizer.zero_grad() antes de loss.backward() não é mais estritamente necessária dentro do loop de treinamento. Agora, por padrão, zera os gradientes dos parâmetros otimizados antes de cada chamada de loss.backward(). Isso significa que os gradientes não se acumulam entre as iterações do loop de treinamento, o que era o comportamento anterior que exigia a chamada explícita de zero_grad().\n",
    "\n",
    "Quando ainda é necessário?\n",
    "\n",
    "Existem algumas situações específicas em que você ainda pode precisar chamar zero_grad() explicitamente:\n",
    "\n",
    "Otimizadores Múltiplos: Se você estiver usando vários otimizadores em seu código, pode ser necessário chamar zero_grad() em cada um deles antes de fazer o backward() para garantir que os gradientes sejam zerados corretamente para cada otimizador.\n",
    "\n",
    "Acúmulo de Gradientes: Em algumas arquiteturas de redes neurais, como RNNs com sequências longas, pode ser útil acumular gradientes em várias etapas antes de fazer a atualização dos parâmetros. Nesse caso, você precisaria chamar zero_grad() apenas no início da sequência e não a cada passo.\n",
    "\n",
    "Backward Múltiplo: Se você estiver chamando loss.backward() várias vezes em uma única iteração do loop de treinamento (por exemplo, para calcular gradientes em relação a diferentes perdas), você precisará chamar zero_grad() antes de cada chamada de backward() para evitar o acúmulo de gradientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros de treinamento\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Converta os dados para tensores e mova-os para a GPU\n",
    "x_train = torch.tensor(np.stack(df_train['Embeddings'])).float().to(device)\n",
    "y_train = torch.tensor(df_train['Encoded Label'].values).long().to(device) \n",
    "x_val = torch.tensor(np.stack(df_test['Embeddings'])).float().to(device)\n",
    "y_val = torch.tensor(df_test['Encoded Label'].values).long().to(device) \n",
    "\n",
    "# Listas para armazenar as métricas durante o treinamento\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Loop de treinamento\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Loop sobre os batches de treinamento\n",
    "    for i in range(0, len(x_train), BATCH_SIZE):\n",
    "        inputs = x_train[i:i+BATCH_SIZE]\n",
    "        labels = y_train[i:i+BATCH_SIZE]\n",
    "\n",
    "        # Zerar os gradientes\n",
    "        # optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = classifier(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Estatísticas\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Adicione as métricas de treinamento ao histórico\n",
    "    train_losses.append(running_loss / (len(x_train) // BATCH_SIZE))\n",
    "    train_accuracies.append(100 * correct / total)\n",
    "\n",
    "    # Avaliação no conjunto de validação a cada época\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = classifier(x_val)\n",
    "        val_loss = criterion(val_outputs, y_val)\n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        val_total = y_val.size(0)\n",
    "        val_correct = (val_predicted == y_val).sum().item()\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "    # Adicione as métricas de validação ao histórico\n",
    "    val_losses.append(val_loss.item())\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Imprima estatísticas de cada época\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {train_losses[-1]:.4f}, Accuracy: {train_accuracies[-1]:.2f}%, Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.2f}%')\n",
    "\n",
    "    # Volte para o modo de treinamento\n",
    "    classifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plotagem do histórico\n",
    "def plot_history(train_losses, train_accuracies, val_losses, val_accuracies):\n",
    "    \"\"\"\n",
    "      Plotting training and validation learning curves for Pytorch pipelines.\n",
    "\n",
    "      Args:\n",
    "        history: model history with all the metric measures\n",
    "    \"\"\"  \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(20, 8)\n",
    "\n",
    "    # Plot loss\n",
    "    ax1.set_title('Loss')\n",
    "    ax1.plot(train_losses, label='train')\n",
    "    ax1.plot(val_losses, label='test')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation'])\n",
    "\n",
    "    # Plot accuracy\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.plot(train_accuracies, label='train')\n",
    "    ax2.plot(val_accuracies, label='test')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando os gráficos de \"Loss\" (perda) e \"Accuracy\" (acurácia) gerados pela função plot_history, podemos identificar alguns pontos que indicam como o treinamento do modelo pode ser melhorado:\n",
    "\n",
    "Overfitting:\n",
    "\n",
    "Perda: A curva de perda de treinamento diminui consistentemente ao longo das épocas, enquanto a perda de validação diminui inicialmente, mas depois começa a aumentar. Esse comportamento é um forte indício de overfitting, ou seja, o modelo está aprendendo a se ajustar muito bem aos dados de treinamento, mas não está generalizando bem para novos dados (conjunto de validação).\n",
    "\n",
    "Acurácia: A acurácia de treinamento aumenta continuamente, enquanto a acurácia de validação atinge um platô e até diminui ligeiramente nas últimas épocas. Isso reforça a indicação de overfitting.\n",
    "Possíveis Melhorias:\n",
    "\n",
    "Regularização: Técnicas de regularização, como dropout ou L1/L2 regularization, podem ser adicionadas ao modelo para evitar o overfitting. O dropout desliga aleatoriamente algumas unidades da rede durante o treinamento, forçando o modelo a aprender representações mais robustas. A regularização L1/L2 adiciona um termo de penalidade à função de perda, desencorajando pesos grandes e complexidade excessiva do modelo.\n",
    "\n",
    "Aumento de Dados: Se possível, aumentar o conjunto de dados de treinamento com novas amostras ou aplicando transformações aos dados existentes pode ajudar o modelo a generalizar melhor.\n",
    "\n",
    "Early Stopping: O Early Stopping já parece estar sendo utilizado, pois o treinamento para em torno da época 18. No entanto, o ponto de parada poderia ser ajustado para interromper o treinamento ainda mais cedo, quando a perda de validação começar a aumentar.\n",
    "\n",
    "Redução da Taxa de Aprendizado: Reduzir a taxa de aprendizado ao longo do treinamento pode ajudar o modelo a convergir para um mínimo da função de perda de forma mais suave e evitar overshooting.\n",
    "\n",
    "Arquitetura do Modelo: Se as técnicas acima não forem suficientes, pode ser necessário reavaliar a arquitetura do modelo. Talvez o modelo seja complexo demais para os dados disponíveis, e uma arquitetura mais simples poderia generalizar melhor.\n",
    "\n",
    "Outras Considerações:\n",
    "\n",
    "Tamanho do Conjunto de Dados: O overfitting é mais comum quando o conjunto de dados de treinamento é pequeno. Se possível, coletar mais dados pode ser uma solução eficaz.\n",
    "Hiperparâmetros: Experimentar com diferentes valores para os hiperparâmetros do modelo, como a taxa de aprendizado, o número de camadas e o número de unidades por camada, também pode ajudar a melhorar o desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões no conjunto de validação com Pytorch\n",
    "with torch.no_grad():\n",
    "    y_hat = classifier(x_val)\n",
    "    _, y_hat = torch.max(y_hat.data, 1)\n",
    "\n",
    "# Converter os tensores para arrays NumPy\n",
    "y_val_np = y_val.cpu().numpy()\n",
    "y_hat_np = y_hat.cpu().numpy()\n",
    "\n",
    "# Criar o dicionário de rótulos\n",
    "labels_dict = dict(zip(df_test['Class Name'], df_test['Encoded Label']))\n",
    "\n",
    "# Calcular e plotar a matriz de confusão\n",
    "cm = skmetrics.confusion_matrix(y_val_np, y_hat_np)\n",
    "disp = skmetrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_dict.keys())\n",
    "disp.plot(xticks_rotation='vertical')\n",
    "plt.title('Confusion matrix for newsgroup test dataset')\n",
    "plt.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adicionar regularização para evitar Overfiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para adicionar as técnicas de regularização Dropout e L2 ao modelo PyTorch, adotamos.\n",
    "\n",
    "1. Dropout\n",
    "\n",
    "A camada de Dropout é adicionada após a primeira camada linear (fc1) e antes da função de ativação ReLU. Isso significa que, durante o treinamento, uma porcentagem dos neurônios nessa camada será desativada aleatoriamente, forçando o modelo a aprender representações mais robustas e menos propensas a overfitting.\n",
    "\n",
    "2. Regularização L2 (Weight Decay)\n",
    "\n",
    "A regularização L2 é implementada adicionando um termo de penalidade à função de perda. No PyTorch, isso é feito especificando o parâmetro weight_decay no otimizador.\n",
    "\n",
    "p=0.5 na camada de Dropout significa que 50% dos neurônios serão desativados aleatoriamente durante o treinamento. Você pode ajustar esse valor dependendo do seu problema e da quantidade de overfitting observada.\n",
    "weight_decay=0.0001 no otimizador: Esse valor controla a força da regularização L2. Valores maiores levam a uma regularização mais forte, o que pode ajudar a prevenir o overfitting, mas também pode prejudicar a capacidade do modelo de aprender padrões complexos nos dados. Você pode ajustar esse valor para encontrar um bom equilíbrio entre underfitting e overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, input_size)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Adicionar camada de Dropout com probabilidade de 0.5\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)  # Aplique o Dropout\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie o modelo classificador\n",
    "classifier = ClassificationModel(embedding_size, len(df_train['Class Name'].unique())).to(device)\n",
    "print(classifier)\n",
    "\n",
    "# Defina a função de perda e o otimizador com weight decay (adicione aqui)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001, weight_decay=0.0001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros de treinamento\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Converta os dados para tensores e mova-os para a GPU\n",
    "x_train = torch.tensor(np.stack(df_train['Embeddings'])).float().to(device)\n",
    "y_train = torch.tensor(df_train['Encoded Label'].values).long().to(device) \n",
    "x_val = torch.tensor(np.stack(df_test['Embeddings'])).float().to(device)\n",
    "y_val = torch.tensor(df_test['Encoded Label'].values).long().to(device) \n",
    "\n",
    "# Listas para armazenar as métricas durante o treinamento\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Loop de treinamento\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Loop sobre os batches de treinamento\n",
    "    for i in range(0, len(x_train), BATCH_SIZE):\n",
    "        inputs = x_train[i:i+BATCH_SIZE]\n",
    "        labels = y_train[i:i+BATCH_SIZE]\n",
    "\n",
    "        # Zerar os gradientes\n",
    "        # optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = classifier(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Estatísticas\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Adicione as métricas de treinamento ao histórico\n",
    "    train_losses.append(running_loss / (len(x_train) // BATCH_SIZE))\n",
    "    train_accuracies.append(100 * correct / total)\n",
    "\n",
    "    # Avaliação no conjunto de validação a cada época\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = classifier(x_val)\n",
    "        val_loss = criterion(val_outputs, y_val)\n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        val_total = y_val.size(0)\n",
    "        val_correct = (val_predicted == y_val).sum().item()\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "    # Adicione as métricas de validação ao histórico\n",
    "    val_losses.append(val_loss.item())\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Imprima estatísticas de cada época\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {train_losses[-1]:.4f}, Accuracy: {train_accuracies[-1]:.2f}%, Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.2f}%')\n",
    "\n",
    "    # Volte para o modo de treinamento\n",
    "    classifier.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar o desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise do Resultado do Retreinamento e Possíveis Melhorias\n",
    "Análise das Mudanças Implementadas:\n",
    "\n",
    "Comparando com o gráfico anterior, podemos observar que as técnicas de regularização (Dropout e L2) tiveram um impacto positivo no treinamento do modelo.\n",
    "\n",
    "Overfitting Reduzido: A diferença entre a perda de treinamento e a perda de validação diminuiu significativamente, indicando que o modelo está generalizando melhor para novos dados. A acurácia de validação também se manteve mais estável e próxima da acurácia de treinamento, confirmando essa melhora na generalização.\n",
    "\n",
    "Convergência mais Suave: As curvas de perda e acurácia agora apresentam uma tendência mais suave, sem oscilações abruptas, o que sugere que o modelo está aprendendo de forma mais estável e controlada.\n",
    "\n",
    "Possíveis Melhorias:\n",
    "\n",
    "Apesar das melhorias, ainda há espaço para otimizar o modelo:\n",
    "\n",
    "Acurácia de Validação: A acurácia de validação ainda pode ser melhorada. Embora tenha se estabilizado, ela não atingiu um valor muito alto. Isso indica que o modelo ainda pode estar subestimando os dados ou que há espaço para aprender padrões mais complexos.\n",
    "\n",
    "Hiperparâmetros: Experimentar com diferentes valores para os hiperparâmetros de regularização (taxa de dropout, weight decay) e do otimizador (taxa de aprendizado) pode levar a um melhor desempenho.\n",
    "\n",
    "Aumento de Dados: Se possível, aumentar o conjunto de dados de treinamento com novas amostras ou aplicando transformações aos dados existentes pode ajudar o modelo a generalizar ainda mais.\n",
    "\n",
    "Arquitetura do Modelo: Se as técnicas acima não forem suficientes, pode ser necessário reavaliar a arquitetura do modelo. Adicionar mais camadas ou usar diferentes tipos de camadas (como camadas convolucionais para processamento de texto) pode melhorar a capacidade do modelo de aprender representações mais complexas dos dados.\n",
    "\n",
    "Early Stopping: O Early Stopping pode ser ajustado para interromper o treinamento mais cedo se a perda de validação começar a aumentar novamente, evitando o overfitting em estágios posteriores.\n",
    "\n",
    "Próximos Passos:\n",
    "\n",
    "Ajuste de Hiperparâmetros: Realize uma busca sistemática pelos melhores valores dos hiperparâmetros, como taxa de aprendizado, weight decay e taxa de dropout, usando técnicas como grid search ou random search.\n",
    "Aumento de Dados: Explore técnicas de aumento de dados específicas para texto, como substituição de sinônimos, back translation ou mixup.\n",
    "Arquitetura do Modelo: Se as melhorias forem limitadas, experimente com arquiteturas mais complexas, como redes neurais recorrentes (RNNs) ou Transformers, que são conhecidas por seu bom desempenho em tarefas de processamento de linguagem natural.\n",
    "Early Stopping: Monitore a perda de validação durante o treinamento e ajuste o critério de Early Stopping para interromper o treinamento quando a perda começar a aumentar, evitando o overfitting.\n",
    "Conclusão:\n",
    "\n",
    "As técnicas de regularização já implementadas tiveram um impacto positivo no modelo, reduzindo o overfitting. No entanto, ainda há espaço para melhorias na acurácia de validação. Experimentar com ajuste de hiperparâmetros, aumento de dados, arquitetura do modelo e Early Stopping pode levar a um modelo ainda mais performático e generalizável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo no conjunto de validação\n",
    "classifier.eval()  # Colocar o modelo em modo de avaliação\n",
    "\n",
    "## Código PyTorch\n",
    "# Fazer previsões no conjunto de validação\n",
    "with torch.no_grad():\n",
    "    y_hat = classifier(x_val)\n",
    "    _, predicted = torch.max(y_hat.data, 1)\n",
    "    accuracy = (predicted == y_val).sum().item() / len(y_val)\n",
    "    print(f'Accuracy on validation set: {100 * accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de hiperparâmetros\n",
    "\n",
    "O ajuste de hiperparâmetros pode ser adotado com a técnica de Grid Search para encontrar os melhores valores para a taxa de aprendizado, weight decay e taxa de dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Defina os valores que você quer testar para cada hiperparâmetro\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.0001, 0.00001],  # Taxa de aprendizado\n",
    "    'weight_decay': [0.0001, 0.001, 0.01],  # Weight decay (L2 regularization)\n",
    "    'dropout_p': [0.2, 0.5, 0.7]  # Taxa de dropout\n",
    "}\n",
    "\n",
    "# Crie um iterador para percorrer todas as combinações de hiperparâmetros\n",
    "param_combinations = ParameterGrid(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo adaptado para ajustar hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mudanças:\n",
    "\n",
    "Adicionar linha para imprimir os hiperparâmetros que estão sendo testados em cada iteração do loop, o que ajuda a acompanhar o progresso do Grid Search: print(f\"Treinando com parâmetros: {params}\")\n",
    "\n",
    "Armazenar Métricas: Criar listas para armazenar as métricas de treinamento e validação para cada combinação de parâmetros, permitindo que você visualize o progresso do treinamento para cada configuração.\n",
    "\n",
    "Usar a última acurácia de validação (val_accuracies[-1]) para determinar se a combinação atual de parâmetros é a melhor:\n",
    "    if val_accuracies[-1] > best_accuracy:\n",
    "\n",
    "Salvar o Melhor Modelo (opcional): Adicionar linha para salvar o estado do melhor modelo encontrado durante o Grid Search. Carregar esse modelo posteriormente para fazer previsões ou continuar o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, dropout_p):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, input_size)\n",
    "        self.dropout = nn.Dropout(p=dropout_p) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis para armazenar os melhores resultados\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "# Loop sobre todas as combinações de hiperparâmetros\n",
    "for params in param_combinations:\n",
    "    print(f\"Treinando com parâmetros: {params}\")  # Adicione esta linha para acompanhar o progresso\n",
    "\n",
    "    # Crie o modelo com os hiperparâmetros atuais\n",
    "    classifier = ClassificationModel(embedding_size, len(df_train['Class Name'].unique()), params['dropout_p']).to(device)\n",
    "\n",
    "    # Defina a função de perda e o otimizador com os hiperparâmetros atuais\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(classifier.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
    "\n",
    "    # Listas para armazenar métricas de treinamento para esta combinação de parâmetros\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Loop de treinamento\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Loop sobre os batches de treinamento\n",
    "        for i in range(0, len(x_train), BATCH_SIZE):\n",
    "            inputs = x_train[i:i + BATCH_SIZE]\n",
    "            labels = y_train[i:i + BATCH_SIZE]\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = classifier(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Estatísticas\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Adicione as métricas de treinamento ao histórico\n",
    "        train_losses.append(running_loss / (len(x_train) // BATCH_SIZE))\n",
    "        train_accuracies.append(100 * correct / total)\n",
    "\n",
    "        # Avaliação no conjunto de validação a cada época\n",
    "        classifier.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = classifier(x_val)\n",
    "            val_loss = criterion(val_outputs, y_val)\n",
    "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "            val_total = y_val.size(0)\n",
    "            val_correct = (val_predicted == y_val).sum().item()\n",
    "            val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "        # Adicione as métricas de validação ao histórico\n",
    "        val_losses.append(val_loss.item())\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Imprima estatísticas de cada época para esta combinação de parâmetros\n",
    "        print(\n",
    "            f'Epoch [{epoch + 1}/{NUM_EPOCHS}], Loss: {train_losses[-1]:.4f}, Accuracy: {train_accuracies[-1]:.2f}%, '\n",
    "            f'Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.2f}%'\n",
    "        )\n",
    "\n",
    "        # Volte para o modo de treinamento\n",
    "        classifier.train()\n",
    "\n",
    "    # Verifique se esta combinação de parâmetros é a melhor até agora\n",
    "    if val_accuracies[-1] > best_accuracy:  # Use a última acurácia de validação\n",
    "        best_accuracy = val_accuracies[-1]\n",
    "        best_params = params\n",
    "\n",
    "        # Opcional: Salve o melhor modelo\n",
    "        torch.save(classifier.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Imprima os melhores resultados\n",
    "print(f'Best validation accuracy: {best_accuracy:.2f}%')\n",
    "print('Best parameters:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo no conjunto de validação\n",
    "classifier.eval()  # Colocar o modelo em modo de avaliação\n",
    "\n",
    "## Código PyTorch\n",
    "# Fazer previsões no conjunto de validação\n",
    "with torch.no_grad():\n",
    "    y_hat = classifier(x_val)\n",
    "    _, predicted = torch.max(y_hat.data, 1)\n",
    "    accuracy = (predicted == y_val).sum().item() / len(y_val)\n",
    "    print(f'Accuracy on validation set: {100 * accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação geral\n",
    "\n",
    "As novas curvas mostram um processo de treinamento muito mais saudável em comparação com as anteriores. A lacuna entre o treinamento e a perda de validação diminuiu significativamente, e ambas as curvas estão diminuindo suavemente, sugerindo que o overfitting foi efetivamente mitigado. A precisão da validação também está mostrando uma clara tendência ascendente, atingindo um platô no final, o que é um bom sinal.\n",
    "\n",
    "Observações específicas\n",
    "\n",
    "Perda: A perda de treinamento e validação diminui constantemente, com a perda de validação seguindo de perto a perda de treinamento. Isso indica uma boa generalização.\n",
    "A perda de validação final é relativamente baixa, o que implica que o modelo está ajustando bem os dados.\n",
    "\n",
    "Precisão: A precisão do treinamento aumenta rapidamente e atinge um valor alto.\n",
    "A precisão da validação também aumenta constantemente, embora em um ritmo um pouco mais lento do que a precisão do treinamento.\n",
    "A lacuna entre a precisão do treinamento e da validação é pequena, confirmando ainda mais que o overfitting está sob controle.\n",
    "\n",
    "Melhorias potenciais\n",
    "\n",
    "Embora os resultados sejam promissores, sempre há espaço para melhorias adicionais:\n",
    "\n",
    "Ajuste fino de hiperparâmetros: embora os resultados atuais sejam bons, há uma possibilidade de atingir um desempenho ainda melhor ajustando ainda mais os hiperparâmetros. Você pode tentar uma busca de grade mais extensa ou explorar outros algoritmos de otimização.\n",
    "\n",
    "Parada antecipada: embora não seja estritamente necessário neste caso, você ainda pode implementar a parada antecipada para evitar qualquer possível overfitting nas épocas posteriores, especialmente se você planeja treinar por uma duração mais longa.\n",
    "\n",
    "Arquitetura do modelo: se você está buscando desempenho de ponta, pode experimentar arquiteturas mais complexas como Redes Neurais Recorrentes (RNNs) ou Transformers, que são conhecidas por se destacarem em tarefas de processamento de linguagem natural.\n",
    "\n",
    "Aumento de dados: se você tiver acesso a mais dados ou puder gerar dados sintéticos, aumentar seu conjunto de treinamento pode melhorar ainda mais os recursos de generalização do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste fino de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# 1. Grid Search mais Extenso\n",
    "\n",
    "# Expandimos a grade de hiperparâmetros\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.0005, 0.0001],           # Taxa de aprendizado com mais opções\n",
    "    'weight_decay': [0.0001, 0.0005, 0.001],  # Weight decay com mais opções\n",
    "    'dropout_p': [0.3, 0.4, 0.5, 0.6]         # Taxa de dropout com mais opções\n",
    "    # 'batch_size': [16, 32, 64]              # Opcional: testar diferentes tamanhos de batch\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search mais Extenso:\n",
    "\n",
    "Adicionamos mais valores para os hiperparâmetros lr e weight_decay, permitindo uma exploração mais detalhada do espaço de busca.\n",
    "\n",
    "Incluímos mais opções para a taxa de dropout (dropout_p), o que pode ajudar a encontrar um equilíbrio ideal entre regularização e capacidade de aprendizado.\n",
    "Opcionalmente, você pode adicionar o batch_size à grade de hiperparâmetros para testar diferentes tamanhos de batch.\n",
    "\n",
    "Algoritmo de Otimização Diferente:\n",
    "\n",
    "Substituímos o otimizador Adam por SGD com momentum.\n",
    "O momentum ajuda a acelerar o treinamento e a superar oscilações na superfície de erro, o que pode levar a uma convergência mais rápida e a um melhor desempenho em alguns casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis para armazenar os melhores resultados\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "# Loop sobre todas as combinações de hiperparâmetros\n",
    "for params in param_combinations:\n",
    "    print(f\"Treinando com parâmetros: {params}\")  # Adicione esta linha para acompanhar o progresso\n",
    "\n",
    "    # Crie o modelo com os hiperparâmetros atuais\n",
    "    classifier = ClassificationModel(embedding_size, len(df_train['Class Name'].unique()), params['dropout_p']).to(device)\n",
    "\n",
    "    # Defina a função de perda e o otimizador com os hiperparâmetros atuais\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.Adam(classifier.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
    "    optimizer = optim.SGD(classifier.parameters(), lr=params['lr'], momentum=0.9, weight_decay=params['weight_decay']) \n",
    "\n",
    "    # Listas para armazenar métricas de treinamento para esta combinação de parâmetros\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Loop de treinamento\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Loop sobre os batches de treinamento\n",
    "        for i in range(0, len(x_train), BATCH_SIZE):\n",
    "            inputs = x_train[i:i + BATCH_SIZE]\n",
    "            labels = y_train[i:i + BATCH_SIZE]\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = classifier(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Estatísticas\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Adicione as métricas de treinamento ao histórico\n",
    "        train_losses.append(running_loss / (len(x_train) // BATCH_SIZE))\n",
    "        train_accuracies.append(100 * correct / total)\n",
    "\n",
    "        # Avaliação no conjunto de validação a cada época\n",
    "        classifier.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = classifier(x_val)\n",
    "            val_loss = criterion(val_outputs, y_val)\n",
    "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "            val_total = y_val.size(0)\n",
    "            val_correct = (val_predicted == y_val).sum().item()\n",
    "            val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "        # Adicione as métricas de validação ao histórico\n",
    "        val_losses.append(val_loss.item())\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Imprima estatísticas de cada época para esta combinação de parâmetros\n",
    "        print(\n",
    "            f'Epoch [{epoch + 1}/{NUM_EPOCHS}], Loss: {train_losses[-1]:.4f}, Accuracy: {train_accuracies[-1]:.2f}%, '\n",
    "            f'Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.2f}%'\n",
    "        )\n",
    "\n",
    "        # Volte para o modo de treinamento\n",
    "        classifier.train()\n",
    "\n",
    "    # Verifique se esta combinação de parâmetros é a melhor até agora\n",
    "    if val_accuracies[-1] > best_accuracy:  # Use a última acurácia de validação\n",
    "        best_accuracy = val_accuracies[-1]\n",
    "        best_params = params\n",
    "\n",
    "        # Opcional: Salve o melhor modelo\n",
    "        torch.save(classifier.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Imprima os melhores resultados\n",
    "print(f'Best validation accuracy: {best_accuracy:.2f}%')\n",
    "print('Best parameters:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo no conjunto de validação\n",
    "classifier.eval()  # Colocar o modelo em modo de avaliação\n",
    "\n",
    "## Código PyTorch\n",
    "# Fazer previsões no conjunto de validação\n",
    "with torch.no_grad():\n",
    "    y_hat = classifier(x_val)\n",
    "    _, predicted = torch.max(y_hat.data, 1)\n",
    "    accuracy = (predicted == y_val).sum().item() / len(y_val)\n",
    "    print(f'Accuracy on validation set: {100 * accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Agregar estratégias de aprimoramento clássicas</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementar o Early Stopping para evita novo Overfiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar: Importamos ReduceLROnPlateau para reduzir a taxa de aprendizado quando a validação para de melhorar.\n",
    "\n",
    "### Early Stopping:\n",
    "\n",
    "    early_stopping_patience: Define o número de épocas consecutivas sem melhora na perda de validação antes de parar o treinamento.\n",
    "\n",
    "    early_stopping_counter: Contador para rastrear o número de épocas sem melhora.\n",
    "\n",
    "    best_val_loss: Armazena a melhor perda de validação até o momento.\n",
    "\n",
    "### Scheduler:\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=1): Cria um scheduler que reduz a taxa de aprendizado quando a métrica monitorada (val_loss) para de melhorar por um número de épocas especificado (patience). O modo 'min' indica que queremos minimizar a métrica.\n",
    "\n",
    "### Atualizar os valores dos melhores hiperparâmetros:\n",
    "\n",
    "    Após a avaliação no conjunto de validação: Se a val_loss atual for menor que a best_val_loss, atualizar best_val_loss e reiniciamos o contador early_stopping_counter.\n",
    "\n",
    "    Caso contrário, incrementamos o contador. Se o contador atingir o limite de paciência (early_stopping_patience), interromper o treinamento.\n",
    "\n",
    "### Reduzir Taxa de Aprendizado:\n",
    "\n",
    "    scheduler.step(val_loss): Chamar o scheduler para verificar se a val_loss melhorou e, se não, reduzir a taxa de aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import sklearn.metrics as skmetrics\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Instale a biblioteca sentence-transformers se ainda não estiver instalada\n",
    "# !pip install -q sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Carregue um modelo de embedding pré-treinado\n",
    "model_name = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Certifique-se de que você tem uma GPU disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)  # Mova o modelo para a GPU\n",
    "\n",
    "# Carregue os dados\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "# Função para pré-processar os dados\n",
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "  # Apply functions to remove names, emails, and extraneous words from data points in newsgroups.data\n",
    "  newsgroup_dataset.data = [re.sub(r'[\\w\\.-]+@[\\w\\.-]+', '', d) for d in newsgroup_dataset.data] # Remove email\n",
    "  newsgroup_dataset.data = [re.sub(r\"\", \"\", d) for d in newsgroup_dataset.data] # Remove names\n",
    "  newsgroup_dataset.data = [d.replace(\"From: \", \"\") for d in newsgroup_dataset.data] # Remove \"From: \"\n",
    "  newsgroup_dataset.data = [d.replace(\"\\nSubject: \", \"\") for d in newsgroup_dataset.data] # Remove \"\\nSubject: \"\n",
    "\n",
    "  # Cut off each text entry after 5,000 characters\n",
    "  newsgroup_dataset.data = [d[0:5000] if len(d) > 5000 else d for d in newsgroup_dataset.data]\n",
    "\n",
    "  # Put data points into dataframe\n",
    "  df_processed = pd.DataFrame(newsgroup_dataset.data, columns=['Text'])\n",
    "  df_processed['Label'] = newsgroup_dataset.target\n",
    "  # Match label to target name index\n",
    "  df_processed['Class Name'] = ''\n",
    "  for idx, row in df_processed.iterrows():\n",
    "    df_processed.at[idx, 'Class Name'] = newsgroup_dataset.target_names[row['Label']]\n",
    "\n",
    "  return df_processed\n",
    "\n",
    "# Apply preprocessing function to training and test datasets\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de embeedings GPU local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(model, df):\n",
    "    # Codifique as frases em embeddings usando o modelo\n",
    "    embeddings = model.encode(df['Text'].tolist(), convert_to_tensor=True, device=device)\n",
    "    \n",
    "    # Converta os embeddings para uma lista de listas e armazene no DataFrame\n",
    "    df['Embeddings'] = embeddings.tolist()\n",
    "    return df\n",
    "\n",
    "# Crie os embeddings localmente\n",
    "df_train = create_embeddings(model, df_train)\n",
    "df_test = create_embeddings(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para amostrar os dados\n",
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "    # Agrupa por 'Label' e amostra 'num_samples' de cada grupo, exclui colunas de agrupamento da operação apply\n",
    "    df = (\n",
    "        df.groupby('Label', as_index=False)\n",
    "        .apply(lambda x: x.sample(num_samples), include_groups=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Filtra apenas as classes que contêm 'classes_to_keep' em 'Class Name'\n",
    "    df_filtered = df[df['Class Name'].str.contains(classes_to_keep)].copy() \n",
    "\n",
    "    # Garante que 'Class Name' seja do tipo category e remapeia os códigos\n",
    "    # Recria a coluna Label, agora contendo os rótulos incorporados (\"Encoded_Label\")\n",
    "    df_filtered['Class Name'] = df_filtered['Class Name'].astype('category')\n",
    "    df_filtered['Label'] = df_filtered['Class Name'].cat.codes\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# Definir parâmetros de amostragem\n",
    "TRAIN_NUM_SAMPLES = 100\n",
    "TEST_NUM_SAMPLES = 25\n",
    "CLASSES_TO_KEEP = 'sci'\n",
    "\n",
    "# Aplicar função de amostragem\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "\n",
    "# Criar embeddings localmente\n",
    "df_train = create_embeddings(model, df_train)\n",
    "df_test = create_embeddings(model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir modelo de classificação em PyTorch com Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelo de classificação em PyTorch com Dropout\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, dropout_p):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, input_size)\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Derivar tamanho do embedding\n",
    "embedding_size = len(df_train['Embeddings'].iloc[0])\n",
    "\n",
    "# Grid Search mais Extenso\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.0005, 0.0001],\n",
    "    'weight_decay': [0.0001, 0.0005, 0.001],\n",
    "    'dropout_p': [0.3, 0.4, 0.5, 0.6]\n",
    "    # 'batch_size': [16, 32, 64]  # Opcional: testar diferentes tamanhos de batch\n",
    "}\n",
    "\n",
    "param_combinations = ParameterGrid(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros de treinamento\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Converta os dados para tensores e mova-os para a GPU\n",
    "x_train = torch.tensor(np.stack(df_train['Embeddings'])).float().to(device)\n",
    "y_train = torch.tensor(df_train['Label'].values).long().to(device) \n",
    "x_val = torch.tensor(np.stack(df_test['Embeddings'])).float().to(device)\n",
    "y_val = torch.tensor(df_test['Label'].values).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis para armazenar os melhores resultados\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "# Loop sobre todas as combinações de hiperparâmetros\n",
    "for params in param_combinations:\n",
    "    print(f\"Treinando com parâmetros: {params}\")\n",
    "\n",
    "    # Crie o modelo com os hiperparâmetros atuais\n",
    "    classifier = ClassificationModel(embedding_size, len(df_train['Class Name'].unique()), params['dropout_p']).to(device)\n",
    "\n",
    "    # Defina a função de perda e o otimizador com os hiperparâmetros atuais    \n",
    "    # optimizer = optim.SGD(classifier.parameters(), lr=params['lr'], momentum=0.9, weight_decay=params['weight_decay']) # Opcional: usar SGD com momentum\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = optim.Adam(classifier.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
    "\n",
    "    # Defina o Early Stopping\n",
    "    early_stopping_patience = 3 \n",
    "    early_stopping_counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # Scheduler para reduzir a taxa de aprendizado\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=1)\n",
    "\n",
    "    # Listas para armazenar métricas de treinamento para esta combinação de parâmetros\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Loop de treinamento com Early Stopping\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Loop sobre os batches de treinamento\n",
    "        for i in range(0, len(x_train), BATCH_SIZE):\n",
    "            inputs = x_train[i:i + BATCH_SIZE]\n",
    "            labels = y_train[i:i + BATCH_SIZE]\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = classifier(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Estatísticas\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Adicione as métricas de treinamento ao histórico\n",
    "        train_losses.append(running_loss / (len(x_train) // BATCH_SIZE))\n",
    "        train_accuracies.append(100 * correct / total)\n",
    "\n",
    "        # Avaliação no conjunto de validação a cada época\n",
    "        classifier.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = classifier(x_val)\n",
    "            val_loss = criterion(val_outputs, y_val)\n",
    "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "            val_total = y_val.size(0)\n",
    "            val_correct = (val_predicted == y_val).sum().item()\n",
    "            val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "        # Adicione as métricas de validação ao histórico\n",
    "        val_losses.append(val_loss.item())\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Early Stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(\"Early stopping!\")\n",
    "\n",
    "                break\n",
    "\n",
    "        # Reduza a taxa de aprendizado se a validação não melhorar\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Imprima estatísticas de cada época para esta combinação de parâmetros\n",
    "        print(\n",
    "            f'Epoch [{epoch + 1}/{NUM_EPOCHS}], Loss: {train_losses[-1]:.4f}, Accuracy: {train_accuracies[-1]:.2f}%, '\n",
    "            f'Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.2f}%'\n",
    "        )\n",
    "\n",
    "        # Volte para o modo de treinamento\n",
    "        classifier.train()\n",
    "\n",
    "    # Verifique se esta combinação de parâmetros é a melhor até agora\n",
    "    if val_accuracies[-1] > best_accuracy:\n",
    "        best_accuracy = val_accuracies[-1]\n",
    "        best_params = params\n",
    "\n",
    "        # Opcional: Salve o melhor modelo\n",
    "        torch.save(classifier.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Imprima os melhores resultados\n",
    "print(f'Best validation accuracy: {best_accuracy:.2f}%')\n",
    "print('Best parameters:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plotagem do histórico\n",
    "def plot_history(train_losses, train_accuracies, val_losses, val_accuracies):\n",
    "    \"\"\"\n",
    "      Plotting training and validation learning curves for Pytorch pipelines.\n",
    "\n",
    "      Args:\n",
    "        history: model history with all the metric measures\n",
    "    \"\"\"  \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(20, 8)\n",
    "\n",
    "    # Plot loss\n",
    "    ax1.set_title('Loss')\n",
    "    ax1.plot(train_losses, label='train')\n",
    "    ax1.plot(val_losses, label='test')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation'])\n",
    "\n",
    "    # Plot accuracy\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.plot(train_accuracies, label='train')\n",
    "    ax2.plot(val_accuracies, label='test')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo no conjunto de validação\n",
    "classifier.eval()  # Colocar o modelo em modo de avaliação\n",
    "\n",
    "## Código PyTorch\n",
    "# Fazer previsões no conjunto de validação\n",
    "with torch.no_grad():\n",
    "    y_hat = classifier(x_val)\n",
    "    _, predicted = torch.max(y_hat.data, 1)\n",
    "    accuracy = (predicted == y_val).sum().item() / len(y_val)\n",
    "    print(f'Accuracy on validation set: {100 * accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões no conjunto de validação com Pytorch\n",
    "with torch.no_grad():\n",
    "    y_hat = classifier(x_val)\n",
    "    _, y_hat = torch.max(y_hat.data, 1)\n",
    "\n",
    "# Converter os tensores para arrays NumPy\n",
    "y_val_np = y_val.cpu().numpy()\n",
    "y_hat_np = y_hat.cpu().numpy()\n",
    "\n",
    "# Criar o dicionário de rótulos\n",
    "labels_dict = dict(zip(df_test['Class Name'], df_test['Label']))\n",
    "\n",
    "# Calcular e plotar a matriz de confusão\n",
    "cm = skmetrics.confusion_matrix(y_val_np, y_hat_np)\n",
    "disp = skmetrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_dict.keys())\n",
    "disp.plot(xticks_rotation='vertical')\n",
    "plt.title('Confusion matrix for newsgroup test dataset')\n",
    "plt.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline RNN completo \n",
    "\n",
    "Utilização de Grid Search, Early Stopping e Avaliações (versão atualizada com DataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos implementar uma arquitetura de Rede Neural Recorrente (RNN) para o seu problema de classificação de texto. Usaremos uma camada LSTM (Long Short-Term Memory), que é um tipo popular de RNN capaz de lidar com dependências de longo prazo em sequências de texto. \n",
    "\n",
    "As RNNs precisam de dados de entrada em formato de sequências numéricas. Precisamos tokenizar o texto e convertê-lo em embeddings de palavras. Vamos usar a biblioteca torchtext para facilitar esse processo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pontos importantes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No pipeline RNN apresentado, a criação dos embeddings pode ocorrer em dois momentos distintos, em resumo, se estivermos usando embeddings pré-treinados, a criação dos embeddings já foi feita durante o pré-treinamento do modelo utilizado. Por outro lado, se não estivermos usando embeddings pré-treinados, a criação dos embeddings ocorre dinamicamente durante o treinamento da RNN, dentro da camada de embedding.:\n",
    "\n",
    "1. Pré-treinamento (opcional): Quando utilizamos embeddings pré-treinados (como os do modelo paraphrase-multilingual-MiniLM-L12-v2 carregado com a biblioteca sentence-transformers), os embeddings já foram criados durante o pré-treinamento desse modelo em um grande corpus de texto.\n",
    "\n",
    "- Nesse caso, você não precisa criar os embeddings explicitamente no seu código, apenas carrega o modelo pré-treinado e o utiliza para obter os embeddings das suas frases de entrada.\n",
    "\n",
    "2. Durante o treinamento da RNN: Se você não estiver usando embeddings pré-treinados, a criação dos embeddings acontece dentro da camada de embedding (self.embedding) da sua classe RNNModel.\n",
    "\n",
    "- A camada de embedding recebe como entrada os índices dos tokens (sequências numéricas representando as palavras) e mapeia cada índice para um vetor denso de tamanho embedding_dim.\n",
    "\n",
    "- Esses vetores densos são os embeddings que representam as palavras no espaço vetorial contínuo, capturando seus significados e relações semânticas.\n",
    "\n",
    "- A camada de embedding é treinada juntamente com o resto do modelo RNN, de forma que os embeddings sejam ajustados para a tarefa específica de classificação de texto que você está realizando.\n",
    "\n",
    "\n",
    "Ou seja, a mesma definição de modelo RNNModel pode ser usada tanto com embeddings pré-treinados quanto com embeddings treinados durante o processo. A definição do modelo RNNModel é flexível o suficiente para lidar com ambos os cenários: embeddings pré-treinados e embeddings treinados durante o processo. A camada de embedding self.embedding é usada apenas quando você não está fornecendo embeddings pré-treinados ao modelo. Para utilizar a mesma definição de modelo em ambos os casos, adaptamos apenas a forma de preparar os dados de entrada (usando embeddings pré-treinados ou gerando-os durante o treinamento).\n",
    "\n",
    "A chave para essa flexibilidade está na camada de embedding (self.embedding). Vamos analisar como ela funciona em cada cenário:\n",
    "\n",
    "1. Para usar embeddings Pré-Treinados\n",
    "\n",
    "Nesse caso, você carrega um modelo de linguagem pré-treinado (como o BERT) que já possui uma camada de embedding interna.\n",
    "\n",
    "Você extrai os embeddings das suas frases usando esse modelo pré-treinado e os passa como entrada para a sua RNN.\n",
    "\n",
    "A camada de embedding self.embedding na sua classe RNNModel não é utilizada nesse cenário, pois os embeddings já foram gerados externamente.\n",
    "\n",
    "O vocab_size e o embedding_dim na definição do modelo são usados apenas para garantir a compatibilidade com os embeddings pré-treinados.\n",
    "\n",
    "2. Para usar embeddings Treinados Durante o Processo\n",
    "\n",
    "Nesse caso, você não utiliza embeddings pré-treinados.\n",
    "\n",
    "A camada de embedding self.embedding na sua classe RNNModel é responsável por criar os embeddings a partir dos índices dos tokens de entrada.\n",
    "\n",
    "O vocab_size representa o tamanho do seu vocabulário (o número de palavras únicas nos seus dados), e o embedding_dim define o tamanho dos vetores densos que representarão cada palavra.\n",
    "\n",
    "Os embeddings são inicializados aleatoriamente e são ajustados durante o treinamento da RNN, juntamente com os outros parâmetros do modelo, para otimizar o desempenho na tarefa de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem diversas formas de otimizar o treinamento com PyTorch, e a melhor abordagem dependerá do seu problema específico, dos seus dados e dos recursos computacionais disponíveis. Aqui estão algumas das técnicas mais comuns e eficazes:\n",
    "\n",
    "1. Otimizadores\n",
    "\n",
    "Escolha do Otimizador: O PyTorch oferece uma variedade de otimizadores, cada um com suas próprias características e vantagens. Alguns dos mais populares incluem:\n",
    "\n",
    "- Adam: Geralmente uma boa escolha inicial, com adaptação automática da taxa de aprendizado para cada parâmetro.\n",
    "- SGD (Stochastic Gradient Descent): Mais simples e fácil de entender, mas pode exigir ajuste manual da taxa de aprendizado e momentum.\n",
    "- RMSprop: Similar ao Adam, mas com um cálculo diferente da taxa de aprendizado adaptativa.\n",
    "- Outros: AdaGrad, Adadelta, Adagrad, etc. Experimente diferentes otimizadores para ver qual funciona melhor para o seu problema.\n",
    "- Ajuste de Hiperparâmetros: O desempenho do otimizador pode ser significativamente afetado pelos seus hiperparâmetros (taxa de aprendizado, momentum, etc.). Utilize técnicas como Grid Search ou Random Search para encontrar os melhores valores para esses hiperparâmetros.\n",
    "\n",
    "2. Funções de Perda\n",
    "\n",
    "Escolha da Função de Perda: A função de perda mede o quão bem o modelo está se saindo durante o treinamento. Escolha a função de perda apropriada para o seu problema (por exemplo, nn.CrossEntropyLoss para classificação multiclasse, nn.MSELoss para regressão, etc.).\n",
    "\n",
    "Perdas Personalizadas: Em alguns casos, pode ser necessário definir sua própria função de perda personalizada para lidar com requisitos específicos do seu problema.\n",
    "\n",
    "3. Técnicas de Regularização\n",
    "\n",
    "- Dropout: Você já está usando Dropout em seu modelo RNN. Essa é uma técnica eficaz para prevenir o overfitting, mas você pode experimentar diferentes taxas de dropout para encontrar o valor ideal.\n",
    "- Weight Decay (L2 Regularization): Você também está usando weight decay no seu otimizador. Ajuste o valor do weight_decay para controlar a força da regularização.\n",
    "- Outras Técnicas: Outras técnicas de regularização, como Batch Normalization ou Layer Normalization, também podem ser úteis, dependendo da arquitetura do seu modelo.\n",
    "\n",
    "4. Aumento de Dados\n",
    "\n",
    "- Geração de Novos Dados: Se possível, aumente o seu conjunto de dados de treinamento gerando novas amostras ou aplicando transformações aos dados existentes. Isso pode ajudar o modelo a generalizar melhor.\n",
    "- Técnicas Específicas para Texto: Para dados de texto, você pode usar técnicas como substituição de sinônimos, back translation ou mixup para gerar novas amostras de treinamento.\n",
    "\n",
    "5. Early Stopping\n",
    "\n",
    "Monitoramento do Desempenho: Você já está usando Early Stopping para interromper o treinamento quando a perda de validação para de melhorar. Certifique-se de ajustar a patience (número de épocas sem melhora antes de parar) de acordo com o seu problema.\n",
    "\n",
    "6. Técnicas Avançadas\n",
    "\n",
    "**Transfer Learning:** Se você tiver um conjunto de dados pequeno, considere usar um modelo pré-treinado em uma tarefa relacionada e ajustar os seus parâmetros para a sua tarefa específica. Isso pode acelerar o treinamento e melhorar o desempenho.\n",
    "\n",
    "- Agendamento da Taxa de Aprendizado: Reduza a taxa de aprendizado ao longo do treinamento para ajudar o modelo a convergir para um mínimo da função de perda de forma mais suave. Você já está usando ReduceLROnPlateau para isso, mas pode experimentar outros agendadores, como StepLR ou CosineAnnealingLR.\n",
    "\n",
    "- Otimização de Hiperparâmetros: Além do Grid Search, explore outras técnicas de otimização de hiperparâmetros, como Random Search ou algoritmos baseados em Bayesian Optimization, para encontrar a melhor configuração de forma mais eficiente.\n",
    "\n",
    "Recomendações:\n",
    "\n",
    "Comece com o básico: Certifique-se de que você está usando um bom otimizador, uma função de perda adequada e técnicas de regularização básicas antes de partir para técnicas mais avançadas.\n",
    "\n",
    "Experimente e Avalie: O processo de otimização de treinamento geralmente envolve experimentação. Teste diferentes técnicas, ajuste hiperparâmetros e avalie o desempenho do seu modelo no conjunto de validação para encontrar a melhor configuração.\n",
    "\n",
    "Monitore o Treinamento: Utilize ferramentas de visualização, como TensorBoard ou bibliotecas de plotagem, para monitorar o progresso do treinamento e identificar problemas como overfitting ou underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principais Fatores a monitorar na aprendizagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao monitorar o progresso do treinamento de um modelo de aprendizado de máquina, como uma RNN, utilizando bibliotecas de plotagem, existem alguns fatores chave que você deve observar para identificar problemas como overfitting e underfitting.\n",
    "\n",
    "Perda (Loss):\n",
    "\n",
    "- Overfitting: A perda no conjunto de treinamento diminui significativamente, enquanto a perda no conjunto de validação começa a aumentar ou se estabiliza em um valor alto. Isso indica que o modelo está aprendendo os detalhes específicos dos dados de treinamento, mas não está generalizando bem para novos dados.\n",
    "- Underfitting: A perda tanto no conjunto de treinamento quanto no de validação permanece alta e não diminui significativamente ao longo das épocas. Isso sugere que o modelo não está aprendendo padrões relevantes nos dados, possivelmente devido à sua simplicidade ou à falta de capacidade de representação.\n",
    "\n",
    "Acurácia (Accuracy):\n",
    "\n",
    "- Overfitting: A acurácia no conjunto de treinamento aumenta consideravelmente, enquanto a acurácia no conjunto de validação se estabiliza ou até mesmo diminui. Isso também é um sinal de que o modelo está memorizando os dados de treinamento em vez de aprender padrões generalizáveis.\n",
    "- Underfitting: A acurácia tanto no conjunto de treinamento quanto no de validação permanece baixa e não melhora significativamente ao longo do treinamento. Isso indica que o modelo não está capturando informações suficientes dos dados para fazer boas previsões.\n",
    "\n",
    "Outras Métricas:\n",
    "\n",
    "- Precisão, Recall e F1-Score: Dependendo do seu problema, outras métricas como precisão, recall e F1-score podem ser relevantes para avaliar o desempenho do modelo. Observe se essas métricas no conjunto de validação se comportam de forma semelhante à acurácia, indicando overfitting ou underfitting.\n",
    "\n",
    "Visualização das Curvas de Aprendizado:\n",
    "\n",
    "- Perda: Plote a perda de treinamento e validação em função do número de épocas. Uma curva de perda de treinamento decrescente e uma curva de perda de validação crescente ou em platô indicam overfitting.\n",
    "- Acurácia: Plote a acurácia de treinamento e validação em função do número de épocas. Uma curva de acurácia de treinamento crescente e uma curva de acurácia de validação estagnada ou decrescente também sugerem overfitting.\n",
    "- Outras Métricas: Se você estiver calculando outras métricas, plote-as também para obter uma visão mais completa do desempenho do modelo.\n",
    "\n",
    "Dicas:\n",
    "\n",
    "Compare as Curvas: A comparação entre as curvas de treinamento e validação é fundamental para identificar overfitting e underfitting. Se as curvas de validação se distanciarem significativamente das curvas de treinamento, isso é um sinal de alerta.\n",
    "\n",
    "Observe o Platô: Se as métricas de validação atingirem um platô e pararem de melhorar, isso pode indicar que o modelo atingiu seu limite de aprendizado com os dados e hiperparâmetros atuais.\n",
    "\n",
    "Experimente: Se você identificar sinais de overfitting ou underfitting, experimente diferentes técnicas de regularização, ajuste de hiperparâmetros, aumento de dados ou arquiteturas de modelo para melhorar o desempenho.\n",
    "\n",
    "Lembre-se: O monitoramento constante do progresso do treinamento e a análise cuidadosa das métricas e curvas de aprendizado são essenciais para identificar problemas e tomar decisões informadas sobre como otimizar seu modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Início da execução do Pipeline RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importações e Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import sklearn.metrics as skmetrics \n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Certifique-se de que você tem uma GPU disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pré-processamento e Amostragem dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregue os dados\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "# Função para pré-processar os dados\n",
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "    # Apply functions to remove names, emails, and extraneous words from data points in newsgroups.data\n",
    "    newsgroup_dataset.data = [re.sub(r'[\\w\\.-]+@[\\w\\.-]+', '', d) for d in newsgroup_dataset.data] # Remove email\n",
    "    newsgroup_dataset.data = [re.sub(r\"\\s+[A-Za-z]+\\s+\\w+\\s+writes:\",\"\", d) for d in newsgroup_dataset.data] # Remove names\n",
    "    newsgroup_dataset.data = [d.replace(\"From: \", \"\") for d in newsgroup_dataset.data] # Remove \"From: \"\n",
    "    newsgroup_dataset.data = [d.replace(\"\\nSubject: \", \"\") for d in newsgroup_dataset.data] # Remove \"\\nSubject:\"\n",
    "\n",
    "    # Cut off each text entry after 5,000 characters\n",
    "    newsgroup_dataset.data = [d[0:5000] if len(d) > 5000 else d for d in newsgroup_dataset.data]\n",
    "\n",
    "    # Put data points into dataframe\n",
    "    df_processed = pd.DataFrame(newsgroup_dataset.data, columns=['Text'])\n",
    "    df_processed['Label'] = newsgroup_dataset.target\n",
    "    # Match label to target name index\n",
    "    df_processed['Class Name'] = ''\n",
    "    for idx, row in df_processed.iterrows():\n",
    "        df_processed.at[idx, 'Class Name'] = newsgroup_dataset.target_names[row['Label']]\n",
    "\n",
    "    return df_processed \n",
    "\n",
    "# Apply preprocessing function to training and test datasets\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test) \n",
    "\n",
    "# Função para amostrar os dados\n",
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "    \"\"\"\n",
    "    Samples data from a DataFrame, keeping only specific classes and re-encoding labels.\n",
    "\n",
    "    Args:\n",
    "        df: The DataFrame to sample from.\n",
    "        num_samples: The number of samples to take from each class.\n",
    "        classes_to_keep: A string or pattern to filter classes based on 'Class Name'.\n",
    "\n",
    "    Returns:\n",
    "        A new DataFrame with the sampled data and re-encoded labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sample 'num_samples' from each 'Label' group, excluding grouping columns\n",
    "    df = (\n",
    "        df.groupby('Label', as_index=False)\n",
    "        .apply(lambda x: x.sample(num_samples), include_groups=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Filter classes based on 'Class Name'\n",
    "    df_filtered = df[df['Class Name'].str.contains(classes_to_keep)].copy()\n",
    "\n",
    "    # Re-encode labels after filtering\n",
    "    df_filtered['Class Name'] = df_filtered['Class Name'].astype('category')\n",
    "    df_filtered['Encoded Label'] = df_filtered['Class Name'].cat.codes\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# Defina os parâmetros de amostragem\n",
    "TRAIN_NUM_SAMPLES = 100\n",
    "TEST_NUM_SAMPLES = 25\n",
    "CLASSES_TO_KEEP = 'sci'\n",
    "\n",
    "# Aplique a função de amostragem\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenização e Criação do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizador e vocabulário (usando transformers)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased') \n",
    "\n",
    "# Parâmetros de treinamento\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Criar um Dataset personalizado\n",
    "class NewsGroupsDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx]['Text']\n",
    "        label = torch.tensor(self.df.iloc[idx]['Encoded Label'], dtype=torch.long)  # Convert to LongTensor directly\n",
    "\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=max_seq_len)\n",
    "        return encoding['input_ids'].squeeze(), encoding['attention_mask'].squeeze(), label\n",
    "\n",
    "# Aplicar o tokenizer aos dados\n",
    "max_seq_len = 128 \n",
    "train_dataset = NewsGroupsDataset(df_train, tokenizer)\n",
    "val_dataset = NewsGroupsDataset(df_test, tokenizer)\n",
    "\n",
    "# Criar DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definição do Modelo RNN e Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o modelo de classificação RNN (LSTM)\n",
    "# (a definição da classe RNNModel permanece a mesma)\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        \"\"\"\n",
    "        Inicializa o modelo RNN.\n",
    "\n",
    "        Args:\n",
    "            vocab_size: O tamanho do vocabulário.\n",
    "            embedding_dim: A dimensão dos embeddings de palavras.\n",
    "            hidden_dim: O tamanho da camada oculta da LSTM.\n",
    "            output_dim: O número de classes de saída.\n",
    "            n_layers: O número de camadas LSTM empilhadas.\n",
    "            dropout: A taxa de dropout aplicada após a camada de embedding e LSTM.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Camada de embedding para converter tokens em vetores densos\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # Camada LSTM para processar a sequência de embeddings\n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           dropout=dropout, \n",
    "                           batch_first=True) \n",
    "\n",
    "        # Camada linear para classificação\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # Dropout para regularização\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text, mask):\n",
    "        \"\"\"\n",
    "        Define o fluxo de dados através do modelo.\n",
    "\n",
    "        Args:\n",
    "            text: Os índices dos tokens de entrada (batch_size, seq_len).\n",
    "            mask: A máscara de atenção para ignorar o padding (batch_size, seq_len).\n",
    "\n",
    "        Returns:\n",
    "            As logits de saída para cada classe (batch_size, output_dim).\n",
    "        \"\"\"\n",
    "\n",
    "        # Aplica o embedding e o dropout à entrada\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "\n",
    "        # Passa os embeddings pela LSTM\n",
    "        output, (hidden, _) = self.rnn(embedded)\n",
    "\n",
    "        # Usa o último estado oculto da última camada LSTM para classificação\n",
    "        hidden = hidden[-1, :, :]  \n",
    "\n",
    "        # Aplica a camada linear e retorna as logits de saída\n",
    "        return self.fc(hidden)\n",
    "\n",
    "# Hiperparâmetros da RNN\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "EMBEDDING_DIM = 768 \n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(df_train['Class Name'].unique())\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# Função para calcular a acurácia\n",
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) \n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\n",
    "\n",
    "# Função para calcular precisão, recall e F1-score\n",
    "def calculate_metrics(preds, labels):\n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    accuracy = (predicted == labels).sum().item() / len(labels)\n",
    "    precision = skmetrics.precision_score(labels.cpu(), predicted.cpu(), average='weighted')\n",
    "    recall = skmetrics.recall_score(labels.cpu(), predicted.cpu(), average='weighted')\n",
    "    f1 = skmetrics.f1_score(labels.cpu(), predicted.cpu(), average='weighted')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Grid Search e Treinamento com Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "def calculate_metrics(preds, labels):\n",
    "    _, predicted = torch.max(preds.data, 1)\n",
    "    accuracy = (predicted == labels).sum().item() / len(labels)\n",
    "    precision = skmetrics.precision_score(labels.cpu(), predicted.cpu(), average='weighted', zero_division=0) \n",
    "    recall = skmetrics.recall_score(labels.cpu(), predicted.cpu(), average='weighted')\n",
    "    f1 = skmetrics.f1_score(labels.cpu(), predicted.cpu(), average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def plot_history(train_losses, train_accuracies, val_losses, val_accuracies, val_precisions, val_recalls, val_f1s):\n",
    "    \"\"\"\n",
    "    Plotting training and validation learning curves using Altair.\n",
    "\n",
    "    Args:\n",
    "        train_losses: List of training loss values.\n",
    "        train_accuracies: List of training accuracy values.\n",
    "        val_losses: List of validation loss values.\n",
    "        val_accuracies: List of validation accuracy values.\n",
    "        val_precisions: List of validation precision values.\n",
    "        val_recalls: List of validation recall values.\n",
    "        val_f1s: List of validation F1-score values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a DataFrame from the history dictionary\n",
    "    df = pd.DataFrame({\n",
    "        'Epoch': range(1, len(train_losses) + 1),\n",
    "        'Train Loss': train_losses,\n",
    "        'Validation Loss': val_losses,\n",
    "        'Train Accuracy': train_accuracies,\n",
    "        'Validation Accuracy': val_accuracies,\n",
    "        'Validation Precision': val_precisions,\n",
    "        'Validation Recall': val_recalls,\n",
    "        'Validation F1': val_f1s\n",
    "    })\n",
    "\n",
    "    # Melt the DataFrame to long format for easier plotting\n",
    "    df_melted = df.melt('Epoch', var_name='Metric', value_name='Value')\n",
    "\n",
    "    # Create the Altair chart for loss\n",
    "    loss_chart = alt.Chart(df_melted[df_melted['Metric'].isin(['Train Loss', 'Validation Loss'])]).mark_line(point=True).encode(\n",
    "        x='Epoch:Q',\n",
    "        y='Value:Q',\n",
    "        color='Metric:N',\n",
    "        tooltip=['Epoch', 'Value', 'Metric']\n",
    "    ).properties(\n",
    "        title='Loss'\n",
    "    ).interactive()\n",
    "\n",
    "    # Create the Altair chart for accuracy\n",
    "    accuracy_chart = alt.Chart(df_melted[df_melted['Metric'].isin(['Train Accuracy', 'Validation Accuracy'])]).mark_line(point=True).encode(\n",
    "        x='Epoch:Q',\n",
    "        y='Value:Q',\n",
    "        color='Metric:N',\n",
    "        tooltip=['Epoch', 'Value', 'Metric']\n",
    "    ).properties(\n",
    "        title='Accuracy'\n",
    "    ).interactive()\n",
    "\n",
    "    # Create the Altair chart for precision, recall and F1\n",
    "    other_metrics_chart = alt.Chart(df_melted[df_melted['Metric'].isin(['Validation Precision', 'Validation Recall', 'Validation F1'])]).mark_line(point=True).encode(\n",
    "        x='Epoch:Q',\n",
    "        y='Value:Q',\n",
    "        color='Metric:N',\n",
    "        tooltip=['Epoch', 'Value', 'Metric']\n",
    "    ).properties(\n",
    "        title='Precision, Recall, and F1'\n",
    "    ).interactive()\n",
    "\n",
    "    # Combine the charts and save as JSON\n",
    "    chart = alt.vconcat(loss_chart, accuracy_chart, other_metrics_chart)\n",
    "    chart.save('training_history_plot.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Grid Search mais Extenso\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.0005, 0.0001],\n",
    "    'weight_decay': [0.0001, 0.0005, 0.001],\n",
    "    'dropout': [0.3, 0.4, 0.5, 0.6]\n",
    "    # 'batch_size': [16, 32, 64]  # Opcional: testar diferentes tamanhos de batch\n",
    "}\n",
    "\n",
    "param_combinations = ParameterGrid(param_grid)\n",
    "\n",
    "# Variáveis para armazenar os melhores resultados\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "# Loop sobre todas as combinações de hiperparâmetros\n",
    "for params in param_combinations:\n",
    "    print(f\"Treinando com parâmetros: {params}\")\n",
    "\n",
    "    # Crie o modelo com os hiperparâmetros atuais\n",
    "    rnn_classifier = RNNModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, params['dropout']).to(device)\n",
    "\n",
    "    # Defina a função de perda e o otimizador com os hiperparâmetros atuais\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(rnn_classifier.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
    "\n",
    "    # Defina o Early Stopping\n",
    "    early_stopping_patience = 3\n",
    "    early_stopping_counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # Scheduler para reduzir a taxa de aprendizado\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=1)\n",
    "\n",
    "    # Listas para armazenar métricas de treinamento para esta combinação de parâmetros\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    val_precisions = []\n",
    "    val_recalls = []\n",
    "    val_f1s = []\n",
    "\n",
    "    # Loop de treinamento com Early Stopping\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "\n",
    "        # Treinamento\n",
    "        rnn_classifier.train()\n",
    "        for input_ids, attention_mask, labels in train_dataloader:\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            predictions = rnn_classifier(input_ids, attention_mask)\n",
    "\n",
    "            # Certifique-se de que 'predictions' é do tipo float e 'labels' é do tipo long\n",
    "            predictions = predictions.float()  # Converter para FloatTensor se necessário\n",
    "            labels = labels.long()  # Converter para LongTensor explicitamente\n",
    "\n",
    "            loss = criterion(predictions, labels)\n",
    "            acc = categorical_accuracy(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad() # Adicionando para zerar os gradientes a cada passo\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "        # Adicione as métricas de treinamento ao histórico\n",
    "        train_losses.append(epoch_loss / len(train_dataloader))\n",
    "        train_accuracies.append(epoch_acc / len(train_dataloader))\n",
    "\n",
    "        # Avaliação no conjunto de validação a cada época\n",
    "        rnn_classifier.eval()\n",
    "        with torch.no_grad():\n",
    "            epoch_val_loss = 0\n",
    "            epoch_val_acc = 0\n",
    "            val_preds = []\n",
    "            val_true = []\n",
    "            for input_ids, attention_mask, labels in val_dataloader:\n",
    "                input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "                # Debugging: Print shapes and lengths within the loop\n",
    "                print(f\"Validação - Batch:\")\n",
    "                print(f\"  input_ids shape: {input_ids.shape}\")\n",
    "                print(f\"  labels shape: {labels.shape}\")\n",
    "\n",
    "                predictions = rnn_classifier(input_ids, attention_mask)\n",
    "\n",
    "                # Debugging: Print shapes and lengths within the loop\n",
    "                print(f\"  predictions shape (antes do softmax): {predictions.shape}\")\n",
    "\n",
    "                loss = criterion(predictions, labels)\n",
    "                acc = categorical_accuracy(predictions, labels)\n",
    "                epoch_val_loss += loss.item()\n",
    "                epoch_val_acc += acc.item()\n",
    "\n",
    "                # Armazenar previsões e rótulos verdadeiros para calcular outras métricas\n",
    "                val_preds.append(predictions.argmax(dim=1).cpu())  # Obter as classes preditas\n",
    "                val_true.extend(labels.cpu().tolist())\n",
    "\n",
    "                # Debugging: Print shapes and lengths within the loop\n",
    "                print(f\"  Current val_preds length: {len(val_preds)}\")\n",
    "                print(f\"  Current val_true length: {len(val_true)}\")\n",
    "\n",
    "        # Concatenar as previsões em um único tensor\n",
    "        val_preds = torch.cat(val_preds, dim=0)\n",
    "\n",
    "        # Debugging: Print shapes antes de calcular as métricas\n",
    "        print(f\"\\nShapes antes de calculate_metrics: val_preds: {val_preds.shape}, val_true: {torch.tensor(val_true).shape}\")\n",
    "\n",
    "        # Calcular precisão, recall e F1-score\n",
    "        val_accuracy, val_precision, val_recall, val_f1 = calculate_metrics(val_preds, torch.tensor(val_true))\n",
    "\n",
    "        # Adicione as métricas de validação ao histórico\n",
    "        val_losses.append(epoch_val_loss / len(val_dataloader))  # Calcular a média da perda de validação\n",
    "        val_accuracies.append(epoch_val_acc / len(val_dataloader))\n",
    "        val_precisions.append(val_precision)\n",
    "        val_recalls.append(val_recall)\n",
    "        val_f1s.append(val_f1)\n",
    "\n",
    "        # Early Stopping (usando a média da perda de validação)\n",
    "        if (epoch_val_loss / len(val_dataloader)) < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss / len(val_dataloader)\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\" Early stopping at epoch {epoch+1}!\")\n",
    "                break\n",
    "\n",
    "        # Reduza a taxa de aprendizado se a validação não melhorar\n",
    "        scheduler.step(epoch_val_loss / len(val_dataloader))\n",
    "\n",
    "        # Imprima estatísticas de cada época para esta combinação de parâmetros (com \\r)\n",
    "        print(\n",
    "            f'\\rEpoch [{epoch + 1}/{NUM_EPOCHS}], Loss: {train_losses[-1]:.4f}, Accuracy: {train_accuracies[-1]:.4f}%, '\n",
    "            f'Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.4f}%, '\n",
    "            f'Val Precision: {val_precisions[-1]:.4f}, Val Recall: {val_recalls[-1]:.4f}, Val F1: {val_f1s[-1]:.4f}',\n",
    "            end=\"\"\n",
    "        )\n",
    "\n",
    "    print()  # Adicione uma nova linha após o término de cada combinação de parâmetros\n",
    "\n",
    "    # Volte para o modo de treinamento\n",
    "    rnn_classifier.train()\n",
    "\n",
    "    # Armazene o histórico de treinamento para esta combinação de parâmetros\n",
    "    history = {\n",
    "        'train_loss': train_losses,\n",
    "        'train_acc': train_accuracies,\n",
    "        'val_loss': val_losses,\n",
    "        'val_acc': val_accuracies,\n",
    "        'val_precision': val_precisions,\n",
    "        'val_recall': val_recalls,\n",
    "        'val_f1': val_f1s\n",
    "    }\n",
    "\n",
    "    # Plote o histórico de treinamento para esta combinação de parâmetros\n",
    "    plot_history(history['train_loss'], history['train_acc'], history['val_loss'], history['val_acc'], history['val_precision'], history['val_recall'], history['val_f1'])\n",
    "\n",
    "    # Verifique se esta combinação de parâmetros é a melhor até agora\n",
    "    if val_accuracies[-1] > best_accuracy:\n",
    "        best_accuracy = val_accuracies[-1]\n",
    "        best_params = params\n",
    "\n",
    "        # Opcional: Salve o melhor modelo\n",
    "        torch.save(rnn_classifier.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Inspecione a configuração do DataLoader (fora do loop)\n",
    "print(\"\\nval_dataloader configuration:\")\n",
    "print(f\"  batch_size: {val_dataloader.batch_size}\")\n",
    "print(f\"  dataset size: {len(val_dataloader.dataset)}\")\n",
    "print(f\"  shuffle: {val_dataloader.shuffle}\") \n",
    "print(f\"  num_workers: {val_dataloader.num_workers}\") \n",
    "\n",
    "# Carregar o melhor modelo salvo (opcional)\n",
    "best_model = RNNModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, best_params['dropout']).to(device)\n",
    "best_model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Revise a arquitetura do modelo (fora do loop)\n",
    "print(\"\\nModel architecture:\")\n",
    "print(best_model) \n",
    "\n",
    "# Imprima os melhores resultados\n",
    "print(f'Best validation accuracy: {best_accuracy:.2f}%')\n",
    "print('Best parameters:', best_params)\n",
    "\n",
    "# Criar o dicionário de rótulos (if available)\n",
    "if 'df_test' in globals():  # Check if df_test exists\n",
    "    labels_dict = dict(zip(df_test['Class Name'], df_test['Encoded Label'])) \n",
    "\n",
    "    # Calcular e plotar a matriz de confusão\n",
    "    cm = skmetrics.confusion_matrix(val_true, val_preds)\n",
    "    disp = skmetrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_dict.keys())\n",
    "    disp.plot(xticks_rotation='vertical')\n",
    "    plt.title('Confusion matrix for newsgroup test dataset')\n",
    "    plt.grid(False) \n",
    " \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Warning: 'df_test' not found. Skipping confusion matrix plot.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação Final do Modelo e Plotagem da Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Carregar o melhor modelo salvo (opcional)\n",
    "best_model = RNNModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, best_params['dropout']).to(device)\n",
    "best_model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Avaliação final no conjunto de validação\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    val_preds = [] # Initialize val_preds here, outside the loop\n",
    "    val_true = []\n",
    "    for batch_idx, (input_ids, attention_mask, labels) in enumerate(val_dataloader):\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = best_model(input_ids, attention_mask) \n",
    "\n",
    "        # Convert logits to probabilities \n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "        # Get predicted class labels \n",
    "        _, predicted_classes = torch.max(probabilities, 1) \n",
    "\n",
    "        # Debugging: Print shapes and lengths within the loop\n",
    "        print(f\"Batch {batch_idx}:\")\n",
    "        print(f\"  input_ids shape: {input_ids.shape}\") \n",
    "        print(f\"  predictions shape: {logits.shape}\") # Print logits shape instead of predictions\n",
    "        print(f\"  labels shape: {labels.shape}\")\n",
    "        print(f\"  Current val_preds length: {len(val_preds)}\")\n",
    "        print(f\"  Current val_true length: {len(val_true)}\")\n",
    "\n",
    "        # Ensure correct number of predictions are appended based on labels size\n",
    "        batch_size = labels.size(0) \n",
    "        val_preds.extend(predicted_classes[:batch_size].cpu().numpy())  \n",
    "        val_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print final lengths for debugging\n",
    "print(f\"\\nFinal: val_preds length={len(val_preds)}, val_true length={len(val_true)}\")\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 4  \n",
    "\n",
    "# Calculate metrics \n",
    "val_accuracy, val_precision, val_recall, val_f1 = calculate_metrics(\n",
    "    torch.tensor(np.array(val_preds)),\n",
    "    torch.tensor(val_true)\n",
    ")\n",
    "\n",
    "# Inspect data loader configuration (outside the loop)\n",
    "print(\"\\nval_dataloader configuration:\")\n",
    "print(f\"  batch_size: {val_dataloader.batch_size}\")\n",
    "print(f\"  dataset size: {len(val_dataloader.dataset)}\")\n",
    "# Add more print statements to inspect other relevant configuration details if needed\n",
    "\n",
    "# Review model architecture (outside the loop)\n",
    "print(\"\\nModel architecture:\")\n",
    "print(best_model) \n",
    "\n",
    "# Print the metrics\n",
    "print(f'Final Validation Accuracy: {val_accuracy:.4f}')\n",
    "print(f'Final Validation Precision: {val_precision:.4f}')\n",
    "print(f'Final Validation Recall: {val_recall:.4f}')\n",
    "print(f'Final Validation F1-Score: {val_f1:.4f}')\n",
    "\n",
    "# Criar o dicionário de rótulos (if available)\n",
    "if 'df_test' in globals(): \n",
    "    labels_dict = dict(zip(df_test['Class Name'], df_test['Encoded Label'])) \n",
    "\n",
    "    # Calculate and plot the confusion matrix\n",
    "    cm = skmetrics.confusion_matrix(val_true, val_preds)\n",
    "    disp = skmetrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_dict.keys())\n",
    "    disp.plot(xticks_rotation='vertical')\n",
    "    plt.title('Confusion matrix for newsgroup test dataset')\n",
    "    plt.grid(False) \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Warning: 'df_test' not found. Skipping confusion matrix plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pré-processamento e Amostragem dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando com RNN (versão antiga com Torchtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import sklearn.metrics as skmetrics \n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Certifique-se de que você tem uma GPU disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Carregue um modelo de embedding pré-treinado\n",
    "model_name = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "model = model.to(device) \n",
    "\n",
    "# Carregue os dados\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "# Função para pré-processar os dados\n",
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "  # Apply functions to remove names, emails, and extraneous words from data points in newsgroups.data\n",
    "  newsgroup_dataset.data = [re.sub(r'[\\w\\.-]+@[\\w\\.-]+', '', d) for d in newsgroup_dataset.data] # Remove email\n",
    "  newsgroup_dataset.data = [re.sub(r\"\", \"\", d) for d in newsgroup_dataset.data] # Remove names\n",
    "  newsgroup_dataset.data = [d.replace(\"From: \", \"\") for d in newsgroup_dataset.data] # Remove \"From: \"\n",
    "  newsgroup_dataset.data = [d.replace(\"\\nSubject: \", \"\") for d in newsgroup_dataset.data] # Remove \"\\nSubject: \"\n",
    "\n",
    "  # Cut off each text entry after 5,000 characters\n",
    "  newsgroup_dataset.data = [d[0:5000] if len(d) > 5000 else d for d in newsgroup_dataset.data]\n",
    "\n",
    "  # Put data points into dataframe\n",
    "  df_processed = pd.DataFrame(newsgroup_dataset.data, columns=['Text'])\n",
    "  df_processed['Label'] = newsgroup_dataset.target\n",
    "  # Match label to target name index\n",
    "  df_processed['Class Name'] = ''\n",
    "  for idx, row in df_processed.iterrows():\n",
    "    df_processed.at[idx, 'Class Name'] = newsgroup_dataset.target_names[row['Label']]\n",
    "\n",
    "  return df_processed\n",
    "\n",
    "# Apply preprocessing function to training and test datasets\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Função para amostrar os dados\n",
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "    # Agrupa por 'Label' e amostra 'num_samples' de cada grupo,\n",
    "    # excluindo as colunas de agrupamento da operação apply\n",
    "    df = (\n",
    "        df.groupby('Label', as_index=False)\n",
    "        .apply(lambda x: x.sample(num_samples), include_groups=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Filtra apenas as classes que contêm 'classes_to_keep' em 'Class Name'\n",
    "    df_filtered = df[df['Class Name'].str.contains(classes_to_keep)].copy() \n",
    "\n",
    "    # Garante que 'Class Name' seja do tipo category e remapeia os códigos\n",
    "    df_filtered['Class Name'] = df_filtered['Class Name'].astype('category')\n",
    "    df_filtered['Encoded Label'] = df_filtered['Class Name'].cat.codes\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# Defina os parâmetros de amostragem\n",
    "TRAIN_NUM_SAMPLES = 100\n",
    "TEST_NUM_SAMPLES = 25\n",
    "CLASSES_TO_KEEP = 'sci'\n",
    "\n",
    "# Aplique a função de amostragem\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP) \n",
    "\n",
    "# Tokenizador\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Função para gerar sequências de tokens a partir do texto\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Construir o vocabulário\n",
    "vocab = build_vocab_from_iterator(yield_tokens(df_train['Text']), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# Função para converter texto em sequências numéricas\n",
    "def text_pipeline(x):\n",
    "    return vocab(tokenizer(x))\n",
    "\n",
    "# Aplicar o pipeline de texto aos dados de treinamento e teste\n",
    "df_train['Text_Seq'] = df_train['Text'].apply(text_pipeline)\n",
    "df_test['Text_Seq'] = df_test['Text'].apply(text_pipeline)\n",
    "\n",
    "# Encontrar o comprimento máximo da sequência para padding\n",
    "max_seq_len = max(df_train['Text_Seq'].apply(len))\n",
    "\n",
    "# Função para fazer o padding das sequências\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(_label)\n",
    "        processed_text = torch.tensor(_text, dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64).to(device) # Mova para a GPU\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0).to(device)       # Mova para a GPU\n",
    "    text_list = pad_sequence(text_list, batch_first=True).to(device)    # Mova para a GPU\n",
    "    return label_list, text_list, offsets\n",
    "\n",
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\n",
    "\n",
    "\n",
    "# Criar DataLoaders para treinamento e validação\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Parâmetros de treinamento\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = list(zip(df_train['Encoded Label'], df_train['Text_Seq']))\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "val_data = list(zip(df_test['Encoded Label'], df_test['Text_Seq']))\n",
    "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "# Defina o modelo de classificação RNN (LSTM)\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        output, (hidden, _) = self.rnn(embedded)\n",
    "        hidden = hidden[-1, :, :]  # Usamos o último estado oculto da última camada\n",
    "        return self.fc(hidden)\n",
    "\n",
    "# Hiperparâmetros da RNN\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(df_train['Class Name'].unique())\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# Grid Search mais Extenso\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.0005, 0.0001],\n",
    "    'weight_decay': [0.0001, 0.0005, 0.001],\n",
    "    'dropout': [0.3, 0.4, 0.5, 0.6]\n",
    "    # 'batch_size': [16, 32, 64]  # Opcional: testar diferentes tamanhos de batch\n",
    "}\n",
    "\n",
    "param_combinations = ParameterGrid(param_grid)\n",
    "\n",
    "# Variáveis para armazenar os melhores resultados\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "# Calcular os offsets de validação\n",
    "_, _, val_offsets = collate_batch(val_data)\n",
    "\n",
    "# Loop sobre todas as combinações de hiperparâmetros\n",
    "for params in param_combinations:\n",
    "    print(f\"Treinando com parâmetros: {params}\")\n",
    "\n",
    "    # Crie o modelo com os hiperparâmetros atuais\n",
    "    rnn_classifier = RNNModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, params['dropout']).to(device)\n",
    "\n",
    "    # Defina a função de perda e o otimizador com os hiperparâmetros atuais\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(rnn_classifier.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
    "\n",
    "    # Defina o Early Stopping\n",
    "    early_stopping_patience = 3\n",
    "    early_stopping_counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # Scheduler para reduzir a taxa de aprendizado\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=1)\n",
    "\n",
    "    # Listas para armazenar métricas de treinamento para esta combinação de parâmetros\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Loop de treinamento com Early Stopping\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "\n",
    "        # Treinamento\n",
    "        rnn_classifier.train()\n",
    "        for labels, text, offsets in train_dataloader:\n",
    "            # Forward + backward + optimize (sem zero_grad())\n",
    "            predictions = rnn_classifier(text, offsets)\n",
    "            loss = criterion(predictions, labels)\n",
    "            acc = categorical_accuracy(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "        # Adicione as métricas de treinamento ao histórico\n",
    "        train_losses.append(epoch_loss / len(train_dataloader))\n",
    "        train_accuracies.append(epoch_acc / len(train_dataloader))\n",
    "\n",
    "        # Avaliação no conjunto de validação a cada época\n",
    "        rnn_classifier.eval()\n",
    "        with torch.no_grad():\n",
    "            epoch_val_loss = 0\n",
    "            epoch_val_acc = 0\n",
    "            for labels, text, offsets in val_dataloader:\n",
    "                predictions = rnn_classifier(text, offsets)\n",
    "                loss = criterion(predictions, labels)\n",
    "                acc = categorical_accuracy(predictions, labels)\n",
    "                epoch_val_loss += loss.item()\n",
    "                epoch_val_acc += acc.item()\n",
    "\n",
    "        # Adicione as métricas de validação ao histórico (corrigido)\n",
    "        val_losses.append(epoch_val_loss / len(val_dataloader)) \n",
    "        val_accuracies.append(epoch_val_acc / len(val_dataloader))\n",
    "\n",
    "        # Early Stopping (movido para dentro do bloco with torch.no_grad())\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "            if early_stopping_counter >= early_stopping_patience: \n",
    "                print(f\" Early stopping at epoch {epoch+1}!\")\n",
    "                break\n",
    "\n",
    "        # Reduza a taxa de aprendizado se a validação não melhorar\n",
    "        scheduler.step(epoch_val_loss) \n",
    "\n",
    "        # Imprima estatísticas de cada época para esta combinação de parâmetros (com \\r)\n",
    "        print(\n",
    "            f'\\rEpoch [{epoch + 1}/{NUM_EPOCHS}], Loss: {train_losses[-1]:.4f}, Accuracy: {train_accuracies[-1]:.4f}%, '\n",
    "            f'Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.4f}%', \n",
    "            end=\"\"\n",
    "        )\n",
    "\n",
    "    print()  # Adicione uma nova linha após o término de cada combinação de parâmetros\n",
    "\n",
    "    # Volte para o modo de treinamento\n",
    "    rnn_classifier.train()\n",
    "\n",
    "    # Verifique se esta combinação de parâmetros é a melhor até agora\n",
    "    if val_accuracies[-1] > best_accuracy:\n",
    "        best_accuracy = val_accuracies[-1]\n",
    "        best_params = params\n",
    "\n",
    "        # Opcional: Salve o melhor modelo\n",
    "        torch.save(rnn_classifier.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Imprima os melhores resultados\n",
    "print(f'Best validation accuracy: {best_accuracy:.2f}%')\n",
    "print('Best parameters:', best_params)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda uninstall -c pytorch torchtext ## BIBLIOTECA DEPRECIADA E ULTRAPASSADA NÃO USAR!!!!\n",
    "# %pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import sklearn.metrics as skmetrics \n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Certifique-se de que você tem uma GPU disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Carregue um modelo de embedding pré-treinado (opcional, se você quiser usar embeddings pré-treinados)\n",
    "model_name = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "model = model.to(device) \n",
    "\n",
    "# Carregue os dados\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "# pré-processar e realizar amostragem dos dados\n",
    "#\n",
    "#\n",
    "\n",
    "# Tokenizador e vocabulário (usando transformers)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')  # Escolha um tokenizer adequado\n",
    "\n",
    "# Criar um Dataset personalizado\n",
    "class NewsGroupsDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx]['Text']\n",
    "        label = self.df.iloc[idx]['Encoded Label']\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=max_seq_len)\n",
    "        return encoding['input_ids'].squeeze(), encoding['attention_mask'].squeeze(), label\n",
    "\n",
    "# Aplicar o tokenizer aos dados\n",
    "max_seq_len = 128  # Defina o comprimento máximo da sequência (ajuste conforme necessário)\n",
    "train_dataset = NewsGroupsDataset(df_train, tokenizer)\n",
    "val_dataset = NewsGroupsDataset(df_test, tokenizer)\n",
    "\n",
    "# Criar DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False) \n",
    "\n",
    "# Defina o modelo de classificação RNN (LSTM)\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text, mask):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        # Aplique a máscara de atenção à saída da RNN\n",
    "        output, (hidden, _) = self.rnn(embedded, mask)\n",
    "        hidden = hidden[-1, :, :] \n",
    "        return self.fc(hidden)\n",
    "\n",
    "# Hiperparâmetros da RNN\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "EMBEDDING_DIM = 300  # Ou use a dimensão dos embeddings pré-treinados se estiver usando\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(df_train['Class Name'].unique())\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# ... (resto do código para Grid Search, treinamento, avaliação e plotagem)\n",
    "\n",
    "# Loop de treinamento com Early Stopping (adaptado para o novo DataLoader)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    # Treinamento\n",
    "    rnn_classifier.train()\n",
    "    for input_ids, attention_mask, labels in train_dataloader:\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        predictions = rnn_classifier(input_ids, attention_mask)\n",
    "        loss = criterion(predictions, labels)\n",
    "        acc = categorical_accuracy(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item() \n",
    "\n",
    "\n",
    "    # ... (resto do código de avaliação, Early Stopping, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop de treinamento com Early Stopping (adaptado para RNN)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    # Treinamento\n",
    "    rnn_classifier.train()\n",
    "    for labels, text, offsets in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = rnn_classifier(text, offsets)\n",
    "        loss = criterion(predictions, labels)\n",
    "        acc = categorical_accuracy(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "    # Adicione as métricas de treinamento ao histórico\n",
    "    train_losses.append(epoch_loss / len(train_dataloader))\n",
    "    train_accuracies.append(epoch_acc / len(train_dataloader))\n",
    "\n",
    "    # Avaliação\n",
    "    rnn_classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_val_loss = 0\n",
    "        epoch_val_acc = 0\n",
    "        for labels, text, offsets in val_dataloader:\n",
    "            predictions = rnn_classifier(text, offsets)\n",
    "            loss = criterion(predictions, labels)\n",
    "            acc = categorical_accuracy(predictions, labels)\n",
    "            epoch_val_loss += loss.item()\n",
    "            epoch_val_acc += acc.item()\n",
    "\n",
    "            # Adicione as métricas de validação ao histórico\n",
    "            val_losses.append(epoch_val_loss / len(val_dataloader))\n",
    "            val_accuracies.append(epoch_val_acc / len(val_dataloader))\n",
    "\n",
    "            # Early Stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                early_stopping_counter = 0\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "\n",
    "                if early_stopping_counter >= early_stopping_patience:\n",
    "                    print(\"Early stopping!\")\n",
    "\n",
    "                    break\n",
    "\n",
    "            # Reduza a taxa de aprendizado se a validação não melhorar\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            # Imprima estatísticas de cada época para esta combinação de parâmetros\n",
    "            print(\n",
    "                f'Epoch [{epoch + 1}/{NUM_EPOCHS}], Loss: {train_losses[-1]:.4f}, Accuracy: {train_accuracies[-1]:.2f}%, '\n",
    "                f'Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.2f}%'\n",
    "            )\n",
    "\n",
    "            # Volte para o modo de treinamento\n",
    "            classifier.train()\n",
    "\n",
    "        # Verifique se esta combinação de parâmetros é a melhor até agora\n",
    "        if val_accuracies[-1] > best_accuracy:\n",
    "            best_accuracy = val_accuracies[-1]\n",
    "            best_params = params\n",
    "\n",
    "            # Opcional: Salve o melhor modelo\n",
    "            torch.save(classifier.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Imprima os melhores resultados\n",
    "print(f'Best validation accuracy: {best_accuracy:.2f}%')\n",
    "print('Best parameters:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(train_losses, train_accuracies, val_losses, val_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
