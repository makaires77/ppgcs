{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Etapas da Metodologia</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapas para gerar o grafo de conhecimento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar os dados dos arquivos JSON:\n",
    "\n",
    "- Carregar os dados dos currículos dos pesquisadores em um DataFrame cuDF.\n",
    "- Carregar os dados da Matriz CEIS em um DataFrame cuDF.\n",
    "- Carregar as relações para biológicos e pequenas moléculas em estruturas de dados Python (listas de dicionários).\n",
    "\n",
    "Criar o grafo cuGraph:\n",
    "- Criar um grafo direcionado cuGraph.\n",
    "- Adicionar nós para cada pesquisador, produto da Matriz CEIS e elemento dos relacionamentos (biológicos e pequenas moléculas).\n",
    "- Definir atributos para os nós, como tipo de nó (\"pesquisador\", \"produto\", \"relacionamento\"), nome, ID, etc.\n",
    "\n",
    "Conectar os nós:\n",
    "- Conectar os nós de pesquisadores aos nós de produtos com base na similaridade entre as áreas de atuação do pesquisador e as áreas de aplicação do produto.\n",
    "- Conectar os nós de produtos aos nós de relacionamento com base no tipo de produto (biológico ou pequena molécula).\n",
    "- Conectar os nós de relacionamento entre si, seguindo as relações definidas nos arquivos JSON.\n",
    "\n",
    "Calcular métricas de grafo:\n",
    "- Calcular métricas de centralidade, como grau de entrada e saída, para identificar os nós mais importantes no grafo.\n",
    "- Calcular métricas de caminho, como distância e betweenness centrality, para analisar as relações entre os nós.\n",
    "- Converter o grafo cuGraph para NetworkX:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de perda adequada para aprendizado não-supervisionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No contexto de aprendizado não-supervisionado para alinhar competências da ICT aos produtos estratégicos, a escolha da função de perda considerou o objetivo de agrupar pesquisadores com competências semelhantes e identificar as lacunas em relação aos produtos estratégicos. Neste caso, não existe nesse cenário rótulos de classe pré-definidos. Portanto, as funções de perda tradicionais, como MSE ou Cross-Entropy, não são as mais adequadas.\n",
    "\n",
    "Considerando as opções de abordagem em redes neurais (com KANs, com Fourier e Híbrida) que serão utilizadas nos problemas de aprendizado não-supervisionado, a **Triplet Loss** surge como uma escolha promissora para esse tipo de problema, pois se concentra em aprender embeddings que agrupam nós semelhantes e separam nós distintos, o que se alinha com o objetivo de agrupar pesquisadores com competências semelhantes e identificar lacunas.\n",
    "\n",
    "O raciocínio sobre a Triplet Loss ser uma boa escolha para o aprendizado não-supervisionado em grafos com o objetivo de alinhar competências se aplica não só para abordagem com KANs mas também, de forma similar, se aplica bem, com algumas adaptações, para as outras abordagens de Rede Neural com Fourier e Rede Neural Híbrida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como aplicar a Triplet Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Definir trios:**\n",
    "    * **Âncora:** Um pesquisador.\n",
    "    * **Positivo:** Outro pesquisador com competências semelhantes à âncora, idealmente trabalhando em um produto estratégico que requer essas competências.\n",
    "    * **Negativo:** Um pesquisador com competências diferentes da âncora, preferencialmente que não esteja associado a nenhum produto estratégico que a âncora poderia contribuir.\n",
    "\n",
    "2. **Calcular perda:**\n",
    "    * A Triplet Loss busca minimizar a distância entre a âncora e o positivo, e maximizar a distância entre a âncora e o negativo.\n",
    "    * A função de perda é definida como:\n",
    "      \n",
    "<center>L = max(d(âncora, positivo) - d(âncora, negativo) + margem, 0)</center>\n",
    "      \n",
    "<center>onde 'd(a, b)' é a distância entre os embeddings de 'a' e 'b', e 'margem' é um hiperparâmetro que define a diferença mínima desejada entre as distâncias.</center>\n",
    "\n",
    "3. **Amostrar trios:**\n",
    "    * A escolha dos trios é crucial para o bom desempenho da Triplet Loss.\n",
    "    * Estratégias de amostragem como \"hard negative mining\" podem ser utilizadas para selecionar os trios mais informativos, que contribuem mais para o aprendizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vantagens da Triplet Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Alinhamento com o objetivo:** A Triplet Loss foca em agrupar nós semelhantes e separar nós distintos, o que é diretamente relevante para o problema de alinhamento de competências.\n",
    "* **Consideração da estrutura do grafo:** A escolha dos trios pode levar em conta as relações entre os nós no grafo, como a colaboração entre pesquisadores ou a participação em projetos comuns.\n",
    "* **Flexibilidade:** A Triplet Loss pode ser combinada com diferentes arquiteturas de redes neurais em grafos, como GNNs, para capturar as informações do grafo de forma mais eficiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação da função de perda com Triplet Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar a Triplet Loss, foi utilizada biblioteca `PyTorch Metric Learning`, que oferece diversas funções de perda e métodos de mineração para facilitar o treinamento.\n",
    "\n",
    "Lembre-se que a escolha da função de perda é apenas um dos aspectos do problema. A arquitetura da rede neural, a estratégia de amostragem dos trios e a escolha dos hiperparâmetros também são importantes para o bom desempenho do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Abordagens GNN com função perda Triplet Loss</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede KAN com função de perda por Triplet Loss:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A KAN foi responsável por gerar os embeddings dos nós do grafo, que foram utilizados pela Triplet Loss para calcular as distâncias entre os nós. A saída da KAN é um vetor de embedding para cada nó, representando suas características e relações no grafo.\n",
    "\n",
    "### Definição dos trios:\n",
    "\n",
    "A definição dos trios (âncora, positivo e negativo) segue a mesma lógica das outras abordagens:\n",
    "- Âncora: Um pesquisador.\n",
    "- Positivo: Outro pesquisador com competências semelhantes à âncora, idealmente associado a um produto estratégico que demanda essas competências.\n",
    "- Negativo: Um pesquisador com competências diferentes da âncora, preferencialmente não associado a produtos estratégicos que a âncora poderia contribuir.\n",
    "\n",
    "\n",
    "### Cálculo da perda:\n",
    "\n",
    "- A Triplet Loss foi calculada com base nos embeddings gerados pela Kolmogorov-Arnold Networks (KAN). \n",
    "\n",
    "- Quanto à amostragem dos trios, foi utilizada uma estratégia de amostragem eficiente, a \"hard negative mining\", para selecionar os trios mais informativos para o aprendizado.\n",
    "\n",
    "- A Triplet Loss foi utilizada para aprender embeddings que representem tanto as características estruturais do grafo quanto as relações de similaridade entre os nós, porém com o diferencial de aprender sobre as relações que ligam os nós (arestas).\n",
    "\n",
    "- Quanto à otimização, durante o treinamento, o otimizador ajustará os pesos da KAN para minimizar a Triplet Loss. A função de perda buscou minimizar a distância entre a âncora e o positivo, e maximizar a distância entre a âncora e o negativo. Isso gerou embeddings que agrupam pesquisadores com competências semelhantes e separam aqueles com competências distintas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural Fourier (Transformadas de Fourier + GNN):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A Triplet Loss pode ser utilizada em conjunto com as Transformadas de Fourier para aprender embeddings que representem tanto as características estruturais do grafo quanto as relações de similaridade entre os nós.\n",
    "\n",
    "* As Transformadas de Fourier podem auxiliar na identificação de padrões e características relevantes na estrutura do grafo,  enquanto a Triplet Loss guia o aprendizado para agrupar nós com competências semelhantes.\n",
    "\n",
    "* A combinação dessas técnicas pode levar a um modelo mais robusto e capaz de capturar diferentes aspectos do problema de alinhamento de competências."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural Híbrida (Controle de Sincronização + GNN):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A Triplet Loss foi utilizada para auxiliar na sincronização dos nós, incentivando o agrupamento de pesquisadores com competências semelhantes e a separação daqueles com competências diferentes.\n",
    "\n",
    "* A dinâmica de sincronização, baseada no valor de Fiedler, pode complementar a Triplet Loss, ajudando a identificar os nós mais importantes para o alinhamento de competências e guiando o aprendizado da rede.\n",
    "\n",
    "* A combinação da Triplet Loss com a GNN permite capturar as informações locais e globais do grafo,  enquanto a dinâmica de sincronização fornece uma perspectiva adicional sobre a importância dos nós e arestas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observações Gerais:**\n",
    "\n",
    "A escolha da função de perda é apenas um dos aspectos do problema. A arquitetura da rede neural, a estratégia de amostragem dos trios e a escolha dos hiperparâmetros também são importantes para o bom desempenho do modelo. Outras funções de perda, como a DGI ou a VGAE, também podem ser exploradas, especialmente se você desejar capturar a estrutura global do grafo e aprender representações mais robustas. É crucial avaliar o desempenho do modelo com diferentes métricas de avaliação, como as discutidas anteriormente, para garantir que ele esteja alinhando as competências da ICT aos produtos estratégicos de forma eficaz.\n",
    "\n",
    "A Triplet Loss é uma função de perda versátil que pode ser aplicada em diferentes abordagens de redes neurais em grafos. Para o problema de alinhamento de competências em aprendizado não-supervisionado, a escolha da melhor função de perda e da arquitetura do modelo dependerá das características específicas do seu problema e dos seus objetivos, mas pode-se observar de forma geral, que:\n",
    "\n",
    "* A escolha dos trios (âncora, positivo e negativo) é crucial para o bom desempenho da Triplet Loss. É importante definir uma estratégia de amostragem que leve em conta as características do grafo e o objetivo de alinhamento de competências.\n",
    "* A margem da Triplet Loss é um hiperparâmetro importante que deve ser ajustado para obter o melhor desempenho.\n",
    "* A Triplet Loss pode ser combinada com outras funções de perda, como a DGI ou a VGAE, para capturar diferentes aspectos do problema e melhorar o aprendizado das representações.\n",
    "* É fundamental avaliar o desempenho do modelo com diferentes métricas de avaliação,  além de analisar os embeddings e clusters gerados para garantir que o modelo esteja alinhando as competências de forma eficaz e interpretável.\n",
    "\n",
    "\n",
    "A interpretabilidade do modelo também é importante. Analise os embeddings gerados e os clusters formados para entender como o modelo está realizando o alinhamento de competências.\n",
    "Ao combinar a Triplet Loss com uma arquitetura de rede neural em grafos adequada e uma estratégia de amostragem eficiente, você poderá desenvolver um modelo de aprendizado não-supervisionado capaz de alinhar as competências da ICT aos produtos estratégicos e auxiliar na identificação de lacunas e oportunidades de desenvolvimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros iniciais e ajuste de hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A escolha dos parâmetros para cada modelo depende de diversos fatores, como o tamanho e a complexidade do grafo de conhecimento, a quantidade de dados de treinamento, a capacidade computacional disponível e o objetivo da análise. \n",
    "\n",
    "Partimos de alguns valores iniciais razoáveis para cada parâmetro para ajustá-los posteriormente com base nos resultados dos experimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `num_features`: Depende do número de features para cada nó do grafo (pesquisadores, competências e produtos). \n",
    "    * **Exemplo:** Se você tiver 10 features para cada pesquisador (e.g., anos de experiência, número de publicações, áreas de atuação), 5 features para cada competência (e.g., nível de proficiência, tipo de competência) e 3 features para cada produto estratégico (e.g., complexidade, área terapêutica), você pode concatenar esses features em um vetor de 18 dimensões.\n",
    "    * **Valor inicial:**  Número total de features extraídas para cada nó.\n",
    "\n",
    "* `hidden_dim`: Define a dimensão das camadas ocultas da KAN.\n",
    "    * **Valor inicial:**  64 ou 128.  Experimentar variações em potências de 2.\n",
    "\n",
    "* `num_classes`: Define o número de classes (clusters) que você deseja gerar.\n",
    "    * **Valor inicial:**  Mesmo valor utilizado no modelo híbrido.\n",
    "\n",
    "* `num_layers`: Define o número de camadas na KAN.\n",
    "    * **Valor inicial:**  3 ou 4 é um bom início. Escolher um valor que faça sentido para o problema.  Você pode usar técnicas como o método do cotovelo para auxiliar na escolha do número ideal de clusters.\n",
    "\n",
    "* `dropout`: Define a taxa de dropout.\n",
    "    * **Valor inicial:**  0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observações:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Ajuste dos parâmetros:**  É fundamental realizar experimentos e analisar os resultados para ajustar os parâmetros e encontrar a melhor configuração para cada modelo.\n",
    "* **Técnicas de otimização:**  Utilize técnicas como grid search ou random search para explorar diferentes combinações de parâmetros e encontrar a configuração ótima.\n",
    "* **Métricas de avaliação:**  Monitore as métricas de avaliação durante o treinamento e a validação para avaliar o desempenho do modelo e guiar o ajuste dos parâmetros.\n",
    "\n",
    "Estes foram apenas os valores iniciais. A melhor configuração para os parâmetros dependerá das características do grafo de conhecimento, da quantidade de dados de treinamento e do objetivo da análise. Esses valores foram buscados por otimização automatizada de hiperparâmetros dentro de espaços de busca relacionados com os valores inciais mostrados acima. A partir dos desse ajuste e de vários experimentos para medição de desempenho computacional é que se chegou aos hiperparâmetros adequados para obter o melhor desempenho de cada modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Implementações em código</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para criar a estrutura de manipulação dos arquivos JSON e construir o grafo de análise, primeiro carregamos os dados dos arquivos JSON e, em seguida, criamos o grafo de conhecimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pytorch-metric-learning\n",
    "\n",
    "# Importações necessárias\n",
    "import os\n",
    "import json\n",
    "import cudf\n",
    "import cugraph\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from git import Repo\n",
    "from pyvis.network import Network\n",
    "from IPython.display import HTML, display\n",
    "from semantic_matcher import RedeNeuralHibrida, RedeNeuralKAN, RedeNeuralFourier\n",
    "\n",
    "def display_full_width_df(df):\n",
    "    \"\"\"\n",
    "    Formats the DataFrame to occupy the entire width of the cell, uses line breaks, and justifies the text to the left.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to be formatted.\n",
    "    \"\"\"\n",
    "\n",
    "    styled_df = df.to_html(classes='full-width-df')\n",
    "    css_style = \"\"\"\n",
    "    <style>\n",
    "    .full-width-df {\n",
    "        width: 100%;\n",
    "    }\n",
    "\n",
    "    .full-width-df td {\n",
    "        word-wrap: break-word;\n",
    "        white-space: pre-wrap;\n",
    "        text-align: left;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    display(HTML(css_style + styled_df))\n",
    "    # return css_style + styled_df\n",
    "\n",
    "def display_full_width_df(df):\n",
    "    \"\"\"\n",
    "    Formats the DataFrame to occupy the entire width of the cell, uses line breaks, and justifies the text to the left.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to be formatted.\n",
    "    \"\"\"\n",
    "\n",
    "    styled_df = df.to_html(classes='full-width-df')\n",
    "    css_style = \"\"\"\n",
    "    <style>\n",
    "    .full-width-df td {\n",
    "        word-wrap: break-word;\n",
    "        white-space: pre-wrap;\n",
    "        text-align: left;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    display(HTML(css_style + styled_df))\n",
    "    # return css_style + styled_df\n",
    "\n",
    "def recuperar_questionario():\n",
    "    filename = 'Alinhamento de competências em pesquisa às políticas para desenvolvimento do CEIS.xlsx'\n",
    "    pathfilename = os.path.join(xlsx_folder, filename)    \n",
    "    df_questionario = pd.read_excel(pathfilename).iloc[:, 7:]\n",
    "    print('Questionamentos realizados em levantamento junto aos pesquisadores da ICT:')\n",
    "    for n,i in enumerate(df_questionario.keys()):\n",
    "        if n==0:\n",
    "            print('\\nQuestões e palavras-chave de pesquisa:')\n",
    "        elif n==2:\n",
    "            print('\\nCompetências já dominadas e a evoluir:')\n",
    "        elif n==4:\n",
    "            print('\\nIntenção de atuar em atividades de desenvolvimento tencológico:')\n",
    "        elif n==5:\n",
    "            print('\\nNível de maturidade segmentado por tipo de tecnologias:')\n",
    "        elif n==11:\n",
    "            print('\\nConhecimentos sobre Estratégia para Desenvolvimento do CEIS, quanto:')\n",
    "        elif n==15:\n",
    "            print('\\nProdutos mais próximos das pesquisas na ICT:')\n",
    "        elif n==19:\n",
    "            print('\\nOcupação do tempo de trabalho por tipos de atividades de trabalho:')\n",
    "        elif n==25:\n",
    "            print('\\nSatisfação e identificação:')        \n",
    "        print(f\"  {n+1:2} {i}\")\n",
    "    return df_questionario\n",
    "\n",
    "def montar_dataframes_levantamento():\n",
    "    filename = 'Alinhamento de competências em pesquisa às políticas para desenvolvimento do CEIS.xlsx'\n",
    "    pathfilename = os.path.join(xlsx_folder, filename)\n",
    "    df_levantamento = pd.read_excel(pathfilename).iloc[:, 7:]\n",
    "    df_levantamento.columns=['questoes_pesquisa','palavras_chave','compet_dominadas','compet_desenvolver','avancar_desenv_desafios',\n",
    "                            'tec_diagnostico','tec_pesquisa','tec_terapeutica','tec_serviço','tec_social','tec_digital',\n",
    "                            'conhec_blocos','conhec_desafios','conhec_plataformas','conhec_produtos',\n",
    "                            'desafio_mais_proximo','produtos_bloco1','produtos_bloco2','adicional_contibuir',\n",
    "                            'tempo_lev_dados','tempo_analise_dados','tempo_debates_grupo','tempo_redigir_textos','tempo_reunioes','tempo_comunicacoes',                      \n",
    "                            'satisfacao','nome']\n",
    "\n",
    "    # df_levantamento.drop(columns=['tempo_fx1','tempo_fx2','tempo_fx3','tempo_fx4','tempo_fx5','tempo_fx6'], inplace=True)\n",
    "    print('Questionamentos realizados em levantamento junto aos pesquisadores da ICT:')\n",
    "    for n,i in enumerate(df_levantamento.keys()):\n",
    "        if n==0:\n",
    "            print('\\nQuestões e palavras-chave de pesquisa:')\n",
    "        elif n==2:\n",
    "            print('\\nCompetências já dominadas e a evoluir:')\n",
    "        elif n==4:\n",
    "            print('\\nIntenção de atuar em atividades de desenvolvimento tencológico:')\n",
    "        elif n==5:\n",
    "            print('\\nNível de maturidade segmentado por tipo de tecnologias:')\n",
    "        elif n==11:\n",
    "            print('\\nConhecimentos sobre Estratégia para Desenvolvimento do CEIS, quanto:')\n",
    "        elif n==15:\n",
    "            print('\\nProdutos mais próximos das pesquisas na ICT:')\n",
    "        elif n==19:\n",
    "            print('\\nOcupação do tempo de trabalho por tipos de atividades de trabalho:')\n",
    "        elif n==25:\n",
    "            print('\\nSatisfação e identificação:')        \n",
    "        print(f\"  {n+1:2} {i}\")\n",
    "\n",
    "    # Criar df_questoes com as 5 primeiras colunas do df_levantamento\n",
    "    df_questoes = df_levantamento.iloc[:, :5]\n",
    "\n",
    "    # Adicionar coluna 'id_resposta' ao df_questoes \n",
    "    df_questoes['id_resposta'] = df_levantamento.index\n",
    "\n",
    "    # Adicionar coluna 'nome_pesquisador' ao df_questoes com os valores da última coluna do df_levantamento \n",
    "    # df_questoes['nome_pesquisador'] = df_levantamento.iloc[:, -1]\n",
    "\n",
    "    # Montar dataframe com faixas de TRL por cada tipo de tecnologia\n",
    "    df_trls = df_levantamento.iloc[:,5:11]\n",
    "    df_trls['id_resposta'] = df_levantamento.index\n",
    "\n",
    "    # Montar dataframe sobre o conhecimento atual sobre estratégia do CEIS\n",
    "    df_estrat_ceis = df_levantamento.iloc[:,11:15]\n",
    "    df_estrat_ceis['id_resposta'] = df_levantamento.index\n",
    "\n",
    "    # Montar dataframe sobre os desafios e produtos mais próximos dentro da estratégia do CEIS\n",
    "    df_produtos_proximos = df_levantamento.iloc[:,15:19]\n",
    "    df_produtos_proximos['id_resposta'] = df_levantamento.index\n",
    "\n",
    "    # Montar dataframe sobre tempo destinado aos tipos de atividades típicas em pesquisa\n",
    "    df_tempo_ativ = df_levantamento.iloc[:,19:25]\n",
    "    df_tempo_ativ['id_resposta'] = df_levantamento.index\n",
    "\n",
    "    # Montar dataframe sobre satisfação com a coordenação de pesquisa e nome\n",
    "    df_satisf = df_levantamento.iloc[:,25:-1]\n",
    "\n",
    "    return df_levantamento, df_questoes, df_trls, df_estrat_ceis, df_produtos_proximos, df_tempo_ativ, df_satisf\n",
    "\n",
    "def listar_questoes_pesquisa(df_questoes):\n",
    "    print('Questões de pesquisa:')\n",
    "    pular=[np.nan,'','as principais questões científicas que norteiam minhas pesquisas na fiocruz ceará, relacionadas ao enfrentamento dos desafios em saúde, envolvem:','essas questões são centrais para o desenvolvimento de soluções que melhorem a vigilância epidemiológica e o acesso ao diagnóstico no brasil.']\n",
    "    for i in df_questoes.iloc[:,0]:\n",
    "        try:\n",
    "            if i.strip().lower() not in pular:\n",
    "                i = i.replace(';','\\n')\n",
    "                for sub_i in i.split('\\n'):\n",
    "                    if sub_i.strip().lower() not in pular:\n",
    "                        print(f'  {sub_i.strip().lower()}')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def listar_palavras_chave(df_questoes):\n",
    "    print('Palavras-Chave:')\n",
    "    pular=['','as principais palavras-chave que podem associar meus temas de pesquisa com oportunidades de fomento que desejo monitorar são:']\n",
    "    for i in df_questoes.iloc[:,1]:\n",
    "        try:\n",
    "            if i.strip().lower() not in pular:\n",
    "                i = i.replace(';','\\n')\n",
    "                for sub_i in i.split('\\n'):\n",
    "                    if sub_i.strip().lower() not in pular:\n",
    "                        print(f'  {sub_i.strip().lower()}')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def listar_desafios_proximos(df_produtos_proximos):\n",
    "    print('Desafios mais próximos das pesquisas na ICT:')\n",
    "    pular = ['', ' ', 'não encontrei produto algum na lista acima que corresponda com minhas pesquisas atuais e no futuro próximo']\n",
    "    for i in df_produtos_proximos.iloc[:,0]:\n",
    "        try:\n",
    "            # Verifica se a string 'i' não está vazia e não contém apenas espaços em branco\n",
    "            if i.strip() and i.lower().strip() not in pular:\n",
    "                i = i.replace(';','\\n')\n",
    "                for sub_i in i.split('\\n'):\n",
    "                    if sub_i.strip().lower() not in pular:\n",
    "                        print(f'  {sub_i.strip().lower()}')\n",
    "            print()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Divide a coluna de desafios em múltiplas colunas, separando os desafios por ponto e vírgula\n",
    "    df_produtos_proximos.iloc[:, 0] = df_produtos_proximos.iloc[:, 0].str.split(';')\n",
    "\n",
    "    # \"Explode\" o DataFrame para que cada desafio fique em uma linha separada\n",
    "    df_exploded = df_produtos_proximos.explode(df_produtos_proximos.columns[0])\n",
    "\n",
    "    # Filtra os valores vazios ou com apenas espaços em branco\n",
    "    df_exploded = df_exploded[df_exploded.iloc[:, 0].str.strip().astype(bool)]\n",
    "\n",
    "    # Calcula a frequência de cada desafio\n",
    "    df_sum = df_exploded[df_produtos_proximos.columns[0]].value_counts()\n",
    "\n",
    "    # Converte a Series para DataFrame e redefine o índice\n",
    "    df = pd.DataFrame(df_sum).reset_index()\n",
    "\n",
    "    # Renomeia as colunas para 'Desafio' e 'Total'\n",
    "    df.columns = ['Desafio', 'Total']\n",
    "    df_full = display_full_width_df(df)\n",
    "\n",
    "def listar_produtos_proximos_emergencias(df_produtos_proximos):\n",
    "    print('Produtos do Bloco 01 (Preparação do Sistema de Saúde para Emergências Sanitárias) mais próximos das pesquisas na ICT:')\n",
    "    pular = ['', 'não encontrei produto algum na lista acima que corresponda com minhas pesquisas atuais e no futuro próximo']\n",
    "    for i in df_produtos_proximos.iloc[:,1]:\n",
    "        try:\n",
    "            if i.lower().strip() not in pular:\n",
    "                i = i.replace(';','\\n')\n",
    "                for sub_i in i.split('\\n'):\n",
    "                    if sub_i.strip().lower() not in pular:\n",
    "                        print(f'  {sub_i.strip().lower()}')\n",
    "        except:\n",
    "            pass   \n",
    "\n",
    "def listar_produtos_proximos_agravos(df_produtos_proximos):\n",
    "    print('Produtos do Bloco 02 (Doenças e Agravos Críticos para o SUS) mais próximos das pesquisas na ICT:')\n",
    "    pular = ['','não encontrei agravo algum na lista acima que corresponda com minhas pesquisas atuais e no futuro próximo']\n",
    "    for i in df_produtos_proximos.iloc[:,2]:\n",
    "        try:\n",
    "            if i.strip().lower() not in pular:\n",
    "                i = i.replace(';','\\n')\n",
    "                for sub_i in i.split('\\n'):\n",
    "                    if sub_i.strip().lower() not in pular:\n",
    "                        print(f'  {sub_i.strip().lower()}')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def produtos_extra(df_produtos_proximos):\n",
    "    print('Produtos extra estratégia do CEIS:')\n",
    "    pular = [np.nan,'não sei responder.','não consigo enxergar','já associado']\n",
    "    for i in df_produtos_proximos.iloc[:,2]:\n",
    "        try:\n",
    "            if i.strip().lower() not in pular:\n",
    "                i = i.replace(';','\\n')\n",
    "                for sub_i in i.split('\\n'):\n",
    "                    if sub_i.strip().lower() not in pular:\n",
    "                        print(f'  {sub_i.strip().lower()}')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def df_to_json(dataframe):\n",
    "  # Converte o DataFrame para JSON no formato 'records' com 'lines=True' e UTF-8\n",
    "  json_data = dataframe.to_json(orient='records', lines=True, force_ascii=False)\n",
    "\n",
    "  # Divide a string JSON em uma lista de strings, uma para cada linha\n",
    "  json_lines = json_data.splitlines()\n",
    "\n",
    "  # Converte cada linha em um objeto JSON\n",
    "  json_objects = []\n",
    "  for line in json_lines:\n",
    "    try:\n",
    "      json_objects.append(json.loads(line))\n",
    "    except json.JSONDecodeError as e:\n",
    "      print(f\"Erro ao analisar a linha: {line}\")\n",
    "      print(e)\n",
    "\n",
    "  # Imprime a lista de objetos JSON\n",
    "  return json_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Síntese dos dados para criar o Grafo de Conhecimento:\n",
      "\n",
      "  Relacionamentos da Cadeia de Agregação de Valor em Produtos por tipo:\n",
      "       Biológicos:  2 chaves: dict_keys(['nodes', 'edges'])\n",
      "    Peq.Moléculas:  2 chaves: dict_keys(['nodes', 'edges'])\n",
      "\n",
      "  Dados das entidades em análise:\n",
      "      Matriz_CEIS:  2 blocos, contendo as chaves: ['bloco', 'id', 'titulo', 'produtos', 'desafios']\n",
      "       Currículos: 38 currículos, com 15 chaves em cada currículo\n",
      "\n",
      "  Dados sobre cada pesquisador:\n",
      "     Identificação\n",
      "     Idiomas\n",
      "     Formação\n",
      "     Atuação Profissional\n",
      "     Linhas de Pesquisa\n",
      "     Áreas\n",
      "     Produções\n",
      "     ProjetosPesquisa\n",
      "     ProjetosExtensão\n",
      "     ProjetosDesenvolvimento\n",
      "     ProjetosOutros\n",
      "     Patentes e registros\n",
      "     Bancas\n",
      "     Orientações\n",
      "     JCR2\n",
      "\n",
      "Lista de produtos por Bloco da Matriz CEIS:\n",
      "  Bloco: B01. PREPARAÇÃO DO SISTEMA DE SAÚDE PARA EMERGÊNCIAS SANITÁRIAS\n",
      "    Vacinas do PNI que demandem atualização tecnológica\n",
      "    Vacinas do PNI que possuem dependência externa\n",
      "    Vacina vírus sincicial respiratório (RSV)\n",
      "    Vacina Chikungunya\n",
      "    Vacina contra Dengue\n",
      "    Vacina Esquistossomose\n",
      "    Vacina Hanseníase\n",
      "    Vacina Leishmanioses\n",
      "    Vacina Zika\n",
      "    Vacina Herpes Zoster\n",
      "    Vacinas combinadas\n",
      "    Vacina associada a formas farmacêuticas não invasivas\n",
      "    Testes diagnósticos moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnósticos in vitro\n",
      "    Kit de extração de ácidos nucléicos\n",
      "    Seringas e agulhas hipodérmicas\n",
      "    Soros Imunossupressores\n",
      "    Hemoderivados e bioprodutos\n",
      "    Novas tecnologias para hemoterapia\n",
      "    Serviços tecnológicos para hemoterapia\n",
      "    Desenvolvimento e produção local de tecnologias de informação e conectividade para centralização e padronização de ensaios sorológicos para triagem do sangue doado\n",
      "    Teste de amplificação de ácidos nucléicos de última geração\n",
      "    Tecnologias para inativação de patógenos em bolsas de sangue de doação voluntária\n",
      "    Máquina de aférese\n",
      "    IFA de base química ou biotecnológica de medicamentos demandados pelo SUS que apresentem dependência externa de insumos críticos da cadeia produtiva para todos os desafios em saúde definidos nesta matriz\n",
      "    Radiofármacos e produtos de medicina nuclear\n",
      "    IFA antimicrobianos\n",
      "    Produtos antimicrobianos demandados pelo SUS que não tenham produção nacional e para microorganismos resistentes\n",
      "    Insumos críticos da cadeia produtiva de dispositivos médicos\n",
      "    IFA obtidos por processos tecnológicos e industriais sustentáveis baseados na química verde\n",
      "    Fitoterápicos e produtos da biodiversidade apoiados pelo SUS\n",
      "    Desenvolvimento e produção local de tecnologias utilizadas na atenção à saúde (telessaude, telemonitoramento, telediagnóstico, entre outros)\n",
      "    Desenvolvimento e produção local de tecnologias de informação e conectividade para gestão de estoques\n",
      "    Desenvolvimento e produção local de tecnologias de informação e conectividade para rastreabilidade de órteses, próteses e meios auxiliares de locomoção dispensados pelo SUS\n",
      "    Desenvolvimento e produção local de tecnologias de informação e conectividade para a gestão de dados clínicos de prontuários eletrônicos\n",
      "    Desenvolvimento e produção local de tecnologias de informação e conectividade com padrões e interoperabilidade nos diversos níveis do SUS\n",
      "    Desenvolvimento e produção local de tecnologias de informação e conectividade para acompanhamento de aquisição, dispensação e desabastecimento de medicamentos\n",
      "    Equipamentos de uso médico adaptados para uso na atenção primária, atendimento pré-hospitalar e domiciliar\n",
      "    Equipamentos de uso médico e odontológico portáteis e com fontes alternativas de energia para uso em locais remotos e sem infraestrutura\n",
      "    Equipamentos para diagnóstico por imagem dotados de soluções integradas\n",
      "    Equipamentos para diagnóstico e terapia clínica e cirúrgica para oftalmologia\n",
      "    Dispositivos de tecnologia assistiva que auxiliem e aumentem a autonomia de pessoas com deficiências visual, auditiva e motora\n",
      "    Cimento de ionômero de vidro de alta viscosidade\n",
      "    Próteses cirúrgicas de ombro, quadril, fêmur, joelho, crânio e odontológicas, em titânio, porcelana ou biomateriais\n",
      "    Dispositivo de assistência ventricular, máquinas de perfusão para órgãos e oxigenação por membrana extracorpórea\n",
      "    Líquido para preservação de órgãos e córnea\n",
      "\n",
      "  Bloco: B02. DOENÇAS E AGRAVOS CRÍTICOS PARA O SUS\n",
      "    Medicamentos negligenciados e Novos esquemas terapêuticos para otimização do tratamento de Tuberculose, Doença de Chagas, Hanseníase, Esquistossomose, Leishmaniose, Malária e demais doenças elencadas pelo CIEDDS\n",
      "    Medicamentos e novos esquemas terapêuticos demandados pelo SUS para tratamento de HIV/AIDS e Hepatites virais\n",
      "    Medicamentos e formulações para tratamento da população pediátrica\n",
      "    Produtos e nutracêuticos para população pediátrica ou vulnerável\n",
      "    Plataforma de RT-PCR para diagnóstico de arboviroses, multiplex ou isolada\n",
      "    Testes diagnóstico moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnóstico in vitro\n",
      "    Teste para determinação de sensibilidade aos antimicrobianos\n",
      "    Kit de extração de ácidos nucléicos\n",
      "    Inibidores de tirosina quinase\n",
      "    Inibidores de ciclina\n",
      "    Acetato de goserrelina\n",
      "    Pertuzumabe\n",
      "    Trastuzumabe deruxtecan\n",
      "    Pembrolizumabe\n",
      "    Blinatumomabe\n",
      "    Lenalidomida\n",
      "    BCG vesical\n",
      "    L-asparaginase/ Pegaspargase\n",
      "    Produtos de Terapia Gênica\n",
      "    Produtos e formulações para tratamento da população pediátrica\n",
      "    Equipamentos e plataformas para telecolposcopia, telepatologia e telerradiologia\n",
      "    Kit de autocoleta para detecção de HPV por biologia molecular\n",
      "    Teste point-of-care para o câncer de colo de útero\n",
      "    Testes diagnósticos moleculares e de anatomia patológica\n",
      "    Medicamentos e IFA utilizados pelo SUS que apresentem dependência externa de insumos críticos da cadeia produtiva\n",
      "    Espiral de platina\n",
      "    Próteses e outros dispositivos médicos implantáveis cardiovasculares\n",
      "    Testes diagnósticos para a dosagem e avaliação de marcadores cardíacos\n",
      "    Medicamentos e IFA utilizados pelo SUS que apresentem dependência externa de insumos críticos da cadeia produtiva\n",
      "    Insulinas e seus análogos\n",
      "    Desenvolvimento e produção local de tecnologias de informação e conectividade para o monitoramento da diabetes\n",
      "    Testes diagnóstico in vitro\n",
      "    Dispositivos médicos para o tratamento de úlceras no pé diabético\n",
      "    Medicamentos e IFA utilizados pelo SUS para doenças relacionadas ao envelhecimento que apresentem dependência externa de insumos críticos da cadeia produtiva\n",
      "    Conjunto de eletrodos e gerador para estimulação elétrica profunda cerebral\n",
      "    Desenvolvimento e produção local de tecnologias de informação e conectividade para melhoria da qualidade de vida da população idosa\n",
      "    Produtos para tratamento da Fibrose Cística: ivacaftor / elexacaftor, tezacaftor e ivacaftor\n",
      "    Produtos para tratamento da Atrofia Medular Espinhal: Risdiplam\n",
      "    Imunossupressores seletivos para Esclerose Múltipla e Hemoglobinúria paroxística noturna\n",
      "    Enzimas para tratamento de Mucopolissaridoses, Doença de Gaucher, Doença de Pompe e Fibrose Cística\n",
      "    Produtos para tratamento da Polineuropatia Amiloidótica Familiar\n",
      "    Produtos para tratamento da Acromegalia, Raquitismo e osteomalácia\n",
      "    Produtos de Terapia Gênica\n",
      "    Produtos e nutracêuticos para pacientes com erros inatos de metabolismo ou outras doenças raras\n",
      "    Equipamentos e insumos para o rastreamento e exames confirmatórios das doenças elegíveis à triagem neonatal\n",
      "    Sequenciamento completo do exoma\n",
      "    Medicamentos e IFA utilizados pelo SUS paradoenças autoimunes, respiratórias e transtornosmentais que apresentem dependência externa de insumos críticos da cadeia produtiva\n",
      "    Produtos de Terapia Gênica\n",
      "    Gerador de pulso para terapia de estimulação do nervo vago\n",
      "    Equipamentos e insumos para diálise peritoneal\n",
      "    Capilares, cateteres e máquina para hemodiálise\n",
      "    Teste rápido e kits diagnóstico para pré-eclâmpsia\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Recuperar dados pré-processados\n",
    "# Informar caminho para arquivo CSV usando raiz do repositório Git como referência\n",
    "repo = Repo(search_parent_directories=True)\n",
    "root_folder = repo.working_tree_dir\n",
    "xlsx_folder = os.path.join(root_folder, '_data', 'in_xls')\n",
    "json_folder = os.path.join(root_folder, '_data', 'out_json')\n",
    "\n",
    "# Carregar os dados dos arquivos JSON\n",
    "with open(os.path.join(json_folder,'curriculos.json'), 'r') as f:\n",
    "    curriculos_data = json.load(f)\n",
    "with open(os.path.join(json_folder,'matriz_ceis.json'), 'r') as f:\n",
    "    matriz_ceis_data = json.load(f)\n",
    "with open(os.path.join(json_folder,'4dm_biologics.json'), 'r') as f:\n",
    "    relacoes_biologicos = json.load(f)\n",
    "with open(os.path.join(json_folder,'4dm_smallmolecules.json'), 'r') as f:\n",
    "    relacoes_pequenas_moleculas = json.load(f)\n",
    "\n",
    "print(\"Síntese dos dados para criar o Grafo de Conhecimento:\\n\")\n",
    "print(\"  Relacionamentos da Cadeia de Agregação de Valor em Produtos por tipo:\")\n",
    "print(f\"       Biológicos: {len(relacoes_biologicos):2} chaves: {relacoes_biologicos.keys()}\")\n",
    "print(f\"    Peq.Moléculas: {len(relacoes_pequenas_moleculas):2} chaves: {relacoes_pequenas_moleculas.keys()}\")\n",
    "print(\"\\n  Dados das entidades em análise:\")\n",
    "print(f\"      Matriz_CEIS: {len(matriz_ceis_data.get('blocos')):2} blocos, contendo as chaves: {list(matriz_ceis_data.get('blocos')[0].keys())}\")\n",
    "print(f\"       Currículos: {len(curriculos_data):2} currículos, com {len(curriculos_data[0])} chaves em cada currículo\")\n",
    "print(f\"\\n  Dados sobre cada pesquisador:\")\n",
    "for i in list(curriculos_data[0].keys()):\n",
    "    print(f\"     {i}\")\n",
    "\n",
    "print('\\nLista de produtos por Bloco da Matriz CEIS:')\n",
    "for n,b in enumerate(matriz_ceis_data.get('blocos')):\n",
    "    print(f\"  Bloco: {b.get('titulo')}\")\n",
    "    for p in b.get('produtos'):\n",
    "        print(f\"    {p.get('nome')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados de levantamento de Questões e Palavras-Chave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questionamentos realizados em levantamento junto aos pesquisadores da ICT:\n",
      "\n",
      "Questões e palavras-chave de pesquisa:\n",
      "   1 questoes_pesquisa\n",
      "   2 palavras_chave\n",
      "\n",
      "Competências já dominadas e a evoluir:\n",
      "   3 compet_dominadas\n",
      "   4 compet_desenvolver\n",
      "\n",
      "Intenção de atuar em atividades de desenvolvimento tencológico:\n",
      "   5 avancar_desenv_desafios\n",
      "\n",
      "Nível de maturidade segmentado por tipo de tecnologias:\n",
      "   6 tec_diagnostico\n",
      "   7 tec_pesquisa\n",
      "   8 tec_terapeutica\n",
      "   9 tec_serviço\n",
      "  10 tec_social\n",
      "  11 tec_digital\n",
      "\n",
      "Conhecimentos sobre Estratégia para Desenvolvimento do CEIS, quanto:\n",
      "  12 conhec_blocos\n",
      "  13 conhec_desafios\n",
      "  14 conhec_plataformas\n",
      "  15 conhec_produtos\n",
      "\n",
      "Produtos mais próximos das pesquisas na ICT:\n",
      "  16 desafio_mais_proximo\n",
      "  17 produtos_bloco1\n",
      "  18 produtos_bloco2\n",
      "  19 adicional_contibuir\n",
      "\n",
      "Ocupação do tempo de trabalho por tipos de atividades de trabalho:\n",
      "  20 tempo_lev_dados\n",
      "  21 tempo_analise_dados\n",
      "  22 tempo_debates_grupo\n",
      "  23 tempo_redigir_textos\n",
      "  24 tempo_reunioes\n",
      "  25 tempo_comunicacoes\n",
      "\n",
      "Satisfação e identificação:\n",
      "  26 satisfacao\n",
      "  27 nome\n"
     ]
    }
   ],
   "source": [
    "df_levantamento, df_questoes, df_trls, df_estrat_ceis, df_produtos_proximos, df_tempo_ativ, df_satisf = montar_dataframes_levantamento()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questionamentos realizados em levantamento junto aos pesquisadores da ICT:\n",
      "\n",
      "Questões e palavras-chave de pesquisa:\n",
      "   1 Qual, ou quais, as principais QUESTÕES CIENTÍFICAS* norteadoras das suas pesquisas, que estão relacionadas ao enfrentamento dos desafios em saúde, estudados nas pesquisas nas quais você atua na Fi...\n",
      "   2 Quais as principais PALAVRAS-CHAVE que podem melhor associar seus temas centrais de pesquisa com OPORTUNIDADES DE FOMENTO que você deseja que sejam monitoradas?\n",
      "\n",
      "Competências já dominadas e a evoluir:\n",
      "   3 Quais as principais COMPETÊNCIAS CIENTÍFICAS E TECNOLÓGICAS* dominadas pelo(s) grupo(s) de pesquisa no qual você atua, que podem contribuir melhor para implementar a Estratégia Nacional de Desenvo...\n",
      "   4 Em sua visão, quais competências científicas e tecnológicas precisam ser melhor desenvolvidas e exploradas na Fiocruz Ceará para ampliar o desempenho e impacto positivo das atividades de pesquisa,...\n",
      "\n",
      "Intenção de atuar em atividades de desenvolvimento tencológico:\n",
      "   5 Na sua pesquisa, você tem objetivo de avançar em etapas de desenvolvimento tecnológico? Em caso positivo, quais as principais atividades executadas? Quais, na sua visão, são os principais desafios...\n",
      "\n",
      "Nível de maturidade segmentado por tipo de tecnologias:\n",
      "   6 Tecnologia para Insumo Diagnóstico\n",
      "   7 Tecnologia para Insumo para Pesquisa\n",
      "   8 Tecnologia para Insumo Terapêutico\n",
      "   9 Tecnologia para Serviço em saúde\n",
      "  10 Tecnologia Social\n",
      "  11 Tecnologia Digital\n",
      "\n",
      "Conhecimentos sobre Estratégia para Desenvolvimento do CEIS, quanto:\n",
      "  12 Blocos\n",
      "  13 Desafios\n",
      "  14 Plataformas\n",
      "  15 Produtos\n",
      "\n",
      "Produtos mais próximos das pesquisas na ICT:\n",
      "  16 Para alinhar pesquisas com o desenvolvimento do CEIS, indique em quais Desafios suas pesquisas guardam relação mais próxima (atualmente, ou no futuro).\n",
      "  17 Para alinhar com a Preparação do Sistema de Saúde para Emergências Sanitárias (Bloco 01 da Matriz desenvolvimento do CEIS), indique quais Produtos podem ser de alguma forma suportados por algum as...\n",
      "  18 Para alinhar com as Doenças e Agravos Críticos para o SUS (Bloco 02 da Matriz desenvolvimento do CEIS), indique quais Produtos podem ser de alguma forma suportados por algum aspecto das suas pesqu...\n",
      "  19 Mesmo que não associado com os desafios e produtos acima listados, de qual maneira você enxerga que sua pesquisa pode contribuir para boa execução da Estratégia Nacional de Desenvolvimento do Comp...\n",
      "\n",
      "Ocupação do tempo de trabalho por tipos de atividades de trabalho:\n",
      "  20 Atividades de buscar dados (levantar fontes, buscar, ordenar resultados)\n",
      "  21 Atividades de ler e analisar dados (refletir sobre os dados, comparar com literatura)\n",
      "  22 Atividades de debates em grupo e construções coletivas\n",
      "  23 Atividades de redigir textos\n",
      "  24 Reuniões de trabalho (presenciais ou remotas)\n",
      "  25 Atendendo comunicações do trabalho (e-mails, Whatzapp, telefonemas etc.)\n",
      "\n",
      "Satisfação e identificação:\n",
      "  26 Avalie seu atual grau de satisfação quanto aos processos de suporte à pesquisa na Fiocruz Ceará, onde 1 estrela é o pior nível de satisfação e 5 estrelas é o melhor nível de satisfação\n",
      "  27 Caso deseje se identificar, informe aqui seu nome completo (ou conforme está no seu Currículo Lattes, caso no Lattes você não use seu nome completo) para incluirmos seu currículo em busca de oport...\n"
     ]
    }
   ],
   "source": [
    "df_questionario = recuperar_questionario()\n",
    "# df_questionario.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questoes_pesquisa</th>\n",
       "      <th>palavras_chave</th>\n",
       "      <th>compet_dominadas</th>\n",
       "      <th>compet_desenvolver</th>\n",
       "      <th>avancar_desenv_desafios</th>\n",
       "      <th>id_resposta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tratamentos mais efetivos para doenças infecci...</td>\n",
       "      <td>nanotecnologia, nanossegurança, doenças neglig...</td>\n",
       "      <td>combinação farmacológica, cultura celular, mod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sim...nosso grupo precisa de apoio para co-des...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avaliação dos atributos da Atenção Primária à ...</td>\n",
       "      <td>Atenção Primária à Saúde\\nEstratégia Saúde da ...</td>\n",
       "      <td>Competências científicas: \\n1. Epidemiologia (...</td>\n",
       "      <td>Pesquisa Clínica (Ensaios Clínicos controlados...</td>\n",
       "      <td>Sim. \\nAvançar em desenvolvimento de pesquisa ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ocorrência de bactérias super resistentes e as...</td>\n",
       "      <td>ciências ômicas, processamento de dados, análi...</td>\n",
       "      <td>No Programa de Desenvolvimento e Inovação Loca...</td>\n",
       "      <td>Precisamos comprar equipamentos que permitam a...</td>\n",
       "      <td>Sim. Inserido no bloco de serviços do CEIS, po...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quais as limitações relacionadas ao diagnóstic...</td>\n",
       "      <td>Doenças Tropicais Negligenciadas, ofidismo, le...</td>\n",
       "      <td>Desenvolvimento de insumos biológicos para apl...</td>\n",
       "      <td>Para ampliar o desempenho e impacto positivo d...</td>\n",
       "      <td>Sim. Seleção e caracterização in vitro e in vi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quais os  impactos que os sistemas agroaliment...</td>\n",
       "      <td>saúde coletiva, agrotóxicos, agroecologia, saú...</td>\n",
       "      <td>Métodos participativos de pesquisa, pesquisas ...</td>\n",
       "      <td>Valorização e equidade de todos os métodos de ...</td>\n",
       "      <td>Porque as tecnologias e soluções com as que tr...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>As relações entre a saúde mental e a atenção p...</td>\n",
       "      <td>Saúde Mental\\nAtenção primaria\\nSuicídio \\nPop...</td>\n",
       "      <td>Não sei responder.</td>\n",
       "      <td>Utilização e cruzamento de grandes bancos de d...</td>\n",
       "      <td>Não.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Como melhorar a efetividade das políticas públ...</td>\n",
       "      <td>Diversidade, equidade nas ciencias, Gênero e r...</td>\n",
       "      <td>Competencias tecnicas e teoricas que contribue...</td>\n",
       "      <td>Integração entre as áreas. Definição de objeti...</td>\n",
       "      <td>Não. As pesquisas nas áreas das ciências human...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Quais os principais desafios na APS? Que inter...</td>\n",
       "      <td>Atenção primária à saúde. Ensino na saúde. Edu...</td>\n",
       "      <td>Desenvolvimento de estudos metodológicos.</td>\n",
       "      <td>Desenvolvimento de estudos que avaliem tecnolo...</td>\n",
       "      <td>Atuo em desenvolvimento de produtos técnicos e...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>As principais questões científicas que norteia...</td>\n",
       "      <td>As principais palavras-chave que podem associa...</td>\n",
       "      <td>As principais competências científicas e tecno...</td>\n",
       "      <td>Na minha visão, as competências científicas e ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   questoes_pesquisa  \\\n",
       "0  tratamentos mais efetivos para doenças infecci...   \n",
       "1  Avaliação dos atributos da Atenção Primária à ...   \n",
       "2  Ocorrência de bactérias super resistentes e as...   \n",
       "3  Quais as limitações relacionadas ao diagnóstic...   \n",
       "4  Quais os  impactos que os sistemas agroaliment...   \n",
       "5  As relações entre a saúde mental e a atenção p...   \n",
       "6  Como melhorar a efetividade das políticas públ...   \n",
       "7  Quais os principais desafios na APS? Que inter...   \n",
       "8  As principais questões científicas que norteia...   \n",
       "\n",
       "                                      palavras_chave  \\\n",
       "0  nanotecnologia, nanossegurança, doenças neglig...   \n",
       "1  Atenção Primária à Saúde\\nEstratégia Saúde da ...   \n",
       "2  ciências ômicas, processamento de dados, análi...   \n",
       "3  Doenças Tropicais Negligenciadas, ofidismo, le...   \n",
       "4  saúde coletiva, agrotóxicos, agroecologia, saú...   \n",
       "5  Saúde Mental\\nAtenção primaria\\nSuicídio \\nPop...   \n",
       "6  Diversidade, equidade nas ciencias, Gênero e r...   \n",
       "7  Atenção primária à saúde. Ensino na saúde. Edu...   \n",
       "8  As principais palavras-chave que podem associa...   \n",
       "\n",
       "                                    compet_dominadas  \\\n",
       "0  combinação farmacológica, cultura celular, mod...   \n",
       "1  Competências científicas: \\n1. Epidemiologia (...   \n",
       "2  No Programa de Desenvolvimento e Inovação Loca...   \n",
       "3  Desenvolvimento de insumos biológicos para apl...   \n",
       "4  Métodos participativos de pesquisa, pesquisas ...   \n",
       "5                                 Não sei responder.   \n",
       "6  Competencias tecnicas e teoricas que contribue...   \n",
       "7          Desenvolvimento de estudos metodológicos.   \n",
       "8  As principais competências científicas e tecno...   \n",
       "\n",
       "                                  compet_desenvolver  \\\n",
       "0                                                NaN   \n",
       "1  Pesquisa Clínica (Ensaios Clínicos controlados...   \n",
       "2  Precisamos comprar equipamentos que permitam a...   \n",
       "3  Para ampliar o desempenho e impacto positivo d...   \n",
       "4  Valorização e equidade de todos os métodos de ...   \n",
       "5  Utilização e cruzamento de grandes bancos de d...   \n",
       "6  Integração entre as áreas. Definição de objeti...   \n",
       "7  Desenvolvimento de estudos que avaliem tecnolo...   \n",
       "8  Na minha visão, as competências científicas e ...   \n",
       "\n",
       "                             avancar_desenv_desafios  id_resposta  \n",
       "0  sim...nosso grupo precisa de apoio para co-des...            0  \n",
       "1  Sim. \\nAvançar em desenvolvimento de pesquisa ...            1  \n",
       "2  Sim. Inserido no bloco de serviços do CEIS, po...            2  \n",
       "3  Sim. Seleção e caracterização in vitro e in vi...            3  \n",
       "4  Porque as tecnologias e soluções com as que tr...            4  \n",
       "5                                               Não.            5  \n",
       "6  Não. As pesquisas nas áreas das ciências human...            6  \n",
       "7  Atuo em desenvolvimento de produtos técnicos e...            7  \n",
       "8                                                NaN            8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'questoes_pesquisa': 'tratamentos mais efetivos para doenças infecciosas e câncer; vacinas; terapias otimizadas baseadas em nanotecnologia ',\n",
       "  'palavras_chave': 'nanotecnologia, nanossegurança, doenças negligenciadas, câncer, terapia combinada, vacinas',\n",
       "  'compet_dominadas': 'combinação farmacológica, cultura celular, modelos experimentais, vacinas, nanotecnologia, imunofarmacologia',\n",
       "  'compet_desenvolver': None,\n",
       "  'avancar_desenv_desafios': 'sim...nosso grupo precisa de apoio para co-desenvolvimento e/ou transferência de tecnologia',\n",
       "  'id_resposta': 0},\n",
       " {'questoes_pesquisa': 'Avaliação dos atributos da Atenção Primária à Saúde; \\nPesquisas epidemiológicas sobre doenças crônicas não transmissíveis, como diabetes mellitus;\\nPesquisa clínica na Estratégia Saúde da Família;\\nDesenvolvimento e validação de tecnologias (aplicativos, vídeos) voltados para a Estratégia Saúde da Família.',\n",
       "  'palavras_chave': 'Atenção Primária à Saúde\\nEstratégia Saúde da Família\\nPesquisa Clínica\\nEnsaios clínicos\\nDiabetes Mellitus\\nTecnologias em saúde',\n",
       "  'compet_dominadas': 'Competências científicas: \\n1. Epidemiologia (Conhecimento, Habilidade e Análise de riscos/fatores associados a doenças) como pano de fundo para os desenhos de pesquisa.\\n2. Bioestatística \\n3. Pesquisa Clínica (Ensaios Clínicos controlados e randomizados)\\n\\nCompetências Tecnológicas:\\n1. Tecnologia de Comunicação e Informação (TIC). \\n2. Modelagem\\n3. Ética em Pesquisa e Saúde.',\n",
       "  'compet_desenvolver': 'Pesquisa Clínica (Ensaios Clínicos controlados e randomizados) - construção de um centro de pesquisa.\\nTecnologia de Comunicação e Informação (TIC). \\nÉtica em Pesquisa e Saúde.',\n",
       "  'avancar_desenv_desafios': 'Sim. \\nAvançar em desenvolvimento de pesquisa clínica;\\nTIC (aplicativos).',\n",
       "  'id_resposta': 1},\n",
       " {'questoes_pesquisa': 'Ocorrência de bactérias super resistentes e associação com poluição ambiental por agrotóxicos; contaminação por metais pesados através da cadeia alimentar e associação com risco de câncer; fatores extrínsecos que contribuem para a incidência de distúrbios metais.',\n",
       "  'palavras_chave': 'ciências ômicas, processamento de dados, análise de vias biológicas, metabolômica, metagenômica, desenvolvimento de métodos diagnósticos e prognósticos de doenças',\n",
       "  'compet_dominadas': 'No Programa de Desenvolvimento e Inovação Local, podemos contribuir com a tecnologia de desenvolvimento de métodos analíticos, processamento de dados, uso da inteligência artificial e aprendizados de máquina para a detecção precoce de doenças.\\nNo Programa para Ampliação e Modernização da Infraestrutura do CEIS, pretendemos montar uma plataforma com análises multiômicas que permita o uso, treinamento e a disseminação dessa tecnologia no estado do Ceará.',\n",
       "  'compet_desenvolver': 'Precisamos comprar equipamentos que permitam as análises multiômicas (principalmente metabolômica e metagenômica) e investir em computadores mais potentes, capazes de processar grande quantidade de dados. ',\n",
       "  'avancar_desenv_desafios': 'Sim. Inserido no bloco de serviços do CEIS, podemos desenvolver métodos analíticos de moléculas para diagnóstico e prognóstico de doenças, em especial distúrbios mentais, doenças decorrentes de emergências sanitárias (poluição ambiental, aquecimento global), doenças crônicas, doenças relacionadas ao envelhecimento (metabólicas, etc).',\n",
       "  'id_resposta': 2},\n",
       " {'questoes_pesquisa': 'Quais as limitações relacionadas ao diagnóstico e tratamento de doenças de importância humana, especialmente doenças negligenciadas?',\n",
       "  'palavras_chave': 'Doenças Tropicais Negligenciadas, ofidismo, leishmaniose, arboviroses, doenças neurodegenetrativas, cancer ',\n",
       "  'compet_dominadas': 'Desenvolvimento de insumos biológicos para aplicação em diagnóstico ou terapêutica',\n",
       "  'compet_desenvolver': 'Para ampliar o desempenho e impacto positivo das atividades de PDI na Fiocruz Ceará é importante o mapeamento das linhas e projetos de pesquisa e desenvolvimento, bem como as competências instaladas nos grupos de pesquisa vigentes da Fiocruz Ceará, consolidar o ambiente multiusuário dos laboratórios, fortalecer a Qualidade e implantação de BPL, além das ações voltadas a integridade de dados. Ainda, estimular a integração das equipes, estabelecer o conceito e estratégias para implantacao e operacionalização de município laboratório. ',\n",
       "  'avancar_desenv_desafios': 'Sim. Seleção e caracterização in vitro e in vivo de insumos biológicos. Desafios: mentorias relacionadas ao ambiente de Inovação, além de aproximação com área de registro de novos dispositivos de diagnóstico e medicamentos biológicos. ',\n",
       "  'id_resposta': 3},\n",
       " {'questoes_pesquisa': 'Quais os  impactos que os sistemas agroalimentares hegemônicos atuais causam na saúde e bem viver da população brasileira e quais os desdobramentos no SUS?\\nQue benefícios e potencialidades podem ser desenvolvidas ao associarmos o campo da Saúde Coletiva com a Agroecologia e quais os desdobramentos no SUS?\\nQue tecnologias/soluções inovadoras e coerentes encontramos nos territórios, realizadas pelas populações do campo, floresta, águas e áreas vulnerabilizadas que podem contribuir com o enfrentamento à crise ecológica atual - sanitária, ambiental, social, política, cultural etc e com o SUS?',\n",
       "  'palavras_chave': 'saúde coletiva, agrotóxicos, agroecologia, saúde popular, povos e comunidades tradicionais, povos indígenas, emergência climática, saúde popular, plantas medicinais e fitoterápicos.',\n",
       "  'compet_dominadas': 'Métodos participativos de pesquisa, pesquisas qualitativas, análises territoriais participativas, educação popular.',\n",
       "  'compet_desenvolver': 'Valorização e equidade de todos os métodos de pesquisa, e de todas as áreas de conhecimento.',\n",
       "  'avancar_desenv_desafios': 'Porque as tecnologias e soluções com as que trabalho são oriundas e produzidas conjuntamente com a população.\\nContudo tenho interesse no desenvolvimento de jogos e experimentos para utilizá-los em atividades de campo com crianças, jovens e adultos. ',\n",
       "  'id_resposta': 4},\n",
       " {'questoes_pesquisa': 'As relações entre a saúde mental e a atenção primária\\nDesigualdades na mortalidade por suicídios entre diferentes grupos.\\nSaúde Mental de populações vulneráveis',\n",
       "  'palavras_chave': 'Saúde Mental\\nAtenção primaria\\nSuicídio \\nPopulações vulneraveis',\n",
       "  'compet_dominadas': 'Não sei responder.',\n",
       "  'compet_desenvolver': 'Utilização e cruzamento de grandes bancos de dados (big data)',\n",
       "  'avancar_desenv_desafios': 'Não.',\n",
       "  'id_resposta': 5},\n",
       " {'questoes_pesquisa': 'Como melhorar a efetividade das políticas públicas de saúde no enfrentamento ao feminicidio e violência doméstica? \\nComo ampliar a equidade de genero e raça na área científica? \\nQue avanços as ações afirmativas vem alcançando para ampliar o acesso aos cursos e atividades da Fiocruz Ceará ?',\n",
       "  'palavras_chave': 'Diversidade, equidade nas ciencias, Gênero e raça, ações afirmativas, violência de gênero e feminicidio, interseccionalidade. ',\n",
       "  'compet_dominadas': 'Competencias tecnicas e teoricas que contribuem com a aplicação da Interseccionalidade. Compromisso institucional com uma Instituição pública mais diversa e inclusiva. Habilidade de construção e ampliação de redes de pesquisa. ',\n",
       "  'compet_desenvolver': 'Integração entre as áreas. Definição de objetivos comuns ',\n",
       "  'avancar_desenv_desafios': 'Não. As pesquisas nas áreas das ciências humanas e sociais precisam também ser colocadas como estratégicas. Penso que o CEIS precisa estimular esse olhar para a contribuição efetiva a sociedade,  aos usuários do sus, população de modo geral',\n",
       "  'id_resposta': 6},\n",
       " {'questoes_pesquisa': 'Quais os principais desafios na APS? Que intervenções podem ser realizadas para melhoria de processos, serviços e práticas na APS? Como estão sendo desenvolvidos os processos de educação permanente em saúde no SUS?',\n",
       "  'palavras_chave': 'Atenção primária à saúde. Ensino na saúde. Educação na saúde. Avaliação de serviços de saúde.',\n",
       "  'compet_dominadas': 'Desenvolvimento de estudos metodológicos.',\n",
       "  'compet_desenvolver': 'Desenvolvimento de estudos que avaliem tecnologias em saúde.',\n",
       "  'avancar_desenv_desafios': 'Atuo em desenvolvimento de produtos técnicos e tecnologicos para o SUS (e não para o CEIS), pois oriento alunos de mestrado e doutorado que devem trazer retorno a sua realidade do serviço ou do seu território de trabalho.',\n",
       "  'id_resposta': 7},\n",
       " {'questoes_pesquisa': 'As principais questões científicas que norteiam minhas pesquisas na Fiocruz Ceará, relacionadas ao enfrentamento dos desafios em saúde, envolvem:\\n\\nVigilância e detecção molecular de patógenos: Como podemos aprimorar a detecção precoce e precisa de patógenos em diferentes matrizes, como amostras clínicas e águas residuais, para antecipar surtos e contribuir para o controle de doenças infecciosas?\\n\\nImpacto das tecnologias de sequenciamento de nova geração (NGS): Como o uso de NGS pode revolucionar o diagnóstico de doenças, permitindo a identificação rápida e precisa de agentes patogênicos, e qual sua aplicabilidade no contexto do SUS, especialmente em áreas vulneráveis?\\n\\nSaúde da mulher e diagnóstico do HPV: Como testes moleculares para detecção de HPV podem ser otimizados para a prevenção e diagnóstico precoce de câncer cervical, e qual a relevância dessa abordagem na saúde pública considerando as diretrizes atuais do Ministério da Saúde?\\n\\nEssas questões são centrais para o desenvolvimento de soluções que melhorem a vigilância epidemiológica e o acesso ao diagnóstico no Brasil.',\n",
       "  'palavras_chave': 'As principais palavras-chave que podem associar meus temas de pesquisa com oportunidades de fomento que desejo monitorar são:\\n\\nSequenciamento de nova geração (NGS)\\nEpidemiologia molecular\\nVigilância translacional\\nDetecção molecular de patógenos\\nSaúde da mulher\\nHPV\\nAmostras clínicas\\nÁguas residuais\\nPrevenção e diagnóstico de ISTs\\nInovação em saúde pública\\nTecnologias diagnósticas para o SUS\\nSaúde pública e vigilância epidemiológica\\n',\n",
       "  'compet_dominadas': 'As principais competências científicas e tecnológicas do grupo de pesquisa em que atuo, que podem contribuir para a implementação da Estratégia Nacional de Desenvolvimento do Complexo Econômico-Industrial da Saúde (CEIS), incluem:\\n\\nSequenciamento de Nova Geração (NGS): Alta capacidade técnica e infraestrutura para realizar o sequenciamento genômico de patógenos, com foco em identificar e caracterizar rapidamente microrganismos em amostras clínicas e ambientais.\\n\\nDesenvolvimento de Testes Moleculares: Expertise no desenvolvimento e validação de testes de diagnóstico molecular, promovendo avanços no diagnóstico precoce e personalizado.\\n\\nEpidemiologia Molecular e Vigilância Translacional: Habilidade para utilizar ferramentas moleculares avançadas em programas de vigilância epidemiológica, permitindo o monitoramento de surtos e a identificação de padrões de transmissão em tempo real, o que fortalece a resposta do sistema de saúde.\\n\\nInovação em Saúde Pública: Capacidade de criar soluções tecnológicas inovadoras voltadas para a saúde pública, com foco na integração de novas tecnologias de diagnóstico no SUS, visando ampliar o acesso à saúde e otimizar a eficiência dos serviços.\\n\\nAnálise de Dados Genômicos e Bioinformática: Competência em análise de grandes volumes de dados gerados por sequenciamento, utilizando ferramentas de bioinformática para interpretar variações genômicas e suas implicações para a saúde pública.\\n\\nTrabalho Multidisciplinar e Parcerias Interinstitucionais: Expertise em colaborar com diversos setores, como saúde pública, biotecnologia e academia, facilitando a tradução de pesquisas em políticas e produtos que fortaleçam o Complexo da Saúde.',\n",
       "  'compet_desenvolver': 'Na minha visão, as competências científicas e tecnológicas que precisam ser melhor desenvolvidas e exploradas na Fiocruz Ceará para ampliar o desempenho e impacto positivo das atividades de pesquisa, desenvolvimento e inovação em tecnologias para a saúde incluem:\\n\\n- Capacitação Avançada em Bioinformática e Inteligência Artificial: É crucial investir em formação e ampliação de competências em análise de dados complexos, como os gerados por sequenciamento genômico, e em inteligência artificial aplicada à saúde. Isso permitiria não apenas interpretar melhor os dados gerados, mas também criar modelos preditivos e soluções baseadas em machine learning para a vigilância epidemiológica e o desenvolvimento de novas ferramentas diagnósticas.\\n- Interdisciplinaridade e Integração de Conhecimento: Desenvolver mais projetos e equipes de pesquisa interdisciplinares, promovendo a integração entre biologia, engenharia, ciência de dados e saúde pública. Essa abordagem colaborativa pode gerar soluções mais inovadoras e eficazes para os desafios complexos da saúde.',\n",
       "  'avancar_desenv_desafios': None,\n",
       "  'id_resposta': 8}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_questoes = df_to_json(df_questoes)\n",
    "json_questoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questões de pesquisa:\n",
      "  tratamentos mais efetivos para doenças infecciosas e câncer\n",
      "  vacinas\n",
      "  terapias otimizadas baseadas em nanotecnologia\n",
      "  avaliação dos atributos da atenção primária à saúde\n",
      "  pesquisas epidemiológicas sobre doenças crônicas não transmissíveis, como diabetes mellitus\n",
      "  pesquisa clínica na estratégia saúde da família\n",
      "  desenvolvimento e validação de tecnologias (aplicativos, vídeos) voltados para a estratégia saúde da família.\n",
      "  ocorrência de bactérias super resistentes e associação com poluição ambiental por agrotóxicos\n",
      "  contaminação por metais pesados através da cadeia alimentar e associação com risco de câncer\n",
      "  fatores extrínsecos que contribuem para a incidência de distúrbios metais.\n",
      "  quais as limitações relacionadas ao diagnóstico e tratamento de doenças de importância humana, especialmente doenças negligenciadas?\n",
      "  quais os  impactos que os sistemas agroalimentares hegemônicos atuais causam na saúde e bem viver da população brasileira e quais os desdobramentos no sus?\n",
      "  que benefícios e potencialidades podem ser desenvolvidas ao associarmos o campo da saúde coletiva com a agroecologia e quais os desdobramentos no sus?\n",
      "  que tecnologias/soluções inovadoras e coerentes encontramos nos territórios, realizadas pelas populações do campo, floresta, águas e áreas vulnerabilizadas que podem contribuir com o enfrentamento à crise ecológica atual - sanitária, ambiental, social, política, cultural etc e com o sus?\n",
      "  as relações entre a saúde mental e a atenção primária\n",
      "  desigualdades na mortalidade por suicídios entre diferentes grupos.\n",
      "  saúde mental de populações vulneráveis\n",
      "  como melhorar a efetividade das políticas públicas de saúde no enfrentamento ao feminicidio e violência doméstica?\n",
      "  como ampliar a equidade de genero e raça na área científica?\n",
      "  que avanços as ações afirmativas vem alcançando para ampliar o acesso aos cursos e atividades da fiocruz ceará ?\n",
      "  quais os principais desafios na aps? que intervenções podem ser realizadas para melhoria de processos, serviços e práticas na aps? como estão sendo desenvolvidos os processos de educação permanente em saúde no sus?\n",
      "  vigilância e detecção molecular de patógenos: como podemos aprimorar a detecção precoce e precisa de patógenos em diferentes matrizes, como amostras clínicas e águas residuais, para antecipar surtos e contribuir para o controle de doenças infecciosas?\n",
      "  impacto das tecnologias de sequenciamento de nova geração (ngs): como o uso de ngs pode revolucionar o diagnóstico de doenças, permitindo a identificação rápida e precisa de agentes patogênicos, e qual sua aplicabilidade no contexto do sus, especialmente em áreas vulneráveis?\n",
      "  saúde da mulher e diagnóstico do hpv: como testes moleculares para detecção de hpv podem ser otimizados para a prevenção e diagnóstico precoce de câncer cervical, e qual a relevância dessa abordagem na saúde pública considerando as diretrizes atuais do ministério da saúde?\n"
     ]
    }
   ],
   "source": [
    "listar_questoes_pesquisa(df_questoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras-Chave:\n",
      "  nanotecnologia, nanossegurança, doenças negligenciadas, câncer, terapia combinada, vacinas\n",
      "  atenção primária à saúde\n",
      "  estratégia saúde da família\n",
      "  pesquisa clínica\n",
      "  ensaios clínicos\n",
      "  diabetes mellitus\n",
      "  tecnologias em saúde\n",
      "  ciências ômicas, processamento de dados, análise de vias biológicas, metabolômica, metagenômica, desenvolvimento de métodos diagnósticos e prognósticos de doenças\n",
      "  doenças tropicais negligenciadas, ofidismo, leishmaniose, arboviroses, doenças neurodegenetrativas, cancer\n",
      "  saúde coletiva, agrotóxicos, agroecologia, saúde popular, povos e comunidades tradicionais, povos indígenas, emergência climática, saúde popular, plantas medicinais e fitoterápicos.\n",
      "  saúde mental\n",
      "  atenção primaria\n",
      "  suicídio\n",
      "  populações vulneraveis\n",
      "  diversidade, equidade nas ciencias, gênero e raça, ações afirmativas, violência de gênero e feminicidio, interseccionalidade.\n",
      "  atenção primária à saúde. ensino na saúde. educação na saúde. avaliação de serviços de saúde.\n",
      "  sequenciamento de nova geração (ngs)\n",
      "  epidemiologia molecular\n",
      "  vigilância translacional\n",
      "  detecção molecular de patógenos\n",
      "  saúde da mulher\n",
      "  hpv\n",
      "  amostras clínicas\n",
      "  águas residuais\n",
      "  prevenção e diagnóstico de ists\n",
      "  inovação em saúde pública\n",
      "  tecnologias diagnósticas para o sus\n",
      "  saúde pública e vigilância epidemiológica\n"
     ]
    }
   ],
   "source": [
    "listar_palavras_chave(df_questoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alinhamento com a estratégia de desenvolvimento do CEIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desafios mais próximos das pesquisas na ICT:\n",
      "  d01. preparação para resposta a emergências em saúde e proteção para doenças imunopreveníveis\n",
      "  d06. tecnologias para sistemas de saúde (sus)\n",
      "  d07. doenças e populações negligenciadas\n",
      "  d08. cânceres com maior incidência\n",
      "  d13. outras doenças crônicas não transmissíveis\n",
      "\n",
      "  d04. vulnerabilidade tecnológica e econômica para acesso em saúde\n",
      "  d06. tecnologias para sistemas de saúde (sus)\n",
      "  d07. doenças e populações negligenciadas\n",
      "  d09. doenças cardiovasculares\n",
      "  d10. diabetes\n",
      "\n",
      "  d06. tecnologias para sistemas de saúde (sus)\n",
      "  d11. doenças associadas ao envelhecimento da população\n",
      "  d13. outras doenças crônicas não transmissíveis\n",
      "\n",
      "  d02. modernização das tecnologias produtivas de soros imunoprotetores\n",
      "  d07. doenças e populações negligenciadas\n",
      "\n",
      "  d05. alternativas tecnológicas para desenvolvimento sustentável e química verde\n",
      "  d07. doenças e populações negligenciadas\n",
      "  d04. vulnerabilidade tecnológica e econômica para acesso em saúde\n",
      "\n",
      "  d04. vulnerabilidade tecnológica e econômica para acesso em saúde\n",
      "  d06. tecnologias para sistemas de saúde (sus)\n",
      "  d07. doenças e populações negligenciadas\n",
      "  d13. outras doenças crônicas não transmissíveis\n",
      "\n",
      "  d07. doenças e populações negligenciadas\n",
      "\n",
      "  d06. tecnologias para sistemas de saúde (sus)\n",
      "\n",
      "  d01. preparação para resposta a emergências em saúde e proteção para doenças imunopreveníveis\n",
      "  d11. doenças associadas ao envelhecimento da população\n",
      "  d07. doenças e populações negligenciadas\n",
      "  d06. tecnologias para sistemas de saúde (sus)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .full-width-df td {\n",
       "        word-wrap: break-word;\n",
       "        white-space: pre-wrap;\n",
       "        text-align: left;\n",
       "    }\n",
       "    </style>\n",
       "    <table border=\"1\" class=\"dataframe full-width-df\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Desafio</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D07. DOENÇAS E POPULAÇÕES NEGLIGENCIADAS</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D06. TECNOLOGIAS PARA SISTEMAS DE SAÚDE (SUS)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D13. OUTRAS DOENÇAS CRÔNICAS NÃO TRANSMISSÍVEIS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D04. VULNERABILIDADE TECNOLÓGICA E ECONÔMICA PARA ACESSO EM SAÚDE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D01. PREPARAÇÃO PARA RESPOSTA A EMERGÊNCIAS EM SAÚDE E PROTEÇÃO PARA DOENÇAS IMUNOPREVENÍVEIS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D11. DOENÇAS ASSOCIADAS AO ENVELHECIMENTO DA POPULAÇÃO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D08. CÂNCERES COM MAIOR INCIDÊNCIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D09. DOENÇAS CARDIOVASCULARES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D10. DIABETES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D02. MODERNIZAÇÃO DAS TECNOLOGIAS PRODUTIVAS DE SOROS IMUNOPROTETORES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D05. ALTERNATIVAS TECNOLÓGICAS PARA DESENVOLVIMENTO SUSTENTÁVEL E QUÍMICA VERDE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "listar_desafios_proximos(df_produtos_proximos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produtos do Bloco 01 (Preparação do Sistema de Saúde para Emergências Sanitárias) mais próximos das pesquisas na ICT:\n",
      "  vacinas do pni que demandem atualização tecnológica\n",
      "  vacina leishmanioses\n",
      "  vacinas combinadas\n",
      "  vacina associada a formas farmacêuticas não invasivas\n",
      "  testes diagnósticos moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnósticos in vitro\n",
      "  ifa antimicrobianos\n",
      "  fitoterápicos e produtos da biodiversidade apoiados pelo sus\n",
      "  testes diagnósticos moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnósticos in vitro\n",
      "  testes diagnósticos moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnósticos in vitro\n",
      "  ifa de base química ou biotecnológica de medicamentos demandados pelo sus que apresentem dependência externa de insumos críticos da cadeia produtiva para todos os desafios em saúde definidos nesta matriz\n",
      "  radiofármacos e produtos de medicina nuclear\n",
      "  fitoterápicos e produtos da biodiversidade apoiados pelo sus\n",
      "  vacinas do pni que demandem atualização tecnológica\n",
      "  vacina contra dengue\n",
      "  testes diagnósticos moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnósticos in vitro\n",
      "  kit de extração de ácidos nucléicos\n"
     ]
    }
   ],
   "source": [
    "listar_produtos_proximos_emergencias(df_produtos_proximos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'desafio_mais_proximo': ['D01. PREPARAÇÃO PARA RESPOSTA A EMERGÊNCIAS EM SAÚDE E PROTEÇÃO PARA DOENÇAS IMUNOPREVENÍVEIS',\n",
       "   'D06. TECNOLOGIAS PARA SISTEMAS DE SAÚDE (SUS)',\n",
       "   'D07. DOENÇAS E POPULAÇÕES NEGLIGENCIADAS',\n",
       "   'D08. CÂNCERES COM MAIOR INCIDÊNCIA',\n",
       "   'D13. OUTRAS DOENÇAS CRÔNICAS NÃO TRANSMISSÍVEIS',\n",
       "   ''],\n",
       "  'produtos_bloco1': 'Vacinas do PNI que demandem atualização tecnológica;Vacina Leishmanioses;Vacinas combinadas;Vacina associada a formas farmacêuticas não invasivas;Testes diagnósticos moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnósticos in vitro;IFA antimicrobianos;',\n",
       "  'produtos_bloco2': '    Medicamentos negligenciados e Novos esquemas terapêuticos para otimização do tratamento de Tuberculose, Doença de Chagas, Hanseníase, Esquistossomose, Leishmaniose, Malária e demais doenças elencadas pelo CIEDDS;Medicamentos e novos esquemas terapêuticos demandados pelo SUS para tratamento de HIV/AIDS e Hepatites virais;Testes diagnóstico moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnóstico in vitro;Produtos de Terapia Gênica;',\n",
       "  'adicional_contibuir': None,\n",
       "  'id_resposta': 0},\n",
       " {'desafio_mais_proximo': ['D04. VULNERABILIDADE TECNOLÓGICA E ECONÔMICA PARA ACESSO EM SAÚDE',\n",
       "   'D06. TECNOLOGIAS PARA SISTEMAS DE SAÚDE (SUS)',\n",
       "   'D07. DOENÇAS E POPULAÇÕES NEGLIGENCIADAS',\n",
       "   'D09. DOENÇAS CARDIOVASCULARES',\n",
       "   'D10. DIABETES',\n",
       "   ''],\n",
       "  'produtos_bloco1': 'Fitoterápicos e produtos da biodiversidade apoiados pelo SUS;',\n",
       "  'produtos_bloco2': 'Medicamentos e novos esquemas terapêuticos demandados pelo SUS para tratamento de HIV/AIDS e Hepatites virais;',\n",
       "  'adicional_contibuir': 'Produção e distribuição em larga escala de fitoterápicos já comprovados em ensaios clínicos, controlados e randomizados, para o controle metabólico de pessoas que vivem com diabetes mellitus (cúrcuma, passiflora, canela e gengibre)\\nComprovação do uso da Doxiciclina como profilaxia pós exposição (DOXY-PEP) na prevenção das principais infecções sexualmente transmissíveis bacterianas (sífilis, clamídia e gonorreia). ',\n",
       "  'id_resposta': 1},\n",
       " {'desafio_mais_proximo': ['D06. TECNOLOGIAS PARA SISTEMAS DE SAÚDE (SUS)',\n",
       "   'D11. DOENÇAS ASSOCIADAS AO ENVELHECIMENTO DA POPULAÇÃO',\n",
       "   'D13. OUTRAS DOENÇAS CRÔNICAS NÃO TRANSMISSÍVEIS',\n",
       "   ''],\n",
       "  'produtos_bloco1': 'Testes diagnósticos moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnósticos in vitro;',\n",
       "  'produtos_bloco2': 'Testes diagnósticos moleculares e de anatomia patológica;',\n",
       "  'adicional_contibuir': 'No uso de aprendizagem de máquina e estatística para processamento e interpretação de dados.',\n",
       "  'id_resposta': 2},\n",
       " {'desafio_mais_proximo': ['D02. MODERNIZAÇÃO DAS TECNOLOGIAS PRODUTIVAS DE SOROS IMUNOPROTETORES',\n",
       "   'D07. DOENÇAS E POPULAÇÕES NEGLIGENCIADAS',\n",
       "   ''],\n",
       "  'produtos_bloco1': 'Testes diagnósticos moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnósticos in vitro;IFA de base química ou biotecnológica de medicamentos demandados pelo SUS que apresentem dependência externa de insumos críticos da cadeia produtiva para todos os desafios em saúde definidos nesta matriz;Radiofármacos e produtos de medicina nuclear;',\n",
       "  'produtos_bloco2': '    Medicamentos negligenciados e Novos esquemas terapêuticos para otimização do tratamento de Tuberculose, Doença de Chagas, Hanseníase, Esquistossomose, Leishmaniose, Malária e demais doenças elencadas pelo CIEDDS;Medicamentos e novos esquemas terapêuticos demandados pelo SUS para tratamento de HIV/AIDS e Hepatites virais;Testes diagnóstico moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnóstico in vitro;Medicamentos e IFA utilizados pelo SUS que apresentem dependência externa de insumos críticos da cadeia produtiva;',\n",
       "  'adicional_contibuir': 'Já associado ',\n",
       "  'id_resposta': 3},\n",
       " {'desafio_mais_proximo': ['D05. ALTERNATIVAS TECNOLÓGICAS PARA DESENVOLVIMENTO SUSTENTÁVEL E QUÍMICA VERDE',\n",
       "   'D07. DOENÇAS E POPULAÇÕES NEGLIGENCIADAS',\n",
       "   'D04. VULNERABILIDADE TECNOLÓGICA E ECONÔMICA PARA ACESSO EM SAÚDE',\n",
       "   ''],\n",
       "  'produtos_bloco1': 'Fitoterápicos e produtos da biodiversidade apoiados pelo SUS;',\n",
       "  'produtos_bloco2': 'Produtos e nutracêuticos para população pediátrica ou vulnerável;Produtos e formulações para tratamento da população pediátrica;Desenvolvimento e produção local de tecnologias de informação e conectividade para melhoria da qualidade de vida da população idosa;',\n",
       "  'adicional_contibuir': 'São pesquisas que podem direcionar a produção de tecnologias inovadoras, com mais assertividade nas demandas das populações em condições de vulnerabilidade.',\n",
       "  'id_resposta': 4},\n",
       " {'desafio_mais_proximo': ['D04. VULNERABILIDADE TECNOLÓGICA E ECONÔMICA PARA ACESSO EM SAÚDE',\n",
       "   'D06. TECNOLOGIAS PARA SISTEMAS DE SAÚDE (SUS)',\n",
       "   'D07. DOENÇAS E POPULAÇÕES NEGLIGENCIADAS',\n",
       "   'D13. OUTRAS DOENÇAS CRÔNICAS NÃO TRANSMISSÍVEIS',\n",
       "   ''],\n",
       "  'produtos_bloco1': 'NÃO ENCONTREI PRODUTO ALGUM NA LISTA ACIMA QUE CORRESPONDA COM MINHAS PESQUISAS ATUAIS E NO FUTURO PRÓXIMO;',\n",
       "  'produtos_bloco2': 'NÃO ENCONTREI AGRAVO ALGUM NA LISTA ACIMA\\xa0QUE CORRESPONDA COM MINHAS PESQUISAS ATUAIS E NO FUTURO PRÓXIMO;',\n",
       "  'adicional_contibuir': 'Não sei responder.',\n",
       "  'id_resposta': 5},\n",
       " {'desafio_mais_proximo': ['D07. DOENÇAS E POPULAÇÕES NEGLIGENCIADAS', ''],\n",
       "  'produtos_bloco1': 'NÃO ENCONTREI PRODUTO ALGUM NA LISTA ACIMA QUE CORRESPONDA COM MINHAS PESQUISAS ATUAIS E NO FUTURO PRÓXIMO;',\n",
       "  'produtos_bloco2': 'NÃO ENCONTREI AGRAVO ALGUM NA LISTA ACIMA\\xa0QUE CORRESPONDA COM MINHAS PESQUISAS ATUAIS E NO FUTURO PRÓXIMO;',\n",
       "  'adicional_contibuir': 'Contribuir para um olhar ampliado para as populações vulnerabilizadas que mais precisam de acesso ao sus ',\n",
       "  'id_resposta': 6},\n",
       " {'desafio_mais_proximo': ['D06. TECNOLOGIAS PARA SISTEMAS DE SAÚDE (SUS)',\n",
       "   ''],\n",
       "  'produtos_bloco1': 'NÃO ENCONTREI PRODUTO ALGUM NA LISTA ACIMA QUE CORRESPONDA COM MINHAS PESQUISAS ATUAIS E NO FUTURO PRÓXIMO;',\n",
       "  'produtos_bloco2': 'NÃO ENCONTREI AGRAVO ALGUM NA LISTA ACIMA\\xa0QUE CORRESPONDA COM MINHAS PESQUISAS ATUAIS E NO FUTURO PRÓXIMO;',\n",
       "  'adicional_contibuir': 'não consigo enxergar',\n",
       "  'id_resposta': 7},\n",
       " {'desafio_mais_proximo': ['D01. PREPARAÇÃO PARA RESPOSTA A EMERGÊNCIAS EM SAÚDE E PROTEÇÃO PARA DOENÇAS IMUNOPREVENÍVEIS',\n",
       "   'D11. DOENÇAS ASSOCIADAS AO ENVELHECIMENTO DA POPULAÇÃO',\n",
       "   'D07. DOENÇAS E POPULAÇÕES NEGLIGENCIADAS',\n",
       "   'D06. TECNOLOGIAS PARA SISTEMAS DE SAÚDE (SUS)',\n",
       "   ''],\n",
       "  'produtos_bloco1': 'Vacinas do PNI que demandem atualização tecnológica;Vacina contra Dengue;Testes diagnósticos moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnósticos in vitro;Kit de extração de ácidos nucléicos;',\n",
       "  'produtos_bloco2': 'Plataforma de RT-PCR para diagnóstico de arboviroses, multiplex ou isolada;Testes diagnóstico moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnóstico in vitro;Kit de extração de ácidos nucléicos;Kit de autocoleta para detecção de HPV por biologia molecular;Teste point-of-care para o câncer de colo de útero;Testes diagnóstico in vitro;',\n",
       "  'adicional_contibuir': None,\n",
       "  'id_resposta': 8}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_produtos_proximos = df_to_json(df_produtos_proximos)\n",
    "json_produtos_proximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produtos do Bloco 02 (Doenças e Agravos Críticos para o SUS) mais próximos das pesquisas na ICT:\n",
      "  medicamentos negligenciados e novos esquemas terapêuticos para otimização do tratamento de tuberculose, doença de chagas, hanseníase, esquistossomose, leishmaniose, malária e demais doenças elencadas pelo ciedds\n",
      "  medicamentos e novos esquemas terapêuticos demandados pelo sus para tratamento de hiv/aids e hepatites virais\n",
      "  testes diagnóstico moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnóstico in vitro\n",
      "  produtos de terapia gênica\n",
      "  medicamentos e novos esquemas terapêuticos demandados pelo sus para tratamento de hiv/aids e hepatites virais\n",
      "  testes diagnósticos moleculares e de anatomia patológica\n",
      "  medicamentos negligenciados e novos esquemas terapêuticos para otimização do tratamento de tuberculose, doença de chagas, hanseníase, esquistossomose, leishmaniose, malária e demais doenças elencadas pelo ciedds\n",
      "  medicamentos e novos esquemas terapêuticos demandados pelo sus para tratamento de hiv/aids e hepatites virais\n",
      "  testes diagnóstico moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnóstico in vitro\n",
      "  medicamentos e ifa utilizados pelo sus que apresentem dependência externa de insumos críticos da cadeia produtiva\n",
      "  produtos e nutracêuticos para população pediátrica ou vulnerável\n",
      "  produtos e formulações para tratamento da população pediátrica\n",
      "  desenvolvimento e produção local de tecnologias de informação e conectividade para melhoria da qualidade de vida da população idosa\n",
      "  plataforma de rt-pcr para diagnóstico de arboviroses, multiplex ou isolada\n",
      "  testes diagnóstico moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnóstico in vitro\n",
      "  kit de extração de ácidos nucléicos\n",
      "  kit de autocoleta para detecção de hpv por biologia molecular\n",
      "  teste point-of-care para o câncer de colo de útero\n",
      "  testes diagnóstico in vitro\n"
     ]
    }
   ],
   "source": [
    "listar_produtos_proximos_agravos(df_produtos_proximos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produtos extra estratégia do CEIS:\n",
      "  medicamentos negligenciados e novos esquemas terapêuticos para otimização do tratamento de tuberculose, doença de chagas, hanseníase, esquistossomose, leishmaniose, malária e demais doenças elencadas pelo ciedds\n",
      "  medicamentos e novos esquemas terapêuticos demandados pelo sus para tratamento de hiv/aids e hepatites virais\n",
      "  testes diagnóstico moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnóstico in vitro\n",
      "  produtos de terapia gênica\n",
      "  \n",
      "  medicamentos e novos esquemas terapêuticos demandados pelo sus para tratamento de hiv/aids e hepatites virais\n",
      "  \n",
      "  testes diagnósticos moleculares e de anatomia patológica\n",
      "  \n",
      "  medicamentos negligenciados e novos esquemas terapêuticos para otimização do tratamento de tuberculose, doença de chagas, hanseníase, esquistossomose, leishmaniose, malária e demais doenças elencadas pelo ciedds\n",
      "  medicamentos e novos esquemas terapêuticos demandados pelo sus para tratamento de hiv/aids e hepatites virais\n",
      "  testes diagnóstico moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnóstico in vitro\n",
      "  medicamentos e ifa utilizados pelo sus que apresentem dependência externa de insumos críticos da cadeia produtiva\n",
      "  \n",
      "  produtos e nutracêuticos para população pediátrica ou vulnerável\n",
      "  produtos e formulações para tratamento da população pediátrica\n",
      "  desenvolvimento e produção local de tecnologias de informação e conectividade para melhoria da qualidade de vida da população idosa\n",
      "  \n",
      "  não encontrei agravo algum na lista acima que corresponda com minhas pesquisas atuais e no futuro próximo\n",
      "  \n",
      "  não encontrei agravo algum na lista acima que corresponda com minhas pesquisas atuais e no futuro próximo\n",
      "  \n",
      "  não encontrei agravo algum na lista acima que corresponda com minhas pesquisas atuais e no futuro próximo\n",
      "  \n",
      "  plataforma de rt-pcr para diagnóstico de arboviroses, multiplex ou isolada\n",
      "  testes diagnóstico moleculares, por imunoensaio, rápidos de antígeno ou anticorpo, point-of-care, autoteste e outros testes diagnóstico in vitro\n",
      "  kit de extração de ácidos nucléicos\n",
      "  kit de autocoleta para detecção de hpv por biologia molecular\n",
      "  teste point-of-care para o câncer de colo de útero\n",
      "  testes diagnóstico in vitro\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "produtos_extra(df_produtos_proximos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tec_diagnostico</th>\n",
       "      <th>tec_pesquisa</th>\n",
       "      <th>tec_terapeutica</th>\n",
       "      <th>tec_serviço</th>\n",
       "      <th>tec_social</th>\n",
       "      <th>tec_digital</th>\n",
       "      <th>id_resposta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TRL1-TRL3</td>\n",
       "      <td>Pronto a Transferir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>TRL1-TRL3</td>\n",
       "      <td>TRL7-TRL9</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRL1-TRL3</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRL1-TRL3</td>\n",
       "      <td>TRL1-TRL3</td>\n",
       "      <td>TRL4-TRL6</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>Concepção de Estudos</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>TRL1-TRL3</td>\n",
       "      <td>Não trabalho com esse tipo</td>\n",
       "      <td>TRL4-TRL6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tec_diagnostico                tec_pesquisa  \\\n",
       "0                         NaN                   TRL1-TRL3   \n",
       "1        Concepção de Estudos        Concepção de Estudos   \n",
       "2                   TRL1-TRL3        Concepção de Estudos   \n",
       "3                   TRL1-TRL3                   TRL1-TRL3   \n",
       "4  Não trabalho com esse tipo  Não trabalho com esse tipo   \n",
       "5  Não trabalho com esse tipo  Não trabalho com esse tipo   \n",
       "6  Não trabalho com esse tipo  Não trabalho com esse tipo   \n",
       "7  Não trabalho com esse tipo  Não trabalho com esse tipo   \n",
       "8        Concepção de Estudos        Concepção de Estudos   \n",
       "\n",
       "              tec_terapeutica                 tec_serviço  \\\n",
       "0         Pronto a Transferir                         NaN   \n",
       "1                   TRL1-TRL3                   TRL7-TRL9   \n",
       "2        Concepção de Estudos        Concepção de Estudos   \n",
       "3                   TRL4-TRL6        Concepção de Estudos   \n",
       "4  Não trabalho com esse tipo  Não trabalho com esse tipo   \n",
       "5  Não trabalho com esse tipo        Concepção de Estudos   \n",
       "6  Não trabalho com esse tipo        Concepção de Estudos   \n",
       "7  Não trabalho com esse tipo        Concepção de Estudos   \n",
       "8  Não trabalho com esse tipo                   TRL1-TRL3   \n",
       "\n",
       "                   tec_social                 tec_digital  id_resposta  \n",
       "0                         NaN                         NaN            0  \n",
       "1        Concepção de Estudos                         NaN            1  \n",
       "2        Concepção de Estudos                         NaN            2  \n",
       "3        Concepção de Estudos                         NaN            3  \n",
       "4  Não trabalho com esse tipo  Não trabalho com esse tipo            4  \n",
       "5        Concepção de Estudos  Não trabalho com esse tipo            5  \n",
       "6        Concepção de Estudos  Não trabalho com esse tipo            6  \n",
       "7        Concepção de Estudos  Não trabalho com esse tipo            7  \n",
       "8  Não trabalho com esse tipo                   TRL4-TRL6            8  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conhec_blocos</th>\n",
       "      <th>conhec_desafios</th>\n",
       "      <th>conhec_plataformas</th>\n",
       "      <th>conhec_produtos</th>\n",
       "      <th>id_resposta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Não desejo ou não posso opinar</td>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>Não desejo ou não posso opinar</td>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conheço Totalmente</td>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Desconheço a maior parte</td>\n",
       "      <td>Desconheço a maior parte</td>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>Desconheço a maior parte</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>Ainda não conheço</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>Conheço a maior parte</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    conhec_blocos           conhec_desafios  \\\n",
       "0               Ainda não conheço     Conheço a maior parte   \n",
       "1  Não desejo ou não posso opinar     Conheço a maior parte   \n",
       "2              Conheço Totalmente     Conheço a maior parte   \n",
       "3           Conheço a maior parte     Conheço a maior parte   \n",
       "4               Ainda não conheço         Ainda não conheço   \n",
       "5               Ainda não conheço         Ainda não conheço   \n",
       "6        Desconheço a maior parte  Desconheço a maior parte   \n",
       "7               Ainda não conheço         Ainda não conheço   \n",
       "8           Conheço a maior parte     Conheço a maior parte   \n",
       "\n",
       "               conhec_plataformas           conhec_produtos  id_resposta  \n",
       "0           Conheço a maior parte     Conheço a maior parte            0  \n",
       "1  Não desejo ou não posso opinar     Conheço a maior parte            1  \n",
       "2               Ainda não conheço     Conheço a maior parte            2  \n",
       "3           Conheço a maior parte     Conheço a maior parte            3  \n",
       "4               Ainda não conheço         Ainda não conheço            4  \n",
       "5               Ainda não conheço         Ainda não conheço            5  \n",
       "6               Ainda não conheço  Desconheço a maior parte            6  \n",
       "7               Ainda não conheço         Ainda não conheço            7  \n",
       "8           Conheço a maior parte     Conheço a maior parte            8  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estrat_ceis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desafio_mais_proximo</th>\n",
       "      <th>produtos_bloco1</th>\n",
       "      <th>produtos_bloco2</th>\n",
       "      <th>adicional_contibuir</th>\n",
       "      <th>id_resposta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[D01. PREPARAÇÃO PARA RESPOSTA A EMERGÊNCIAS E...</td>\n",
       "      <td>Vacinas do PNI que demandem atualização tecnol...</td>\n",
       "      <td>Medicamentos negligenciados e Novos esquem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[D04. VULNERABILIDADE TECNOLÓGICA E ECONÔMICA ...</td>\n",
       "      <td>Fitoterápicos e produtos da biodiversidade apo...</td>\n",
       "      <td>Medicamentos e novos esquemas terapêuticos dem...</td>\n",
       "      <td>Produção e distribuição em larga escala de fit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[D06. TECNOLOGIAS PARA SISTEMAS DE SAÚDE (SUS)...</td>\n",
       "      <td>Testes diagnósticos moleculares, por imunoensa...</td>\n",
       "      <td>Testes diagnósticos moleculares e de anatomia ...</td>\n",
       "      <td>No uso de aprendizagem de máquina e estatístic...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[D02. MODERNIZAÇÃO DAS TECNOLOGIAS PRODUTIVAS ...</td>\n",
       "      <td>Testes diagnósticos moleculares, por imunoensa...</td>\n",
       "      <td>Medicamentos negligenciados e Novos esquem...</td>\n",
       "      <td>Já associado</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[D05. ALTERNATIVAS TECNOLÓGICAS PARA DESENVOLV...</td>\n",
       "      <td>Fitoterápicos e produtos da biodiversidade apo...</td>\n",
       "      <td>Produtos e nutracêuticos para população pediát...</td>\n",
       "      <td>São pesquisas que podem direcionar a produção ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[D04. VULNERABILIDADE TECNOLÓGICA E ECONÔMICA ...</td>\n",
       "      <td>NÃO ENCONTREI PRODUTO ALGUM NA LISTA ACIMA QUE...</td>\n",
       "      <td>NÃO ENCONTREI AGRAVO ALGUM NA LISTA ACIMA QUE ...</td>\n",
       "      <td>Não sei responder.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[D07. DOENÇAS E POPULAÇÕES NEGLIGENCIADAS, ]</td>\n",
       "      <td>NÃO ENCONTREI PRODUTO ALGUM NA LISTA ACIMA QUE...</td>\n",
       "      <td>NÃO ENCONTREI AGRAVO ALGUM NA LISTA ACIMA QUE ...</td>\n",
       "      <td>Contribuir para um olhar ampliado para as popu...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[D06. TECNOLOGIAS PARA SISTEMAS DE SAÚDE (SUS), ]</td>\n",
       "      <td>NÃO ENCONTREI PRODUTO ALGUM NA LISTA ACIMA QUE...</td>\n",
       "      <td>NÃO ENCONTREI AGRAVO ALGUM NA LISTA ACIMA QUE ...</td>\n",
       "      <td>não consigo enxergar</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[D01. PREPARAÇÃO PARA RESPOSTA A EMERGÊNCIAS E...</td>\n",
       "      <td>Vacinas do PNI que demandem atualização tecnol...</td>\n",
       "      <td>Plataforma de RT-PCR para diagnóstico de arbov...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                desafio_mais_proximo  \\\n",
       "0  [D01. PREPARAÇÃO PARA RESPOSTA A EMERGÊNCIAS E...   \n",
       "1  [D04. VULNERABILIDADE TECNOLÓGICA E ECONÔMICA ...   \n",
       "2  [D06. TECNOLOGIAS PARA SISTEMAS DE SAÚDE (SUS)...   \n",
       "3  [D02. MODERNIZAÇÃO DAS TECNOLOGIAS PRODUTIVAS ...   \n",
       "4  [D05. ALTERNATIVAS TECNOLÓGICAS PARA DESENVOLV...   \n",
       "5  [D04. VULNERABILIDADE TECNOLÓGICA E ECONÔMICA ...   \n",
       "6       [D07. DOENÇAS E POPULAÇÕES NEGLIGENCIADAS, ]   \n",
       "7  [D06. TECNOLOGIAS PARA SISTEMAS DE SAÚDE (SUS), ]   \n",
       "8  [D01. PREPARAÇÃO PARA RESPOSTA A EMERGÊNCIAS E...   \n",
       "\n",
       "                                     produtos_bloco1  \\\n",
       "0  Vacinas do PNI que demandem atualização tecnol...   \n",
       "1  Fitoterápicos e produtos da biodiversidade apo...   \n",
       "2  Testes diagnósticos moleculares, por imunoensa...   \n",
       "3  Testes diagnósticos moleculares, por imunoensa...   \n",
       "4  Fitoterápicos e produtos da biodiversidade apo...   \n",
       "5  NÃO ENCONTREI PRODUTO ALGUM NA LISTA ACIMA QUE...   \n",
       "6  NÃO ENCONTREI PRODUTO ALGUM NA LISTA ACIMA QUE...   \n",
       "7  NÃO ENCONTREI PRODUTO ALGUM NA LISTA ACIMA QUE...   \n",
       "8  Vacinas do PNI que demandem atualização tecnol...   \n",
       "\n",
       "                                     produtos_bloco2  \\\n",
       "0      Medicamentos negligenciados e Novos esquem...   \n",
       "1  Medicamentos e novos esquemas terapêuticos dem...   \n",
       "2  Testes diagnósticos moleculares e de anatomia ...   \n",
       "3      Medicamentos negligenciados e Novos esquem...   \n",
       "4  Produtos e nutracêuticos para população pediát...   \n",
       "5  NÃO ENCONTREI AGRAVO ALGUM NA LISTA ACIMA QUE ...   \n",
       "6  NÃO ENCONTREI AGRAVO ALGUM NA LISTA ACIMA QUE ...   \n",
       "7  NÃO ENCONTREI AGRAVO ALGUM NA LISTA ACIMA QUE ...   \n",
       "8  Plataforma de RT-PCR para diagnóstico de arbov...   \n",
       "\n",
       "                                 adicional_contibuir  id_resposta  \n",
       "0                                                NaN            0  \n",
       "1  Produção e distribuição em larga escala de fit...            1  \n",
       "2  No uso de aprendizagem de máquina e estatístic...            2  \n",
       "3                                      Já associado             3  \n",
       "4  São pesquisas que podem direcionar a produção ...            4  \n",
       "5                                 Não sei responder.            5  \n",
       "6  Contribuir para um olhar ampliado para as popu...            6  \n",
       "7                               não consigo enxergar            7  \n",
       "8                                                NaN            8  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_produtos_proximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempo_lev_dados</th>\n",
       "      <th>tempo_analise_dados</th>\n",
       "      <th>tempo_debates_grupo</th>\n",
       "      <th>tempo_redigir_textos</th>\n",
       "      <th>tempo_reunioes</th>\n",
       "      <th>tempo_comunicacoes</th>\n",
       "      <th>id_resposta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>De 20 a 40% do tempo  (~2h/dia)</td>\n",
       "      <td>De 40 a 60% do tempo  (~4h/dia)</td>\n",
       "      <td>De 20 a 40% do tempo  (~2h/dia)</td>\n",
       "      <td>De 60 a 80% do tempo  (~6h/dia)</td>\n",
       "      <td>De 80 a 100% do tempo  (~8h/dia)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>De 20 a 40% do tempo  (~2h/dia)</td>\n",
       "      <td>De 40 a 60% do tempo  (~4h/dia)</td>\n",
       "      <td>De 20 a 40% do tempo  (~2h/dia)</td>\n",
       "      <td>De 40 a 60% do tempo  (~4h/dia)</td>\n",
       "      <td>De 40 a 60% do tempo  (~4h/dia)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>De 20 a 40% do tempo  (~2h/dia)</td>\n",
       "      <td>De 60 a 80% do tempo  (~6h/dia)</td>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>De 80 a 100% do tempo  (~8h/dia)</td>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>De 20 a 40% do tempo  (~2h/dia)</td>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>De 40 a 60% do tempo  (~4h/dia)</td>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Não consigo estimar</td>\n",
       "      <td>Não consigo estimar</td>\n",
       "      <td>Não consigo estimar</td>\n",
       "      <td>Não consigo estimar</td>\n",
       "      <td>Não consigo estimar</td>\n",
       "      <td>Não consigo estimar</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>De 20 a 40% do tempo  (~2h/dia)</td>\n",
       "      <td>De 40 a 60% do tempo  (~4h/dia)</td>\n",
       "      <td>De 40 a 60% do tempo  (~4h/dia)</td>\n",
       "      <td>De 60 a 80% do tempo  (~6h/dia)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>De 20 a 40% do tempo  (~2h/dia)</td>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Não consigo estimar</td>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Até 20% do tempo (~1,5h/dia)</td>\n",
       "      <td>De 20 a 40% do tempo  (~2h/dia)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tempo_lev_dados              tempo_analise_dados  \\\n",
       "0     Até 20% do tempo (~1,5h/dia)  De 20 a 40% do tempo  (~2h/dia)   \n",
       "1     Até 20% do tempo (~1,5h/dia)  De 20 a 40% do tempo  (~2h/dia)   \n",
       "2  De 20 a 40% do tempo  (~2h/dia)  De 60 a 80% do tempo  (~6h/dia)   \n",
       "3                              NaN                              NaN   \n",
       "4     Até 20% do tempo (~1,5h/dia)     Até 20% do tempo (~1,5h/dia)   \n",
       "5              Não consigo estimar              Não consigo estimar   \n",
       "6     Até 20% do tempo (~1,5h/dia)     Até 20% do tempo (~1,5h/dia)   \n",
       "7     Até 20% do tempo (~1,5h/dia)     Até 20% do tempo (~1,5h/dia)   \n",
       "8              Não consigo estimar     Até 20% do tempo (~1,5h/dia)   \n",
       "\n",
       "               tempo_debates_grupo              tempo_redigir_textos  \\\n",
       "0  De 40 a 60% do tempo  (~4h/dia)   De 20 a 40% do tempo  (~2h/dia)   \n",
       "1  De 40 a 60% do tempo  (~4h/dia)   De 20 a 40% do tempo  (~2h/dia)   \n",
       "2     Até 20% do tempo (~1,5h/dia)  De 80 a 100% do tempo  (~8h/dia)   \n",
       "3                              NaN                               NaN   \n",
       "4  De 20 a 40% do tempo  (~2h/dia)      Até 20% do tempo (~1,5h/dia)   \n",
       "5              Não consigo estimar               Não consigo estimar   \n",
       "6  De 20 a 40% do tempo  (~2h/dia)   De 40 a 60% do tempo  (~4h/dia)   \n",
       "7                              NaN      Até 20% do tempo (~1,5h/dia)   \n",
       "8     Até 20% do tempo (~1,5h/dia)                               NaN   \n",
       "\n",
       "                    tempo_reunioes                tempo_comunicacoes  \\\n",
       "0  De 60 a 80% do tempo  (~6h/dia)  De 80 a 100% do tempo  (~8h/dia)   \n",
       "1  De 40 a 60% do tempo  (~4h/dia)   De 40 a 60% do tempo  (~4h/dia)   \n",
       "2     Até 20% do tempo (~1,5h/dia)      Até 20% do tempo (~1,5h/dia)   \n",
       "3                              NaN                               NaN   \n",
       "4  De 40 a 60% do tempo  (~4h/dia)      Até 20% do tempo (~1,5h/dia)   \n",
       "5              Não consigo estimar               Não consigo estimar   \n",
       "6  De 40 a 60% do tempo  (~4h/dia)   De 60 a 80% do tempo  (~6h/dia)   \n",
       "7  De 20 a 40% do tempo  (~2h/dia)      Até 20% do tempo (~1,5h/dia)   \n",
       "8     Até 20% do tempo (~1,5h/dia)   De 20 a 40% do tempo  (~2h/dia)   \n",
       "\n",
       "   id_resposta  \n",
       "0            0  \n",
       "1            1  \n",
       "2            2  \n",
       "3            3  \n",
       "4            4  \n",
       "5            5  \n",
       "6            6  \n",
       "7            7  \n",
       "8            8  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tempo_ativ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfacao\n",
       "0         4.0\n",
       "1         4.0\n",
       "2         3.0\n",
       "3         NaN\n",
       "4         5.0\n",
       "5         3.0\n",
       "6         3.0\n",
       "7         4.0\n",
       "8         2.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_satisf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Lista de relacionamentos por tipo de produtos\")\n",
    "# for i,j in relacoes_biologicos.items():\n",
    "#     for k in j:\n",
    "#         print(k.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapas da cadeia de valor 4DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lista de relacionamentos por tipo de produtos\")\n",
    "for i,j in relacoes_pequenas_moleculas.items():\n",
    "    for k in j:\n",
    "        rotulo = k.get('id')\n",
    "        if rotulo:\n",
    "            print(f\"  {rotulo}\")\n",
    "        else:\n",
    "            print(f\"{  k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lista de relacionamentos por tipo de produtos\")\n",
    "for i,j in relacoes_biologicos.items():\n",
    "    for k in j:\n",
    "        rotulo = k.get('id')\n",
    "        if rotulo:\n",
    "            print(f\"  {rotulo}\")\n",
    "        else:\n",
    "            print(f\"{  k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparar o Grafo de Conhecimento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "grafo = nx.Graph()\n",
    "# ... (código para adicionar nós e arestas ao grafo)\n",
    "\n",
    "grafo_treino, grafo_teste = train_test_split(grafo, test_size=0.2)\n",
    "\n",
    "# Configuração dos parâmetros dos modelos\n",
    "parametros_iniciais = {\n",
    "    'num_features': ...,  # Número de features dos nós\n",
    "    'hidden_dim': 4,  # Dimensão da camada oculta\n",
    "    'num_classes': 7,  # Número de classes (clusters)\n",
    "    'dropout': 0.5  # Taxa de dropout\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Criação dos modelos com instanciação das classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelo_kan     = RedeNeuralKAN(parametros_iniciais)\n",
    "modelo_fourier = RedeNeuralFourier(parametros_iniciais)\n",
    "modelo_hibrido = RedeNeuralHibrida(parametros_iniciais)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Treinamento dos modelos\n",
    "\n",
    "Utilizar o grafo de treinamento (grafo_treino) para treinar cada um dos modelos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Treinamento do modelo de GNN com Sincronização (híbrido)\n",
    "\n",
    "    Inspirado em https://iopscience.iop.org/article/10.1209/0295-5075/ad76d6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_modelo(modelo, grafo_treino, epochs=100, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Treina um modelo de rede neural em grafos.\n",
    "\n",
    "    Args:\n",
    "      modelo: O modelo da rede neural.\n",
    "      grafo_treino: O grafo de conhecimento para treinamento.\n",
    "      epochs: O número de épocas de treinamento.\n",
    "      learning_rate: A taxa de aprendizado do otimizador.\n",
    "\n",
    "    Funcionamento:\n",
    "      Recebe o modelo, o grafo de treinamento, o número de épocas e a taxa de aprendizado como parâmetros.\n",
    "      Cria um otimizador Adam para atualizar os pesos do modelo.\n",
    "      Define a função de perda como CrossEntropyLoss (ajustável para a função de perda mais adequada ao problema).\n",
    "      Prepara os dados de treinamento (features, edge_index, edge_weight e labels, se houver).\n",
    "      Itera pelas épocas de treinamento, executando o modelo, calculando a perda, os gradientes e atualizando os pesos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Criar o otimizador\n",
    "        optimizer = torch.optim.Adam(modelo.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Definir a função de perda (exemplo: cross-entropy)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Preparar os dados de treinamento\n",
    "        x = torch.tensor(list(nx.get_node_attributes(grafo_treino, 'features').values()), dtype=torch.float)\n",
    "        edge_index = torch.tensor(list(grafo_treino.edges()), dtype=torch.long).t().contiguous()\n",
    "        edge_weight = torch.tensor(list(nx.get_edge_attributes(grafo_treino, 'weight').values()), dtype=torch.float)\n",
    "        \n",
    "        # ... (código para obter os rótulos dos nós, se houver)\n",
    "        # labels = ...\n",
    "\n",
    "        # Treinar o modelo\n",
    "        modelo.train()  # Mudar para o modo de treinamento\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()  # Zerar os gradientes\n",
    "            out = modelo(x, edge_index, edge_weight)  # Executar o modelo\n",
    "            loss = criterion(out, labels)  # Calcular a perda\n",
    "            loss.backward()  # Calcular os gradientes\n",
    "            optimizer.step()  # Atualizar os pesos do modelo\n",
    "\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no treinamento do modelo: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Chamar a função para treinar o modelo_hibrido\n",
    "treinar_modelo(modelo_hibrido, grafo_treino, epochs=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Função de treinamento do modelo_kan_mse\n",
    "\n",
    "    Com função de perda Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_kan = nn.MSELoss()  \n",
    "\n",
    "def treinar_modelo_kan_mse(modelo, grafo_treino, epochs=100, learning_rate=0.01, criterion=criterion_kan):\n",
    "    \"\"\"\n",
    "    Treina um modelo de rede neural KAN em grafos.\n",
    "\n",
    "    Args:\n",
    "      modelo: O modelo da rede neural KAN.\n",
    "      grafo_treino: O grafo de conhecimento para treinamento.\n",
    "      epochs: O número de épocas de treinamento.\n",
    "      learning_rate: A taxa de aprendizado do otimizador.\n",
    "      criterion: A função de perda.\n",
    "    \n",
    "    Função de Perda: A função de perda utilizada foi o MSELoss. \n",
    "    \n",
    "    Pode-se ajustar para uma função de perda mais adequada ao problema, considerando aprendizado não-supervisionado. \n",
    "    Uma opção seria utilizar uma função de perda baseada na distância entre os embeddings de nós que deveriam estar no mesmo cluster.\n",
    "    Ou ainda, pode-se também usar função de perda baseada em Triplet Loss.\n",
    "    \n",
    "    Rótulos: Ajustar o código para obter os rótulos dos nós (labels) de acordo com o seu problema. \n",
    "    Como o problema é de aprendizado não-supervisionado, os rótulos podem ser definidos com base em alguma heurística ou conhecimento prévio sobre o problema.\n",
    "    \n",
    "    Hiperparâmetros: Ajustar o número de épocas (epochs) e a taxa de aprendizado (learning_rate) para obter o melhor desempenho do modelo.    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Criar o otimizador\n",
    "        optimizer = torch.optim.Adam(modelo.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Preparar os dados de treinamento\n",
    "        x = torch.tensor(list(nx.get_node_attributes(grafo_treino, 'features').values()), dtype=torch.float)\n",
    "        edge_index = torch.tensor(list(grafo_treino.edges()), dtype=torch.long).t().contiguous()\n",
    "        edge_weight = torch.tensor(list(nx.get_edge_attributes(grafo_treino, 'weight').values()), dtype=torch.float)\n",
    "        \n",
    "        # ... (código para obter os rótulos dos nós, se houver - ajustar para o seu problema)\n",
    "        # labels = ...\n",
    "\n",
    "        # Treinar o modelo\n",
    "        modelo.train()  # Mudar para o modo de treinamento\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()  # Zerar os gradientes\n",
    "            out = modelo(x, edge_index, edge_weight)  # Executar o modelo\n",
    "            \n",
    "            # Calcular a perda (considerando que labels é um tensor com os valores desejados para os nós)\n",
    "            loss = criterion(out, labels)  \n",
    "            loss.backward()  # Calcular os gradientes\n",
    "            optimizer.step()  # Atualizar os pesos do modelo\n",
    "\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no treinamento do modelo KAN: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Chamar a função para treinar o modelo_kan\n",
    "treinar_modelo_kan_mse(modelo_kan, grafo_treino, epochs=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Função de treinamento do modelo_kan_triplet\n",
    "\n",
    "    Com função de perda por triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import losses\n",
    "\n",
    "# Exemplo de função para gerar trios (âncora, positivo, negativo)\n",
    "def gerar_triplets(grafo, embeddings):\n",
    "    \"\"\"\n",
    "    Gera trios (âncora, positivo, negativo) para a Triplet Loss.\n",
    "\n",
    "    Args:\n",
    "      grafo: O grafo de conhecimento.\n",
    "      embeddings: Os embeddings dos nós.\n",
    "\n",
    "    Returns:\n",
    "      Um tensor com os trios.\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    for no_ancora in grafo.nodes():\n",
    "        # Encontrar nós positivos (similares à âncora)\n",
    "        # ... (implementar lógica para encontrar nós positivos)\n",
    "\n",
    "        # Encontrar nós negativos (diferentes da âncora)\n",
    "        # ... (implementar lógica para encontrar nós negativos)\n",
    "\n",
    "        for no_positivo in nos_positivos:\n",
    "            for no_negativo in nos_negativos:\n",
    "                triplets.append([no_ancora, no_positivo, no_negativo])\n",
    "\n",
    "    return torch.tensor(triplets)\n",
    "\n",
    "def treinar_modelo_kan_triplet(modelo, grafo_treino, epochs=100, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Treina um modelo de rede neural KAN em grafos utilizando Triplet Loss.\n",
    "\n",
    "    Args:\n",
    "      modelo: O modelo da rede neural KAN.\n",
    "      grafo_treino: O grafo de conhecimento para treinamento.\n",
    "      epochs: O número de épocas de treinamento.\n",
    "      learning_rate: A taxa de aprendizado do otimizador.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Criar o otimizador\n",
    "        optimizer = torch.optim.Adam(modelo.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Preparar os dados de treinamento\n",
    "        x = torch.tensor(list(nx.get_node_attributes(grafo_treino, 'features').values()), dtype=torch.float)\n",
    "        edge_index = torch.tensor(list(grafo_treino.edges()), dtype=torch.long).t().contiguous()\n",
    "        edge_weight = torch.tensor(list(nx.get_edge_attributes(grafo_treino, 'weight').values()), dtype=torch.float)\n",
    "\n",
    "        # Criar a função de perda Triplet Loss\n",
    "        loss_func = losses.TripletMarginLoss()\n",
    "\n",
    "        # Treinar o modelo\n",
    "        modelo.train()  # Mudar para o modo de treinamento\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()  # Zerar os gradientes\n",
    "            embeddings = modelo(x, edge_index, edge_weight)  # Executar o modelo\n",
    "            \n",
    "            # Gerar os trios (âncora, positivo, negativo), com lógica de acordo com o problema\n",
    "            triplets = gerar_triplets(grafo_treino, embeddings) \n",
    "\n",
    "            # Calcular a Triplet Loss\n",
    "            loss = loss_func(embeddings, triplets)  \n",
    "            loss.backward()  # Calcular os gradientes\n",
    "            optimizer.step()  # Atualizar os pesos do modelo\n",
    "\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no treinamento do modelo KAN: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Chamar a função para treinar o modelo_kan\n",
    "treinar_modelo_kan_triplet(modelo_kan, grafo_treino, epochs=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Função para treinamento do modelo_fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo_fourier\n",
    "criterion_fourier = nn.KLDivLoss() # Ajustar a função de perda para o modelo Fourier (exemplo: Kullback-Leibler Divergence)  \n",
    "\n",
    "def treinar_modelo_fourier(modelo, grafo_treino, epochs=100, learning_rate=0.01, criterion=criterion_fourier):\n",
    "    \"\"\"\n",
    "    Treina um modelo de rede neural Fourier em grafos.\n",
    "\n",
    "    Args:\n",
    "      modelo: O modelo da rede neural Fourier.\n",
    "      grafo_treino: O grafo de conhecimento para treinamento.\n",
    "      epochs: O número de épocas de treinamento.\n",
    "      learning_rate: A taxa de aprendizado do otimizador.\n",
    "      criterion: A função de perda.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Criar o otimizador\n",
    "        optimizer = torch.optim.Adam(modelo.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Preparar os dados de treinamento\n",
    "        x = torch.tensor(list(nx.get_node_attributes(grafo_treino, 'features').values()), dtype=torch.float)\n",
    "        edge_index = torch.tensor(list(grafo_treino.edges()), dtype=torch.long).t().contiguous()\n",
    "        edge_weight = torch.tensor(list(nx.get_edge_attributes(grafo_treino, 'weight').values()), dtype=torch.float)\n",
    "        # ... (código para obter os rótulos dos nós, se houver - ajustar para o seu problema)\n",
    "        # labels = ...\n",
    "\n",
    "        # Treinar o modelo\n",
    "        modelo.train()  # Mudar para o modo de treinamento\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()  # Zerar os gradientes\n",
    "            out = modelo(x, edge_index, edge_weight)  # Executar o modelo\n",
    "\n",
    "            # Ajustar a saída do modelo e os rótulos para a KLDivLoss\n",
    "            # (a saída deve ser um tensor de probabilidades e os rótulos devem ser um tensor de índices)\n",
    "            out = torch.nn.functional.log_softmax(out, dim=1)  # Aplicar log_softmax na saída\n",
    "            # Converter labels para one-hot encoding e aplicar log_softmax (ajuste para o seu problema)\n",
    "            labels_onehot = torch.nn.functional.one_hot(labels, num_classes=out.shape[1]).float()\n",
    "            labels_onehot = torch.nn.functional.log_softmax(labels_onehot, dim=1) \n",
    "\n",
    "            # Calcular a perda \n",
    "            loss = criterion(out, labels_onehot)  \n",
    "            loss.backward()  # Calcular os gradientes\n",
    "            optimizer.step()  # Atualizar os pesos do modelo\n",
    "\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no treinamento do modelo Fourier: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Chamar a função para treinar o modelo_fourier\n",
    "treinar_modelo_fourier(modelo_fourier, grafo_treino, epochs=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Instanciar a classe de testes e realizar as análises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie uma instância da classe TesteRedeNeural para avaliar o desempenho de cada modelo no grafo de teste (grafo_teste):\n",
    "teste_rede_neural = TesteRedeNeural(grafo_teste, parametros_modelo)  # Instanciar a classe de testes\n",
    "\n",
    "# Controle de Sincronização + GNN\n",
    "clusters_hibrido, embeddings_hibrido = modelo_hibrido.inferir(grafo_teste)  # Realizar inferência\n",
    "analises_hibrido = teste_rede_neural.testar_inferencia(clusters_hibrido, embeddings_hibrido)\n",
    "\n",
    "# KAN + GNN\n",
    "clusters_kan, embeddings_kan = modelo_kan.inferir(grafo_teste)\n",
    "analises_kan = teste_rede_neural.testar_inferencia(clusters_kan, embeddings_kan)\n",
    "\n",
    "# Transformadas de Fourier + GNN\n",
    "clusters_fourier, embeddings_fourier = modelo_fourier.inferir(grafo_teste)\n",
    "analises_fourier = teste_rede_neural.testar_inferencia(clusters_fourier, embeddings_fourier)\n",
    "\n",
    "# 6. Comparação dos resultados\n",
    "def gerar_tabela_latex(analises):\n",
    "    \"\"\"\n",
    "    Gera uma tabela LaTeX com os resultados das análises.\n",
    "\n",
    "    Args:\n",
    "      analises: Um dicionário contendo as análises dos modelos.\n",
    "\n",
    "    Returns:\n",
    "      Uma string com o código LaTeX da tabela.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(analises)\n",
    "    df.index = ['Híbrido', 'KAN', 'Fourier']\n",
    "    latex_table = df.to_latex(float_format=\"%.3f\", caption=\"Resultados das Análises\", label=\"tab:resultados\")\n",
    "    return latex_table\n",
    "\n",
    "# Agregar as análises em um dicionário\n",
    "analises = {\n",
    "    'Híbrido': analises_hibrido,\n",
    "    'KAN': analises_kan,\n",
    "    'Fourier': analises_fourier,\n",
    "}\n",
    "\n",
    "# Gerar a tabela LaTeX\n",
    "tabela_latex = gerar_tabela_latex(analises)\n",
    "\n",
    "# Exibir a tabela LaTeX\n",
    "print(tabela_latex)\n",
    "\n",
    "# Salvar a tabela em um arquivo .tex\n",
    "with open('resultados_analises.tex', 'w') as f:\n",
    "    f.write(tabela_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma instância da classe SemanticMatching\n",
    "from semantic_matcher import ENPreprocessor, SemanticMatcher\n",
    "tradutor = ENPreprocessor()\n",
    "matcher = SemanticMatcher(curriculos_data, matriz_ceis_data, relacoes_biologicos, relacoes_pequenas_moleculas)\n",
    "\n",
    "# Executar as etapas de processamento\n",
    "matcher.traduzir_nomes_produtos()\n",
    "matcher.extrair_caracteristicas()\n",
    "matcher.classificar_produtos()\n",
    "matcher.conectar_produtos_grafo()\n",
    "\n",
    "# Imprimir informações sobre os grafos\n",
    "print(\"Grafo de Biológicos:\")\n",
    "print(\"Número de nós:\", matcher.biologicos.number_of_nodes())\n",
    "print(\"Número de arestas:\", matcher.biologicos.number_of_edges())\n",
    "\n",
    "print(\"\\nGrafo de Pequenas Moléculas:\")\n",
    "print(\"Número de nós:\", matcher.pequenas_moleculas.number_of_nodes())\n",
    "print(\"Número de arestas:\", matcher.pequenas_moleculas.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cudf\n",
    "import cugraph\n",
    "import json\n",
    "from pyvis.network import Network\n",
    "\n",
    "json_folder = os.path.join(os.getcwd(),'_data','out_json')\n",
    "\n",
    "# Carregar os dados dos arquivos JSON com cuDF\n",
    "curriculos_df = cudf.read_json(os.path.join(json_folder,'curriculos.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curriculos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_ceis_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cugraph\n",
    "import json\n",
    "import time\n",
    "from pyvis.network import Network\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Funções para calcular as transformadas de Fourier\n",
    "def naive_fourier(x, gridsize=300):\n",
    "    # ... (implementação da Naive Fourier Transform) ...\n",
    "    pass  # Substitua pelo código da transformada\n",
    "\n",
    "def gft(x, edge_index):\n",
    "    # ... (implementação da Graph Fourier Transform) ...\n",
    "    pass  # Substitua pelo código da transformada\n",
    "\n",
    "def wavelet_transform(x, edge_index, num_scales=5):\n",
    "    # ... (implementação da Wavelet Transform) ...\n",
    "    pass  # Substitua pelo código da transformada\n",
    "\n",
    "def fractional_fourier(x, alpha=0.5):\n",
    "    # ... (implementação da Fractional Fourier Transform) ...\n",
    "    pass  # Substitua pelo código da transformada\n",
    "\n",
    "def qft(x):\n",
    "  \"\"\"Calcula a QFT de um quaternion.\"\"\"\n",
    "  # ... (implementação da Transformada de Fourier Quaterniônica) ...\n",
    "  pass  # Substitua pelo código da transformada\n",
    "\n",
    "def conectar_pesquisadores_produtos(graph, curriculos_df, matriz_ceis_df, tipo_transformada):\n",
    "    \"\"\"Conecta pesquisadores a produtos com base na similaridade de áreas de atuação.\"\"\"\n",
    "\n",
    "    # Extrair áreas de atuação dos pesquisadores e produtos\n",
    "    pesquisadores_areas = curriculos_df['Áreas'].to_arrow().to_pylist()\n",
    "    produtos_areas = []\n",
    "    for bloco in matriz_ceis_df['blocos'].to_arrow().to_pylist():\n",
    "        for produto in bloco['produtos']:\n",
    "            produtos_areas.append(produto['nome'])  # Usando o nome do produto como representação da área\n",
    "\n",
    "    # Converter áreas de atuação em vetores numéricos (ex: usando word embeddings)\n",
    "    # ... (implementar lógica para converter áreas em vetores) ...\n",
    "\n",
    "    # Aplicar a transformada de Fourier selecionada\n",
    "    if tipo_transformada == 'naive':\n",
    "        pesquisadores_transformados = [naive_fourier(areas) for areas in pesquisadores_areas]\n",
    "        produtos_transformados = [naive_fourier(areas) for areas in produtos_areas]\n",
    "    elif tipo_transformada == 'gft':\n",
    "        # ... (aplicar GFT) ...\n",
    "        pass\n",
    "    elif tipo_transformada == 'wavelet':\n",
    "        # ... (aplicar Wavelet Transform) ...\n",
    "        pass\n",
    "    elif tipo_transformada == 'fractional':\n",
    "        # ... (aplicar Fractional Fourier Transform) ...\n",
    "        pass\n",
    "    elif tipo_transformada == 'qft':\n",
    "        # ... (aplicar QFT) ...\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Tipo de transformada inválido.\")\n",
    "\n",
    "    # Calcular a similaridade de cosseno entre os vetores transformados\n",
    "    similaridade = cosine_similarity(pesquisadores_transformados, produtos_transformados)\n",
    "\n",
    "    # Criar as arestas no grafo cuGraph com base na similaridade\n",
    "    limite_similaridade = 0.8  # Definir um limite para a similaridade\n",
    "    for i, pesquisador_id in enumerate(pesquisadores_ids):\n",
    "        for j, produto_id in enumerate(produtos_ids):\n",
    "            if similaridade[i, j] > limite_similaridade:\n",
    "                G.add_edge(pesquisador_id, produto_id, weight=similaridade[i, j])\n",
    "\n",
    "# --- Avaliação das abordagens ---\n",
    "\n",
    "resultados = {}\n",
    "tipos_transformadas = ['naive', 'gft', 'wavelet', 'fractional', 'qft']\n",
    "\n",
    "for tipo_transformada in tipos_transformadas:\n",
    "    inicio = time.time()\n",
    "\n",
    "    # Criar um novo grafo para cada tipo de transformada\n",
    "    G = cugraph.Graph()\n",
    "    G.add_nodes_from(pesquisadores_ids, tipo='pesquisador')\n",
    "    G.add_nodes_from(produtos_ids, tipo='produto')\n",
    "\n",
    "    # Conectar pesquisadores e produtos\n",
    "    conectar_pesquisadores_produtos(G, curriculos_df, matriz_ceis_df, tipo_transformada)\n",
    "\n",
    "    fim = time.time()\n",
    "    tempo_execucao = fim - inicio\n",
    "\n",
    "    # Calcular as métricas de avaliação\n",
    "    num_arestas = G.number_of_edges()\n",
    "\n",
    "    # ... (calcular precisão e recall usando um conjunto de dados de referência) ...\n",
    "\n",
    "    resultados[tipo_transformada] = {\n",
    "        'num_arestas': num_arestas,\n",
    "        'tempo_execucao': tempo_execucao,\n",
    "        # 'precisao': precisao,\n",
    "        # 'recall': recall\n",
    "    }\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(resultados)\n",
    "\n",
    "# --- Visualização (opcional) ---\n",
    "# ... (criar gráficos com Altair para comparar as métricas) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pré-processamento dos dados com cuDF\n",
    "# (Extrair IDs e informações relevantes para os nós e arestas)\n",
    "pesquisadores_ids = curriculos_df['Identificação']['ID Lattes'].to_arrow().to_pylist()\n",
    "produtos_ids = []\n",
    "for bloco in matriz_ceis_df['blocos'].to_arrow().to_pylist():\n",
    "    for produto in bloco['produtos']:\n",
    "        produtos_ids.append(produto['id'])\n",
    "\n",
    "# Criar um grafo cuGraph\n",
    "G = cugraph.Graph()\n",
    "\n",
    "# Adicionar os nós ao grafo cuGraph\n",
    "G.add_nodes_from(pesquisadores_ids, tipo='pesquisador')\n",
    "G.add_nodes_from(produtos_ids, tipo='produto')\n",
    "\n",
    "# Criar as arestas entre pesquisadores e produtos (definir critérios)\n",
    "# ... (implementar lógica para conectar pesquisadores a produtos usando cuDF) ...\n",
    "# EXEMPLO: conectar pesquisadores a produtos com base na similaridade de áreas de atuação\n",
    "\n",
    "# Calcular métricas de grafo com cuGraph\n",
    "degree_centrality = cugraph.degree_centrality(G)\n",
    "\n",
    "# Converter o grafo cuGraph para NetworkX\n",
    "graph_nx = G.to_networkx()\n",
    "\n",
    "# Criar o grafo PyVis 'net' a partir do grafo NetworkX 'graph_nx'\n",
    "net = Network(notebook=True, directed=True)\n",
    "net.from_nx(graph_nx)\n",
    "\n",
    "# Personalizar a visualização (opcional)\n",
    "# ... (utilizar as métricas calculadas com cuGraph para definir o tamanho dos nós, cores, etc.) ...\n",
    "\n",
    "# Mostrar o grafo na célula do Jupyter\n",
    "net.show(\"graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "\n",
    "json_folder = os.path.join(os.getcwd(),'_data','out_json')\n",
    "\n",
    "# Carregar os dados dos arquivos JSON\n",
    "with open(os.path.join(json_folder,'curriculos.json'), 'r') as f:\n",
    "    curriculos_data = json.load(f)\n",
    "with open(os.path.join(json_folder,'matriz_ceis.json'), 'r') as f:\n",
    "    matriz_ceis_data = json.load(f)\n",
    "\n",
    "# Criar um grafo direcionado\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Adicionar os pesquisadores como nós\n",
    "for pesquisador in curriculos_data:\n",
    "    graph.add_node(pesquisador['Identificação']['ID Lattes'], tipo='pesquisador', **pesquisador)\n",
    "\n",
    "# Adicionar os produtos como nós\n",
    "for bloco in matriz_ceis_data['blocos']:\n",
    "    for produto in bloco['produtos']:\n",
    "        graph.add_node(produto['id'], tipo='produto', **produto)\n",
    "\n",
    "# Função para criar as arestas entre pesquisadores e produtos\n",
    "def create_edges(graph, pesquisador_node, produto_node):\n",
    "    \"\"\"Cria arestas entre pesquisadores e produtos com base em suas propriedades.\"\"\"\n",
    "    pesquisador_data = pesquisador_node[1]\n",
    "    produto_data = produto_node[1]\n",
    "\n",
    "    # Lógica para conectar pesquisadores a produtos (EXEMPLO)\n",
    "    # Verificar se as áreas de atuação do pesquisador são relevantes para o produto\n",
    "    for area in pesquisador_data['Áreas'].values():\n",
    "        if any(keyword in area for keyword in [\"Biotecnologia\", \"Saúde\", \"Química\", \"Biologia\"]):\n",
    "            graph.add_edge(pesquisador_node[0], produto_node[0])\n",
    "            return  # Criar apenas uma aresta por produto\n",
    "\n",
    "# Iterar pelos nós e criar as arestas\n",
    "for pesquisador_node in graph.nodes(data=True):\n",
    "    if pesquisador_node[1]['tipo'] == 'pesquisador':\n",
    "        for produto_node in graph.nodes(data=True):\n",
    "            if produto_node[1]['tipo'] == 'produto':\n",
    "                create_edges(graph, pesquisador_node, produto_node)\n",
    "\n",
    "# Imprimir os primeiros 5 nós e arestas\n",
    "print(\"Nós:\", list(graph.nodes(data=True))[:5])\n",
    "print(\"Arestas:\", list(graph.edges(data=True))[:5])\n",
    "\n",
    "# Mostrar o número de nós e arestas\n",
    "print(\"Número de nós:\", graph.number_of_nodes())\n",
    "print(\"Número de arestas:\", graph.number_of_edges())\n",
    "\n",
    "# Mostrar os tipos de nós presentes no grafo\n",
    "tipos_nos = set(no[1]['tipo'] for no in graph.nodes(data=True))\n",
    "print(\"Tipos de nós:\", tipos_nos)\n",
    "\n",
    "# Mostrar as propriedades dos nós\n",
    "print(\"Propriedades dos nós:\")\n",
    "for no in graph.nodes(data=True):\n",
    "    print(no)\n",
    "\n",
    "# Mostrar a distribuição das arestas entre os nós\n",
    "# (Exemplo: calcular o grau de cada nó)\n",
    "graus = dict(graph.degree())\n",
    "print(\"Distribuição de graus dos nós:\", graus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(notebook=True, directed=True)  # notebook=True para exibir no Jupyter, directed=True para grafo direcionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.from_nx(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir opções de layout\n",
    "net.repulsion(node_distance=200, central_gravity=0.2)\n",
    "\n",
    "# Configurar a física da visualização\n",
    "net.show_buttons(filter_=['physics'])  # Mostrar botões para controlar a física\n",
    "\n",
    "# Definir cores para os nós com base no tipo\n",
    "for node in net.nodes:\n",
    "    if node['tipo'] == 'pesquisador':\n",
    "        node['color'] = 'blue'\n",
    "    elif node['tipo'] == 'produto':\n",
    "        node['color'] = 'green'\n",
    "\n",
    "# Ajustar o tamanho dos nós com base no grau\n",
    "degrees = dict(graph.degree())\n",
    "for node in net.nodes:\n",
    "    node['size'] = degrees[node['id']] * 5  # Aumentar o tamanho proporcionalmente ao grau\n",
    "\n",
    "# net.show(\"graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "# Exibir o conteúdo do arquivo HTML na célula do Jupyter\n",
    "HTML(filename='graph.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cudf\n",
    "# import cugraph\n",
    "# import json\n",
    "# import networkx as nx\n",
    "# from pyvis.network import Network\n",
    "# from googletrans import Translator\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# class SemanticMatching:\n",
    "#     def __init__(self, curriculos_df, matriz_ceis_data, relacoes_biologicos,\n",
    "#                  relacoes_pequenas_moleculas):\n",
    "#         self.curriculos_df = curriculos_df\n",
    "#         self.matriz_ceis_data = matriz_ceis_data\n",
    "#         self.relacoes_biologicos = relacoes_biologicos\n",
    "#         self.relacoes_pequenas_moleculas = relacoes_pequenas_moleculas\n",
    "#         self.translator = Translator()\n",
    "#         self.produtos_df = self.criar_dataframe_produtos()\n",
    "#         self.biologicos, self.pequenas_moleculas = self.criar_grafos_relacionamentos()\n",
    "\n",
    "#     def criar_dataframe_produtos(self):\n",
    "#         json_folder = os.path.join(os.getcwd(),'_data','out_json')\n",
    "\n",
    "#         # Carregar a Matriz CEIS\n",
    "#         with open(os.path.join(json_folder,'matriz_ceis.json'), 'r') as f:\n",
    "#             matriz_ceis_data = json.load(f)\n",
    "\n",
    "#         # Extrair os dados dos produtos\n",
    "#         produtos = []\n",
    "#         for bloco in matriz_ceis_data['blocos']:\n",
    "#             for produto in bloco['produtos']:\n",
    "#                 produto['bloco_id'] = bloco['id']\n",
    "#                 produto['bloco_nome'] = bloco['titulo']\n",
    "#                 produtos.append(produto)\n",
    "\n",
    "#         # Retornar o DataFrame cuDF\n",
    "#         return cudf.DataFrame(produtos)\n",
    "\n",
    "#     def criar_grafos_relacionamentos(self):\n",
    "#         # ... (código para criar os grafos de biológicos e pequenas moléculas) ...\n",
    "#         biologicos = nx.DiGraph()\n",
    "#         for node in self.relacoes_biologicos[\"nodes\"]:\n",
    "#             biologicos.add_node(node['id'], **node)\n",
    "#         for edge in self.relacoes_biologicos[\"edges\"]:\n",
    "#             biologicos.add_edge(edge['from'], edge['to'])\n",
    "\n",
    "#         pequenas_moleculas = nx.DiGraph()\n",
    "#         for node in self.relacoes_pequenas_moleculas[\"nodes\"]:\n",
    "#             pequenas_moleculas.add_node(node['id'], **node)\n",
    "#         for edge in self.relacoes_pequenas_moleculas[\"edges\"]:\n",
    "#             pequenas_moleculas.add_edge(edge['from'], edge['to'])\n",
    "#         return biologicos, pequenas_moleculas\n",
    "\n",
    "#     def traduzir_nomes_produtos(self):\n",
    "#         # ... (código para traduzir os nomes dos produtos) ...\n",
    "#         self.produtos_df['nome_en'] = self.produtos_df['nome'].apply(\n",
    "#             lambda x: self.translator.translate(x, dest='en').text)\n",
    "\n",
    "#     def extrair_caracteristicas(self):\n",
    "#         # ... (código para extrair características semânticas) ...\n",
    "#         pass  # Implemente a extração de características aqui\n",
    "\n",
    "#     def classificar_produtos(self):\n",
    "#         # ... (código para classificar os produtos) ...\n",
    "#         pass  # Implemente a classificação dos produtos aqui\n",
    "\n",
    "#     def calcular_similaridade(self, produto, grafo, tipo_transformada):\n",
    "#         # ... (código para calcular similaridade usando a abordagem especificada) ...\n",
    "#         pass  # Implemente o cálculo de similaridade aqui\n",
    "\n",
    "#     def conectar_produtos_grafo(self):\n",
    "#         # ... (código para conectar os produtos aos grafos) ...\n",
    "#         pass  # Implemente a conexão dos produtos aos grafos aqui\n",
    "\n",
    "#     def avaliar_desempenho(self):\n",
    "#         # ... (código para avaliar o desempenho das abordagens) ...\n",
    "#         pass  # Implemente a avaliação de desempenho aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "yy = 2024\n",
    "print (f\"O calendário do ano {yy} é:\")\n",
    "print (calendar.calendar(yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import calendar\n",
    "\n",
    "# yy = 2024\n",
    "# # mm = 10\n",
    "# # print(calendar.month(yy,mm))\n",
    "\n",
    "# for i in range(1,13):\n",
    "#     print(calendar.month(yy,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Define the CSS style for the DataFrame with the text wrapping in the lines and occupying the entire width of the cell\n",
    "# style = \"\"\"\n",
    "# <style>\n",
    "# .dataframe {\n",
    "#     width: 100%;\n",
    "# }\n",
    "\n",
    "# .dataframe td {\n",
    "#     word-wrap: break-word;\n",
    "#     white-space: pre-wrap;\n",
    "# }\n",
    "# </style>\n",
    "# \"\"\"\n",
    "\n",
    "# # Divide a coluna de desafios em múltiplas colunas, separando os desafios por ponto e vírgula\n",
    "# df_produtos_proximos.iloc[:, 0] = df_produtos_proximos.iloc[:, 0].str.split(';')\n",
    "\n",
    "# # \"Explode\" o DataFrame para que cada desafio fique em uma linha separada\n",
    "# df_exploded = df_produtos_proximos.explode(df_produtos_proximos.columns[0])\n",
    "\n",
    "# # Calcula a frequência de cada desafio\n",
    "# df_sum = df_exploded[df_produtos_proximos.columns[0]].value_counts()\n",
    "\n",
    "# # Converte a Series para DataFrame e redefine o índice\n",
    "# df = pd.DataFrame(df_sum).reset_index()\n",
    "\n",
    "# # Renomeia as colunas para 'Desafio' e 'Total'\n",
    "# df.columns = ['Desafio', 'Total']\n",
    "\n",
    "# # Exibe o DataFrame resultante\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
