{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defasagem Poder de Compra da remuneração do Servidores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install camelot-py[cv] tabulate\n",
    "# !pip3 install pandas-ods-reader\n",
    "# %pip install ezodf\n",
    "# %pip install thefuzz\n",
    "# %pip uninstall sqlalchemy-migrate\n",
    "# %pip install camelot-py[cv] --use-pep517\n",
    "# %pip install --upgrade camelot-py[cv]\n",
    "# %pip install --upgrade PyPDF2\n",
    "# %pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, requests\n",
    "import pandas as pd\n",
    "import camelot\n",
    "import pdfplumber\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def download_pdf_files(url, save_folder):\n",
    "    \"\"\"Baixa todos os arquivos de \"Relatório\" de uma página da web e salva em uma pasta local.\n",
    "\n",
    "    Args:\n",
    "        url: A URL da página da web.\n",
    "        save_folder: O caminho da pasta local onde os arquivos serão salvos.\n",
    "    \"\"\"    \n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    url = 'https://www.gov.br/servidor/pt-br/observatorio-de-pessoal-govbr/tabela-de-remuneracao-dos-servidores-publicos-federais-civis-e-dos-ex-territorios'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            print('Página acessada com sucesso, busando links para relatórios em PDF...')\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Tempo limite excedido ao tentar acessar a página: {url}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Ocorreu um erro ao baixar os arquivos, tente novamente mais tarde: {e}\")\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    relatorio_links = [link['href'] for link in soup.find_all('a', string='Relatório')]\n",
    "    print(f'{len(relatorio_links)} relatórios em PDF encontrados')\n",
    "\n",
    "    pattern = re.compile(r'Caderno', re.IGNORECASE)  # Case-insensitive match\n",
    "    caderno_links = [link['href'] for link in soup.find_all('a', string=pattern)]\n",
    "    print(f'{len(caderno_links)} relatórios em PDF tipo caderno encontrados')\n",
    "\n",
    "    print('Realizando downloads...')\n",
    "    if relatorio_links:\n",
    "        for link in tqdm(relatorio_links, desc=\"Obtendo relatórios...\"):\n",
    "            if link.endswith('@@download/file'):\n",
    "                file_name = link.split('/')[-3].split('/')[0]\n",
    "            else:\n",
    "                file_name = link.split('/')[-1]\n",
    "            file_path = os.path.join(save_folder, file_name)\n",
    "\n",
    "            with requests.get(link, stream=True) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(file_path, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "    else:\n",
    "        print('Nenum link para relatórios em PDF encontrado')\n",
    "\n",
    "    if caderno_links:   \n",
    "        for link in tqdm(caderno_links, desc=\"Obtendo cadernos...\"):\n",
    "            if link.endswith('@@download/file'):\n",
    "                file_name = link.split('/')[-3].split('/')[0]\n",
    "            else:\n",
    "                file_name = link.split('/')[-1]\n",
    "            file_path = os.path.join(save_folder, file_name)\n",
    "\n",
    "            with requests.get(link, stream=True) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(file_path, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "    else:\n",
    "        print('Nenhum link para cadernos em PDF encontrado')\n",
    "\n",
    "    print(f\"Relatórios PDF extraídos e salvos em {save_folder}\")\n",
    "\n",
    "    list_string =  [('tabela-de-remuneracao-','tab_'),('TabeladeRemunerao','tab_'),('TabelaRemunFev23Vol82Page','tab_82_2023'),\n",
    "                    ('tabela-remunjul23-vol83-2','tab_83_2023'),('151217_tab_','tab_'),('2009-1','2009'),\n",
    "                    ('-jan','_'),('_jan','_'),('_fev','_'),('_mar','_'),('-marco-','_'),('_abr','_'),('_mai','_'),\n",
    "                    ('-maio','_'),('_jun','_'),('_jul','_'),('-julho-','_'),('_set','_'),('-ago-','_'),('-ago','_'),\n",
    "                    ('_ago','_'),('_sto','_'),('-setembro','_'),('-set','_'),('_out','_'),('Nov','_'),('_dez','_'),\n",
    "                    ('tab_82Page','tab_82_2023'),('tab_83-2','tab_83_2023'),('-semlogo22',''),('2012_03','2012'),\n",
    "                    ('-semlogo22',''),('_eiro','_'),('-marco','_'),('_sto','_')]\n",
    "    \n",
    "    for _ in range(3):\n",
    "        rename_pdf_file(save_folder, list_string)\n",
    "\n",
    "def rename_pdf_file(save_folder, list_string):\n",
    "    for filename in os.listdir(save_folder):\n",
    "        if filename.endswith('.pdf') or filename.endswith('.ods'):  # Verifica se é um arquivo PDF ou ODS\n",
    "            for i, j in list_string:\n",
    "                new_filename = filename.replace(i, j)\n",
    "                old_path = os.path.join(save_folder, filename)\n",
    "                new_path = os.path.join(save_folder, new_filename)\n",
    "                try:\n",
    "                    os.rename(old_path, new_path)\n",
    "                except OSError as e:\n",
    "                    pass\n",
    "                    # print(f\"Error renaming: {e}\")    \n",
    "\n",
    "def download_ods_files(url, save_folder):\n",
    "    \"\"\"Baixa todos os arquivos .ods de uma página da web e salva em uma pasta local.\n",
    "\n",
    "    Args:\n",
    "        url: A URL da página da web.\n",
    "        save_folder: O caminho da pasta local onde os arquivos serão salvos.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print('Página acessada com sucesso, busando links para arquivos ODS...')\n",
    "\n",
    "    response.raise_for_status()  # Verifica se a requisição foi bem-sucedida\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    ods_links = [link['href'] for link in soup.find_all('a', href=True) if link['href'].endswith('.ods')]\n",
    "    if ods_links:\n",
    "        print(f'{len(ods_links)} arquivos ODS encontrados, realizando downloads...')\n",
    "    for link in ods_links:\n",
    "        filename = os.path.basename(link)  # Obtém o nome do arquivo\n",
    "        save_path = os.path.join(save_folder, filename)  # Caminho completo para salvar\n",
    "        response = requests.get(link)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        with open(save_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "        print(f\"Arquivo {filename} baixado com sucesso!\")\n",
    "\n",
    "def extract_summary_and_tables(pdf):\n",
    "    \"\"\"Extrai o sumário e tabelas do PDF.\"\"\"\n",
    "    li=None\n",
    "    lf=None\n",
    "    linhas=[]\n",
    "    sumario = []\n",
    "    all_tables = []\n",
    "\n",
    "    for page in pdf.pages:\n",
    "        print(f'Processando: {page.page_number:3}/{len(pdf.pages)}...')\n",
    "        clear_output(wait=True)  # Limpa a saída e espera a próxima impressão\n",
    "        text = page.extract_text()\n",
    "        for n,line in enumerate(text.split('\\n')):\n",
    "            linhas.append(line)\n",
    "            # localizar linha de final do sumário\n",
    "            if 'Sumário' in line:\n",
    "                li = n\n",
    "            # localizar linha de início do sumário\n",
    "            elif 'INDICE' in line:\n",
    "                lf = n\n",
    "\n",
    "        # Coletar tabelas\n",
    "        for table in page.extract_tables():\n",
    "            print(f'Tabela encontrada na página {page.page_number}')\n",
    "            all_tables.append(table)\n",
    "    \n",
    "    print(f'Sumário das linhas {li} a {lf} total de {len(linhas)}')\n",
    "    print(f'Total de {len(all_tables)} tabelas detectadas.')\n",
    "\n",
    "    # Criar DataFrames\n",
    "    if linhas:\n",
    "        df_summary = pd.DataFrame(linhas, columns=['Sumário'])\n",
    "    else:\n",
    "        print('Nenhuma linha de sumário encontrada no arquivo PDF')\n",
    "        df_summary = pd.DataFrame()\n",
    "    if all_tables:\n",
    "        df_tables = pd.DataFrame(all_tables[0])  # Criar DataFrame a partir da primeira tabela (assumindo que todas têm a mesma estrutura)\n",
    "        for table in all_tables[1:]:\n",
    "            df_tables = pd.concat([df_tables, pd.DataFrame(table)], ignore_index=True)\n",
    "    else:\n",
    "        print('Nenhuma tabela encontrada no arquivo PDF')\n",
    "        df_tables = pd.DataFrame()\n",
    "\n",
    "    return df_summary, li, lf, df_tables\n",
    "\n",
    "def extract_remuneration_tables(pdf, df_summary):\n",
    "    \"\"\"Extrai as tabelas de remuneração com base no sumário.\"\"\"\n",
    "    all_data = []\n",
    "    for _, row in df_summary.iterrows():\n",
    "        orgao, cargo, paginas = row\n",
    "        for pagina in map(int, paginas.split(',')):\n",
    "            page = pdf.pages[pagina - 1]  # Páginas em pdfplumber começam em 0\n",
    "            tables = page.extract_tables()\n",
    "\n",
    "            # Encontrar a tabela de remuneração\n",
    "            remuneration_table = None\n",
    "            for table in tables:\n",
    "                if any(\"CLASSE\" in row[0] for row in table):\n",
    "                    remuneration_table = table\n",
    "                    break\n",
    "\n",
    "        if remuneration_table is None:\n",
    "            raise ValueError(\"Tabela de remuneração não encontrada no PDF.\")\n",
    "\n",
    "        # Extrair cabeçalho (considerando que a primeira linha contém os rótulos)\n",
    "        header = remuneration_table[0]\n",
    "        data = remuneration_table[1:]\n",
    "\n",
    "        # Criar DataFrame\n",
    "        df = pd.DataFrame(data, columns=header)\n",
    "\n",
    "        # Extrair informações de órgão, cargo e posição do texto da página\n",
    "        text = page.extract_text()\n",
    "        orgao_cargo_matches = re.findall(r\"(\\d+)\\.\\s*(.+?)\\s*-\", text)  # Encontrar todos os órgãos e cargos\n",
    "\n",
    "        # Criar dicionário para mapear número do órgão para nome do órgão e cargo\n",
    "        orgao_cargo_map = {int(num): (orgao, cargo.split('-')[0].strip()) for num, orgao, cargo in orgao_cargo_matches}\n",
    "\n",
    "        # Adicionar colunas de metadados\n",
    "        df['Órgão'] = df['CLASSE'].astype(int).map(lambda x: orgao_cargo_map.get(x, ('', ''))[0])\n",
    "        df['Cargo'] = df['CLASSE'].astype(int).map(lambda x: orgao_cargo_map.get(x, ('', ''))[1])\n",
    "\n",
    "        # Limpeza e formatação\n",
    "        df = df.drop(columns=[\"CLASSE\"])  \n",
    "        df = df.fillna('')  \n",
    "        for col in [\"ATIVO\\nSUBSÍDIO (em R$)\", \"APOSENTADO\\nSUBSÍDIO (em R$)\"]:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str).str.replace(\".\", \"\", regex=False).str.replace(\",\", \".\", regex=False)\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                all_data.append(df)\n",
    "    if all_data:  # Verifica se alguma tabela foi extraída\n",
    "        return pd.concat(all_data, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()  # Retorna um DataFrame vazio se nenhuma tabela for encontrada\n",
    "\n",
    "## Utilizando pdfplumber (conclui com sucesso mas não extrai bem os números)\n",
    "def process_table(table, cargo, data_posicao):\n",
    "    \"\"\"Processa um DataFrame, adicionando informações de cargo e data.\"\"\"\n",
    "    table['Cargo'] = cargo\n",
    "    table['Data Posição'] = data_posicao\n",
    "    return table\n",
    "\n",
    "def extract_tables_pdfplumber(file_path):\n",
    "    \"\"\"Extrai tabelas de um arquivo PDF usando pdfplumber.\"\"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        tables = []\n",
    "        for page in pdf.pages:\n",
    "            for table in page.extract_tables():\n",
    "                df = pd.DataFrame(table)\n",
    "                tables.append(df)\n",
    "    return tables\n",
    "\n",
    "def extract_remun_tables_pdfplumber(folder_path):\n",
    "    \"\"\"Extrai e consolida tabelas de remuneração de arquivos PDF na pasta.\"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    for filename in tqdm(os.listdir(folder_path), desc=\"Extraindo arquivos baixados...\"):\n",
    "        if filename.endswith('.pdf'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            tables = extract_tables_pdfplumber(file_path)\n",
    "\n",
    "            for table in tables:\n",
    "                # Extrair informações de cargo e data (adaptar conforme o formato do arquivo)\n",
    "                cargo = table.iloc[0, 0]  # Exemplo: assumindo que o cargo está na primeira célula\n",
    "                data_posicao = filename.split('_')[0]  # Exemplo: assumindo que a data está no início do nome\n",
    "\n",
    "                df = process_table(table, cargo, data_posicao)\n",
    "                all_data.append(df)\n",
    "\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "## Utilizando camelot ()\n",
    "def process_table_camelot(table, cargo, data_posicao):\n",
    "    \"\"\"Processa um DataFrame (tabela do Camelot), adicionando informações de cargo e data.\"\"\"\n",
    "    df = table.df\n",
    "    df['Cargo'] = cargo\n",
    "    df['Data Posição'] = data_posicao\n",
    "    return df\n",
    "\n",
    "def extract_tables_camelot(file_path):\n",
    "    \"\"\"Extrai tabelas de um arquivo PDF usando Camelot.\n",
    "    Parâmetros do Camelot:\n",
    "        line_scale: aumentar o valor do parâmetro line_scale. Isso pode ajudar o Camelot a detectar as linhas horizontais que separam as células com quebras de linha.\n",
    "        split_text: usar o parâmetro split_text=True. Isso fará com que o Camelot divida as células com quebras de linha em várias linhas.\n",
    "        flag_size: usar o parâmetro flag_size=True. Isso pode ajudar o Camelot a identificar células com quebras de linha que são maiores do que o tamanho médio das células.\n",
    "        strip_text: usar o parâmetro strip_text='\\n'. Isso removerá as quebras de linha do texto extraído, o que pode ser útil se as quebras de linha não forem relevantes para a sua análise.\n",
    "    \"\"\"\n",
    "    tables = camelot.read_pdf(file_path, pages='all', line_scale=40, split_text=True, flag_size=True)\n",
    "    return tables\n",
    "\n",
    "\n",
    "def split_merged_cells(table):\n",
    "    \"\"\"Divide células mescladas em um DataFrame do Camelot.\"\"\"\n",
    "    df = table.df\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.split('\\n')\n",
    "        df = df.explode(col)\n",
    "    df = df.fillna(method='ffill')\n",
    "    return df\n",
    "\n",
    "def extract_remun_tables_camelot(folder_path):\n",
    "    \"\"\"Extrai e consolida tabelas de remuneração de arquivos PDF na pasta (usando Camelot).\"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    for filename in tqdm(sorted(os.listdir(folder_path)), desc=\"Extraindo arquivos baixados...\"):\n",
    "        print(f'Acessando: {filename}')\n",
    "        if filename.endswith('.pdf'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                tables = extract_tables_camelot(file_path)\n",
    "\n",
    "                for table in tables:\n",
    "                    # Pré-processamento com PyMuPDF (fitz) para dividir células mescladas\n",
    "                    table.df = split_merged_cells(table)  \n",
    "\n",
    "                    # Extrair informações de cargo e data (adaptar conforme o formato do arquivo)\n",
    "                    cargo = table.df.iloc[0, 0]  # Corrigido para usar .iloc no DataFrame\n",
    "                    data_posicao = filename.split('_')[0]\n",
    "\n",
    "                    df = process_table_camelot(table, cargo, data_posicao)\n",
    "                    all_data.append(df)\n",
    "            except ValueError:\n",
    "                print(f\"Erro ao processar o arquivo {filename}. Pulando para o próximo.\")\n",
    "\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "def process_remuneration_data(df_remuneracao):\n",
    "    \"\"\"Processa o DataFrame para organizar as informações de remuneração.\"\"\"\n",
    "\n",
    "    # 1. Filtrar linhas relevantes (com valores numéricos)\n",
    "    df_filtered = df_remuneracao[pd.to_numeric(df_remuneracao[9], errors='coerce').notnull()].copy()\n",
    "\n",
    "    # 2. Extrair nível e parcelas (adaptar os índices conforme a estrutura do seu DataFrame)\n",
    "    df_filtered['Nível'] = df_filtered[8].astype(str).str.extract(r'(P\\d+)')\n",
    "    df_filtered['Parcela'] = df_filtered[8]\n",
    "\n",
    "    # 3. Pivotar o DataFrame\n",
    "    df_pivot = df_filtered.pivot_table(index=['Cargo', 'Nível', 'Data Posição'], columns='Parcela', values=9)\n",
    "\n",
    "    # Limpeza e formatação adicionais (opcional)\n",
    "    df_pivot = df_pivot.replace('NaN', np.nan)  # Substituir 'NaN' por valores nulos\n",
    "    df_pivot = df_pivot.applymap(lambda x: x.replace('.', '').replace(',', '.') if isinstance(x, str) else x)\n",
    "    df_pivot = df_pivot.astype(float)\n",
    "\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baixar relatórios em PDF com dados de remuneração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Página acessada com sucesso, busando links para relatórios em PDF...\n",
      "18 relatórios em PDF encontrados\n",
      "56 relatórios em PDF tipo caderno encontrados\n",
      "Realizando downloads...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb67de83c3147cb9727f7dc0729192a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtendo relatórios...:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2311303402e5431ea585c89ae773b340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtendo cadernos...:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatórios PDF extraídos e salvos em F://TabRemunRel\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.gov.br/servidor/pt-br/observatorio-de-pessoal-govbr/tabela-de-remuneracao-dos-servidores-publicos-federais-civis-e-dos-ex-territorios'\n",
    "save_folder = 'F://TabRemunRel'\n",
    "\n",
    "# Deixar comentado para evitar downloads desnecessário\n",
    "download_pdf_files(url, save_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrair sumários em cada relatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cargo_and_page(lst_strings):\n",
    "    \"\"\"Extrai o cargo e o número da página de uma lista de strings.\n",
    "\n",
    "    Args:\n",
    "        strings: Uma lista de strings no formato \"Cargo - ... - Nível ...... Página\".\n",
    "\n",
    "    Returns:\n",
    "        Um dicionário onde as chaves são os nomes dos cargos e os valores são os números das páginas.\n",
    "    \"\"\"\n",
    "\n",
    "    cargo_page_map = {}\n",
    "    for string in lst_strings:\n",
    "        match = re.search(r\"(.+?)\\s+\\.{3,}\\s+(\\d+)\", string)  # Regex para extrair cargo e página\n",
    "        if match:\n",
    "            cargo = match.group(1).strip()  # Remove espaços em branco do cargo\n",
    "            page = int(match.group(2))  # Converte o número da página para inteiro\n",
    "            cargo_page_map[cargo] = page\n",
    "    return cargo_page_map\n",
    "\n",
    "def starts_with_roman_numeral(string):\n",
    "    \"\"\"Verifica se uma string começa com um algarismo romano maiúsculo seguido de espaço, '-' ou '–' e espaço.\n",
    "\n",
    "    Args:\n",
    "        string: A string a ser verificada.\n",
    "\n",
    "    Returns:\n",
    "        True se a string começar com o padrão, False caso contrário.\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = r\"^[IVXLCDM]+\\s+[-–]\\s+\"  # Expressão regular com '-' e '–'\n",
    "    return bool(re.match(pattern, string))\n",
    "\n",
    "def extrair_sumario(folder_path, df_summary):\n",
    "    all_data = []\n",
    "    arquivos = sorted(os.listdir(folder_path))[-1:]\n",
    "    print(f'{len(arquivos)} arquivos PDF a processar...')\n",
    "    for filename in arquivos:\n",
    "        print(f'\\nProcessando {filename}...')\n",
    "        if filename.endswith('.pdf'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with pdfplumber.open(file_path) as pdf:\n",
    "\n",
    "                df_summary, li, lf, df_tables = extract_summary_and_tables(pdf)\n",
    "                # df = extract_remuneration_tables(pdf, df_summary)\n",
    "                # print(f'  {len(df.index)} linhas processadas')\n",
    "    \n",
    "    for n,i in enumerate([x for x in df_summary['Sumário']]):\n",
    "        if i=='Sumário':\n",
    "            li=n\n",
    "        elif 'INDICE....' in i:\n",
    "            lf=n\n",
    "\n",
    "    ignorar = [str(x) for x in range(0,600)]\n",
    "    lst_sumario = [x for x in df_summary['Sumário'].iloc[li:lf] if x not in ignorar]\n",
    "    lst_tipo_remun = []\n",
    "    lst_orgaos = []\n",
    "    lst_cargos = []\n",
    "    \n",
    "    for i in lst_sumario:\n",
    "        if i == 'Sumário':\n",
    "            pass\n",
    "        elif i.startswith('Elaborado'):\n",
    "            periodo = i\n",
    "        elif starts_with_roman_numeral(i):\n",
    "            lst_tipo_remun.append(i)\n",
    "        elif '....' not in i and i not in lst_tipo_remun and not i.startswith('Elaborado'):\n",
    "            lst_orgaos.append(i)\n",
    "        else:\n",
    "            lst_cargos.append(i.split('  '))\n",
    "\n",
    "    # map_cargo_page = extract_cargo_and_page(lst_cargos)\n",
    "\n",
    "    return periodo, lst_sumario, lst_tipo_remun, lst_orgaos, lst_cargos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sumário das linhas 0 a 0 total de 64440\n",
      "Total de 14 tabelas detectadas.\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'F:\\\\TabRemunRel'\n",
    "periodo, lst_sumario, lst_tipo_remun, lst_orgaos, lst_cargos = extrair_sumario(folder_path, df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01. Agência Brasileira de Inteligência - ABIN',\n",
       " '02. Agências Reguladoras - (ANA - ANAC - ANEEL - ANS - ANATEL - ANTAQ - ANTT - ANVISA - ANCINE - ANP)',\n",
       " 'ANA - Agência Nacional de Águas e Saneamento Básico',\n",
       " 'ANAC - Agência Nacional de Aviação Civil',\n",
       " 'ANCINE - Agência Nacional do Cinema',\n",
       " 'ANEEL- Agência Nacional de Energia Elétrica',\n",
       " 'ANS - Agência Nacional de Saúde Suplementar',\n",
       " 'ANP- Agência Nacional do Petróleo, Gás Natural e Biocombustíveis',\n",
       " 'ANATEL - Agência Nacional de Telecomunicações',\n",
       " 'ANTAQ - Agência Nacional de Transportes Aquaviários',\n",
       " 'ANTT - Agência Nacional de Transportes Terrestres',\n",
       " 'ANVISA - Agência Nacional de Vigilância Sanitária',\n",
       " '03. Área Jurídica',\n",
       " '04. Banco Central do Brasil',\n",
       " '05. Comissão de Valores Mobiliários - CVM',\n",
       " '06. Grupo Gestão',\n",
       " '07. Instituto de Pesquisa Econômica Aplicada - IPEA',\n",
       " '08. Ministério da Agricultura, Pecuária e Abastecimento - MAPA',\n",
       " '09. Polícia Federal',\n",
       " '10.Polícia Rodoviária',\n",
       " '11. Serviço Exterior Brasileiro',\n",
       " '12. Superintendência de Seguros Privados - SUSEP',\n",
       " '13. Agência Brasileira de Inteligência - ABIN',\n",
       " '14. Agências Reguladoras - (ANA - ANAC - ANEEL - ANS - ANATEL - ANTAQ - ANTT - ANVISA - ANCINE - ANP)',\n",
       " 'Plano Especial de Cargos da Agência Nacional de Vigilância Sanitária (ANVISA)',\n",
       " 'Plano Especial de Cargos das Agências Reguladoras (ANA - ANAC - ANEEL - ANS - ANATEL - ANTAQ - ANTT - ANCINE - ANP)',\n",
       " '15. Auditoria Federal',\n",
       " '16. Cargos Específicos',\n",
       " '17. Ciência e Tecnologia',\n",
       " '18. Comissão de Valores Mobiliários - CVM',\n",
       " '19. Departamento Nacional de Auditoria do Sistema Único de Saúde - DENASUS',\n",
       " '20. Departamento Nacional de Infraestrutura de Transportes - DNIT',\n",
       " 'Cargos de Nível Intermediário do Plano Especial de Cargos do DNIT não referidos no art. 3º-A da Lei nº 11.171/2005 (art. 3º-C da Lei nº 11.171/2005) - NI . 150',\n",
       " \"21. AGÊNCIA NACIONAL DE MINERAÇÃO - ANM (extinto DNPM item 'a' I do art.39 da Lei nº 13.575, de 2017)\",\n",
       " '22. DOCENTE',\n",
       " 'Magistério Superior',\n",
       " 'Cargo Isolado de Professor Titular-Livre do Magistério Superior',\n",
       " 'Magistério Ensino Básico, Técnico e Tecnológico',\n",
       " 'Cargo Isolado de Professor Titular-Livre do Ensino Básico, Técnico e Tecnológico',\n",
       " 'Magistério Ensino Básico Federal',\n",
       " 'Magistério Ensino Básico Federal dos Ex-Territórios',\n",
       " '23. Endemias',\n",
       " '24. Fundo Nacional de Desenvolvimento da Educação - FNDE',\n",
       " '25. Fundação Nacional do Índio - FUNAI',\n",
       " '26. Fundação Oswaldo Cruz - FIOCRUZ',\n",
       " '27. Grupo-Defesa Aérea e Controle do Tráfego Aéreo - DACTA',\n",
       " '28. Grupo P-1500',\n",
       " '29. Hospital da Forças Armadas - HFA',\n",
       " '30. IBAMA, Instituto Chico Mendes e Ministério do Meio Ambiente',\n",
       " '31. Imprensa Nacional',\n",
       " '32. Infraestrutura',\n",
       " '33. Instituto Brasileiro de Geografia e Estatística - IBGE',\n",
       " '34. Instituto Brasileiro de Turismo - EMBRATUR',\n",
       " '35. Instituto Evandro Chagas - IEC e Centro Nacional de Primatas - CENP',\n",
       " '36. Instituto Nacional da Propriedade Industrial - INPI',\n",
       " '37. Instituto de Pesquisa Econômica Aplicada - IPEA',\n",
       " '38. Instituto Nacional de Colonização e Reforma Agrária - INCRA',\n",
       " '39. Instituto Nacional de Estudos e Pesquisas Educacionais - INEP',\n",
       " '40. Instituto Nacional de Metrologia, Normalização e Qualidade Industrial - INMETRO',\n",
       " '41. Instituto Nacional do Seguro Social - INSS',\n",
       " '42. Ministério da Agricultura, Pecuária e Abastecimento - MAPA',\n",
       " '43. Plano de Classificação de Cargos - (PCC)',\n",
       " '44. Plano Especial de Cargos da Cultura',\n",
       " '45. Plano Especial de Cargos do Departamento de Polícia Federal',\n",
       " '46. Plano Especial de Cargos do Departamento de Polícia Rodoviária Federal',\n",
       " '47. Plano Especial de Cargos do Ministério da Fazenda - PECFAZ',\n",
       " '48. Superintendência da Zona Franca de Manaus - SUFRAMA',\n",
       " '49. Plano Geral de Cargos do Poder Executivo - PGPE',\n",
       " 'Cargos do PGPE',\n",
       " 'Cargos do PGPE - Servidores do PGPE lotados e em efetivo exercício na CEPLAC/MAPA',\n",
       " 'Cargos do PGPE - servidores do PGPE lotados e em efetivo exercício no INMET/MAPA',\n",
       " 'Cargos do PGPE - servidores do PGPE em exercício na SPU/ MP',\n",
       " '50. Políticas Sociais',\n",
       " '51. Previdenciária',\n",
       " '52. Previdência, Saúde e Trabalho',\n",
       " '53. Quadro de Pessoal da Advocacia-Geral da União - AGU',\n",
       " '54. Quadro de Pessoal do Ministério da Justiça',\n",
       " '55. Seguridade Social e do Trabalho',\n",
       " '56. Seguro Social',\n",
       " '57. Superintendência de Seguros Privados - SUSEP',\n",
       " '58. Superintendência Nacional de Previdência Complementar - PREVIC',\n",
       " '59. Técnico-Administrativos em Educação - PCCTAE',\n",
       " '60. Tecnologia Militar',\n",
       " '61. Tribunal Marítimo',\n",
       " '62. Cargos em Comissão e Gratificações',\n",
       " '63. Quadro em Extinção da União',\n",
       " 'Plano de Classificação de Cargos dos ex-Territórios Federais - PCC-Ext',\n",
       " 'Estrutura Remuneratória Especial de Cargos Específicos do Quadro em Extinção da União ex-Territórios Federais',\n",
       " 'Cargos: Engenheiro, Arquiteto, Economista, Estatístico e Geólogo integrantes do PCC-Ext que optaram pela Estrutura Remuneratória Especial, de que trata art. 19 da Lei nº',\n",
       " 'Carreiras de Gestão Governamental do Quadro em Extinção da União ex-Territórios Federais',\n",
       " 'Grupo Tributação, Arrecadação e Fiscalização da União do Quadro em Extinção da União ex-Territórios Federais',\n",
       " 'Carreiras de Magistério optantes do Quadro em Extinção da União ex-Territórios Federais',\n",
       " 'Policiais Civis do Quadro em Extinção da União ex-Territórios Federais',\n",
       " 'Polícia Militar e do Corpo de Bombeiros Militar do Quadro em Extinção da União ex-Territórios Federais']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_orgaos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nível Intermediário Posição: maio/2023</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATIVO APOSENTADO\\nCLASSE PADRÃO\\nSUBSÍDIO (em ...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lll 11.805,13 11.805,13\\nESPECIAL ll 11.517,20...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>FCE 2.05</td>\n",
       "      <td>FCE 3.05</td>\n",
       "      <td>FCE 4.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>FCE 2.04</td>\n",
       "      <td>FCE 3.04</td>\n",
       "      <td>FCE 4.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>FCE 2.03</td>\n",
       "      <td>FCE 3.03</td>\n",
       "      <td>FCE 4.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>FCE 2.02</td>\n",
       "      <td>FCE 3.02</td>\n",
       "      <td>FCE 4.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>FCE 2.01</td>\n",
       "      <td>FCE 3.01</td>\n",
       "      <td>FCE 4.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         1         2    \n",
       "0                                                None                 NaN  \\\n",
       "1                                                  83                 NaN   \n",
       "2              Nível Intermediário Posição: maio/2023      None       NaN   \n",
       "3   ATIVO APOSENTADO\\nCLASSE PADRÃO\\nSUBSÍDIO (em ...                 NaN   \n",
       "4   lll 11.805,13 11.805,13\\nESPECIAL ll 11.517,20...      None       NaN   \n",
       "..                                                ...       ...       ...   \n",
       "70                                           FCE 2.05  FCE 3.05  FCE 4.05   \n",
       "71                                           FCE 2.04  FCE 3.04  FCE 4.04   \n",
       "72                                           FCE 2.03  FCE 3.03  FCE 4.03   \n",
       "73                                           FCE 2.02  FCE 3.02  FCE 4.02   \n",
       "74                                           FCE 2.01  FCE 3.01  FCE 4.01   \n",
       "\n",
       "     3    4    5    6    7    8    9   ...   24   25   26   27   28   29   30   \n",
       "0   NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \\\n",
       "1   NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2   NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3   NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4   NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "70  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "71  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "72  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "73  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "74  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "     31   32   33  \n",
       "0   NaN  NaN  NaN  \n",
       "1   NaN  NaN  NaN  \n",
       "2   NaN  NaN  NaN  \n",
       "3   NaN  NaN  NaN  \n",
       "4   NaN  NaN  NaN  \n",
       "..  ...  ...  ...  \n",
       "70  NaN  NaN  NaN  \n",
       "71  NaN  NaN  NaN  \n",
       "72  NaN  NaN  NaN  \n",
       "73  NaN  NaN  NaN  \n",
       "74  NaN  NaN  NaN  \n",
       "\n",
       "[75 rows x 34 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in df_summary['Sumário']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nível Intermediário Posição: maio/2023',\n",
       " 'ATIVO APOSENTADO\\nCLASSE PADRÃO\\nSUBSÍDIO (em R$) SUBSÍDIO (em R$)',\n",
       " 'lll 11.805,13 11.805,13\\nESPECIAL ll 11.517,20 11.517,20\\nl 11.236,30 11.236,30\\nVl 10.701,25 10.701,25\\nV 10.440,24 10.440,24\\nlV 10.185,59 10.185,59\\nPRIMEIRA\\nlll 9.937,17 9.937,17\\nll 9.694,79 9.694,79\\nl 9.458,33 9.458,33\\nVl 9.007,95 9.007,95\\nV 8.788,22 8.788,22\\nlV 8.573,87 8.573,87\\nSEGUNDA\\nlll 8.364,77 8.364,77\\nll 8.160,75 8.160,75\\nl 7.961,72 7.961,72\\nV 7.582,57 7.582,57\\nlV 7.397,64 7.397,64\\nTERCEIRA lll 7.217,21 7.217,21\\nll 7.041,18 7.041,18\\nl 6.869,43 6.869,43',\n",
       " 'CLASSES DE CAPACITAÇÃO I',\n",
       " 'ATIVO e\\nAPOSENTA\\nVencimento DO ATIVO e APOSENTADO\\nBásico (VB) SEM IQ - COM IQ - TOTAL (em R$)\\nTOTAL\\n(em R$)\\nÁREA DE CONHECIMENTO COM RELAÇÃO DIRETA ÁREA DE CONHECIMENTO COM RELAÇÃO INDIRETA\\n10% 15% 20% 25% 30% 52% 75% 10% 15% 20% 35% 50%\\nA B=(A) C=A+ * D=A+* E=A+* F=A+* G=A+* H=A+* I=A+* J=A+* K=A+* L=A+ * M=A+* N=A+*',\n",
       " 'CLASSES DE CAPACITAÇÃO III',\n",
       " 'ATIVO e\\nAPOSENTA\\nVencimento DO ATIVO e APOSENTADO\\nBásico (VB) SEM IQ - COM IQ - TOTAL (em R$)\\nTOTAL\\n(em R$)\\nÁREA DE CONHECIMENTO COM RELAÇÃO DIRETA ÁREA DE CONHECIMENTO COM RELAÇÃO INDIRETA\\n10% 15% 20% 25% 30% 52% 75% 10% 15% 20% 35% 50%\\nA B=(A) C=A+ * D=A+* E=A+* F=A+* G=A+* H=A+* I=A+* J=A+* K=A+* L=A+ * M=A+* N=A+*',\n",
       " 'P33',\n",
       " 'P34',\n",
       " 'P35',\n",
       " 'P36',\n",
       " 'P37',\n",
       " 'P38',\n",
       " 'P39',\n",
       " 'P40',\n",
       " 'P41',\n",
       " 'P42',\n",
       " 'P43',\n",
       " 'P44',\n",
       " 'P45',\n",
       " 'P46',\n",
       " 'P47',\n",
       " 'P48',\n",
       " 'CATEGORIA\\nASSESSORAMENTO - Código\\n2',\n",
       " 'FCE 2.17',\n",
       " 'FCE 2.16',\n",
       " 'FCE 2.15',\n",
       " 'FCE 2.14',\n",
       " 'FCE 2.13',\n",
       " 'FCE 2.12',\n",
       " 'FCE 2.11',\n",
       " 'FCE 2.10',\n",
       " 'FCE 2.09',\n",
       " 'FCE 2.08',\n",
       " 'FCE 2.07',\n",
       " 'FCE 2.06',\n",
       " 'FCE 2.05',\n",
       " 'FCE 2.04',\n",
       " 'FCE 2.03',\n",
       " 'FCE 2.02',\n",
       " 'FCE 2.01']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in df_tables[0].iloc[2:] if x != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_table(df_table):\n",
    "    ignore = ['-','',None]\n",
    "    for i in [x for x in df_table.iloc[2:] if (x not in ignore and type(x) is not float)]:\n",
    "        print(f'{i}')\n",
    "    print('-'*125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nível Intermediário Posição: maio/2023</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATIVO APOSENTADO\\nCLASSE PADRÃO\\nSUBSÍDIO (em ...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lll 11.805,13 11.805,13\\nESPECIAL ll 11.517,20...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>FCE 2.05</td>\n",
       "      <td>FCE 3.05</td>\n",
       "      <td>FCE 4.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>FCE 2.04</td>\n",
       "      <td>FCE 3.04</td>\n",
       "      <td>FCE 4.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>FCE 2.03</td>\n",
       "      <td>FCE 3.03</td>\n",
       "      <td>FCE 4.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>FCE 2.02</td>\n",
       "      <td>FCE 3.02</td>\n",
       "      <td>FCE 4.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>FCE 2.01</td>\n",
       "      <td>FCE 3.01</td>\n",
       "      <td>FCE 4.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         1         2    \n",
       "0                                                None                 NaN  \\\n",
       "1                                                  83                 NaN   \n",
       "2              Nível Intermediário Posição: maio/2023      None       NaN   \n",
       "3   ATIVO APOSENTADO\\nCLASSE PADRÃO\\nSUBSÍDIO (em ...                 NaN   \n",
       "4   lll 11.805,13 11.805,13\\nESPECIAL ll 11.517,20...      None       NaN   \n",
       "..                                                ...       ...       ...   \n",
       "70                                           FCE 2.05  FCE 3.05  FCE 4.05   \n",
       "71                                           FCE 2.04  FCE 3.04  FCE 4.04   \n",
       "72                                           FCE 2.03  FCE 3.03  FCE 4.03   \n",
       "73                                           FCE 2.02  FCE 3.02  FCE 4.02   \n",
       "74                                           FCE 2.01  FCE 3.01  FCE 4.01   \n",
       "\n",
       "     3    4    5    6    7    8    9   ...   24   25   26   27   28   29   30   \n",
       "0   NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \\\n",
       "1   NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2   NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3   NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4   NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "70  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "71  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "72  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "73  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "74  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "     31   32   33  \n",
       "0   NaN  NaN  NaN  \n",
       "1   NaN  NaN  NaN  \n",
       "2   NaN  NaN  NaN  \n",
       "3   NaN  NaN  NaN  \n",
       "4   NaN  NaN  NaN  \n",
       "..  ...  ...  ...  \n",
       "70  NaN  NaN  NaN  \n",
       "71  NaN  NaN  NaN  \n",
       "72  NaN  NaN  NaN  \n",
       "73  NaN  NaN  NaN  \n",
       "74  NaN  NaN  NaN  \n",
       "\n",
       "[75 rows x 34 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nível Intermediário Posição: maio/2023\n",
      "ATIVO APOSENTADO\n",
      "CLASSE PADRÃO\n",
      "SUBSÍDIO (em R$) SUBSÍDIO (em R$)\n",
      "lll 11.805,13 11.805,13\n",
      "ESPECIAL ll 11.517,20 11.517,20\n",
      "l 11.236,30 11.236,30\n",
      "Vl 10.701,25 10.701,25\n",
      "V 10.440,24 10.440,24\n",
      "lV 10.185,59 10.185,59\n",
      "PRIMEIRA\n",
      "lll 9.937,17 9.937,17\n",
      "ll 9.694,79 9.694,79\n",
      "l 9.458,33 9.458,33\n",
      "Vl 9.007,95 9.007,95\n",
      "V 8.788,22 8.788,22\n",
      "lV 8.573,87 8.573,87\n",
      "SEGUNDA\n",
      "lll 8.364,77 8.364,77\n",
      "ll 8.160,75 8.160,75\n",
      "l 7.961,72 7.961,72\n",
      "V 7.582,57 7.582,57\n",
      "lV 7.397,64 7.397,64\n",
      "TERCEIRA lll 7.217,21 7.217,21\n",
      "ll 7.041,18 7.041,18\n",
      "l 6.869,43 6.869,43\n",
      "CLASSES DE CAPACITAÇÃO I\n",
      "ATIVO e\n",
      "APOSENTA\n",
      "Vencimento DO ATIVO e APOSENTADO\n",
      "Básico (VB) SEM IQ - COM IQ - TOTAL (em R$)\n",
      "TOTAL\n",
      "(em R$)\n",
      "ÁREA DE CONHECIMENTO COM RELAÇÃO DIRETA ÁREA DE CONHECIMENTO COM RELAÇÃO INDIRETA\n",
      "10% 15% 20% 25% 30% 52% 75% 10% 15% 20% 35% 50%\n",
      "A B=(A) C=A+ * D=A+* E=A+* F=A+* G=A+* H=A+* I=A+* J=A+* K=A+* L=A+ * M=A+* N=A+*\n",
      "CLASSES DE CAPACITAÇÃO III\n",
      "ATIVO e\n",
      "APOSENTA\n",
      "Vencimento DO ATIVO e APOSENTADO\n",
      "Básico (VB) SEM IQ - COM IQ - TOTAL (em R$)\n",
      "TOTAL\n",
      "(em R$)\n",
      "ÁREA DE CONHECIMENTO COM RELAÇÃO DIRETA ÁREA DE CONHECIMENTO COM RELAÇÃO INDIRETA\n",
      "10% 15% 20% 25% 30% 52% 75% 10% 15% 20% 35% 50%\n",
      "A B=(A) C=A+ * D=A+* E=A+* F=A+* G=A+* H=A+* I=A+* J=A+* K=A+* L=A+ * M=A+* N=A+*\n",
      "P33\n",
      "P34\n",
      "P35\n",
      "P36\n",
      "P37\n",
      "P38\n",
      "P39\n",
      "P40\n",
      "P41\n",
      "P42\n",
      "P43\n",
      "P44\n",
      "P45\n",
      "P46\n",
      "P47\n",
      "P48\n",
      "CATEGORIA\n",
      "ASSESSORAMENTO - Código\n",
      "2\n",
      "FCE 2.17\n",
      "FCE 2.16\n",
      "FCE 2.15\n",
      "FCE 2.14\n",
      "FCE 2.13\n",
      "FCE 2.12\n",
      "FCE 2.11\n",
      "FCE 2.10\n",
      "FCE 2.09\n",
      "FCE 2.08\n",
      "FCE 2.07\n",
      "FCE 2.06\n",
      "FCE 2.05\n",
      "FCE 2.04\n",
      "FCE 2.03\n",
      "FCE 2.02\n",
      "FCE 2.01\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "CLASSES DE CAPACITAÇÃO II\n",
      "ATIVO e\n",
      "APOSENTA\n",
      "Vencimento DO ATIVO e APOSENTADO\n",
      "Básico (VB) SEM IQ - COM IQ - TOTAL (em R$)\n",
      "TOTAL\n",
      "(em R$)\n",
      "ÁREA DE CONHECIMENTO COM RELAÇÃO DIRETA ÁREA DE CONHECIMENTO COM RELAÇÃO INDIRETA\n",
      "10% 15% 20% 25% 30% 52% 75% 10% 15% 20% 35% 50%\n",
      "A B=(A) C=A+ * D=A+* E=A+* F=A+* G=A+* H=A+* I=A+* J=A+* K=A+* L=A+ * M=A+* N=A+*\n",
      "CLASSES DE CAPACITAÇÃO IV\n",
      "ATIVO e\n",
      "APOSENTA\n",
      "Vencimento DO ATIVO e APOSENTADO\n",
      "Básico (VB) SEM IQ - COM IQ - TOTAL (em R$)\n",
      "TOTAL\n",
      "(em R$)\n",
      "ÁREA DE CONHECIMENTO COM RELAÇÃO DIRETA ÁREA DE CONHECIMENTO COM RELAÇÃO INDIRETA\n",
      "10% 15% 20% 25% 30% 52% 75% 10% 15% 20% 35% 50%\n",
      "A B=(A) C=A+ * D=A+* E=A+* F=A+* G=A+* H=A+* I=A+* J=A+* K=A+* L=A+ * M=A+* N=A+*\n",
      "9.838,59\n",
      "10.222,29\n",
      "10.620,97\n",
      "11.035,18\n",
      "11.465,56\n",
      "11.912,71\n",
      "12.377,31\n",
      "12.860,03\n",
      "13.361,57\n",
      "13.882,67\n",
      "14.424,09\n",
      "14.986,63\n",
      "15.571,11\n",
      "16.178,38\n",
      "16.809,34\n",
      "17.464,91\n",
      "CATEGORIA\n",
      "DIREÇÃO DE\n",
      "PROJETOS - Código\n",
      "3\n",
      "FCE 3.16\n",
      "FCE 3.15\n",
      "FCE 3.14\n",
      "FCE 3.13\n",
      "FCE 3.12\n",
      "FCE 3.11\n",
      "FCE 3.10\n",
      "FCE 3.09\n",
      "FCE 3.08\n",
      "FCE 3.07\n",
      "FCE 3.06\n",
      "FCE 3.05\n",
      "FCE 3.04\n",
      "FCE 3.03\n",
      "FCE 3.02\n",
      "FCE 3.01\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "9.838,59\n",
      "10.222,29\n",
      "10.620,97\n",
      "11.035,18\n",
      "11.465,56\n",
      "11.912,71\n",
      "12.377,31\n",
      "12.860,03\n",
      "13.361,57\n",
      "13.882,67\n",
      "14.424,09\n",
      "14.986,63\n",
      "15.571,11\n",
      "16.178,38\n",
      "16.809,34\n",
      "17.464,91\n",
      "CATEGORIA\n",
      "ASSESSORAMENT\n",
      "O TÉCNICO\n",
      "ESPECIALIZADO -\n",
      "Código 4\n",
      "FCE 4.13\n",
      "FCE 4.12\n",
      "FCE 4.11\n",
      "FCE 4.10\n",
      "FCE 4.09\n",
      "FCE 4.08\n",
      "FCE 4.07\n",
      "FCE 4.06\n",
      "FCE 4.05\n",
      "FCE 4.04\n",
      "FCE 4.03\n",
      "FCE 4.02\n",
      "FCE 4.01\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "10.822,45\n",
      "11.244,52\n",
      "11.683,07\n",
      "12.138,70\n",
      "12.612,12\n",
      "13.103,98\n",
      "13.615,04\n",
      "14.146,03\n",
      "14.697,73\n",
      "15.270,94\n",
      "15.866,50\n",
      "16.485,29\n",
      "17.128,22\n",
      "17.796,22\n",
      "18.490,27\n",
      "19.211,40\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "11.314,38\n",
      "11.755,63\n",
      "12.214,12\n",
      "12.690,46\n",
      "13.185,39\n",
      "13.699,62\n",
      "14.233,91\n",
      "14.789,03\n",
      "15.365,81\n",
      "15.965,07\n",
      "16.587,70\n",
      "17.234,62\n",
      "17.906,78\n",
      "18.605,14\n",
      "19.330,74\n",
      "20.084,65\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "11.806,31\n",
      "12.266,75\n",
      "12.745,16\n",
      "13.242,22\n",
      "13.758,67\n",
      "14.295,25\n",
      "14.852,77\n",
      "15.432,04\n",
      "16.033,88\n",
      "16.659,20\n",
      "17.308,91\n",
      "17.983,96\n",
      "18.685,33\n",
      "19.414,06\n",
      "20.171,21\n",
      "20.957,89\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "12.298,24\n",
      "12.777,86\n",
      "13.276,21\n",
      "13.793,98\n",
      "14.331,95\n",
      "14.890,89\n",
      "15.471,64\n",
      "16.075,04\n",
      "16.701,96\n",
      "17.353,34\n",
      "18.030,11\n",
      "18.733,29\n",
      "19.463,89\n",
      "20.222,98\n",
      "21.011,68\n",
      "21.831,14\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "12.790,17\n",
      "13.288,98\n",
      "13.807,26\n",
      "14.345,73\n",
      "14.905,23\n",
      "15.486,52\n",
      "16.090,50\n",
      "16.718,04\n",
      "17.370,04\n",
      "18.047,47\n",
      "18.751,32\n",
      "19.482,62\n",
      "20.242,44\n",
      "21.031,89\n",
      "21.852,14\n",
      "22.704,38\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "14.954,66\n",
      "15.537,88\n",
      "16.143,87\n",
      "16.773,47\n",
      "17.427,65\n",
      "18.107,32\n",
      "18.813,51\n",
      "19.547,25\n",
      "20.309,59\n",
      "21.101,66\n",
      "21.924,62\n",
      "22.779,68\n",
      "23.668,09\n",
      "24.591,14\n",
      "25.550,20\n",
      "26.546,66\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "17.217,53\n",
      "17.889,01\n",
      "18.586,70\n",
      "19.311,57\n",
      "20.064,73\n",
      "20.847,24\n",
      "21.660,29\n",
      "22.505,05\n",
      "23.382,75\n",
      "24.294,67\n",
      "25.242,16\n",
      "26.226,60\n",
      "27.249,44\n",
      "28.312,17\n",
      "29.416,35\n",
      "30.563,59\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "10.822,45\n",
      "11.244,52\n",
      "11.683,07\n",
      "12.138,70\n",
      "12.612,12\n",
      "13.103,98\n",
      "13.615,04\n",
      "14.146,03\n",
      "14.697,73\n",
      "15.270,94\n",
      "15.866,50\n",
      "16.485,29\n",
      "17.128,22\n",
      "17.796,22\n",
      "18.490,27\n",
      "19.211,40\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "11.314,38\n",
      "11.755,63\n",
      "12.214,12\n",
      "12.690,46\n",
      "13.185,39\n",
      "13.699,62\n",
      "14.233,91\n",
      "14.789,03\n",
      "15.365,81\n",
      "15.965,07\n",
      "16.587,70\n",
      "17.234,62\n",
      "17.906,78\n",
      "18.605,14\n",
      "19.330,74\n",
      "20.084,65\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "11.806,31\n",
      "12.266,75\n",
      "12.745,16\n",
      "13.242,22\n",
      "13.758,67\n",
      "14.295,25\n",
      "14.852,77\n",
      "15.432,04\n",
      "16.033,88\n",
      "16.659,20\n",
      "17.308,91\n",
      "17.983,96\n",
      "18.685,33\n",
      "19.414,06\n",
      "20.171,21\n",
      "20.957,89\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "13.282,10\n",
      "13.800,09\n",
      "14.338,31\n",
      "14.897,49\n",
      "15.478,51\n",
      "16.082,16\n",
      "16.709,37\n",
      "17.361,04\n",
      "18.038,12\n",
      "18.741,60\n",
      "19.472,52\n",
      "20.231,95\n",
      "21.021,00\n",
      "21.840,81\n",
      "22.692,61\n",
      "23.577,63\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "14.757,89\n",
      "15.333,44\n",
      "15.931,46\n",
      "16.552,77\n",
      "17.198,34\n",
      "17.869,07\n",
      "18.565,97\n",
      "19.290,05\n",
      "20.042,36\n",
      "20.824,01\n",
      "21.636,14\n",
      "22.479,95\n",
      "23.356,67\n",
      "24.267,57\n",
      "25.214,01\n",
      "26.197,37\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "P34\n",
      "P35\n",
      "P36\n",
      "P37\n",
      "P38\n",
      "P39\n",
      "P40\n",
      "P41\n",
      "P42\n",
      "P43\n",
      "P44\n",
      "P45\n",
      "P46\n",
      "P47\n",
      "P48\n",
      "P49\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "10.222,29\n",
      "10.620,97\n",
      "11.035,18\n",
      "11.465,56\n",
      "11.912,71\n",
      "12.377,31\n",
      "12.860,03\n",
      "13.361,57\n",
      "13.882,67\n",
      "14.424,09\n",
      "14.986,63\n",
      "15.571,11\n",
      "16.178,38\n",
      "16.809,34\n",
      "17.464,91\n",
      "18.146,04\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "10.222,29\n",
      "10.620,97\n",
      "11.035,18\n",
      "11.465,56\n",
      "11.912,71\n",
      "12.377,31\n",
      "12.860,03\n",
      "13.361,57\n",
      "13.882,67\n",
      "14.424,09\n",
      "14.986,63\n",
      "15.571,11\n",
      "16.178,38\n",
      "16.809,34\n",
      "17.464,91\n",
      "18.146,04\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "11.244,52\n",
      "11.683,07\n",
      "12.138,70\n",
      "12.612,12\n",
      "13.103,98\n",
      "13.615,04\n",
      "14.146,03\n",
      "14.697,73\n",
      "15.270,94\n",
      "15.866,50\n",
      "16.485,29\n",
      "17.128,22\n",
      "17.796,22\n",
      "18.490,27\n",
      "19.211,40\n",
      "19.960,64\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "11.755,63\n",
      "12.214,12\n",
      "12.690,46\n",
      "13.185,39\n",
      "13.699,62\n",
      "14.233,91\n",
      "14.789,03\n",
      "15.365,81\n",
      "15.965,07\n",
      "16.587,70\n",
      "17.234,62\n",
      "17.906,78\n",
      "18.605,14\n",
      "19.330,74\n",
      "20.084,65\n",
      "20.867,95\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "12.266,75\n",
      "12.745,16\n",
      "13.242,22\n",
      "13.758,67\n",
      "14.295,25\n",
      "14.852,77\n",
      "15.432,04\n",
      "16.033,88\n",
      "16.659,20\n",
      "17.308,91\n",
      "17.983,96\n",
      "18.685,33\n",
      "19.414,06\n",
      "20.171,21\n",
      "20.957,89\n",
      "21.775,25\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "12.777,86\n",
      "13.276,21\n",
      "13.793,98\n",
      "14.331,95\n",
      "14.890,89\n",
      "15.471,64\n",
      "16.075,04\n",
      "16.701,96\n",
      "17.353,34\n",
      "18.030,11\n",
      "18.733,29\n",
      "19.463,89\n",
      "20.222,98\n",
      "21.011,68\n",
      "21.831,14\n",
      "22.682,55\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "13.288,98\n",
      "13.807,26\n",
      "14.345,73\n",
      "14.905,23\n",
      "15.486,52\n",
      "16.090,50\n",
      "16.718,04\n",
      "17.370,04\n",
      "18.047,47\n",
      "18.751,32\n",
      "19.482,62\n",
      "20.242,44\n",
      "21.031,89\n",
      "21.852,14\n",
      "22.704,38\n",
      "23.589,85\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "15.537,88\n",
      "16.143,87\n",
      "16.773,47\n",
      "17.427,65\n",
      "18.107,32\n",
      "18.813,51\n",
      "19.547,25\n",
      "20.309,59\n",
      "21.101,66\n",
      "21.924,62\n",
      "22.779,68\n",
      "23.668,09\n",
      "24.591,14\n",
      "25.550,20\n",
      "26.546,66\n",
      "27.581,98\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "17.889,01\n",
      "18.586,70\n",
      "19.311,57\n",
      "20.064,73\n",
      "20.847,24\n",
      "21.660,29\n",
      "22.505,05\n",
      "23.382,75\n",
      "24.294,67\n",
      "25.242,16\n",
      "26.226,60\n",
      "27.249,44\n",
      "28.312,17\n",
      "29.416,35\n",
      "30.563,59\n",
      "31.755,57\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "11.244,52\n",
      "11.683,07\n",
      "12.138,70\n",
      "12.612,12\n",
      "13.103,98\n",
      "13.615,04\n",
      "14.146,03\n",
      "14.697,73\n",
      "15.270,94\n",
      "15.866,50\n",
      "16.485,29\n",
      "17.128,22\n",
      "17.796,22\n",
      "18.490,27\n",
      "19.211,40\n",
      "19.960,64\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "11.755,63\n",
      "12.214,12\n",
      "12.690,46\n",
      "13.185,39\n",
      "13.699,62\n",
      "14.233,91\n",
      "14.789,03\n",
      "15.365,81\n",
      "15.965,07\n",
      "16.587,70\n",
      "17.234,62\n",
      "17.906,78\n",
      "18.605,14\n",
      "19.330,74\n",
      "20.084,65\n",
      "20.867,95\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "12.266,75\n",
      "12.745,16\n",
      "13.242,22\n",
      "13.758,67\n",
      "14.295,25\n",
      "14.852,77\n",
      "15.432,04\n",
      "16.033,88\n",
      "16.659,20\n",
      "17.308,91\n",
      "17.983,96\n",
      "18.685,33\n",
      "19.414,06\n",
      "20.171,21\n",
      "20.957,89\n",
      "21.775,25\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "13.800,09\n",
      "14.338,31\n",
      "14.897,49\n",
      "15.478,51\n",
      "16.082,16\n",
      "16.709,37\n",
      "17.361,04\n",
      "18.038,12\n",
      "18.741,60\n",
      "19.472,52\n",
      "20.231,95\n",
      "21.021,00\n",
      "21.840,81\n",
      "22.692,61\n",
      "23.577,63\n",
      "24.497,15\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "15.333,44\n",
      "15.931,46\n",
      "16.552,77\n",
      "17.198,34\n",
      "17.869,07\n",
      "18.565,97\n",
      "19.290,05\n",
      "20.042,36\n",
      "20.824,01\n",
      "21.636,14\n",
      "22.479,95\n",
      "23.356,67\n",
      "24.267,57\n",
      "25.214,01\n",
      "26.197,37\n",
      "27.219,06\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,series in enumerate(df_tables):\n",
    "    extract_data_table(df_tables[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLASSES DE CAPACITAÇÃO II\\nATIVO e\\nAPOSENTA\\nVencimento DO ATIVO e APOSENTADO\\nBásico (VB) SEM IQ - COM IQ - TOTAL (em R$)\\nTOTAL\\n(em R$)\\nÁREA DE CONHECIMENTO COM RELAÇÃO DIRETA ÁREA DE CONHECIMENTO COM RELAÇÃO INDIRETA\\n10% 15% 20% 25% 30% 52% 75% 10% 15% 20% 35% 50%\\nA B=(A) C=A+ * D=A+* E=A+* F=A+* G=A+* H=A+* I=A+* J=A+* K=A+* L=A+ * M=A+* N=A+*',\n",
       " 'CLASSES DE CAPACITAÇÃO IV\\nATIVO e\\nAPOSENTA\\nVencimento DO ATIVO e APOSENTADO\\nBásico (VB) SEM IQ - COM IQ - TOTAL (em R$)\\nTOTAL\\n(em R$)\\nÁREA DE CONHECIMENTO COM RELAÇÃO DIRETA ÁREA DE CONHECIMENTO COM RELAÇÃO INDIRETA\\n10% 15% 20% 25% 30% 52% 75% 10% 15% 20% 35% 50%\\nA B=(A) C=A+ * D=A+* E=A+* F=A+* G=A+* H=A+* I=A+* J=A+* K=A+* L=A+ * M=A+* N=A+*',\n",
       " '9.838,59',\n",
       " '10.222,29',\n",
       " '10.620,97',\n",
       " '11.035,18',\n",
       " '11.465,56',\n",
       " '11.912,71',\n",
       " '12.377,31',\n",
       " '12.860,03',\n",
       " '13.361,57',\n",
       " '13.882,67',\n",
       " '14.424,09',\n",
       " '14.986,63',\n",
       " '15.571,11',\n",
       " '16.178,38',\n",
       " '16.809,34',\n",
       " '17.464,91',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 'CATEGORIA\\nDIREÇÃO DE\\nPROJETOS - Código\\n3',\n",
       " '-',\n",
       " 'FCE 3.16',\n",
       " 'FCE 3.15',\n",
       " 'FCE 3.14',\n",
       " 'FCE 3.13',\n",
       " 'FCE 3.12',\n",
       " 'FCE 3.11',\n",
       " 'FCE 3.10',\n",
       " 'FCE 3.09',\n",
       " 'FCE 3.08',\n",
       " 'FCE 3.07',\n",
       " 'FCE 3.06',\n",
       " 'FCE 3.05',\n",
       " 'FCE 3.04',\n",
       " 'FCE 3.03',\n",
       " 'FCE 3.02',\n",
       " 'FCE 3.01']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "[x for x in df_tables[1].iloc[2:] if (x != '' and x is not None and x != float)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sumário</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5411</th>\n",
       "      <td>Médico Cirurgião da Carreira da Previdência, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>Médico Cirurgião da Carreira da Previdência, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5413</th>\n",
       "      <td>Médico da Área Médica do HFA - 20 h - NS 256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>Médico da Área Médica do HFA - 40 h - NS 256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>Médico da Carreira da Previdência, da Saúde e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>Médico da Carreira da Previdência, da Saúde e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>Médico da Carreira da Seguridade Social e do T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418</th>\n",
       "      <td>Médico da Carreira da Seguridade Social e do T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>Médico da Carreira do Seguro Social de que tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5420</th>\n",
       "      <td>Médico da Carreira do Seguro Social de que tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>Médico do Plano Especial de Cargos das Agência...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>Médico do Plano Especial de Cargos das Agência...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>Médico do Plano de Classificação de Cargos-PCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>Médico do Plano de Classificação de Cargos-PCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>Médico do Plano de Carreiras do IBGE de que tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>Médico do Plano de Carreiras do IBGE de que tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>Médico de Sáude Pública da Carreira da Previdê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>Médico de Sáude Pública da Carreira da Previdê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>Médico de Saúde Pública Carreira da Seguridade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>Médico de Saúde Pública Carreira da Seguridade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>Médico de Saúde Pública do PGPE de que trata a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>Médico de Saúde Pública do PGPE de que trata a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>Médico do Plano de Carreira e Cargos do IPEA, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>Médico do PGPE de que trata a Lei nº 11.357/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>Médico do PGPE de que trata a Lei nº 11.357/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5436</th>\n",
       "      <td>Médico do Plano de Carreira dos Cargos de Refo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5437</th>\n",
       "      <td>Médico do Plano de Carreira dos Cargos de Refo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5438</th>\n",
       "      <td>Médico do Plano de Carreira dos Cargos Técnico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5439</th>\n",
       "      <td>Médico do Plano de Carreira dos Cargos Técnico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>Médico do Plano de Carreiras e Cargos de Ciênc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5441</th>\n",
       "      <td>Médico do Plano de Carreiras e Cargos de Ciênc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5442</th>\n",
       "      <td>Médico do Plano de Carreiras e Cargos de Pesqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>Médico do Plano de Carreiras e Cargos de Pesqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5444</th>\n",
       "      <td>Médico do Plano Especial de Cargos do Ministér...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5445</th>\n",
       "      <td>Médico do Plano Especial de Cargos do Ministér...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5446</th>\n",
       "      <td>Médico do Plano Especial de Cargos da SUFRAMA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447</th>\n",
       "      <td>Médico do Plano Especial de Cargos da SUFRAMA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>Médico do Plano Especial de Cargos de que trat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5449</th>\n",
       "      <td>Médico do Plano Especial de Cargos de que trat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5450</th>\n",
       "      <td>Médico do Plano Especial de Cargos do Departam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5451</th>\n",
       "      <td>Médico do Plano Especial de Cargos do Departam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>Médico do Plano Especial de Cargos do Departam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5453</th>\n",
       "      <td>Médico do Plano Especial de Cargos do Departam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5454</th>\n",
       "      <td>Médico do Plano Especial de Cargos do DNIT, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5455</th>\n",
       "      <td>Médico do Plano Especial de Cargos do DNIT, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5456</th>\n",
       "      <td>Médico do Quadro de Pessoal da Advocacia-Geral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5457</th>\n",
       "      <td>Médico do Quadro de Pessoal da Advocacia-Geral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458</th>\n",
       "      <td>Médico do Quadro de Pessoal da FUNAI de que tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5459</th>\n",
       "      <td>Médico do Quadro de Pessoal da FUNAI de que tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5460</th>\n",
       "      <td>Médico do Quadro de Pessoal da Imprensa Nacion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>Médico do Quadro de Pessoal da Imprensa Nacion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5462</th>\n",
       "      <td>Médico integrantes do Quadro de Pessoal do INS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5463</th>\n",
       "      <td>Médico integrantes do Quadro de Pessoal do INS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>Médico do Trabalho da Carreira da Previdência,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>Médico do Trabalho da Carreira da Previdência,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>Médico do Trabalho Carreira da Seguridade Soci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5467</th>\n",
       "      <td>Médico do Trabalho Carreira da Seguridade Soci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>Médico do Trabalho do Plano de Classificação d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5469</th>\n",
       "      <td>Médico do Trabalho do Plano de Classificação d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>Médico do Trabalho do PGPE de que trata a Lei ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sumário\n",
       "5411  Médico Cirurgião da Carreira da Previdência, d...\n",
       "5412  Médico Cirurgião da Carreira da Previdência, d...\n",
       "5413       Médico da Área Médica do HFA - 20 h - NS 256\n",
       "5414       Médico da Área Médica do HFA - 40 h - NS 256\n",
       "5415  Médico da Carreira da Previdência, da Saúde e ...\n",
       "5416  Médico da Carreira da Previdência, da Saúde e ...\n",
       "5417  Médico da Carreira da Seguridade Social e do T...\n",
       "5418  Médico da Carreira da Seguridade Social e do T...\n",
       "5419  Médico da Carreira do Seguro Social de que tra...\n",
       "5420  Médico da Carreira do Seguro Social de que tra...\n",
       "5421  Médico do Plano Especial de Cargos das Agência...\n",
       "5422  Médico do Plano Especial de Cargos das Agência...\n",
       "5423  Médico do Plano de Classificação de Cargos-PCC...\n",
       "5424  Médico do Plano de Classificação de Cargos-PCC...\n",
       "5425  Médico do Plano de Carreiras do IBGE de que tr...\n",
       "5426  Médico do Plano de Carreiras do IBGE de que tr...\n",
       "5427  Médico de Sáude Pública da Carreira da Previdê...\n",
       "5428  Médico de Sáude Pública da Carreira da Previdê...\n",
       "5429  Médico de Saúde Pública Carreira da Seguridade...\n",
       "5430  Médico de Saúde Pública Carreira da Seguridade...\n",
       "5431  Médico de Saúde Pública do PGPE de que trata a...\n",
       "5432  Médico de Saúde Pública do PGPE de que trata a...\n",
       "5433  Médico do Plano de Carreira e Cargos do IPEA, ...\n",
       "5434  Médico do PGPE de que trata a Lei nº 11.357/20...\n",
       "5435  Médico do PGPE de que trata a Lei nº 11.357/20...\n",
       "5436  Médico do Plano de Carreira dos Cargos de Refo...\n",
       "5437  Médico do Plano de Carreira dos Cargos de Refo...\n",
       "5438  Médico do Plano de Carreira dos Cargos Técnico...\n",
       "5439  Médico do Plano de Carreira dos Cargos Técnico...\n",
       "5440  Médico do Plano de Carreiras e Cargos de Ciênc...\n",
       "5441  Médico do Plano de Carreiras e Cargos de Ciênc...\n",
       "5442  Médico do Plano de Carreiras e Cargos de Pesqu...\n",
       "5443  Médico do Plano de Carreiras e Cargos de Pesqu...\n",
       "5444  Médico do Plano Especial de Cargos do Ministér...\n",
       "5445  Médico do Plano Especial de Cargos do Ministér...\n",
       "5446  Médico do Plano Especial de Cargos da SUFRAMA ...\n",
       "5447  Médico do Plano Especial de Cargos da SUFRAMA ...\n",
       "5448  Médico do Plano Especial de Cargos de que trat...\n",
       "5449  Médico do Plano Especial de Cargos de que trat...\n",
       "5450  Médico do Plano Especial de Cargos do Departam...\n",
       "5451  Médico do Plano Especial de Cargos do Departam...\n",
       "5452  Médico do Plano Especial de Cargos do Departam...\n",
       "5453  Médico do Plano Especial de Cargos do Departam...\n",
       "5454  Médico do Plano Especial de Cargos do DNIT, de...\n",
       "5455  Médico do Plano Especial de Cargos do DNIT, de...\n",
       "5456  Médico do Quadro de Pessoal da Advocacia-Geral...\n",
       "5457  Médico do Quadro de Pessoal da Advocacia-Geral...\n",
       "5458  Médico do Quadro de Pessoal da FUNAI de que tr...\n",
       "5459  Médico do Quadro de Pessoal da FUNAI de que tr...\n",
       "5460  Médico do Quadro de Pessoal da Imprensa Nacion...\n",
       "5461  Médico do Quadro de Pessoal da Imprensa Nacion...\n",
       "5462  Médico integrantes do Quadro de Pessoal do INS...\n",
       "5463  Médico integrantes do Quadro de Pessoal do INS...\n",
       "5464  Médico do Trabalho da Carreira da Previdência,...\n",
       "5465  Médico do Trabalho da Carreira da Previdência,...\n",
       "5466  Médico do Trabalho Carreira da Seguridade Soci...\n",
       "5467  Médico do Trabalho Carreira da Seguridade Soci...\n",
       "5468  Médico do Trabalho do Plano de Classificação d...\n",
       "5469  Médico do Trabalho do Plano de Classificação d...\n",
       "5470  Médico do Trabalho do PGPE de que trata a Lei ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary[-180:-120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>P Poossiçiçããoo: :e essssaa i ninfoforrmmaaççã...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0                                                  1 2\n",
       "0    P Poossiçiçããoo: :e essssaa i ninfoforrmmaaççã...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATIVO APOSENTADO\\nSUBSÍDIO (em R$) SUBSÍDIO (e...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>27.369,67 27.369,67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>26.319,29 26.319,29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>24.500,44 24.500,44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>22.802,63 22.802,63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>21.226,79 21.226,79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>19.199,06 19.199,06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0                    1\n",
       "0  ATIVO APOSENTADO\\nSUBSÍDIO (em R$) SUBSÍDIO (e...                 None\n",
       "1                                               None  27.369,67 27.369,67\n",
       "2                                               None  26.319,29 26.319,29\n",
       "3                                               None  24.500,44 24.500,44\n",
       "4                                               None  22.802,63 22.802,63\n",
       "5                                               None  21.226,79 21.226,79\n",
       "6                                               None  19.199,06 19.199,06"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_summary[9]\n",
    "l1 = df_temp[0][0].split('\\n')[0].split(' ')[:2]\n",
    "l2 = df_temp[0][0].split('\\n')[1].split('(em R$)')[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27303.7, 27303.7]\n",
      "[24146.6, 24146.6]\n",
      "[21014.49, 21014.49]\n"
     ]
    }
   ],
   "source": [
    "for i in df_temp[1].values:\n",
    "    if i is not None:\n",
    "        print([float(x.replace('.','').replace(',','.')) for x in i.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ATIVO', 'APOSENTADO']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SUBSÍDIO ', ' SUBSÍDIO ']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrair tabelas de remuneração das carreiras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'F:\\\\TabRemunRel'\n",
    "df_remuneracao = extract_remun_tables_pdfplumber(folder_path)\n",
    "df_remuneracao['Cargo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remuneracao[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camelot causando erro, Ghostscript instalado mas provavelmente não acessível\n",
    "try:\n",
    "    import ghostscript\n",
    "    print(\"Ghostscript está instalado!\")\n",
    "except ImportError:\n",
    "    print(\"Ghostscript não está instalado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'F:\\\\TabRemunRel'\n",
    "df_remuneracao = extract_remun_tables_camelot(folder_path)\n",
    "df_remuneracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remuneracao[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_remuneracao_processado = process_remuneration_data(df_remuneracao)\n",
    "df_remuneracao_processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remuneracao[60:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_remuneration_table(file_path):\n",
    "    \"\"\"Extrai a tabela de remuneração de um arquivo PDF.\"\"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        tables = []\n",
    "        for page in pdf.pages:\n",
    "            tables.extend(page.extract_tables())\n",
    "\n",
    "        # Encontrar a tabela de remuneração\n",
    "        remuneration_table = None\n",
    "        for table in tables:\n",
    "            if any(\"CLASSE\" in row[0] for row in table):  # Verificar se \"CLASSE\" está presente em alguma célula da primeira coluna\n",
    "                remuneration_table = table\n",
    "                break\n",
    "\n",
    "        if remuneration_table is None:\n",
    "            raise ValueError(\"Tabela de remuneração não encontrada no PDF.\")\n",
    "\n",
    "        # Extrair cabeçalho (considerando que a primeira linha contém os rótulos)\n",
    "        header = remuneration_table[0]\n",
    "        data = remuneration_table[1:]\n",
    "\n",
    "        # Criar DataFrame\n",
    "        df = pd.DataFrame(data, columns=header)\n",
    "\n",
    "        # Extrair informações de órgão, cargo e posição do texto da página\n",
    "        text = page.extract_text()\n",
    "        orgao_cargo_matches = re.findall(r\"(\\d+)\\.\\s*(.+?)\\s*-\", text)  # Encontrar todos os órgãos e cargos\n",
    "\n",
    "        # Criar dicionário para mapear número do órgão para nome do órgão e cargo\n",
    "        orgao_cargo_map = {int(num): (orgao, cargo.split('-')[0].strip()) for num, orgao, cargo in orgao_cargo_matches}\n",
    "\n",
    "        # Adicionar colunas de metadados\n",
    "        df['Órgão'] = df['CLASSE'].astype(int).map(lambda x: orgao_cargo_map.get(x, ('', ''))[0])\n",
    "        df['Cargo'] = df['CLASSE'].astype(int).map(lambda x: orgao_cargo_map.get(x, ('', ''))[1])\n",
    "\n",
    "        # Limpeza e formatação\n",
    "        df = df.drop(columns=[\"CLASSE\"])  \n",
    "        df = df.fillna('')  \n",
    "        for col in [\"ATIVO\\nSUBSÍDIO (em R$)\", \"APOSENTADO\\nSUBSÍDIO (em R$)\"]:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str).str.replace(\".\", \"\", regex=False).str.replace(\",\", \".\", regex=False)\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remuneracao = pd.concat(all_data, ignore_index=True)\n",
    "df_remuneracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.gov.br/servidor/pt-br/observatorio-de-pessoal-govbr/tabela-de-remuneracao-dos-servidores-publicos-federais-civis-e-dos-ex-territorios'\n",
    "save_folder = 'F://TabRemun'\n",
    "\n",
    "download_ods_files(url, save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.listdir('F://TabRemun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 =  ['ESPECIAL', 'lll', 3703.72, 872.0, None, 752.0, 827.0, 902.0, 1462.0, 2925.0, None, 4575.72, 5327.72, 5402.72, 5477.72, 6037.72, 7500.72, None, 545.0, None, 4248.72, 5000.72, 5075.72, 5150.72, 5710.72, 7173.72, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
    "print(len(list1))\n",
    "\n",
    "columns = ['PADRAO', 'NIVEL', 'A', 'B', 'VZ1' , 'C','D' ,'E', 'F','G', 'VZ2', 'H', 'I', 'J', 'VZ5', 'K', 'L', 'M', 'VZ3', 'N', 'VZ4', 'O', 'P', 'Q', 'R', 'S', 'T']\n",
    "print(len(columns))\n",
    "\n",
    "for n,i in enumerate(zip(columns,list1)):\n",
    "    print(f'{n+1:2}: {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'C://TabRemun'\n",
    "search_string = 'FIOCRUZ'\n",
    "\n",
    "columns_to_extract = ['PADRAO', 'NIVEL', 'A', 'B', 'VZ1' , 'C','D' ,'E', 'F','G=(A+B)', 'VZ2', 'H=(A+B+D)', 'I=(A+B+E)', 'J=(A+B+F)', 'VZ5', 'K=(A+C)', 'L=(A+C+D)', 'M=(A+C+E)', 'VZ3', 'N=(A+C+F)', 'VZ4', 'O', 'P=(A+O)', 'Q=(A+D+O)', 'R=(A+E+O)', 'S=(A+F+O)']\n",
    "print(len(columns_to_extract))\n",
    "\n",
    "df_final = extract_data_from_zip(folder_path, search_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import ezodf\n",
    "from io import BytesIO\n",
    "import tempfile\n",
    "\n",
    "def extract_data_from_zip(folder_path, search_string):\n",
    "    all_data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.zip'):\n",
    "            zip_file_path = os.path.join(folder_path, filename)\n",
    "            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "                main_folder = zip_ref.namelist()[0]\n",
    "\n",
    "                for item in zip_ref.namelist():\n",
    "                    if item.startswith(main_folder) and search_string in item and item.endswith('/'):\n",
    "                        subfolder_name = item\n",
    "                        break\n",
    "                else:\n",
    "                    print(f\"Subpasta com '{search_string}' não encontrada em {filename}.\")\n",
    "                    continue\n",
    "\n",
    "                for name in zip_ref.namelist():\n",
    "                    if name.startswith(subfolder_name) and name.endswith('.ods'):\n",
    "                        with zip_ref.open(name) as file:\n",
    "                            try:\n",
    "                                ods_data = BytesIO(file.read())\n",
    "\n",
    "                                with tempfile.NamedTemporaryFile(delete=False, suffix='.ods') as temp:\n",
    "                                    temp.write(ods_data.getvalue())\n",
    "                                    temp_path = temp.name\n",
    "\n",
    "                                doc = ezodf.opendoc(temp_path)\n",
    "                                sheet = doc.sheets[0]\n",
    "                                # Converte a planilha em um DataFrame do Pandas\n",
    "                                data = []\n",
    "                                for i, row in enumerate(sheet.rows()):\n",
    "                                    data.append([cell.value for cell in row])\n",
    "\n",
    "                                # Cria um DataFrame\n",
    "                                df = pd.DataFrame(data)\n",
    "                                os.remove(temp_path)\n",
    "\n",
    "                                # Encontra a data \"Posição\" iterando de baixo para cima\n",
    "                                date = None\n",
    "                                for index, row in df[::-1].iterrows():\n",
    "                                    for cell in row:\n",
    "                                        if cell is not None:  # Verifica se a célula não é None\n",
    "                                            date_string = re.search(r'(janeiro|fevereiro|março|abril|maio|junho|julho|agosto|setembro|outubro|novembro|dezembro)/\\d{4}', str(cell))\n",
    "                                            if date_string:\n",
    "                                                date = date_string.group()\n",
    "                                                break\n",
    "                                    if date:\n",
    "                                        break\n",
    "\n",
    "                                # Normaliza os nomes das colunas (remove espaços, quebras de linha, converte para minúsculas e substitui espaços por underscores)\n",
    "                                df.columns = (\n",
    "                                    df.iloc[0]\n",
    "                                    .astype(str)\n",
    "                                    .str.strip()\n",
    "                                    .str.replace('\\n', '', regex=False)\n",
    "                                    .str.replace(r'[ =+\\(\\)]', '', regex=True)  # Remove caracteres especiais\n",
    "                                    .str.lower()\n",
    "                                )\n",
    "\n",
    "                                ['PADRAO', 'NIVEL', 'A', 'B', 'VZ1' , 'C','D' ,'E', 'F','G', 'VZ2', 'H', 'I', 'J', 'VZ5', 'K', 'L', 'M', 'VZ3', 'N', 'VZ4', 'O', 'P', 'Q', 'R', 'S', 'T']\n",
    "\n",
    "                                # Mapeia os nomes das colunas para os nomes corretos (incluindo \"Classe\")\n",
    "                                column_mapping = {\n",
    "                                    'Cargo': 'Cargo',\n",
    "                                    'Classe': 'Classe',\n",
    "                                    'Padrao': 'Padrao',\n",
    "                                    'A': 'vb',\n",
    "                                    'B': 'ativo_100p_sem_rt',\n",
    "                                    'C': 'ativo_100p_aperf_espec',\n",
    "                                    'D': 'ativo_100p_mestre',\n",
    "                                    'E': 'ativo_100p_doutor',\n",
    "                                    'F': 'aposentado_sem_rt',\n",
    "                                    'G': 'aposentado_aperf_espec',\n",
    "                                    'H': 'aposentado_mestre',\n",
    "                                    'I': 'aposentado_doutor',\n",
    "                                    'K': 'ativo_100p_sem_rt',\n",
    "                                    'L': 'ativo_100p_aperf_espec',\n",
    "                                    'M': 'ativo_100p_mestre',\n",
    "                                    'N': 'ativo_100p_doutor',\n",
    "                                    'O': 'aposentado_sem_rt',\n",
    "                                    'P': 'aposentado_aperf_espec',\n",
    "                                    'Q': 'aposentado_mestre',\n",
    "                                    'R': 'aposentado_doutor',\n",
    "                                    'T': 'aposentado_doutor',\n",
    "                                }\n",
    "\n",
    "                                df = df.rename(columns=column_mapping)\n",
    "                                df = df.iloc[1:].copy()\n",
    "\n",
    "                                # Remove colunas duplicadas antes de usar o reindex\n",
    "                                df = df.loc[:,~df.columns.duplicated()]\n",
    "                                # Extrai apenas as colunas desejadas, preenchendo com NaN se não existirem\n",
    "                                df_extracted = df.reindex(columns=['Cargo','Classe', 'Padrao', 'VB', 'Ativo_100p_semRT', 'Ativo_100p_AperfEspec', 'Ativo_100p_Mestre', 'Ativo_100p_Doutor', 'Aposentado_SemRT', 'Aposentado_AperfEspec', 'Aposentado_Mestre', 'Aposentado_Doutor', 'Data'], fill_value=np.nan)\n",
    "                                df_extracted.loc[:, 'Data'] = date  # Use .loc para atribuir o valor\n",
    "\n",
    "                                # Extrai o nome do cargo do nome do arquivo\n",
    "                                cargo = os.path.splitext(os.path.basename(name))[0]\n",
    "                                cargo = re.sub(r'[0-9]', '', cargo).strip()\n",
    "                                df_extracted['Cargo'] = cargo\n",
    "                                # Converte todas as colunas para numérico, se possível, exceto 'Data' e 'Cargo'\n",
    "                                for col in df_extracted.columns:\n",
    "                                    if col not in ['Data', 'Cargo', 'classe', 'padrao']:\n",
    "                                        df_extracted[col] = pd.to_numeric(df_extracted[col], errors='coerce')\n",
    "\n",
    "                                # Remove linhas com todos os valores nulos\n",
    "                                df_extracted = df_extracted.dropna(how='all')\n",
    "\n",
    "                                # Extrai a classe e o padrão para cada linha\n",
    "                                classe = None\n",
    "                                padrao = None\n",
    "                                for idx, row in df_extracted.iterrows():  \n",
    "                                    if pd.notna(row.get('classe', None)):  # Verifica se a coluna 'classe' existe\n",
    "                                        classe = row['classe']\n",
    "                                    else:\n",
    "                                        classe = 'NA'  # Atribui 'NA' se a coluna não existir\n",
    "\n",
    "                                    if pd.notna(row.get('padrao', None)):  # Verifica se a coluna 'padrao' existe\n",
    "                                        padrao = row['padrao']\n",
    "\n",
    "                                    # Adiciona os dados apenas se classe e padrão não forem nulos\n",
    "                                    if classe is not None and padrao is not None:\n",
    "                                        df_extracted.loc[idx, 'CLASSE'] = classe\n",
    "                                        df_extracted.loc[idx, 'PADRÃO'] = padrao\n",
    "\n",
    "                                all_data.append(df_extracted)\n",
    "                            except Exception as e:\n",
    "                                print(f\"Erro ao ler a planilha {name}: {e}\")\n",
    "\n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        return final_df\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download arquivos de dados zipados\n",
    "# url = 'https://www.gov.br/servidor/pt-br/observatorio-de-pessoal-govbr/tabela-de-remuneracao-dos-servidores-publicos-federais-civis-e-dos-ex-territorios'\n",
    "# save_folder = 'C://TabRemun'\n",
    "\n",
    "# download_ods_files(url, save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import re\n",
    "import tempfile\n",
    "import numpy as np\n",
    "\n",
    "def extract_data_from_zip(folder_path, search_string):\n",
    "    all_data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.zip'):\n",
    "            zip_file_path = os.path.join(folder_path, filename)\n",
    "            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "                main_folder = zip_ref.namelist()[0]\n",
    "\n",
    "                for item in zip_ref.namelist():\n",
    "                    if item.startswith(main_folder) and search_string in item and item.endswith('/'):\n",
    "                        subfolder_name = item\n",
    "                        break\n",
    "                else:\n",
    "                    print(f\"Subpasta com '{search_string}' não encontrada em {filename}.\")\n",
    "                    continue\n",
    "\n",
    "                for name in zip_ref.namelist():\n",
    "                    if name.startswith(subfolder_name) and name.endswith('.ods'):\n",
    "                        with zip_ref.open(name) as file:\n",
    "                            try:\n",
    "                                text = file.read().decode('utf-8', errors='replace')\n",
    "\n",
    "                                # Find the header row\n",
    "                                header_row = None\n",
    "                                for i, line in enumerate(text.splitlines()):\n",
    "                                    if 'Padrão' in line:\n",
    "                                        header_row = i\n",
    "                                        break\n",
    "\n",
    "                                if header_row is None:\n",
    "                                    raise ValueError(\"Rótulos das colunas não encontrados.\")\n",
    "\n",
    "                                # Extract data starting from the row after the header\n",
    "                                data = []\n",
    "                                for line in text.splitlines()[header_row + 1:]:\n",
    "                                    row_values = [x.strip() for x in line.split('\\t') if x.strip()]\n",
    "                                    data.append(row_values)\n",
    "\n",
    "                                # Create DataFrame\n",
    "                                columns = ['PADRAO', 'NIVEL', 'A', 'B', 'VZ1' , 'C','D' ,'E', 'F','G', 'VZ2', 'H', 'I', 'J', 'VZ5', 'K', 'L', 'M', 'VZ3', 'N', 'VZ4', 'O', 'P', 'Q', 'R', 'S', 'T']\n",
    "                                df = pd.DataFrame(data, columns=columns[:len(data[0])])  # Use the number of columns in the data\n",
    "\n",
    "                                # Encontra a data \"Posição\" iterando de baixo para cima\n",
    "                                date = None\n",
    "                                for index, row in df[::-1].iterrows():\n",
    "                                    for cell in row:\n",
    "                                        if cell is not None:  # Verifica se a célula não é None\n",
    "                                            date_string = re.search(r'(janeiro|fevereiro|março|abril|maio|junho|julho|agosto|setembro|outubro|novembro|dezembro)/\\d{4}', str(cell))\n",
    "                                            if date_string:\n",
    "                                                date = date_string.group()\n",
    "                                                break\n",
    "                                    if date:\n",
    "                                        break\n",
    "\n",
    "                                # Normalize column names\n",
    "                                df.columns = (\n",
    "                                    df.columns\n",
    "                                    .astype(str)\n",
    "                                    .str.strip()\n",
    "                                    .str.replace('\\n', '', regex=False)\n",
    "                                    .str.replace(r'[ =+\\(\\)]', '', regex=True)\n",
    "                                    .str.lower()\n",
    "                                )\n",
    "\n",
    "                                # Map column names\n",
    "                                column_mapping = {\n",
    "                                    'a': 'vb',\n",
    "                                    'k': 'ativo_100p_sem_rt',\n",
    "                                    'l': 'ativo_100p_aperf_espec',\n",
    "                                    'm': 'ativo_100p_mestre',\n",
    "                                    'n': 'ativo_100p_doutor',\n",
    "                                    'p': 'aposentado_sem_rt',\n",
    "                                    'q': 'aposentado_aperf_espec',\n",
    "                                    'r': 'aposentado_mestre',\n",
    "                                    's': 'aposentado_doutor',\n",
    "                                    'classe': 'classe',\n",
    "                                    'padrao': 'padrao',\n",
    "                                    'ativo 100% sem rt': 'ativo_100p_sem_rt',\n",
    "                                    'ativo 100% aperfeiçoamento/especialização': 'ativo_100p_aperf_espec',\n",
    "                                    'ativo 100% mestre': 'ativo_100p_mestre',\n",
    "                                    'ativo 100% doutor': 'ativo_100p_doutor',\n",
    "                                    'aposentado sem rt': 'aposentado_sem_rt',\n",
    "                                    'aposentado aperfeiçoamento/especialização': 'aposentado_aperf_espec',\n",
    "                                    'aposentado mestre': 'aposentado_mestre',\n",
    "                                    'aposentado doutor': 'aposentado_doutor',\n",
    "                                }\n",
    "                                df = df.rename(columns=column_mapping)\n",
    "\n",
    "                                # Extract relevant columns, fill missing columns with NaN values\n",
    "                                df_extracted = df.reindex(columns=['classe', 'padrao', 'vb', 'ativo_100p_sem_rt', 'ativo_100p_aperf_espec', 'ativo_100p_mestre', 'ativo_100p_doutor', 'aposentado_sem_rt', 'aposentado_aperf_espec', 'aposentado_mestre', 'aposentado_doutor', 'Data', 'Cargo'], fill_value=np.nan)\n",
    "\n",
    "                                # Extract cargo from file name\n",
    "                                cargo = os.path.splitext(os.path.basename(name))[0]\n",
    "                                cargo = re.sub(r'[0-9]', '', cargo).strip()\n",
    "\n",
    "                                df_extracted['Data'] = date\n",
    "                                df_extracted['Cargo'] = cargo\n",
    "\n",
    "                                # Convert numeric columns to numeric data types\n",
    "                                for col in df_extracted.columns:\n",
    "                                    if col not in ['Data', 'Cargo', 'classe', 'padrao']:\n",
    "                                        df_extracted[col] = pd.to_numeric(df_extracted[col], errors='coerce')\n",
    "\n",
    "                                # Remove rows with all NaN values\n",
    "                                df_extracted = df_extracted.dropna(how='all')\n",
    "\n",
    "                                # Extract 'classe' and 'padrao' for each row, filling with 'NA' if not found\n",
    "                                classe = None\n",
    "                                padrao = None\n",
    "                                for idx, row in df_extracted.iterrows():\n",
    "                                    if pd.notna(row.get('classe', None)):\n",
    "                                        classe = row['classe']\n",
    "                                    else:\n",
    "                                        classe = 'NA'\n",
    "\n",
    "                                    if pd.notna(row.get('padrao', None)):\n",
    "                                        padrao = row['padrao']\n",
    "\n",
    "                                    # Add the data only if classe and padrao are not None\n",
    "                                    if classe is not None and padrao is not None:\n",
    "                                        df_extracted.loc[idx, 'CLASSE'] = classe\n",
    "                                        df_extracted.loc[idx, 'PADRÃO'] = padrao\n",
    "\n",
    "                                all_data.append(df_extracted)\n",
    "                            except Exception as e:\n",
    "                                print(f\"Erro ao ler a planilha {name}: {e}\")\n",
    "\n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        return final_df\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'C://TabRemun'\n",
    "search_string = 'FIOCRUZ'\n",
    "df_final = extract_data_from_zip(folder_path, search_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in df_final['Data'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in df_final['Cargo'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso\n",
    "folder_path = 'F://TabRemun'\n",
    "search_string = 'FIOCRUZ'\n",
    "columns_to_extract = [\"CLASSE\", \"PADRÃO\", \"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G=(A+B)\",\"H=(A+B+D)\",\"I=(A+B+E)\",\"J=(A+B+F)\",\"K=(A+C)\", \"L=(A+C+D)\", \"M=(A+C+E)\", \"N=(A+C+F)\",\t\"O\", \"P=(A+O)\",\t\"Q=(A+D+O)\", \"R=(A+E+O)\", \"S=(A+F+O)\"]\n",
    "rotulos = {\"VB\": \"A\",\n",
    "           \"Teto Atividade Sem RT\": \"K=(A+C)\",\n",
    "           \"Teto Atividade Aperf./Espec.\":\t\"L=(A+C+D)\",\n",
    "           \"Teto Atividade Mestre\": \"M=(A+C+E)\",\n",
    "           \"Teto Atividade Doutor\": \"N=(A+C+F)\",\n",
    "           \"Teto Aposentado Sem RT\": \"P=(A+O)\",\n",
    "           \"Teto Aposentado Aperf./Espec.\":\t\"Q=(A+D+O)\",\n",
    "           \"Teto Aposentado Mestre\": \"R=(A+E+O)\",\n",
    "           \"Teto Aposentado Doutor\": \"S=(A+F+O)\",\n",
    "           }\n",
    "\n",
    "df_final = extract_data_from_zip(folder_path, search_string, columns_to_extract)\n",
    "\n",
    "if df_final is not None:\n",
    "    print(df_final)\n",
    "else:\n",
    "    print(\"Nenhum dado encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_ipca_completo = \"https://servicodados.ibge.gov.br/api/v3/agregados/1737/periodos/197912|198001|198002|198003|198004|198005|198006|198007|198008|198009|198010|198011|198012|198101|198102|198103|198104|198105|198106|198107|198108|198109|198110|198111|198112|198201|198202|198203|198204|198205|198206|198207|198208|198209|198210|198211|198212|198301|198302|198303|198304|198305|198306|198307|198308|198309|198310|198311|198312|198401|198402|198403|198404|198405|198406|198407|198408|198409|198410|198411|198412|198501|198502|198503|198504|198505|198506|198507|198508|198509|198510|198511|198512|198601|198602|198603|198604|198605|198606|198607|198608|198609|198610|198611|198612|198701|198702|198703|198704|198705|198706|198707|198708|198709|198710|198711|198712|198801|198802|198803|198804|198805|198806|198807|198808|198809|198810|198811|198812|198901|198902|198903|198904|198905|198906|198907|198908|198909|198910|198911|198912|199001|199002|199003|199004|199005|199006|199007|199008|199009|199010|199011|199012|199101|199102|199103|199104|199105|199106|199107|199108|199109|199110|199111|199112|199201|199202|199203|199204|199205|199206|199207|199208|199209|199210|199211|199212|199301|199302|199303|199304|199305|199306|199307|199308|199309|199310|199311|199312|199401|199402|199403|199404|199405|199406|199407|199408|199409|199410|199411|199412|199501|199502|199503|199504|199505|199506|199507|199508|199509|199510|199511|199512|199601|199602|199603|199604|199605|199606|199607|199608|199609|199610|199611|199612|199701|199702|199703|199704|199705|199706|199707|199708|199709|199710|199711|199712|199801|199802|199803|199804|199805|199806|199807|199808|199809|199810|199811|199812|199901|199902|199903|199904|199905|199906|199907|199908|199909|199910|199911|199912|200001|200002|200003|200004|200005|200006|200007|200008|200009|200010|200011|200012|200101|200102|200103|200104|200105|200106|200107|200108|200109|200110|200111|200112|200201|200202|200203|200204|200205|200206|200207|200208|200209|200210|200211|200212|200301|200302|200303|200304|200305|200306|200307|200308|200309|200310|200311|200312|200401|200402|200403|200404|200405|200406|200407|200408|200409|200410|200411|200412|200501|200502|200503|200504|200505|200506|200507|200508|200509|200510|200511|200512|200601|200602|200603|200604|200605|200606|200607|200608|200609|200610|200611|200612|200701|200702|200703|200704|200705|200706|200707|200708|200709|200710|200711|200712|200801|200802|200803|200804|200805|200806|200807|200808|200809|200810|200811|200812|200901|200902|200903|200904|200905|200906|200907|200908|200909|200910|200911|200912|201001|201002|201003|201004|201005|201006|201007|201008|201009|201010|201011|201012|201101|201102|201103|201104|201105|201106|201107|201108|201109|201110|201111|201112|201201|201202|201203|201204|201205|201206|201207|201208|201209|201210|201211|201212|201301|201302|201303|201304|201305|201306|201307|201308|201309|201310|201311|201312|201401|201402|201403|201404|201405|201406|201407|201408|201409|201410|201411|201412|201501|201502|201503|201504|201505|201506|201507|201508|201509|201510|201511|201512|201601|201602|201603|201604|201605|201606|201607|201608|201609|201610|201611|201612|201701|201702|201703|201704|201705|201706|201707|201708|201709|201710|201711|201712|201801|201802|201803|201804|201805|201806|201807|201808|201809|201810|201811|201812|201901|201902|201903|201904|201905|201906|201907|201908|201909|201910|201911|201912|202001|202002|202003|202004|202005|202006|202007|202008|202009|202010|202011|202012|202101|202102|202103|202104|202105|202106|202107|202108|202109|202110|202111|202112|202201|202202|202203|202204|202205|202206|202207|202208|202209|202210|202211|202212|202301|202302|202303|202304|202305|202306|202307|202308|202309|202310|202311|202312|202401|202402|202403|202404|202405/variaveis/2266?localidades=N1[all]\"\n",
    "url_ipca = \"https://servicodados.ibge.gov.br/api/v3/agregados/1737/periodos/199212|199301|199302|199303|199304|199305|199306|199307|199308|199309|199310|199311|199312|199401|199402|199403|199404|199405|199406|199407|199408|199409|199410|199411|199412|199501|199502|199503|199504|199505|199506|199507|199508|199509|199510|199511|199512|199601|199602|199603|199604|199605|199606|199607|199608|199609|199610|199611|199612|199701|199702|199703|199704|199705|199706|199707|199708|199709|199710|199711|199712|199801|199802|199803|199804|199805|199806|199807|199808|199809|199810|199811|199812|199901|199902|199903|199904|199905|199906|199907|199908|199909|199910|199911|199912|200001|200002|200003|200004|200005|200006|200007|200008|200009|200010|200011|200012|200101|200102|200103|200104|200105|200106|200107|200108|200109|200110|200111|200112|200201|200202|200203|200204|200205|200206|200207|200208|200209|200210|200211|200212|200301|200302|200303|200304|200305|200306|200307|200308|200309|200310|200311|200312|200401|200402|200403|200404|200405|200406|200407|200408|200409|200410|200411|200412|200501|200502|200503|200504|200505|200506|200507|200508|200509|200510|200511|200512|200601|200602|200603|200604|200605|200606|200607|200608|200609|200610|200611|200612|200701|200702|200703|200704|200705|200706|200707|200708|200709|200710|200711|200712|200801|200802|200803|200804|200805|200806|200807|200808|200809|200810|200811|200812|200901|200902|200903|200904|200905|200906|200907|200908|200909|200910|200911|200912|201001|201002|201003|201004|201005|201006|201007|201008|201009|201010|201011|201012|201101|201102|201103|201104|201105|201106|201107|201108|201109|201110|201111|201112|201201|201202|201203|201204|201205|201206|201207|201208|201209|201210|201211|201212|201301|201302|201303|201304|201305|201306|201307|201308|201309|201310|201311|201312|201401|201402|201403|201404|201405|201406|201407|201408|201409|201410|201411|201412|201501|201502|201503|201504|201505|201506|201507|201508|201509|201510|201511|201512|201601|201602|201603|201604|201605|201606|201607|201608|201609|201610|201611|201612|201701|201702|201703|201704|201705|201706|201707|201708|201709|201710|201711|201712|201801|201802|201803|201804|201805|201806|201807|201808|201809|201810|201811|201812|201901|201902|201903|201904|201905|201906|201907|201908|201909|201910|201911|201912|202001|202002|202003|202004|202005|202006|202007|202008|202009|202010|202011|202012|202101|202102|202103|202104|202105|202106|202107|202108|202109|202110|202111|202112|202201|202202|202203|202204|202205|202206|202207|202208|202209|202210|202211|202212|202301|202302|202303|202304|202305|202306|202307|202308|202309|202310|202311|202312|202401|202402|202403|202404|202405/variaveis/2266?localidades=N1[all]\"\n",
    "# url_tab_var = \"https://apisidra.ibge.gov.br/values/t/1737/n1/all/v/2266/p/all\"\n",
    "indices_mensais = {}\n",
    "\n",
    "response = requests.get(url_ipca_completo)\n",
    "if response.status_code == 200:\n",
    "    print('Requisição realizada com sucesso!')\n",
    "response.raise_for_status()\n",
    "\n",
    "dados_ipca = json.loads(response.content)\n",
    "indices_ipca = dados_ipca[0]['resultados'][0].get('series')[0].get('serie')\n",
    "print(f'{len(indices_ipca)} índices IPCA mensais extraídos do IBGE')\n",
    "\n",
    "# Cria uma lista de tuplas a partir dos itens do dicionário\n",
    "lista_dados = list(indices_ipca.items())\n",
    "\n",
    "# Cria o DataFrame\n",
    "df = pd.DataFrame(lista_dados, columns=[\"AnoMes\", \"Valor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Dados fornecidos\n",
    "anos = list(range(2010, 2027))\n",
    "inflacao = [0.02, 0.015, 0.025, 0.029, 0.018, 0.02, 0.015, 0.025, 0.029, 0.018, 0.012, 0.047, 0.07, 0.05, 0.03, 0.025, 0.02]\n",
    "ajuste = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.2, 0.2, 0.2]\n",
    "\n",
    "# Calcula os valores reais ajustados\n",
    "valores_reais = [100]  # Começa com 100 em 2015\n",
    "for i in range(1, len(anos)):\n",
    "    valor_anterior = valores_reais[i - 1]\n",
    "    valor_atual = valor_anterior * (1 - inflacao[i - 1]) * (1 + ajuste[i - 1])\n",
    "    valores_reais.append(valor_atual)\n",
    "\n",
    "# Cria um DataFrame\n",
    "df = pd.DataFrame({'Anos': anos, 'Valores em Reais': valores_reais})\n",
    "\n",
    "# Cria o gráfico de barras com Plotly\n",
    "fig = go.Figure(data=[go.Bar(x=df['Anos'], y=df['Valores em Reais'])])\n",
    "\n",
    "# Personaliza o layout\n",
    "fig.update_layout(\n",
    "    title='Poder de Compra Real Ajustado (2010-2026)',\n",
    "    xaxis_title='Ano',\n",
    "    yaxis_title='Valor Real (R$)',\n",
    "    xaxis=dict(\n",
    "        dtick=1,  # Garante que cada ano seja mostrado\n",
    "        tickmode='linear'  # Modo linear para ticks\n",
    "    )\n",
    ")\n",
    "\n",
    "# Atualiza o gráfico para adicionar rótulos de dados\n",
    "fig.update_traces(texttemplate='%{y:.2f}', textposition='inside')\n",
    "\n",
    "# Exibe o gráfico\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados_ipca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_perdas(ano_inicio, ano_final, reajustes_anuais):\n",
    "    url_ipca_completo = \"https://servicodados.ibge.gov.br/api/v3/agregados/1737/periodos/197912|198001|198002|198003|198004|198005|198006|198007|198008|198009|198010|198011|198012|198101|198102|198103|198104|198105|198106|198107|198108|198109|198110|198111|198112|198201|198202|198203|198204|198205|198206|198207|198208|198209|198210|198211|198212|198301|198302|198303|198304|198305|198306|198307|198308|198309|198310|198311|198312|198401|198402|198403|198404|198405|198406|198407|198408|198409|198410|198411|198412|198501|198502|198503|198504|198505|198506|198507|198508|198509|198510|198511|198512|198601|198602|198603|198604|198605|198606|198607|198608|198609|198610|198611|198612|198701|198702|198703|198704|198705|198706|198707|198708|198709|198710|198711|198712|198801|198802|198803|198804|198805|198806|198807|198808|198809|198810|198811|198812|198901|198902|198903|198904|198905|198906|198907|198908|198909|198910|198911|198912|199001|199002|199003|199004|199005|199006|199007|199008|199009|199010|199011|199012|199101|199102|199103|199104|199105|199106|199107|199108|199109|199110|199111|199112|199201|199202|199203|199204|199205|199206|199207|199208|199209|199210|199211|199212|199301|199302|199303|199304|199305|199306|199307|199308|199309|199310|199311|199312|199401|199402|199403|199404|199405|199406|199407|199408|199409|199410|199411|199412|199501|199502|199503|199504|199505|199506|199507|199508|199509|199510|199511|199512|199601|199602|199603|199604|199605|199606|199607|199608|199609|199610|199611|199612|199701|199702|199703|199704|199705|199706|199707|199708|199709|199710|199711|199712|199801|199802|199803|199804|199805|199806|199807|199808|199809|199810|199811|199812|199901|199902|199903|199904|199905|199906|199907|199908|199909|199910|199911|199912|200001|200002|200003|200004|200005|200006|200007|200008|200009|200010|200011|200012|200101|200102|200103|200104|200105|200106|200107|200108|200109|200110|200111|200112|200201|200202|200203|200204|200205|200206|200207|200208|200209|200210|200211|200212|200301|200302|200303|200304|200305|200306|200307|200308|200309|200310|200311|200312|200401|200402|200403|200404|200405|200406|200407|200408|200409|200410|200411|200412|200501|200502|200503|200504|200505|200506|200507|200508|200509|200510|200511|200512|200601|200602|200603|200604|200605|200606|200607|200608|200609|200610|200611|200612|200701|200702|200703|200704|200705|200706|200707|200708|200709|200710|200711|200712|200801|200802|200803|200804|200805|200806|200807|200808|200809|200810|200811|200812|200901|200902|200903|200904|200905|200906|200907|200908|200909|200910|200911|200912|201001|201002|201003|201004|201005|201006|201007|201008|201009|201010|201011|201012|201101|201102|201103|201104|201105|201106|201107|201108|201109|201110|201111|201112|201201|201202|201203|201204|201205|201206|201207|201208|201209|201210|201211|201212|201301|201302|201303|201304|201305|201306|201307|201308|201309|201310|201311|201312|201401|201402|201403|201404|201405|201406|201407|201408|201409|201410|201411|201412|201501|201502|201503|201504|201505|201506|201507|201508|201509|201510|201511|201512|201601|201602|201603|201604|201605|201606|201607|201608|201609|201610|201611|201612|201701|201702|201703|201704|201705|201706|201707|201708|201709|201710|201711|201712|201801|201802|201803|201804|201805|201806|201807|201808|201809|201810|201811|201812|201901|201902|201903|201904|201905|201906|201907|201908|201909|201910|201911|201912|202001|202002|202003|202004|202005|202006|202007|202008|202009|202010|202011|202012|202101|202102|202103|202104|202105|202106|202107|202108|202109|202110|202111|202112|202201|202202|202203|202204|202205|202206|202207|202208|202209|202210|202211|202212|202301|202302|202303|202304|202305|202306|202307|202308|202309|202310|202311|202312|202401|202402|202403|202404|202405/variaveis/2266?localidades=N1[all]\"\n",
    "    url_ipca = \"https://servicodados.ibge.gov.br/api/v3/agregados/1737/periodos/199212|199301|199302|199303|199304|199305|199306|199307|199308|199309|199310|199311|199312|199401|199402|199403|199404|199405|199406|199407|199408|199409|199410|199411|199412|199501|199502|199503|199504|199505|199506|199507|199508|199509|199510|199511|199512|199601|199602|199603|199604|199605|199606|199607|199608|199609|199610|199611|199612|199701|199702|199703|199704|199705|199706|199707|199708|199709|199710|199711|199712|199801|199802|199803|199804|199805|199806|199807|199808|199809|199810|199811|199812|199901|199902|199903|199904|199905|199906|199907|199908|199909|199910|199911|199912|200001|200002|200003|200004|200005|200006|200007|200008|200009|200010|200011|200012|200101|200102|200103|200104|200105|200106|200107|200108|200109|200110|200111|200112|200201|200202|200203|200204|200205|200206|200207|200208|200209|200210|200211|200212|200301|200302|200303|200304|200305|200306|200307|200308|200309|200310|200311|200312|200401|200402|200403|200404|200405|200406|200407|200408|200409|200410|200411|200412|200501|200502|200503|200504|200505|200506|200507|200508|200509|200510|200511|200512|200601|200602|200603|200604|200605|200606|200607|200608|200609|200610|200611|200612|200701|200702|200703|200704|200705|200706|200707|200708|200709|200710|200711|200712|200801|200802|200803|200804|200805|200806|200807|200808|200809|200810|200811|200812|200901|200902|200903|200904|200905|200906|200907|200908|200909|200910|200911|200912|201001|201002|201003|201004|201005|201006|201007|201008|201009|201010|201011|201012|201101|201102|201103|201104|201105|201106|201107|201108|201109|201110|201111|201112|201201|201202|201203|201204|201205|201206|201207|201208|201209|201210|201211|201212|201301|201302|201303|201304|201305|201306|201307|201308|201309|201310|201311|201312|201401|201402|201403|201404|201405|201406|201407|201408|201409|201410|201411|201412|201501|201502|201503|201504|201505|201506|201507|201508|201509|201510|201511|201512|201601|201602|201603|201604|201605|201606|201607|201608|201609|201610|201611|201612|201701|201702|201703|201704|201705|201706|201707|201708|201709|201710|201711|201712|201801|201802|201803|201804|201805|201806|201807|201808|201809|201810|201811|201812|201901|201902|201903|201904|201905|201906|201907|201908|201909|201910|201911|201912|202001|202002|202003|202004|202005|202006|202007|202008|202009|202010|202011|202012|202101|202102|202103|202104|202105|202106|202107|202108|202109|202110|202111|202112|202201|202202|202203|202204|202205|202206|202207|202208|202209|202210|202211|202212|202301|202302|202303|202304|202305|202306|202307|202308|202309|202310|202311|202312|202401|202402|202403|202404|202405/variaveis/2266?localidades=N1[all]\"\n",
    "    # url_tab_var = \"https://apisidra.ibge.gov.br/values/t/1737/n1/all/v/2266/p/all\"\n",
    "    indices_mensais = {}\n",
    "\n",
    "    response = requests.get(url_ipca_completo)\n",
    "    if response.status_code == 200:\n",
    "        print('Requisição realizada com sucesso!')\n",
    "    response.raise_for_status()\n",
    "\n",
    "    dados_ipca = json.loads(response.content)\n",
    "    indices_ipca = dados_ipca[0]['resultados'][0].get('series')[0].get('serie')\n",
    "    print(f'{len(indices_ipca)} índices IPCA mensais extraídos do IBGE')\n",
    "\n",
    "    # Cria uma lista de tuplas a partir dos itens do dicionário\n",
    "    lista_dados = list(indices_ipca.items())\n",
    "\n",
    "    # Cria o DataFrame\n",
    "    df = pd.DataFrame(lista_dados, columns=[\"AnoMes\", \"Valor\"])    \n",
    "\n",
    "    # 1. Converter a coluna `Valor` para o tipo numérico\n",
    "    df['Valor'] = pd.to_numeric(df['Valor'])\n",
    "\n",
    "    # # Filtrar o DataFrame para o período desejado\n",
    "    # df = df[\n",
    "    #     (int(str(df['AnoMes'])[:4]) >= ano_inicio) & (int(str(df['AnoMes'])[:4]) <= ano_final)\n",
    "    # ]\n",
    "\n",
    "    # 2. Criar uma nova coluna `Ano` extraindo o ano da coluna `AnoMes`\n",
    "    df['Ano'] = df['AnoMes'].astype(str).str[:4].astype(int)\n",
    "\n",
    "    # 3. Calcular a variação percentual mensal do IPCA\n",
    "    df['InflacaoMensal'] = df['Valor'].pct_change() * -100\n",
    "    df['InflacaoMensal'] = df['InflacaoMensal'].fillna(0)\n",
    "\n",
    "    # 4. Calcular a inflação acumulada por ano\n",
    "    df_inflacao_anual = df.groupby('Ano')['InflacaoMensal'].sum().reset_index()\n",
    "    df_inflacao_anual = df_inflacao_anual.rename(columns={'InflacaoMensal': 'PerdaInflacao'})\n",
    "\n",
    "    # 5. Criar um dicionário com anos e correções\n",
    "    anos = df_inflacao_anual['Ano'].unique().tolist()\n",
    "    correcoes_salariais_lista = [0 for x in anos]  # Lista de zeros por padrão\n",
    "    if reajustes_anuais:  # Verificar se a lista de reajustes não está vazia\n",
    "        correcoes_salariais_lista = reajustes_anuais[:len(anos)]  # Usar os reajustes fornecidos\n",
    "    correcoes_salariais = dict(zip(anos, correcoes_salariais_lista))\n",
    "\n",
    "    # 6. Criar um DataFrame a partir das correções salariais\n",
    "    df_salarios = pd.DataFrame(list(correcoes_salariais.items()), columns=['Ano', 'CorrecaoSalarial'])\n",
    "\n",
    "    # 7. Fazer o merge entre os DataFrames\n",
    "    df_merged = df_inflacao_anual.merge(df_salarios, on='Ano', how='left')\n",
    "\n",
    "    # 8. Preencher os valores NaN da coluna 'CorrecaoSalarial' com 0\n",
    "    df_merged['CorrecaoSalarial'] = df_merged['CorrecaoSalarial'].fillna(0)\n",
    "\n",
    "    # 9. Calcular a diferença acumulada entre a correção salarial e a perda por inflação\n",
    "    df_merged['SaldoAcumulado'] = (df_merged['CorrecaoSalarial'] - df_merged['PerdaInflacao']).cumsum()\n",
    "\n",
    "    # Filtrar o DataFrame para o período desejado\n",
    "    df_merged_filtrado = df_merged[\n",
    "        (df_merged['Ano'] >= ano_inicio) & (df_merged['Ano'] <= ano_final)\n",
    "    ]\n",
    "\n",
    "    # Zerar o saldo acumulado no ano de início\n",
    "    df_merged_filtrado.loc[df_merged_filtrado['Ano'] == ano_inicio, 'SaldoAcumuladoAjustado'] = 0\n",
    "\n",
    "    # 10. Calcular o valor absoluto máximo para definir o domínio do eixo y principal e secundário\n",
    "    max_abs_valor = max(\n",
    "        df_merged_filtrado['PerdaInflacao'].abs().max(),\n",
    "        df_merged_filtrado['CorrecaoSalarial'].abs().max(),\n",
    "        df_merged_filtrado['SaldoAcumulado'].abs().max()\n",
    "    )\n",
    "\n",
    "    # Preparar os dados para o gráfico de barras\n",
    "    df_barras = df_merged_filtrado.melt(id_vars='Ano', value_vars=['PerdaInflacao', 'CorrecaoSalarial'], var_name='Tipo', value_name='Valor')\n",
    "\n",
    "    # Calcular o valor absoluto máximo para definir o domínio do eixo y principal\n",
    "    max_abs_valor_barras = max(df_merged_filtrado['PerdaInflacao'].abs().max(), df_merged_filtrado['CorrecaoSalarial'].abs().max())\n",
    "\n",
    "    # Calcular o valor mínimo e máximo do SaldoAcumulado para definir o domínio do eixo y da linha\n",
    "    min_saldo_acumulado = df_merged_filtrado['SaldoAcumulado'].min()\n",
    "    max_saldo_acumulado = df_merged_filtrado['SaldoAcumulado'].max()\n",
    "\n",
    "    # Criar o gráfico de barras\n",
    "    barras = alt.Chart(df_barras).mark_bar().encode(\n",
    "        x=alt.X('Ano:O', axis=alt.Axis(labelAngle=-45)),\n",
    "        y=alt.Y('Valor:Q', axis=alt.Axis(title='Variação (%)', titleColor='black'), scale=alt.Scale(domain=[-max_abs_valor_barras, max_abs_valor_barras])),\n",
    "        color=alt.Color('Tipo:N', scale={'domain': ['PerdaInflacao', 'CorrecaoSalarial'], 'range': ['red', 'steelblue']}),\n",
    "        tooltip=['Ano', 'Valor', 'Tipo']\n",
    "    ).properties(\n",
    "        title='Perda por Inflação, Reposição Salarial e Saldo Acumulado'\n",
    "    )\n",
    "\n",
    "    # Adicionar os rótulos às barras\n",
    "    text = barras.mark_text(\n",
    "        align='center',\n",
    "        baseline='bottom',\n",
    "        dy=-5\n",
    "    ).encode(\n",
    "        text=alt.Text('Valor:Q', format='.2f')\n",
    "    )\n",
    "\n",
    "    # Criar o gráfico de linha para o saldo acumulado (eixo secundário)\n",
    "    linha = alt.Chart(df_merged_filtrado).mark_line(color='green', point=True).encode(\n",
    "        x='Ano:O',\n",
    "        y=alt.Y('SaldoAcumulado:Q', axis=alt.Axis(title='Saldo Acumulado (%)', titleColor='green'), scale=alt.Scale(domain=[min_saldo_acumulado, max_saldo_acumulado])),\n",
    "        tooltip=['Ano', 'SaldoAcumulado']\n",
    "    )\n",
    "\n",
    "    # Adicionar rótulos de dados à linha\n",
    "    text_linha = linha.mark_text(\n",
    "        align='left',\n",
    "        baseline='middle',\n",
    "        dx=5,  # Nudge text to right so it doesn't overlap with the line\n",
    "        color='black'\n",
    "    ).encode(\n",
    "        text=alt.Text('SaldoAcumulado:Q', format='.2f')\n",
    "    )\n",
    "\n",
    "    # Combinar os gráficos com os rótulos\n",
    "    grafico_final = alt.layer(barras + text, linha + text_linha).resolve_scale(\n",
    "        y='independent'\n",
    "    ).interactive()\n",
    "\n",
    "\n",
    "    grafico_final = grafico_final.properties(\n",
    "        height=600,  # Largura de 800 pixels\n",
    "        width=1100  # Largura de 1200 pixels\n",
    "    )\n",
    "\n",
    "    return df_merged, grafico_final\n",
    "\n",
    "# Exemplo de uso\n",
    "ano_inicio = 2003\n",
    "ano_final = 2023\n",
    "reajustes_anuais = [2.5, 3.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0, 10.5, 11.0, 11.5, 12.0, 12.5, 13.0, 13.5]  # Exemplo de reajustes\n",
    "\n",
    "df_merged, grafico_final = plotar_perdas(ano_inicio, ano_final, reajustes_anuais)\n",
    "grafico_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.renderers.enable('jupyterlab')\n",
    "grafico_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a coluna `Valor` para o tipo numérico\n",
    "df['Valor'] = pd.to_numeric(df['Valor'])\n",
    "\n",
    "# Extrair o ano da coluna `AnoMes`\n",
    "df['Ano'] = df['AnoMes'].astype(str).str[:4].astype(int)\n",
    "\n",
    "# Filtrar para manter apenas os meses de dezembro\n",
    "df_dezembro = df[df['AnoMes'].astype(str).str[-2:] == '12'].copy()\n",
    "\n",
    "# Agrupar por ano e selecionar o primeiro valor de cada ano\n",
    "df_anual = df_dezembro.groupby('Ano')['Valor'].first().reset_index()\n",
    "\n",
    "# Obter o ano de início e o ano de término do usuário\n",
    "ano_inicio = int(input(\"Digite o ano de início: \"))\n",
    "ano_termino = int(input(\"Digite o ano de término: \"))\n",
    "\n",
    "# Filtrar para o período desejado\n",
    "df_periodo = df_anual[(df_anual['Ano'] >= ano_inicio) & (df_anual['Ano'] <= ano_termino)]\n",
    "\n",
    "# Calcular a variação acumulada do IPCA\n",
    "variacao_acumulada = (df_periodo['Valor'].iloc[-1] / df_periodo['Valor'].iloc[0] - 1) * 100\n",
    "\n",
    "# Calcular a taxa anual equivalente\n",
    "num_anos = ano_termino - ano_inicio + 1\n",
    "taxa_anual = ((1 + variacao_acumulada / 100) ** (1 / num_anos) - 1) * 100\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(f'Variação acumulada do IPCA de {ano_inicio} a {ano_termino}: {variacao_acumulada:.2f}%')\n",
    "print(f'Taxa anual equivalente: {taxa_anual:.2f}%')\n",
    "\n",
    "# Filtrar para o período desejado\n",
    "df_periodo = df_anual[(df_anual['Ano'] >= ano_inicio) & (df_anual['Ano'] <= ano_termino)]\n",
    "\n",
    "# Calcular a variação acumulada do IPCA\n",
    "variacao_acumulada = (df_periodo['Valor'].iloc[-1] / df_periodo['Valor'].iloc[0] - 1) * 100\n",
    "\n",
    "# Calcular a taxa anual equivalente\n",
    "num_anos = ano_termino - ano_inicio + 1\n",
    "taxa_anual = ((1 + variacao_acumulada / 100) ** (1 / num_anos) - 1) * 100\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(f'Variação acumulada do IPCA de {ano_inicio} a {ano_termino}: {variacao_acumulada:.2f}%')\n",
    "print(f'Taxa anual equivalente: {taxa_anual:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a coluna `Valor` para o tipo numérico\n",
    "df['Valor'] = pd.to_numeric(df['Valor'])\n",
    "\n",
    "# Extrair o ano da coluna `AnoMes`\n",
    "df['Ano'] = df['AnoMes'].astype(str).str[:4].astype(int)\n",
    "\n",
    "# Filtrar para manter apenas os meses de dezembro\n",
    "df_dezembro = df[df['AnoMes'].astype(str).str[-2:] == '12'].copy()\n",
    "\n",
    "# Agrupar por ano e selecionar o primeiro valor de cada ano\n",
    "df_anual = df_dezembro.groupby('Ano')['Valor'].first().reset_index()\n",
    "\n",
    "# Obter o ano de início e o ano de término do usuário\n",
    "ano_inicio = int(input(\"Digite o ano de início: \"))\n",
    "ano_termino = int(input(\"Digite o ano de término: \"))\n",
    "\n",
    "# Filtrar para o período desejado\n",
    "df_periodo = df_anual[(df_anual['Ano'] >= ano_inicio) & (df_anual['Ano'] <= ano_termino)]\n",
    "\n",
    "# Calcular a variação acumulada do IPCA\n",
    "variacao_acumulada = (df_periodo['Valor'].iloc[-1] / df_periodo['Valor'].iloc[0] - 1) * 100\n",
    "\n",
    "# Calcular a taxa anual equivalente\n",
    "num_anos = ano_termino - ano_inicio + 1\n",
    "taxa_anual = ((1 + variacao_acumulada / 100) ** (1 / num_anos) - 1) * 100\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(f'Variação acumulada do IPCA de {ano_inicio} a {ano_termino}: {variacao_acumulada:.2f}%')\n",
    "print(f'Taxa anual equivalente: {taxa_anual:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "# Criar um DataFrame com os dados de reposição salarial\n",
    "df_reposicao = df_merged[['Ano', 'CorrecaoSalarial']].rename(columns={'CorrecaoSalarial': 'Valor'})\n",
    "df_reposicao['Tipo'] = 'Reposição Salarial'\n",
    "\n",
    "# Criar um DataFrame com os dados de perda por inflação\n",
    "df_perda_inflacao = df_merged[['Ano', 'InflacaoPercentual']].rename(columns={'InflacaoPercentual': 'Valor'})\n",
    "df_perda_inflacao['Valor'] = -df_perda_inflacao['Valor']  # Inverter os valores para ficarem negativos\n",
    "df_perda_inflacao['Tipo'] = 'Perda por Inflação'\n",
    "\n",
    "# Concatenar os DataFrames de reposição e perda\n",
    "df_plot = pd.concat([df_reposicao, df_perda_inflacao])\n",
    "\n",
    "# Calcular o valor absoluto máximo para definir o domínio do eixo y principal\n",
    "max_abs_valor = df_plot['Valor'].abs().max()\n",
    "\n",
    "# Criar o gráfico de barras\n",
    "barras = alt.Chart(df_plot).mark_bar().encode(\n",
    "    x=alt.X('Ano:O', axis=alt.Axis(labelAngle=-45)),\n",
    "    y=alt.Y('Valor:Q', scale=alt.Scale(domain=[-max_abs_valor, max_abs_valor])),  # Ajustar escala y\n",
    "    color=alt.Color('Tipo:N', scale={'domain': ['Perda por Inflação', 'Reposição Salarial'], 'range': ['red', 'steelblue']}),\n",
    "    tooltip=['Ano', 'Valor', 'Tipo']\n",
    ").properties(\n",
    "    title='Reposição Salarial, Perda por Inflação e Saldo Acumulado'\n",
    ")\n",
    "\n",
    "# Adicionar os rótulos às barras\n",
    "text = barras.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=-5  # Nudge text upwards so it doesn't overlap with the bar\n",
    ").encode(\n",
    "    text=alt.Text('Valor:Q', format='.2f')\n",
    ")\n",
    "\n",
    "# Criar o gráfico de linha para o saldo acumulado (eixo secundário)\n",
    "linha = alt.Chart(df_merged).mark_line(color='green', point=True).encode(\n",
    "    x='Ano:O',\n",
    "    y=alt.Y('DiferencaAcumulada:Q', axis=alt.Axis(title='Saldo Acumulado', titleColor='green')),\n",
    "    tooltip=['Ano', 'DiferencaAcumulada']\n",
    ")\n",
    "\n",
    "# Combinar os gráficos\n",
    "grafico_final = alt.layer(barras + text, linha).resolve_scale(\n",
    "    y = 'independent'\n",
    ").interactive()\n",
    "\n",
    "# Exibir o gráfico\n",
    "grafico_final\n",
    "\n",
    "grafico_final = grafico_final.properties(\n",
    "    height=600,  # Largura de 800 pixels\n",
    "    width=1100  # Largura de 1200 pixels\n",
    ")\n",
    "# Salve o gráfico em um arquivo JSON\n",
    "grafico_final.save('grafico_perda_ganho_poder_compra.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.renderers.enable('jupyterlab')\n",
    "grafico_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(indices_ipca.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dados_ipca[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "from io import BytesIO, TextIOWrapper\n",
    "\n",
    "url_tab_var = \"https://apisidra.ibge.gov.br/values/t/1737/n1/all/v/2266/p/all\"\n",
    "indices_mensais = {}\n",
    "\n",
    "response = requests.get(url_tab_var)\n",
    "response.raise_for_status()\n",
    "\n",
    "meses=[]\n",
    "indices=[]\n",
    "\n",
    "# Ler o CSV com TextIOWrapper para converter bytes em strings\n",
    "with TextIOWrapper(BytesIO(response.content), encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\";\")\n",
    "\n",
    "    # Extrair dados relevantes e construir dicionário\n",
    "    for row in reader:\n",
    "        print(row)\n",
    "        if \"D3C\" in row:\n",
    "            meses.append(row)\n",
    "        if \"V\" in row:\n",
    "            indices.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(meses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sidrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sidrapy\n",
    "\n",
    "# Importa os dados do SIDRA\n",
    "ipca_raw = sidrapy.get_table(table_code= \"1737\",\n",
    "                            territorial_level = \"1\",\n",
    "                            ibge_territorial_code = \"all\",\n",
    "                            period = \"all\",\n",
    "                            )\n",
    "\n",
    "# Checamos a importação\n",
    "ipca_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Converter a coluna D3C para numérico, ignorando valores não numéricos\n",
    "ipca_raw['D3C'] = pd.to_numeric(ipca_raw['D3C'], errors='coerce')\n",
    "\n",
    "# Filtrar as linhas onde D3C é igual a 2265\n",
    "filtro = ipca_raw['D3C'] == 2265\n",
    "ipca_filtrado = ipca_raw[filtro]\n",
    "\n",
    "ipca_filtrado[[\"V\",\"D2C\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sidrapy\n",
    "\n",
    "# Importa os dados do SIDRA\n",
    "pib_sa_raw = sidrapy.get_table(table_code= \"1621\",\n",
    "                            territorial_level = \"1\",\n",
    "                            ibge_territorial_code = \"all\",\n",
    "                            period = \"all\",\n",
    "                            classification = \"11255/90707\")\n",
    "\n",
    "# Checamos a importação\n",
    "pib_sa_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poder_compra import IPCAData\n",
    "\n",
    "ipca = IPCAData()\n",
    "meses, indices = ipca.obter_numeros_indice()\n",
    "for i, j in zip(meses, indices):\n",
    "    print(i,j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "a,b = indices[3].split(\": \")\n",
    "{a.replace(\"\\\"\",\"\"): (b.replace(\"\\\"\",\"\").replace(\",\",\"\"))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.replace(\"\\\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(b.replace(\"\\\"\",\"\").replace(\",\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair dados relevantes e construir dicionário\n",
    "for row in reader:\n",
    "    if row[2] == \"MN\" and row[1] == \"Número-índice\":\n",
    "        data = row[4270].replace(\" \", \"-\") \n",
    "        valor = float(row[3].replace(\",\", \".\"))\n",
    "        indices_mensais[data] = valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_mensais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poder_compra import IPCAData\n",
    "\n",
    "ipca_data = IPCAData()\n",
    "poder_compra = PoderCompra(ipca_data.dados_ipca)\n",
    "perdas = poder_compra.calcular_perdas()\n",
    "\n",
    "previsao = PrevisaoInflacao(ipca_data.dados_ipca)\n",
    "inflacao_futura = previsao.prever()\n",
    "\n",
    "Visualizacao.plotar_evolucao_poder_compra(ipca_data.dados_ipca, perdas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
