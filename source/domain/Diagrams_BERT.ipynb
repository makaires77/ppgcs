{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representação da implementação da Arquitetura BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR\n",
    "    subgraph Input [Inputs]\n",
    "    end\n",
    "\n",
    "    subgraph Embeddings [\"Input Embedding\"]\n",
    "        word_embeddings([\"word_embeddings\"]) \n",
    "        position_embeddings([\"position_embeddings\"])\n",
    "        token_type_embeddings([\"token_type_embeddings\"]) \n",
    "        LayerNorm([\"LayerNorm\"])\n",
    "        Dropout([\"Dropout\"])\n",
    "    end\n",
    "\n",
    "    subgraph Encoder [Encoder]\n",
    "        subgraph BertLayersEncoder[6 x BertLayer]\n",
    "            subgraph BertAttention\n",
    "                subgraph BertSelfAttention\n",
    "                    query([\"Query Linear\"])\n",
    "                    key([\"Key Linear\"])\n",
    "                    value([\"Value Linear\"])\n",
    "                    Dropout_self_attention([\"Dropout Self Attention\"])\n",
    "                end\n",
    "                subgraph BertSelfOutput\n",
    "                    dense_self_output([\"Linear Dense\"])\n",
    "                    LayerNorm_self_output([\"Layer Norm\"])\n",
    "                    Dropout_self_output([\"Dropout Self Output\"])\n",
    "                end\n",
    "            end\n",
    "            subgraph BertIntermediate\n",
    "                dense_intermediate([\"LinearDense\"])\n",
    "                intermediate_act_fn([\"GELUActivation\"])\n",
    "            end\n",
    "            subgraph BertOutput\n",
    "                dense_output([\"Dense Linear Output\"])\n",
    "            end\n",
    "            subgraph LayerNorm e Dropout\n",
    "                LayerNorm_output([\"LayerNorm Output\"])\n",
    "                Dropout_bert_output([\"Dropout Output\"])                \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    subgraph Decoder [Decoder]\n",
    "        subgraph BertLayersDecoder[6 x BertLayer]\n",
    "            subgraph BertAttentionDecoder\n",
    "                subgraph BertSelfAttentionDecoder\n",
    "                    query([\"Query Linear\"])\n",
    "                    key([\"Key Linear\"])\n",
    "                    value([\"Value Linear\"])\n",
    "                    Dropout_self_attention([\"Dropout Self Attention\"])\n",
    "                end\n",
    "                subgraph BertSelfOutputDecoder\n",
    "                    dense_self_output([\"Linear Dense\"])\n",
    "                    LayerNorm_self_output([\"Layer Norm\"])\n",
    "                    Dropout_self_output([\"Dropout Self Output\"])\n",
    "                end\n",
    "            end\n",
    "            subgraph BertIntermediateDecoder\n",
    "                dense_intermediate([\"LinearDense\"])\n",
    "                intermediate_act_fn([\"GELUActivation\"])\n",
    "            end\n",
    "            subgraph BertOutputDecoder\n",
    "                dense_output([\"Dense Linear Output\"])\n",
    "            end\n",
    "            subgraph LayerNorm e Dropout Decoder\n",
    "                LayerNorm_output([\"LayerNorm Output\"])\n",
    "                Dropout_bert_output([\"Dropout Output\"])                \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    subgraph Saídas\n",
    "        attentions\n",
    "        pooler_output\n",
    "        hidden_states\n",
    "        last_hidden_state\n",
    "    end\n",
    "\n",
    "    subgraph Pooler [Optional Pooler]\n",
    "        dense_pooler( Linear )\n",
    "        activation( Tanh )\n",
    "        output( pooler_output )\n",
    "    end\n",
    "\n",
    "    Input --> Embeddings\n",
    "    Embeddings --> Encoder\n",
    "    Encoder --> Decoder\n",
    "    Encoder -.- Pooler\n",
    "    Decoder --> Saídas\n",
    "\n",
    "    word_embeddings -.- position_embeddings\n",
    "    position_embeddings -.- token_type_embeddings\n",
    "    token_type_embeddings -.- LayerNorm \n",
    "    LayerNorm -.- Dropout\n",
    "    \n",
    "    attentions -.- pooler_output\n",
    "    pooler_output -.- hidden_states\n",
    "    hidden_states -.- last_hidden_state    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR\n",
    "    subgraph Input [Input]\n",
    "    end\n",
    "\n",
    "    subgraph Embeddings\n",
    "        word_embeddings([\"word_embeddings\"]) \n",
    "        position_embeddings([\"position_embeddings\"])\n",
    "        token_type_embeddings([\"token_type_embeddings\"]) \n",
    "        LayerNorm([\"LayerNorm\"])\n",
    "        Dropout([\"Dropout\"])\n",
    "    end\n",
    "\n",
    "    subgraph Encoder [Encoder]\n",
    "        BertLayers[12 x BertLayer]\n",
    "    end\n",
    "\n",
    "    subgraph Pooler [Pooler]\n",
    "        dense_pooler( Linear )\n",
    "        activation( Tanh )\n",
    "    end\n",
    "\n",
    "    subgraph BertLayer\n",
    "        BertAttention\n",
    "        BertIntermediate\n",
    "        BertOutput\n",
    "        LayerNorm_output([\"LayerNorm\"])\n",
    "        Dropout_output([\"Dropout\"])\n",
    "    end\n",
    "\n",
    "    subgraph BertAttention\n",
    "        BertSelfAttention\n",
    "        BertSelfOutput\n",
    "    end\n",
    "\n",
    "    subgraph BertSelfAttention\n",
    "        query([\"Linear\"])\n",
    "        key([\"Linear\"])\n",
    "        value([\"Linear\"])\n",
    "        Dropout_self_attention([\"Dropout\"])\n",
    "    end\n",
    "\n",
    "    subgraph BertSelfOutput\n",
    "        dense_self_output([\"Linear\"])\n",
    "        LayerNorm_self_output([\"LayerNorm\"])\n",
    "        Dropout_self_output([\"Dropout\"])\n",
    "    end\n",
    "\n",
    "    subgraph BertIntermediate\n",
    "        dense_intermediate([\"Linear\"])\n",
    "        intermediate_act_fn(( GELUActivation ))\n",
    "    end\n",
    "\n",
    "    subgraph BertOutput\n",
    "        dense_output([\"Linear\"])\n",
    "        LayerNorm_output([\"LayerNorm\"])\n",
    "        Dropout_bert_output([\"Dropout\"])\n",
    "    end\n",
    "\n",
    "    Input --> Embeddings\n",
    "    Embeddings --> Encoder\n",
    "    Encoder --> Pooler\n",
    "    Pooler --> BertOutput(( pooler_output )) \n",
    "    Encoder --> last_hidden_state(( last_hidden_state ))\n",
    "\n",
    "    BertLayers --> BertLayer\n",
    "    BertLayer --> BertAttention\n",
    "    BertAttention --> BertSelfAttention\n",
    "    BertSelfAttention --> BertSelfOutput\n",
    "    BertAttention -.-> BertSelfOutput  \n",
    "    BertSelfOutput --> BertOutput\n",
    "    BertLayer -.-> BertOutput \n",
    "    BertOutput --> LayerNorm_output\n",
    "    LayerNorm_output --> Dropout_output\n",
    "    Dropout_output --> BertLayer \n",
    "    BertLayer --> BertIntermediate\n",
    "    BertIntermediate --> GELUActivation\n",
    "    BertIntermediate --> BertOutput\n",
    "    BertSelfAttention --> query\n",
    "    BertSelfAttention --> key\n",
    "    BertSelfAttention --> value\n",
    "    BertSelfAttention --> Dropout_self_attention\n",
    "    BertOutput --> dense_output\n",
    "    BertOutput --> LayerNorm_output\n",
    "    LayerNorm_output --> Dropout_bert_output\n",
    "\n",
    "    %% Embeddings - vertical arrangement\n",
    "    word_embeddings --> position_embeddings\n",
    "    position_embeddings --> token_type_embeddings\n",
    "    token_type_embeddings --> LayerNorm\n",
    "    LayerNorm --> Dropout\n",
    "\n",
    "    %% BertLayer Outputs\n",
    "    BertLayer --> hidden_states(( hidden_states ))\n",
    "    BertAttention --> attentions(( attentions ))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
