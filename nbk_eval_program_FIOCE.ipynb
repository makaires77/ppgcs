{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b48e5c3",
   "metadata": {},
   "source": [
    "## <center>Avaliação regular perfil docente dos<br /> Programas de Pós-graduação da Fiocruz Ceará</center>\n",
    "\n",
    "    Antonio Marcos Aires Barbosa – Fiocruz Ceará\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "    Reavaliação de meio termo do corpo docente do programa, a fim de acompanhar a manutenção dos parâmetros exigidos pela CAPES – Área de ?????? e readequar a composição do grupo. São considerados os docentes permanentes (DP) e docentes colaboradores (DC), com base nos mesmos parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e961c",
   "metadata": {},
   "source": [
    "# Definir Indicadores para Programas Fiocruz Ceará"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c3005",
   "metadata": {},
   "source": [
    "## Indicadores\n",
    "### 1. Pontuação por Fator de Impacto\n",
    "- Meta: PFI >= 600 em pelo menos 70% dos docentes\n",
    "\n",
    "    Indicador: Total de pontos conforme periódicos das publicações no período\n",
    "     Objetivo: Publicar trabalhos em periódicos de elevado impacto\n",
    "               \n",
    "         Meta: 70% dos docentes permanentes com PFI >= 600 pontos no quadriênio\n",
    "               (150/ano e ao menos 03 artigos A, no mínimo 02 em A1, ou 04 artigos A2);\n",
    " \n",
    "      Cálculo: Soma ponderada pela estratificação Qualis de acordo com o que segue:\n",
    "        A1 = 100 pontos\n",
    "        A2 = 80 pontos\n",
    "        B1 = 60 pontos\n",
    "        B2 = 40 pontos\n",
    "        B3 = 20 pontos\n",
    "        B4 = 10 pontos\n",
    "        B5 = 2 pontos.\n",
    "\n",
    "\n",
    "Parâmetro para classificaçao do periódico:\n",
    "\n",
    "        A1: FI Periódico ou CPD >= 4,300\n",
    "        A2: FI Periódico ou CPD entre 2,950 e 4,299\n",
    "        B1: FI Periódico ou CPD entre 1,800 e 2,949\n",
    "        B2: FI Periódico ou CPD entre 1,100 e 1,799\n",
    "        B3: FI Periódico ou CPD entre 0,300 e 1,099\n",
    "        B4: FI Periódico ou CPD entre 0,001 e 0,299, (ou Scielo, Scimago, PubMed ou Web of Science)\n",
    "        B5: Periódicos sem FI ou CPD e indexado nas lases Lilacs ou Latindex    \n",
    "\n",
    "### 2. Índice de Produção Conjunta dos docentes com discentes (IPC >= 50%):\n",
    "    Indicador: Índice de publicações com discentes por orientador (IPC)\n",
    "     Objetivo: Em, pelo menos, 50 % dos artigos publicados deve constar discentes do programa\n",
    "         Meta: IPC >= 50,00\n",
    "      \n",
    "      Cálculo:\n",
    "\n",
    "$$\\sum_{k=1}^{n}\\, 100 * \\frac{QPCD}{QPAT}$$\n",
    "\n",
    "        onde:\n",
    "               n = Artigos completos publicado em periódicos indexados\n",
    "            QPCD = Qte. Publicação de Artigos com discentes do Programa na lista de autores\n",
    "            QPAT = Qte. Publicação de Artigos Total no período avaliado\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3cf167",
   "metadata": {},
   "source": [
    "# <b>F00: Preparar Ambiente e pastas locais</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed4cec7",
   "metadata": {},
   "source": [
    "#### Instalar Git, WSL, amb.virtual ou Contêiner Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc48fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instalar o WSL e integrar ao VSCode, no terminal rodar:\n",
    "## Verificar versões já instaladas\n",
    "#wsl -l -v\n",
    "## Atualizar para WSL2 para que as instalações de distros já rodem em WSL2 por padrão\n",
    "#wsl --set-default-version 2\n",
    "## Reiniciar a máquina e instalar distribuição Linux Ubuntu LTS pelo store do windows\n",
    "## Configurar VScode: iniciar VScode e instalar a extensão \"Remote - WSL\" para desenvolver diretamente no VSCode dentro do ambiente do WSL.\n",
    "# Após a instalação, na parte inferior esquerda da janela do VSCode, aparecerá o ícone verde.\n",
    "# Clicar no ícone verde e selecionar \"New WSL Window\" ou \"Reopen in WSL\" se o projeto já estiver aberto.\n",
    "# Agora, o VSCode estará rodando dentro do contexto do seu WSL, pode-se abrir terminais dentro do VSCode que acessarão diretamente o Linux.\n",
    "\n",
    "## Instalar Python e o Pip:\n",
    "# sudo apt update\n",
    "# sudo apt install python3-pip\n",
    "\n",
    "## Inserir dados do Git no VScode, no terminal rodar:\n",
    "# git config --global user.name \"nome_usuario_gi\"\n",
    "# git config --global user.email \"email_git\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f72ab53",
   "metadata": {},
   "source": [
    "#### Instalar gerenciador e pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3348635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intalar os gerenciador de pacotes PIP  no terminal do WSL executar:\n",
    "# sudo apt update\n",
    "# sudo apt upgrade\n",
    "# sudo apt install python3-pip\n",
    "# python3 -m pip install --upgrade pip\n",
    "\n",
    "## Atualizar o gerenciador de pacotes e ferramentas de compilação\n",
    "# %pip install --upgrade pip setuptools wheel\n",
    "\n",
    "## Instalar primeiro o GraphViz antes do ygraphviz, no terminal do WSL rodar e depois reiniciar o kernel:\n",
    "## Para Linux e WSL instalar a partir do terminal:\n",
    "# sudo apt-get install graphviz graphviz-dev\n",
    "\n",
    "## Para Windows, atualizar o gerenciador de pacotes e ferramentas de compilação:\n",
    "# %pip install --upgrade pip setuptools wheel\n",
    "\n",
    "## Instalar o Chocolatey (Só para Windows, não no WSL)\n",
    "## Baixar e instalar o gerenciador chocolatey em https://jcutrer.com/windows/install-chocolatey-choco-windows10\n",
    "# Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\n",
    "\n",
    "## Baixar e instalar o Graphviz em https://www.graphviz.org/download/\n",
    "## https://savleen307.medium.com/pygraphviz-installation-in-windows-f45cc6fed981\n",
    "## Seguir as instruções em https://pygraphviz.github.io/documentation/stable/install.html#id1\n",
    "# O comando na página acima está errado por conter duas aspas onde não deve, executar o comando abaixo:\n",
    "# python -m pip install --use-pep517 --config-settings=\"--global-option=build_ext\" --config-settings=\"--global-option=-IC:\\Program Files\\Graphviz\\include\" --config-settings=--global-option=\"-LC:\\Program Files\\Graphviz\\lib\" pygraphviz\n",
    "\n",
    "## Instalar o pacote no ambiente local\n",
    "# %pip install pygraphviz\n",
    "\n",
    "## Para instalar o Conda (Miniconda ou Anaconda) no WSL, baixar o script de instalação diretamente do site oficial e executá-lo manualmente.\n",
    "## Passos para instalar o Miniconda como exemplo:\n",
    "## Baixar script de instalação do Miniconda para Linux:\n",
    "# wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "# bash Miniconda3-latest-Linux-x86_64.sh\n",
    "# conda --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af3065f",
   "metadata": {},
   "source": [
    "#### Instalar requirements.txt e importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25a9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Localizar requirements.txt para instalar bibliotecas no ambente\n",
    "# os.listdir('./../../../../')\n",
    "# %pip install -r ./../../../../requirements.txt\n",
    "\n",
    "## Outras instalações pontuais quando necessário, por exemplo:\n",
    "# import os, tqdm\n",
    "# %pip install chardet\n",
    "# print(tqdm.__version__)\n",
    "# %pip3 install --upgrade plotly\n",
    "# %pip3 install omegaconf --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87ef1b",
   "metadata": {},
   "source": [
    "#### Instalar e configurar GPU e CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2bc898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instalar drivers da GPU e compilador CUDA Nvidia\n",
    "## Obter comandos adequados para cada sistema em: https://developer.nvidia.com/cuda-downloads\n",
    "## Exemplo para Linux com Ubuntu\n",
    "# wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin\n",
    "# sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "# wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda-repo-wsl-ubuntu-12-4-local_12.4.0-1_amd64.deb\n",
    "# sudo dpkg -i cuda-repo-wsl-ubuntu-12-4-local_12.4.0-1_amd64.deb\n",
    "# sudo cp /var/cuda-repo-wsl-ubuntu-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/\n",
    "# sudo apt-get update\n",
    "# sudo apt-get -y install cuda-toolkit-12-4\n",
    "\n",
    "## Instruções para instalação do PyTorch para usar a GPU em Windows\n",
    "# https://sh-tsang.medium.com/tutorial-cuda-cudnn-anaconda-jupyter-pytorch-installation-in-windows-10-96b2a2f0ac57\n",
    "\n",
    "## Para máquinas com apenas CPU\n",
    "# !pip install torch torchvision\n",
    "\n",
    "## Testar cálculo na GPU\n",
    "# import torch\n",
    "# x = torch.rand(5, 3)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e551ffdc",
   "metadata": {},
   "source": [
    "#### Implementar classes para obter e preparar dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c921ae65",
   "metadata": {},
   "source": [
    "    LattesScraper (Extrair currículos Lattes)\n",
    "    SoupParser (Extrair dados de Objeto Soup)\n",
    "    Neo4jPersister (Persistir em Neo4j)\n",
    "    DatasetArticlesGenerator (Gerar Datasets)\n",
    "    DictToHDF5 (converter dicionários para HDF5)\n",
    "    ArticlesCounter (Montar qte artigos e atualização)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f6e3cb",
   "metadata": {},
   "source": [
    "#### Gerar pastas e classes de processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edfd06ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd, os, re, sys, time, json, subprocess\n",
    "\n",
    "## Configurar exibição do pandas para melhor visualizar os dados\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('colheader_justify', 'left')\n",
    "pd.set_option('display.max_rows', 600)\n",
    "\n",
    "def find_repo_root(path='.', depth=10):\n",
    "    ''' \n",
    "    Busca o arquivo .git e retorna string com a pasta raiz do repositório\n",
    "    '''\n",
    "    # Prevent infinite recursion by limiting depth\n",
    "    if depth < 0:\n",
    "        return None\n",
    "    path = Path(path).absolute()\n",
    "    if (path / '.git').is_dir():\n",
    "        return path\n",
    "    return find_repo_root(path.parent, depth-1)\n",
    "\n",
    "delay = 10\n",
    "\n",
    "## Definir a pasta de base do repositório local\n",
    "base_repo_dir = find_repo_root()\n",
    "\n",
    "## Sempre construir os caminhos usando os.path.join para compatibilidade WxL\n",
    "folder_utils = os.path.join(base_repo_dir, 'utils')\n",
    "folder_domain = os.path.join(base_repo_dir, 'source', 'domain')\n",
    "folder_data_input = os.path.join(base_repo_dir, '_data', 'in_csv')\n",
    "folder_data_output = os.path.join(base_repo_dir, '_data', 'out_json')\n",
    "\n",
    "## Adicionar pastas locais ao sys.path para importar pacotes criados localmente\n",
    "sys.path.append(folder_utils)\n",
    "sys.path.append(folder_domain)\n",
    "# from scraper_pasteur import PasteurScraper\n",
    "# from scraper_sucupira import SucupiraScraper\n",
    "# from scraper_sucupira_edge import SucupiraScraperEdge\n",
    "from environment_setup import EnvironmentSetup\n",
    "from chromedriver_manager import ChromeDriverManager\n",
    "from neo4j_persister import Neo4jPersister\n",
    "from lattes_scrapper import JSONFileManager, LattesScraper, HTMLParser, SoupParser, GetQualis, ArticlesCounter, DictToHDF5, attribute_to_be_non_empty\n",
    "\n",
    "t00 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff45fefc",
   "metadata": {},
   "source": [
    "### Checar Chromedriver e GoogleChrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71efa162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versões 125 Chrome e 125 Chromedriver estão compatíveis\n"
     ]
    }
   ],
   "source": [
    "# Cria instância da classe ChromeDriverManager e verifica compatibilidade entre versões do Chrome e Chromedriver\n",
    "actualizer = ChromeDriverManager()\n",
    "actualizer.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3962aad",
   "metadata": {},
   "source": [
    "### Obter Qualis Periódicos Plataforma Sucupira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d03c0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sucupira = SucupiraScraperEdge()\n",
    "# sucupira.scrape_sucupira()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb1692",
   "metadata": {},
   "source": [
    "# <b>F01: Obter dados de Docentes</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd18ddb",
   "metadata": {},
   "source": [
    "## Rodar testes e definir pastas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b06c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary directories are ensured.\n",
      "Processador em uso: \n",
      "Arquitetura modelo: Intel64 Family 6 Model 158 Stepping 10, GenuineIntel\n",
      "Arquitetura em uso: 64bit\n",
      "Frequência das CPU: 3000.0 MHz\n",
      "  Qte CPUs físicas: 6\n",
      "  Qte CPUs lógicas: 6\n",
      "Carga total na CPU: 4.2%\n",
      "Ocupação atual CPU: user=1.8%, system=2.8%, idle=95.1%\n",
      "\n",
      "Espaço Total em disco: 475.78 GB\n",
      "Espaço em disco usado: 432.89 GB 91.0%\n",
      "Espaço em disco livre: 42.89 GB 9.0%\n",
      "\n",
      "Capacidade memórias RAM: 15.78 GB\n",
      "Utilização atual da RAM: 10.94 GB\n",
      "\n",
      "VERSÕES DOS DRIVERS CUDA, PYTORCH E GPU\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Wed_Jul_14_19:47:52_Pacific_Daylight_Time_2021\n",
      "Cuda compilation tools, release 11.4, V11.4.100\n",
      "Build cuda_11.4.r11.4/compiler.30188945_0\n",
      "\n",
      "    PyTorch: 1.12.1+cpu\n",
      "Dispositivo: cpu\n",
      "  ERRO!! Ao configurar a GPU: Torch not compiled with CUDA enabled \n",
      "\n",
      "\n",
      "VERSÕES DAS PRINCIPAIS BIBLIOTECAS INSTALADAS NO ENVIROMENT\n",
      "Ambiente Conda ativo: Python38-PyTorch\n",
      "Interpretador em uso: c:\\Users\\marcos.aires\\.conda\\envs\\Python38-PyTorch\\python.exe\n",
      " Python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)] \n",
      "    Pip: pip 24.0 from C:\\Users\\marcos.aires\\AppData\\Roaming\\Python\\Python38\\site-packages\\pip (python 3.8)\n",
      "\n",
      "\n",
      "Pasta para xls_zip já existe!\n",
      "Pasta para csv já existe!\n",
      "Pasta para json já existe!\n",
      "Pasta para fig já existe!\n",
      "Pasta para output já existe!\n",
      "\n",
      "Caminho da pasta raiz: C:\\Users\\marcos.aires\\fioce\n",
      "Caminho para xls_zip: xls_zip\n",
      "Caminho para csv: csv\n",
      "Caminho para json: json\n",
      "Caminho para fig: fig\n",
      "Caminho para output: output\n"
     ]
    }
   ],
   "source": [
    "# Cria instância da classe EnvironmenSetup e preparar pastas\n",
    "preparer = EnvironmentSetup()\n",
    "folder_name = input(\"Digite o nome da pasta principal: \")\n",
    "preparer.set_root_path(folder_name)\n",
    "preparer.try_cpu()\n",
    "preparer.try_gpu()\n",
    "preparer.try_amb()\n",
    "# preparer.try_browser()\n",
    "preparer.preparar_pastas()\n",
    "\n",
    "## Remover diretórios no linux\n",
    "# !rm -rf /home/mak/fioce\n",
    "# os.listdir('/home/mak/fioce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616b92e7",
   "metadata": {},
   "source": [
    "## Montar lista_busca para dados de Docentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55130d7a",
   "metadata": {},
   "source": [
    "### Carregar nomes de planilha com dados de Docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279f1c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 nomes de colaboradores no total, todos vínculos e status\n",
      " 10 tipos de vínculos\n",
      "\n",
      "Tipos de vínculos ['SERVIDOR', 'COORENAÇÃO GERAL', 'TERCEIRIZADO', 'BOLSISTA', 'ESTÁGIO PEC', 'UNADIG', 'NORMATEL', 'SERVIDOR-CEDIDA PARA CORREGEDORIA ', 'SERVIDOR-CEDIDA PARA FIOCRUZ PE', 'SERVIDOR-CEDIDO PARA AUDITORIA INTERNA']\n",
      "  Tipos de status ['ATIVO', 'AFASTADO', 'EXONERADO', 'CONTRATO ENCERRADO', 'APOSENTADA', 'REMOÇÃO']\n",
      "\n",
      "58 nomes para extrair currículos\n",
      " 1. Alice Paula Di Sabatino Guimaraes\n",
      " 2. Ana Claudia De Araújo Teixeira\n",
      " 3. Ana Camila Oliveira Alves\n",
      " 4. Angela Christina De Moraes Ostritz\n",
      " 5. Adriana Costa Bacelo\n",
      " 6. Anna Carolina Machado Marinho\n",
      " 7. Antonio Marcos Aires Barbosa\n",
      " 8. Anya Pimentel Gomes Fernandes Vieira Meyer\n",
      " 9. Bruno Bezerra Carvalho\n",
      "10. Carla Freire Celedônio Fernandes\n",
      "11. Carlos Jose Araujo Pinheiro\n",
      "12. Claudia Stutz Zubieta\n",
      "13. Charles Cerqueira De Abreu\n",
      "14. Clarice Gomes E Souza Dabés\n",
      "15. Clarissa Romero Teixeira\n",
      "16. Dayane Alves Costa\n",
      "17. Donat Alexander De Chapeaurouge\n",
      "18. Eduardo Ruback Dos Santos\n",
      "19. Ezequiel Valentim De Melo\n",
      "20. Fabio Miyajima\n",
      "21. Fernando Braga Stehling Dias\n",
      "22. Fernando Ferreira Carneiro\n",
      "23. Galba Freire Moita\n",
      "24. Giovanny Augusto Camacho Antevere Mazzarotto\n",
      "25. Gilvan Pessoa Furtado\n",
      "26. Ivana Cristina De Holanda Cunha Barrêto\n",
      "27. Ivanildo Lopes Farias\n",
      "28. Jaime Ribeiro Filho\n",
      "29. João Baptista Estabile Neto\n",
      "30. João Hermínio Martins Da Silva\n",
      "31. José Luis Passos Cordeiro\n",
      "32. Kamila Matos Albuquerque \n",
      "33. Luciana Coelho Serafim\n",
      "34. Luciana Pereira Lindenmeyer\n",
      "35. Luciana Silvério Alleluia Higino Da Silva\n",
      "36. Luciano Pinto Zorzanelli\n",
      "37. Luis Fernando Pessoa De Andrade\n",
      "38. Luiz Odorico Monteiro De Andrade\n",
      "39. Marcela Helena Gambim Fonseca\n",
      "40. Marcelo Jorge Lopes Coutinho\n",
      "41. Marcos Roberto Lourenzoni\n",
      "42. Márcio Flávio Moura De Araújo \n",
      "43. Margareth Borges Coutinho Gallo\n",
      "44. Marlos De Medeiros Chaves\n",
      "45. Maximiliano Loiola Ponte De Souza\n",
      "46. Nilton Luiz Costa Machado\n",
      "47. Patricia Maria Ferreira da Silva\n",
      "48. Raphael Trevizani\n",
      "49. Regis Bernardo Brandim Gomes\n",
      "50. Renato Caldeira De Souza\n",
      "51. Roberto Nicolete\n",
      "52. Roberto Wagner Junior Freire De Freitas\n",
      "53. Rodrigo Carvalho Nogueira \n",
      "54. Sergio Dos Santos Reis\n",
      "55. Sharmenia De Araujo Soares Nuto\n",
      "56. Vanira Matos Pessoa\n",
      "57. Venúcia Bruna Magalhães Pereira\n",
      "58. Fernanda Savicki de Almeida\n"
     ]
    }
   ],
   "source": [
    "# Ler dados do arquivo Excel do Setor de Recursos Humanos\n",
    "pathdata = '_data/in_xls/'\n",
    "datasheet = 'fioce_colaboradores-2023.xls'\n",
    "\n",
    "# Ler apenas os cabeçalhos do arquivo Excel\n",
    "headers = pd.read_excel(pathdata+datasheet, skiprows=3, header=0, nrows=0).columns\n",
    "# headers\n",
    "\n",
    "# Usar função para indicar quais colunas devem ser eliminadas na leitura\n",
    "def cols_to_keep(col_name):\n",
    "    return col_name not in ['QUANT','Unnamed: 3','Unnamed: 6','Unnamed: 9','ADICIONAL OCUPACIONAL',\n",
    "                            'EMPRESA/BOLSA/PROGRAMA','GESTOR','ADI','POSSE NA FIOCRUZ',\n",
    "                            'VIGÊNCIA BOLSA/ENCERRAMENTO DO CONTRATO','Unnamed: 17',\n",
    "                            'EMAIL INSTITUCIONAL','EMAIL PESSOAL','GENERO','DATA NASCIMENTO',\n",
    "                            'Unnamed: 22','FORMAÇÃO','ENDEREÇO RESIDENCIAL']\n",
    "\n",
    "# Filtrar cabeçalhos com base na função\n",
    "selected_columns = [col for col in headers if cols_to_keep(col)]\n",
    "\n",
    "# Ler dados do arquivo Excel do Setor de Recursos Humanos\n",
    "fioce_pessoal = pd.read_excel(pathdata+datasheet, skiprows=3, header=0, usecols=selected_columns)\n",
    "print(f'{len(fioce_pessoal.index)} nomes de colaboradores no total, todos vínculos e status')\n",
    "print(f'{len(fioce_pessoal[\"VÍNCULO\"].unique()):3} tipos de vínculos')\n",
    "\n",
    "print('\\nTipos de vínculos',list(fioce_pessoal['VÍNCULO'].unique()))\n",
    "print('  Tipos de status',list(fioce_pessoal['STATUS'].unique()))\n",
    "filtro1 = fioce_pessoal.VÍNCULO == 'SERVIDOR'\n",
    "filtro2 = fioce_pessoal['STATUS'].isin(['ATIVO', 'AFASTADO'])\n",
    "lista_nomes = fioce_pessoal[(filtro1) & (filtro2)]['NOME'].tolist()\n",
    "\n",
    "print(f'\\n{len(lista_nomes)} nomes para extrair currículos')\n",
    "for i,nome in enumerate(lista_nomes):\n",
    "    print(f'{i+1:2}. {nome}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc89b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "grupos_internos = fioce_pessoal['ÁREA'].unique()\n",
    "coordenacoes=[]\n",
    "grupos_tematicos=[]\n",
    "for i in grupos_internos:\n",
    "    # print(i)\n",
    "    if 'coordenação' in str(i).lower():\n",
    "        coordenacoes.append(i)\n",
    "    elif str(i) != 'nan':\n",
    "        grupos_tematicos.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "288fb373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coordenação Geral',\n",
       " 'Coordenação Geral ',\n",
       " 'Coordenação Geral ( EPSJV/FIOCRUZ)',\n",
       " 'Coordenação Geral (QUALIDADE)',\n",
       " 'Coordenação Geral (SECRETARIA EXECUTIVA)',\n",
       " 'Coordenação da Gestão e Desenvolvimento Institucional ',\n",
       " 'Coordenação da Gestão e Desenvolvimento Institucional   (ALMOXARIFADO)',\n",
       " 'Coordenação da Gestão e Desenvolvimento Institucional (COMPRAS)',\n",
       " 'Coordenação da Gestão e Desenvolvimento Institucional (COORDENAÇÃO) ',\n",
       " 'Coordenação da Gestão e Desenvolvimento Institucional (FINANCEIRO)',\n",
       " 'Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA / SIMAM)',\n",
       " 'Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA)',\n",
       " 'Coordenação da Gestão e Desenvolvimento Institucional (LOGÍSTICA)',\n",
       " 'Coordenação da Gestão e Desenvolvimento Institucional (PATRIMÔNIO)',\n",
       " 'Coordenação da Gestão e Desenvolvimento Institucional (PLANEJAMENTO)',\n",
       " 'Coordenação da Gestão e Desenvolvimento Institucional (SGP / ST)',\n",
       " 'Coordenação da Gestão e Desenvolvimento Institucional (TIC)',\n",
       " 'Coordenação da Gestão e Desenvolvimento Institucional(ALMOXARIFADO)',\n",
       " 'Coordenação de Educação, Informação e Comunicação (BIBLIOTECA)',\n",
       " 'Coordenação de Educação, Informação e Comunicação (COMUNICAÇÃO)',\n",
       " 'Coordenação de Educação, Informação e Comunicação (COORDENAÇÃO)',\n",
       " 'Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)',\n",
       " 'Coordenação de Pesquisa',\n",
       " 'Coordenação de Pesquisa e Coleções Biológicas ',\n",
       " 'Coordenação de Produção e  Inovação em Saúde ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordenacoes.sort()\n",
    "coordenacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7507b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bio-Manguinhos',\n",
       " 'Biotecnologia',\n",
       " 'Biotecnologia-GR1 (IMUNOPARASITOLOGIA)',\n",
       " 'Biotecnologia-GR2 (VIGILÂNCIA GENÔMICA)',\n",
       " 'Biotecnologia-GR3 (BIOTECNOLOGIA)',\n",
       " 'Central Analitica - UNADIG',\n",
       " 'Saúde Digital',\n",
       " 'Saúde da Família',\n",
       " 'Saúde e Ambiente']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grupos_tematicos.sort()\n",
    "grupos_tematicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5adb022c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 currículos a extrair da plataforma Lattes\n"
     ]
    }
   ],
   "source": [
    "# Outras atividades não relacionadas diretamente com pesquisa\n",
    "remover = ['Angela Christina De Moraes Ostritz',\n",
    "           'Bruno Bezerra Carvalho',\n",
    "           'Carlos Jose Araujo Pinheiro',\n",
    "           'Charles Cerqueira De Abreu',\n",
    "           'Ezequiel Valentim De Melo',\n",
    "           'Ivanildo Lopes Farias',\n",
    "           'João Baptista Estabile Neto',\n",
    "           'Kamila Matos Albuquerque',\n",
    "           'Luciana Coelho Serafim',\n",
    "           'Luciano Pinto Zorzanelli',\n",
    "           'Luciana Silvério Alleluia Higino Da Silva',\n",
    "           'Luis Fernando Pessoa De Andrade',\n",
    "           'Marcelo Jorge Lopes Coutinho',\n",
    "           'Nilton Luiz Costa Machado',\n",
    "           'Patricia Maria Ferreira da Silva',\n",
    "           'Renato Caldeira De Souza',\n",
    "           'Sergio Dos Santos Reis',\n",
    "           'Clarice Gomes E Souza Dabés',\n",
    "           'Luciana Pereira Lindenmeyer',\n",
    "           'Rodrigo Carvalho Nogueira',\n",
    "           \n",
    "        #    'Ana Camila Oliveira Alves',\n",
    "        #    'Antonio Marcos Aires Barbosa',\n",
    "        #    'Venúcia Bruna Magalhães Pereira',\n",
    "           ]\n",
    "\n",
    "trocar = {\n",
    "    'Maximiliano Loiola Ponte De Souza': 'Maximiliano Ponte',\n",
    "    'Raphael Trevizani Roque': 'Raphael Trevizani',\n",
    "    }\n",
    "\n",
    "lista_busca=[]\n",
    "for i in lista_nomes:\n",
    "    if i.strip() in trocar.keys():\n",
    "        lista_busca.append(trocar.get(i))\n",
    "    elif i.strip() not in remover:\n",
    "        lista_busca.append(i)\n",
    "\n",
    "# Limitando quantidade para testes\n",
    "# lista_busca = lista_busca[:5]\n",
    "\n",
    "print(f'{len(lista_busca)} currículos a extrair da plataforma Lattes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d842eb06",
   "metadata": {},
   "source": [
    "### Carregar nomes de arquivo .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "580d2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, pandas as pd\n",
    "# from environment_setup import EnvironmentSetup\n",
    "# preparer = EnvironmentSetup()\n",
    "\n",
    "# ## Montar lista_nomes com arquivo .csv\n",
    "# pathfilename = os.path.join(folder_data_input,'nomesdocentes.csv')\n",
    "# lista_busca = pd.read_csv(pathfilename,header=None)[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35849f4e",
   "metadata": {},
   "source": [
    "## <b>Processar extração de dados de Docentes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95ffba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 currículos Lattes a extrair\n"
     ]
    }
   ],
   "source": [
    "## Definir termos de vínculo\n",
    "repo_root = preparer.find_repo_root(os.getcwd())\n",
    "pasta_dados = os.path.join(repo_root,'data','output')\n",
    "termos_busca = ['Fiocruz', 'Cruz', 'Imunopatologia', 'Ministerio da Saude']\n",
    "print(f'{len(lista_busca)} currículos Lattes a extrair')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d2a31",
   "metadata": {},
   "source": [
    "### Extrair currículos de Docentes da plataforma Lattes\n",
    "    (12~16min/37nomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07a2e8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando currículos com qualquer nível de formação\n",
      " 1/38: Alice Paula Di Sabatino Guimaraes\n",
      "       002 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      " 2/38: Ana Claudia De Araújo Teixeira\n",
      "        2 currículos homônimos: Ana Claudia De Araújo Teixeira\n",
      "                         Fiocruz | False | ['Ana Claudia Teixeira de Araujo ']\n",
      "                            Cruz | False | ['Ana Claudia Teixeira de Araujo ']\n",
      "                  Imunopatologia | False | ['Ana Claudia Teixeira de Araujo ']\n",
      "             Ministerio da Saude | False | ['Ana Claudia Teixeira de Araujo ']\n",
      "                         Fiocruz | True | ['Ana Cláudia de Araújo Teixeira  Doutorado em Educação Brasileira pela Universidade Federal do Ceará, Brasil(2008) Pesquisadora em Saúde Pública da Fundação Oswaldo Cruz - Fiocruz Ceará , Brasil']\n",
      "       009 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      " 3/38: Ana Camila Oliveira Alves\n",
      "       002 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      " 4/38: Adriana Costa Bacelo\n",
      "       025 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      " 5/38: Anna Carolina Machado Marinho\n",
      "       007 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      " 6/38: Antonio Marcos Aires Barbosa\n",
      "       002 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      " 7/38: Anya Pimentel Gomes Fernandes Vieira Meyer\n",
      "       104 artigos extraídos\n",
      "       DOI indisponível para 01 artigo extraído\n",
      "       Extração bem-sucedida\n",
      " 8/38: Carla Freire Celedônio Fernandes\n",
      "       046 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      " 9/38: Claudia Stutz Zubieta\n",
      "       007 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "10/38: Clarissa Romero Teixeira\n",
      "       045 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "11/38: Dayane Alves Costa\n",
      "        7 currículos homônimos: Dayane Alves Costa\n",
      "                         Fiocruz | False | ['Dayane Alves Costa  Graduação em Bacharelado em Química pela Faculdade de Ciências Integradas do Pontal, Brasil(2013)']\n",
      "                            Cruz | False | ['Dayane Alves Costa  Graduação em Bacharelado em Química pela Faculdade de Ciências Integradas do Pontal, Brasil(2013)']\n",
      "                  Imunopatologia | False | ['Dayane Alves Costa  Graduação em Bacharelado em Química pela Faculdade de Ciências Integradas do Pontal, Brasil(2013)']\n",
      "             Ministerio da Saude | False | ['Dayane Alves Costa  Graduação em Bacharelado em Química pela Faculdade de Ciências Integradas do Pontal, Brasil(2013)']\n",
      "                         Fiocruz | False | ['Dayane Machado Costa Alves  Ensino Médio (2o grau) pela Escola Estadual Madre Maria Blandina, Brasil(2010) Trabalha no Instituto Federal do Triângulo Mineiro , Brasil']\n",
      "                            Cruz | False | ['Dayane Machado Costa Alves  Ensino Médio (2o grau) pela Escola Estadual Madre Maria Blandina, Brasil(2010) Trabalha no Instituto Federal do Triângulo Mineiro , Brasil']\n",
      "                  Imunopatologia | False | ['Dayane Machado Costa Alves  Ensino Médio (2o grau) pela Escola Estadual Madre Maria Blandina, Brasil(2010) Trabalha no Instituto Federal do Triângulo Mineiro , Brasil']\n",
      "             Ministerio da Saude | False | ['Dayane Machado Costa Alves  Ensino Médio (2o grau) pela Escola Estadual Madre Maria Blandina, Brasil(2010) Trabalha no Instituto Federal do Triângulo Mineiro , Brasil']\n",
      "                         Fiocruz | False | ['Carla Dayane Alves Costa  Graduação em Ciências Biológicas pela Universidade Estadual de Montes Claros, Brasil(2012)']\n",
      "                            Cruz | False | ['Carla Dayane Alves Costa  Graduação em Ciências Biológicas pela Universidade Estadual de Montes Claros, Brasil(2012)']\n",
      "                  Imunopatologia | False | ['Carla Dayane Alves Costa  Graduação em Ciências Biológicas pela Universidade Estadual de Montes Claros, Brasil(2012)']\n",
      "             Ministerio da Saude | False | ['Carla Dayane Alves Costa  Graduação em Ciências Biológicas pela Universidade Estadual de Montes Claros, Brasil(2012)']\n",
      "                         Fiocruz | False | ['Dayane Alves Costa  Doutorado em Alergia e Imunopatologia pela Universidade de São Paulo, Brasil(2017) Estatutária da Universidade Federal de São Paulo , Brasil']\n",
      "                            Cruz | False | ['Dayane Alves Costa  Doutorado em Alergia e Imunopatologia pela Universidade de São Paulo, Brasil(2017) Estatutária da Universidade Federal de São Paulo , Brasil']\n",
      "                  Imunopatologia | True | ['Dayane Alves Costa  Doutorado em Alergia e Imunopatologia pela Universidade de São Paulo, Brasil(2017) Estatutária da Universidade Federal de São Paulo , Brasil']\n",
      "       010 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "12/38: Donat Alexander De Chapeaurouge\n",
      "       043 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "13/38: Eduardo Ruback Dos Santos\n",
      "       006 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "14/38: Fabio Miyajima\n",
      "       064 artigos extraídos\n",
      "       DOI indisponível em 13 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "15/38: Fernando Braga Stehling Dias\n",
      "       023 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "16/38: Fernando Ferreira Carneiro\n",
      "        3 currículos homônimos: Fernando Ferreira Carneiro\n",
      "                         Fiocruz | False | ['Fernando Antônio Carneiro Ferreira  Graduação em Engenharia Civil pela Universidade Federal de Santa Catarina, Brasil(1975) Engenheiro Regional do Departamento de Estradas de Rodagem do Estado de Minas Gerais , Brasil']\n",
      "                            Cruz | False | ['Fernando Antônio Carneiro Ferreira  Graduação em Engenharia Civil pela Universidade Federal de Santa Catarina, Brasil(1975) Engenheiro Regional do Departamento de Estradas de Rodagem do Estado de Minas Gerais , Brasil']\n",
      "                  Imunopatologia | False | ['Fernando Antônio Carneiro Ferreira  Graduação em Engenharia Civil pela Universidade Federal de Santa Catarina, Brasil(1975) Engenheiro Regional do Departamento de Estradas de Rodagem do Estado de Minas Gerais , Brasil']\n",
      "             Ministerio da Saude | False | ['Fernando Antônio Carneiro Ferreira  Graduação em Engenharia Civil pela Universidade Federal de Santa Catarina, Brasil(1975) Engenheiro Regional do Departamento de Estradas de Rodagem do Estado de Minas Gerais , Brasil']\n",
      "                         Fiocruz | False | ['Fernando Ferreira Carneiro  Doutorado em Ciência Animal - Med. Vet. Prev. e Epidemiologia pela Escola de Veterinária da UFMG, Brasil(2007) Pesquisador da Fundação Oswaldo Cruz , Brasil']\n",
      "                            Cruz | True | ['Fernando Ferreira Carneiro  Doutorado em Ciência Animal - Med. Vet. Prev. e Epidemiologia pela Escola de Veterinária da UFMG, Brasil(2007) Pesquisador da Fundação Oswaldo Cruz , Brasil']\n",
      "       064 artigos extraídos\n",
      "       DOI indisponível para 01 artigo extraído\n",
      "       Extração bem-sucedida\n",
      "17/38: Galba Freire Moita\n",
      "        2 currículos homônimos: Galba Freire Moita\n",
      "                         Fiocruz | False | ['Galba Freire Moita Júnior  Graduação em Engenharia de Teleinformática pela Universidade Federal do Ceará, Brasil(2012)']\n",
      "                            Cruz | False | ['Galba Freire Moita Júnior  Graduação em Engenharia de Teleinformática pela Universidade Federal do Ceará, Brasil(2012)']\n",
      "                  Imunopatologia | False | ['Galba Freire Moita Júnior  Graduação em Engenharia de Teleinformática pela Universidade Federal do Ceará, Brasil(2012)']\n",
      "             Ministerio da Saude | False | ['Galba Freire Moita Júnior  Graduação em Engenharia de Teleinformática pela Universidade Federal do Ceará, Brasil(2012)']\n",
      "                         Fiocruz | False | ['Galba Freire Moita  Doutorado em Administração pela Universidade Federal de Minas Gerais, Brasil(2019) Coordenador Geral Monitoramento e Avaliação do Ministerio da Saude do Brasil , Brasil']\n",
      "                            Cruz | False | ['Galba Freire Moita  Doutorado em Administração pela Universidade Federal de Minas Gerais, Brasil(2019) Coordenador Geral Monitoramento e Avaliação do Ministerio da Saude do Brasil , Brasil']\n",
      "                  Imunopatologia | False | ['Galba Freire Moita  Doutorado em Administração pela Universidade Federal de Minas Gerais, Brasil(2019) Coordenador Geral Monitoramento e Avaliação do Ministerio da Saude do Brasil , Brasil']\n",
      "             Ministerio da Saude | True | ['Galba Freire Moita  Doutorado em Administração pela Universidade Federal de Minas Gerais, Brasil(2019) Coordenador Geral Monitoramento e Avaliação do Ministerio da Saude do Brasil , Brasil']\n",
      "       011 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "18/38: Giovanny Augusto Camacho Antevere Mazzarotto\n",
      "       012 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "19/38: Gilvan Pessoa Furtado\n",
      "       024 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "20/38: Ivana Cristina De Holanda Cunha Barrêto\n",
      "       074 artigos extraídos\n",
      "       DOI indisponível para 01 artigo extraído\n",
      "       Extração bem-sucedida\n",
      "21/38: Jaime Ribeiro Filho\n",
      "        2 currículos homônimos: Jaime Ribeiro Filho\n",
      "                         Fiocruz | False | ['Jaime Ribeiro Falcão Filho  Ensino Médio (2o grau) pelo Marista Pio X, Brasil(2016)']\n",
      "                            Cruz | False | ['Jaime Ribeiro Falcão Filho  Ensino Médio (2o grau) pelo Marista Pio X, Brasil(2016)']\n",
      "                  Imunopatologia | False | ['Jaime Ribeiro Falcão Filho  Ensino Médio (2o grau) pelo Marista Pio X, Brasil(2016)']\n",
      "             Ministerio da Saude | False | ['Jaime Ribeiro Falcão Filho  Ensino Médio (2o grau) pelo Marista Pio X, Brasil(2016)']\n",
      "                         Fiocruz | False | ['Jaime Ribeiro Filho  Bolsista de Produtividade em Pesquisa 2 Doutorado em Biologia Celular e Molecular pela Fundação Oswaldo Cruz, Brasil(2013) Pesquisador em Saúde Pública da Fundação Oswaldo Cruz , Brasil']\n",
      "                            Cruz | True | ['Jaime Ribeiro Filho  Bolsista de Produtividade em Pesquisa 2 Doutorado em Biologia Celular e Molecular pela Fundação Oswaldo Cruz, Brasil(2013) Pesquisador em Saúde Pública da Fundação Oswaldo Cruz , Brasil']\n",
      "       109 artigos extraídos\n",
      "       DOI indisponível em 19 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "22/38: João Hermínio Martins Da Silva\n",
      "       029 artigos extraídos\n",
      "       DOI indisponível para 01 artigo extraído\n",
      "       Extração bem-sucedida\n",
      "23/38: José Luis Passos Cordeiro\n",
      "       045 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "24/38: Luiz Odorico Monteiro De Andrade\n",
      "       087 artigos extraídos\n",
      "       DOI indisponível em 04 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "25/38: Marcela Helena Gambim Fonseca\n",
      "       018 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "26/38: Marcos Roberto Lourenzoni\n",
      "       027 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "27/38: Márcio Flávio Moura De Araújo \n",
      "       147 artigos extraídos\n",
      "       DOI indisponível para 01 artigo extraído\n",
      "       Extração bem-sucedida\n",
      "28/38: Margareth Borges Coutinho Gallo\n",
      "       018 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "29/38: Marlos De Medeiros Chaves\n",
      "       007 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "30/38: Maximiliano Ponte\n",
      "       045 artigos extraídos\n",
      "       DOI indisponível em 05 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "31/38: Raphael Trevizani\n",
      "       004 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "32/38: Regis Bernardo Brandim Gomes\n",
      "       042 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "33/38: Roberto Nicolete\n",
      "       061 artigos extraídos\n",
      "       DOI indisponível em 06 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "34/38: Roberto Wagner Junior Freire De Freitas\n",
      "       095 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "35/38: Sharmenia De Araujo Soares Nuto\n",
      "       054 artigos extraídos\n",
      "       DOI indisponível em 02 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "36/38: Vanira Matos Pessoa\n",
      "       032 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "37/38: Venúcia Bruna Magalhães Pereira\n",
      "       006 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "38/38: Fernanda Savicki de Almeida\n",
      "       008 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "Arquivo salvo em c:\\Users\\marcos.aires\\ppgcs\\_data\\in_csv\\temp_dict_list.json\n",
      "\n",
      "00:17:25 para busca de 38 nomes com extração de dados de 38 dicionários\n"
     ]
    }
   ],
   "source": [
    "## Passar parâmetro only_doctors para False para extrair também níveis mestrado e graduação\n",
    "t1 = time.time()\n",
    "scraper = LattesScraper(termos_busca, 'bolt://localhost:7687', 'neo4j', 'password', only_doctors=False)\n",
    "\n",
    "dict_list_docents = scraper.scrape(lista_busca, termos_busca)\n",
    "print(f'\\n{scraper.tempo(t1,time.time())} para busca de {len(lista_busca)} nomes com extração de dados de {len(dict_list_docents)} dicionários')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1f877f",
   "metadata": {},
   "source": [
    "### Carregar arquivo salvo previamente da primeira extração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0490db43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 dicionários carregados\n"
     ]
    }
   ],
   "source": [
    "jfm = JSONFileManager()\n",
    "folder_data_input = os.path.join(os.getcwd(),'_data','in_csv')\n",
    "filename = 'temp_dict_list.json'\n",
    "pathfilename = os.path.join(folder_data_input, filename)\n",
    "dict_list_docents, formatted_creation_date, formatted_modification_date, time_count, unit = jfm.load_from_json(os.path.join(pasta_dados, pathfilename))\n",
    "\n",
    "print(f'{len(dict_list_docents)} dicionários carregados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09abb07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nome': 'Fernanda Savicki de Almeida',\n",
       " 'ID Lattes': '6908395306417399',\n",
       " 'Última atualização': '03/01/2024'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_list_docents[-1].get('Identificação')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340ce781",
   "metadata": {},
   "source": [
    "### Identificar currículos remanescentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ed4d5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando currículos com qualquer nível de formação\n",
      "38 currículos a buscar no total\n",
      "38 currículos já extraídos\n",
      "(01) Alice Paula Di Sabatino Guimarães\n",
      "(02) Ana Cláudia de Araújo Teixeira\n",
      "(03) Ana Camila Oliveira Alves\n",
      "(04) Adriana Costa Bacelo\n",
      "(05) Anna Carolina Machado Marinho\n",
      "(06) Antonio Marcos Aires Barbosa\n",
      "(07) Anya Pimentel Gomes Fernandes Vieira Meyer\n",
      "(08) Carla Freire Celedonio Fernandes\n",
      "(09) Claudia Stutz Zubieta\n",
      "(10) Clarissa Romero Teixeira\n",
      "(11) Dayane Alves Costa\n",
      "(12) Donat Alexander de Chapeaurouge\n",
      "(13) Eduardo Ruback dos Santos\n",
      "(14) Fabio Miyajima\n",
      "(15) Fernando Braga Stehling Dias\n",
      "(16) Fernando Ferreira Carneiro\n",
      "(17) Galba Freire Moita\n",
      "(18) Giovanny Augusto Camacho Antevere Mazzarotto\n",
      "(19) Gilvan Pessoa Furtado\n",
      "(20) Ivana Cristina de Holanda Cunha Barreto\n",
      "(21) Jaime Ribeiro Filho\n",
      "(22) João Hermínio Martins da Silva\n",
      "(23) José Luís Passos Cordeiro\n",
      "(24) Luiz Odorico Monteiro de Andrade\n",
      "(25) Marcela Helena Gambim Fonseca\n",
      "(26) Marcos Roberto Lourenzoni\n",
      "(27) Márcio Flávio Moura de Araújo\n",
      "(28) Margareth Borges Coutinho Gallo\n",
      "(29) Marlos de Medeiros Chaves\n",
      "(30) Maximiliano Ponte\n",
      "(31) Raphael Trevizani\n",
      "(32) Regis Bernardo Brandim Gomes\n",
      "(33) Roberto Nicolete\n",
      "(34) Roberto Wagner Júnior Freire de Freitas\n",
      "(35) Sharmênia de Araújo Soares Nuto\n",
      "(36) Vanira Matos Pessoa\n",
      "(37) Venúcia Bruna Magalhães Pereira\n",
      "(38) Fernanda Savicki de Almeida\n",
      "\n",
      "0 currículos não extraídos\n"
     ]
    }
   ],
   "source": [
    "termos_busca = ['Fiocruz', 'Cruz', 'Imunopatologia', 'Ministerio da Saude']\n",
    "scraper = LattesScraper(termos_busca, \n",
    "                        'bolt://localhost:7687', 'neo4j', 'password', \n",
    "                        only_doctors=False)\n",
    "\n",
    "lista_restante = scraper.avaliar_remanescentes(lista_busca, dict_list_docents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e08b2e",
   "metadata": {},
   "source": [
    "### Adicionar nomes ou novos termos, se necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11ae091a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Caroline Pereira Bittencourt Passaes\n"
     ]
    }
   ],
   "source": [
    "lista_restante.append('Caroline Pereira Bittencourt Passaes')\n",
    "for i in lista_restante:\n",
    "    print(f'   {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d43ba36",
   "metadata": {},
   "source": [
    "### Extrair currículos remanescentes ou adicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b33d6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resta extrair 1 currículos:\n",
      "['Caroline Pereira Bittencourt Passaes']\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Buscando currículos com qualquer nível de formação\n",
      " 1/1: Caroline Pereira Bittencourt Passaes\n",
      "       033 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "Arquivo salvo em c:\\Users\\marcos.aires\\ppgcs\\_data\\in_csv\\temp_dict_list.json\n",
      "\n",
      "00:00:36 para busca de 1 nomes com extração de dados de 1 dicionários\n",
      "Total de dicionários na lista completa: 39\n",
      "Arquivo JSON salvo em: c:\\Users\\marcos.aires\\ppgcs\\_data\\in_csv\\combined_dict_list.json\n"
     ]
    }
   ],
   "source": [
    "# lista_dict_combinado = extract_remanescents(lista_restante, dict_list_actual)\n",
    "lista_dict_combinado = scraper.extract_remanescents(lista_restante, dict_list_docents, termos_busca)\n",
    "filepath = os.path.join(folder_data_input,'dict_list_docents.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e369b295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 docentes com colaboração discente identificada\n",
      "\n",
      "\n",
      "Exemplo de dados dos artigos:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ano': '2021',\n",
       " 'fator_impacto_jcr': '',\n",
       " 'ISSN': '20452322',\n",
       " 'titulo': 'SARS-CoV-2 genomic surveillance in Rondônia, Brazilian Western Amazon',\n",
       " 'revista': 'Scientific Reports',\n",
       " 'autores': 'BOTELHO-SOUZA, LUAN FELIPO2021BOTELHO-SOUZA, LUAN FELIPO ; NOGUEIRA-LIMA, FELIPE SOUZA ; ROCA, TÁRCIO PEIXOTO ; NAVECA, FELIPE GOMES ; DE OLIVERIA DOS SANTOS, ALCIONE ; MAIA, ADRIANA CRISTINA SALVADOR ; DA SILVA, CICILEIA CORREIA ; DE MELO MENDONÇA, ALINE LINHARES FERREIRA ; LUGTENBURG, CELINA APARECIDA BERTONI ; AZZI, CAMILA FLÁVIA GOMES ; FONTES, JULIANA LOCA FURTADO ; CAVALCANTE, SUELEN ; DE CÁSSIA PONTELLO RAMPAZZO, RITA ; SANTOS, CAIO HENRIQUE NEMETH ;DI SABATINO GUIMARÃES, ALICE PAULA; MÁXIMO, FERNANDO RODRIGUES ; VILLALOBOS-SALCEDO, JUAN MIGUEL ; VIEIRA, DEUSILENE SOUZA . ',\n",
       " 'data_issn': '20452322',\n",
       " 'DOI': 'http://dx.doi.org/10.1038/s41598-021-83203-2'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'{len(lista_dict_combinado)} docentes com colaboração discente identificada')\n",
    "print('\\n\\nExemplo de dados dos artigos:')\n",
    "[x.get('Produções') for x in lista_dict_combinado][0].get('Artigos completos publicados em periódicos')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f78b5",
   "metadata": {},
   "source": [
    "### Listar arquivos JSON gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "508b6080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['combined_dict_list.json',\n",
       " 'dict_list_combined.json',\n",
       " 'dict_list_discents.json',\n",
       " 'dict_list_discents_combined.json',\n",
       " 'dict_list_docents.json',\n",
       " 'dict_list_temp.json',\n",
       " 'indicadores.csv',\n",
       " 'nomesdocentes.csv',\n",
       " 'ppgcs',\n",
       " 'qlattes',\n",
       " 'temp_dict_list.json',\n",
       " 'veiculos.csv']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_data_input = os.path.join(os.getcwd(),'_data','in_csv')\n",
    "os.listdir(folder_data_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27f8ff",
   "metadata": {},
   "source": [
    "### Salvar dados completos dos currículos de Docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4ab5b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adicionando Qualis Periódicos\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lista_dict_combinado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAdicionando Qualis Periódicos\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m pathfilename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_data_input,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocents_dict_list.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m stratifier\u001b[38;5;241m.\u001b[39mbuscar_qualis_e_atualizar_arquivo(\u001b[43mlista_dict_combinado\u001b[49m, pathfilename)\n\u001b[0;32m      8\u001b[0m scraper\u001b[38;5;241m.\u001b[39msave_to_json(lista_dict_combinado, pathfilename)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(lista_dict_combinado)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dicionários com currículos completos extraídos\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lista_dict_combinado' is not defined"
     ]
    }
   ],
   "source": [
    "from lattes_scrapper import GetQualis\n",
    "stratifier = GetQualis()\n",
    "\n",
    "# Acrescentar Qualis periódicos aos dicionários de docentes\n",
    "print('\\nAdicionando Qualis Periódicos')\n",
    "pathfilename = os.path.join(folder_data_input,'docents_dict_list.json')\n",
    "stratifier.buscar_qualis_e_atualizar_arquivo(lista_dict_combinado, pathfilename)\n",
    "scraper.save_to_json(lista_dict_combinado, pathfilename)\n",
    "\n",
    "print(f'{len(lista_dict_combinado)} dicionários com currículos completos extraídos')\n",
    "print('\\n\\nExemplo de dados dos artigos:')\n",
    "[x.get('Produções') for x in lista_dict_combinado][0].get('Artigos completos publicados em periódicos')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb57a6e",
   "metadata": {},
   "source": [
    "### Visualizar nomes extraídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ea423ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alice Paula Di Sabatino Guimarães',\n",
       " 'Ana Cláudia de Araújo Teixeira',\n",
       " 'Ana Camila Oliveira Alves',\n",
       " 'Adriana Costa Bacelo',\n",
       " 'Anna Carolina Machado Marinho',\n",
       " 'Antonio Marcos Aires Barbosa',\n",
       " 'Anya Pimentel Gomes Fernandes Vieira Meyer',\n",
       " 'Carla Freire Celedonio Fernandes',\n",
       " 'Claudia Stutz Zubieta',\n",
       " 'Clarissa Romero Teixeira',\n",
       " 'Dayane Alves Costa',\n",
       " 'Donat Alexander de Chapeaurouge',\n",
       " 'Eduardo Ruback dos Santos',\n",
       " 'Fabio Miyajima',\n",
       " 'Fernando Braga Stehling Dias',\n",
       " 'Fernando Ferreira Carneiro',\n",
       " 'Galba Freire Moita',\n",
       " 'Giovanny Augusto Camacho Antevere Mazzarotto',\n",
       " 'Gilvan Pessoa Furtado',\n",
       " 'Ivana Cristina de Holanda Cunha Barreto',\n",
       " 'Jaime Ribeiro Filho',\n",
       " 'João Hermínio Martins da Silva',\n",
       " 'José Luís Passos Cordeiro',\n",
       " 'Luiz Odorico Monteiro de Andrade',\n",
       " 'Marcela Helena Gambim Fonseca',\n",
       " 'Marcos Roberto Lourenzoni',\n",
       " 'Márcio Flávio Moura de Araújo',\n",
       " 'Margareth Borges Coutinho Gallo',\n",
       " 'Marlos de Medeiros Chaves',\n",
       " 'Maximiliano Ponte',\n",
       " 'Raphael Trevizani',\n",
       " 'Regis Bernardo Brandim Gomes',\n",
       " 'Roberto Nicolete',\n",
       " 'Roberto Wagner Júnior Freire de Freitas',\n",
       " 'Sharmênia de Araújo Soares Nuto',\n",
       " 'Vanira Matos Pessoa',\n",
       " 'Venúcia Bruna Magalhães Pereira',\n",
       " 'Fernanda Savicki de Almeida',\n",
       " 'Caroline Pereira Bittencourt Passaes']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'docents_dict_list.json'\n",
    "pathfilename = os.path.join(folder_data_input, filename)\n",
    "dict_list_docents_complete, formatted_creation_date, formatted_modification_date, time_count, unit = jfm.load_from_json(pathfilename)\n",
    "[i.get('Identificação').get('Nome') for i in dict_list_docents_complete]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b193bf",
   "metadata": {},
   "source": [
    "# F01a: Carregar extração prévia de Docentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dcfe43",
   "metadata": {},
   "source": [
    "### Carregar arquivos de dados dos docentes gerados previamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00a8642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos disponíveis na pasta para dados de entrada:\n",
      "  combined_dict_list.json\n",
      "  dict_list_discents_combined.json\n",
      "  dict_list_temp.json\n",
      "  discents_dict_list.json\n",
      "  docents_dict_list.json\n",
      "  temp_dict_list.json\n",
      "\n",
      "39 currículos carregados na lista de dicionários 'docents_dict_list.json'\n",
      "Arquivo criado inicialmente em 22/05/2024 11:18:21 carregado com sucesso\n",
      "Extração realizada em 23/05/2024 08:27:15 a 35.1 minutos\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd, os, re, sys, time, pytz, json, subprocess\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('colheader_justify', 'left')\n",
    "pd.set_option('display.max_rows', 600)\n",
    "\n",
    "def find_repo_root(path='.', depth=10):\n",
    "    ''' \n",
    "    Busca o arquivo .git e retorna string com a pasta raiz do repositório\n",
    "    '''\n",
    "    # Prevent infinite recursion by limiting depth\n",
    "    if depth < 0:\n",
    "        return None\n",
    "    path = Path(path).absolute()\n",
    "    if (path / '.git').is_dir():\n",
    "        return path\n",
    "    return find_repo_root(path.parent, depth-1)\n",
    "\n",
    "delay = 10\n",
    "\n",
    "## Definir a pasta de base do repositório local\n",
    "base_repo_dir = find_repo_root()\n",
    "\n",
    "## Sempre construir os caminhos usando os.path.join para compatibilidade WxL\n",
    "folder_utils = os.path.join(base_repo_dir, 'utils')\n",
    "folder_domain = os.path.join(base_repo_dir, 'source', 'domain')\n",
    "folder_data_input = os.path.join(base_repo_dir, '_data', 'in_csv')\n",
    "folder_data_output = os.path.join(base_repo_dir, '_data', 'output')\n",
    "sys.path.append(folder_utils)\n",
    "sys.path.append(folder_domain)\n",
    "# from scraper_pasteur import PasteurScraper\n",
    "# from scraper_sucupira import SucupiraScraper\n",
    "# from scraper_sucupira_edge import SucupiraScraperEdge\n",
    "from environment_setup import EnvironmentSetup\n",
    "from chromedriver_manager import ChromeDriverManager\n",
    "from neo4j_persister import Neo4jPersister\n",
    "from lattes_scrapper import JSONFileManager, LattesScraper, HTMLParser, SoupParser, GetQualis, ArticlesCounter, DiscentCollaborationCounter, DictToHDF5, attribute_to_be_non_empty\n",
    "\n",
    "# Carregar para variável dict_list_docents os dicionários com dados dos Docentes\n",
    "jfm = JSONFileManager()\n",
    "jfm.list_json(folder_data_input)\n",
    "filename = 'docents_dict_list.json'\n",
    "\n",
    "dict_list_docents, formatted_creation_date, formatted_modification_date, time_count, unit = jfm.load_from_json(os.path.join(folder_data_input,filename))\n",
    "print(f\"\\n{len(dict_list_docents)} currículos carregados na lista de dicionários '{filename}'\")\n",
    "print(f\"Arquivo criado inicialmente em {formatted_creation_date} carregado com sucesso\")\n",
    "print(f\"Extração realizada em {formatted_modification_date} a {time_count} {unit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d4549",
   "metadata": {},
   "source": [
    "### Acrescentar/Atualizar Qualis Periódicos, caso ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa835f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33/ 33 artigos do autor  39/ 39\n"
     ]
    }
   ],
   "source": [
    "from lattes_scrapper import GetQualis\n",
    "stratifier = GetQualis()\n",
    "\n",
    "# Definir caminho e nome para escrever o arquivo com dados periódicos qualis dos docentes\n",
    "print('\\nAdicionando Qualis Periódicos')\n",
    "pathfilename = os.path.join(folder_data_input,'docents_dict_list.json')\n",
    "\n",
    "# Atualizar a lista de dicionários dict_list_docents com o Qualis para cara Artigo\n",
    "stratifier.buscar_qualis_e_atualizar_arquivo(dict_list_docents, pathfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec28b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ano': '2024',\n",
       " 'fator_impacto_jcr': '16.6',\n",
       " 'ISSN': '20411723',\n",
       " 'titulo': 'Early antiretroviral therapy favors post-treatment SIV control associated with the expansion of enhanced memory CD8  T-cells',\n",
       " 'revista': 'Nature Communications',\n",
       " 'autores': 'PASSAES, CAROLINE2024PASSAES, CAROLINE; DESJARDINS, DELPHINE ; CHAPEL, ANAÏS ; MONCEAUX, VALÉRIE ; LEMAITRE, JULIEN ; MÉLARD, ADELINE ; PERDOMO-CELIS, FEDERICO ; PLANCHAIS, CYRIL ; GOURVÈS, MAËL ; DIMANT, NASTASIA ; DAVID, ANNIE ; DEREUDDRE-BOSQUET, NATHALIE ; BARRAIL-TRAN, AURÉLIE ; GOUGET, HÉLÈNE ; GUILLAUME, CÉLINE ; RELOUZAT, FRANCIS ; LAMBOTTE, OLIVIER ; GUEDJ, JÉRÉMIE ; MÜLLER-TRUTWIN, MICHAELA ; MOUQUET, HUGO . Early antiretroviral therapy favors post-treatment SIV control associated with the expansion of enhanced memory CD8+ T-cells. Nature Communications, v. 15, p. 178, 2024.',\n",
       " 'data_issn': '20411723',\n",
       " 'DOI': 'http://dx.doi.org/10.1038/s41467-023-44389-3',\n",
       " 'Qualis': 'A1'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirmar se a chave 'Qualis' foi adicionada ao dicionário dos Artigos em dict_list_docents\n",
    "[x.get('Produções') for x in dict_list_docents][-1].get('Artigos completos publicados em periódicos')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb81910",
   "metadata": {},
   "source": [
    "### Visualizar quantitativo de artigos extraídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e00e5447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 dicionários montados\n",
      " 0C 002A 002T Dif:000 None \n",
      " 1C 009A 009T Dif:000 None \n",
      " 2C 002A 002T Dif:000 None \n",
      " 3C 025A 025T Dif:000 None \n",
      " 4C 007A 007T Dif:000 None \n",
      " 5C 002A 002T Dif:000 None \n",
      " 6C 104A 104T Dif:000 None \n",
      " 7C 046A 046T Dif:000 None \n",
      " 8C 007A 007T Dif:000 None \n",
      " 9C 045A 045T Dif:000 None \n",
      "10C 010A 010T Dif:000 None \n",
      "11C 043A 043T Dif:000 None \n",
      "12C 006A 006T Dif:000 None \n",
      "13C 064A 064T Dif:000 None \n",
      "14C 023A 023T Dif:000 None \n",
      "15C 064A 064T Dif:000 None \n",
      "16C 011A 011T Dif:000 None \n",
      "17C 012A 012T Dif:000 None \n",
      "18C 024A 024T Dif:000 None \n",
      "19C 074A 074T Dif:000 None \n",
      "20C 109A 109T Dif:000 None \n",
      "21C 029A 029T Dif:000 None \n",
      "22C 045A 045T Dif:000 None \n",
      "23C 087A 087T Dif:000 None \n",
      "24C 018A 018T Dif:000 None \n",
      "25C 027A 027T Dif:000 None \n",
      "26C 147A 147T Dif:000 None \n",
      "27C 018A 018T Dif:000 None \n",
      "28C 007A 007T Dif:000 None \n",
      "29C 045A 045T Dif:000 None \n",
      "30C 004A 004T Dif:000 None \n",
      "31C 042A 042T Dif:000 None \n",
      "32C 061A 061T Dif:000 None \n",
      "33C 095A 095T Dif:000 None \n",
      "34C 054A 054T Dif:000 None \n",
      "35C 032A 032T Dif:000 None \n",
      "36C 006A 006T Dif:000 None \n",
      "37C 008A 008T Dif:000 None \n",
      "38C 033A 033T Dif:000 None \n",
      "\n",
      "Total de artigos em todos períodos: 1447\n",
      "Total de títulos em todos períodos: 1447\n"
     ]
    }
   ],
   "source": [
    "## Contagem de artigos para simples confererência\n",
    "print(f'{len(dict_list_docents)} dicionários montados')\n",
    "qte_artigos=0\n",
    "qte_titulos=0\n",
    "for k,i in enumerate(dict_list_docents):\n",
    "    try:\n",
    "        qte_jcr = len(i.get('Produções').get('Artigos completos publicados em periódicos'))\n",
    "    except:\n",
    "        qte_jcr = 0\n",
    "    try:\n",
    "       qte_jcr2 = len(i['JCR2'])\n",
    "    except:\n",
    "       qte_jcr2 = 0\n",
    "    qte_artigos+=qte_jcr\n",
    "    qte_titulos+=qte_jcr2\n",
    "    status=qte_jcr2-qte_jcr\n",
    "    print(f\"{k:>2}C {qte_jcr:>03}A {qte_jcr2:>03}T Dif:{status:>03} {i.get('Identificação').get('name')} \")\n",
    "\n",
    "print(f'\\nTotal de artigos em todos períodos: {qte_artigos}')\n",
    "print(f'Total de títulos em todos períodos: {qte_titulos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8143a095",
   "metadata": {},
   "source": [
    "## Apurar artigos e atualizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e4e023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x.get('Produções') for x in dict_list_docents][3].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d5a2aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>id_lattes</th>\n",
       "      <th>curriculos</th>\n",
       "      <th>ultima_atualizacao</th>\n",
       "      <th>dias_defasagem</th>\n",
       "      <th>qte_artigos_periodicos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8793885517658468</td>\n",
       "      <td>Alice Paula Di Sabatino Guimarães</td>\n",
       "      <td>05/06/2023</td>\n",
       "      <td>353</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4719434295908748</td>\n",
       "      <td>Ana Cláudia de Araújo Teixeira</td>\n",
       "      <td>14/02/2024</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3711456559794028</td>\n",
       "      <td>Ana Camila Oliveira Alves</td>\n",
       "      <td>20/03/2023</td>\n",
       "      <td>430</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8861663346303670</td>\n",
       "      <td>Adriana Costa Bacelo</td>\n",
       "      <td>14/03/2024</td>\n",
       "      <td>70</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7628730583729553</td>\n",
       "      <td>Anna Carolina Machado Marinho</td>\n",
       "      <td>24/04/2024</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7085533025242495</td>\n",
       "      <td>Antonio Marcos Aires Barbosa</td>\n",
       "      <td>11/09/2023</td>\n",
       "      <td>255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7659758489387356</td>\n",
       "      <td>Anya Pimentel Gomes Fernandes Vieira Meyer</td>\n",
       "      <td>09/05/2024</td>\n",
       "      <td>14</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3922481112087617</td>\n",
       "      <td>Carla Freire Celedonio Fernandes</td>\n",
       "      <td>19/05/2024</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9103171701657660</td>\n",
       "      <td>Claudia Stutz Zubieta</td>\n",
       "      <td>01/04/2024</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5208987549081354</td>\n",
       "      <td>Clarissa Romero Teixeira</td>\n",
       "      <td>07/05/2024</td>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3737057462808079</td>\n",
       "      <td>Dayane Alves Costa</td>\n",
       "      <td>07/12/2023</td>\n",
       "      <td>168</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3279548172969453</td>\n",
       "      <td>Donat Alexander de Chapeaurouge</td>\n",
       "      <td>24/06/2019</td>\n",
       "      <td>1795</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6386175381185758</td>\n",
       "      <td>Eduardo Ruback dos Santos</td>\n",
       "      <td>14/05/2024</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0998235420634887</td>\n",
       "      <td>Fabio Miyajima</td>\n",
       "      <td>11/08/2023</td>\n",
       "      <td>286</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1210738427769812</td>\n",
       "      <td>Fernando Braga Stehling Dias</td>\n",
       "      <td>04/04/2024</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8414094465792735</td>\n",
       "      <td>Fernando Ferreira Carneiro</td>\n",
       "      <td>26/03/2024</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9365792416334714</td>\n",
       "      <td>Galba Freire Moita</td>\n",
       "      <td>14/02/2024</td>\n",
       "      <td>99</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4491426793431771</td>\n",
       "      <td>Giovanny Augusto Camacho Antevere Mazzarotto</td>\n",
       "      <td>02/05/2024</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4259673144880085</td>\n",
       "      <td>Gilvan Pessoa Furtado</td>\n",
       "      <td>14/09/2023</td>\n",
       "      <td>252</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0926082188345417</td>\n",
       "      <td>Ivana Cristina de Holanda Cunha Barreto</td>\n",
       "      <td>05/03/2024</td>\n",
       "      <td>79</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5885477643638071</td>\n",
       "      <td>Jaime Ribeiro Filho</td>\n",
       "      <td>13/05/2024</td>\n",
       "      <td>10</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4614096538855002</td>\n",
       "      <td>João Hermínio Martins da Silva</td>\n",
       "      <td>24/04/2024</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3430534497997843</td>\n",
       "      <td>José Luís Passos Cordeiro</td>\n",
       "      <td>04/01/2024</td>\n",
       "      <td>140</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4138758876612437</td>\n",
       "      <td>Luiz Odorico Monteiro de Andrade</td>\n",
       "      <td>20/05/2024</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9063434685117456</td>\n",
       "      <td>Marcela Helena Gambim Fonseca</td>\n",
       "      <td>20/02/2024</td>\n",
       "      <td>93</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1350673719062370</td>\n",
       "      <td>Marcos Roberto Lourenzoni</td>\n",
       "      <td>20/05/2024</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3560955068874194</td>\n",
       "      <td>Márcio Flávio Moura de Araújo</td>\n",
       "      <td>20/05/2024</td>\n",
       "      <td>3</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2733793442953892</td>\n",
       "      <td>Margareth Borges Coutinho Gallo</td>\n",
       "      <td>25/01/2024</td>\n",
       "      <td>119</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5961912954763405</td>\n",
       "      <td>Marlos de Medeiros Chaves</td>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7890789338463575</td>\n",
       "      <td>Maximiliano Ponte</td>\n",
       "      <td>05/03/2024</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7223174055569374</td>\n",
       "      <td>Raphael Trevizani</td>\n",
       "      <td>23/01/2023</td>\n",
       "      <td>486</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2521004210048823</td>\n",
       "      <td>Regis Bernardo Brandim Gomes</td>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0447073555893530</td>\n",
       "      <td>Roberto Nicolete</td>\n",
       "      <td>22/03/2024</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6831739238509460</td>\n",
       "      <td>Roberto Wagner Júnior Freire de Freitas</td>\n",
       "      <td>11/05/2024</td>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0636763091396917</td>\n",
       "      <td>Sharmênia de Araújo Soares Nuto</td>\n",
       "      <td>16/05/2024</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9013874934045331</td>\n",
       "      <td>Vanira Matos Pessoa</td>\n",
       "      <td>30/04/2024</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9284843601128833</td>\n",
       "      <td>Venúcia Bruna Magalhães Pereira</td>\n",
       "      <td>08/05/2024</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6908395306417399</td>\n",
       "      <td>Fernanda Savicki de Almeida</td>\n",
       "      <td>03/01/2024</td>\n",
       "      <td>141</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2952628863641871</td>\n",
       "      <td>Caroline Pereira Bittencourt Passaes</td>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_lattes         curriculos                                     \\\n",
       "0   8793885517658468             Alice Paula Di Sabatino Guimarães   \n",
       "1   4719434295908748                Ana Cláudia de Araújo Teixeira   \n",
       "2   3711456559794028                     Ana Camila Oliveira Alves   \n",
       "3   8861663346303670                          Adriana Costa Bacelo   \n",
       "4   7628730583729553                 Anna Carolina Machado Marinho   \n",
       "5   7085533025242495                  Antonio Marcos Aires Barbosa   \n",
       "6   7659758489387356    Anya Pimentel Gomes Fernandes Vieira Meyer   \n",
       "7   3922481112087617              Carla Freire Celedonio Fernandes   \n",
       "8   9103171701657660                         Claudia Stutz Zubieta   \n",
       "9   5208987549081354                      Clarissa Romero Teixeira   \n",
       "10  3737057462808079                            Dayane Alves Costa   \n",
       "11  3279548172969453               Donat Alexander de Chapeaurouge   \n",
       "12  6386175381185758                     Eduardo Ruback dos Santos   \n",
       "13  0998235420634887                                Fabio Miyajima   \n",
       "14  1210738427769812                  Fernando Braga Stehling Dias   \n",
       "15  8414094465792735                    Fernando Ferreira Carneiro   \n",
       "16  9365792416334714                            Galba Freire Moita   \n",
       "17  4491426793431771  Giovanny Augusto Camacho Antevere Mazzarotto   \n",
       "18  4259673144880085                         Gilvan Pessoa Furtado   \n",
       "19  0926082188345417       Ivana Cristina de Holanda Cunha Barreto   \n",
       "20  5885477643638071                           Jaime Ribeiro Filho   \n",
       "21  4614096538855002                João Hermínio Martins da Silva   \n",
       "22  3430534497997843                     José Luís Passos Cordeiro   \n",
       "23  4138758876612437              Luiz Odorico Monteiro de Andrade   \n",
       "24  9063434685117456                 Marcela Helena Gambim Fonseca   \n",
       "25  1350673719062370                     Marcos Roberto Lourenzoni   \n",
       "26  3560955068874194                 Márcio Flávio Moura de Araújo   \n",
       "27  2733793442953892               Margareth Borges Coutinho Gallo   \n",
       "28  5961912954763405                     Marlos de Medeiros Chaves   \n",
       "29  7890789338463575                             Maximiliano Ponte   \n",
       "30  7223174055569374                             Raphael Trevizani   \n",
       "31  2521004210048823                  Regis Bernardo Brandim Gomes   \n",
       "32  0447073555893530                              Roberto Nicolete   \n",
       "33  6831739238509460       Roberto Wagner Júnior Freire de Freitas   \n",
       "34  0636763091396917               Sharmênia de Araújo Soares Nuto   \n",
       "35  9013874934045331                           Vanira Matos Pessoa   \n",
       "36  9284843601128833               Venúcia Bruna Magalhães Pereira   \n",
       "37  6908395306417399                   Fernanda Savicki de Almeida   \n",
       "38  2952628863641871          Caroline Pereira Bittencourt Passaes   \n",
       "\n",
       "   ultima_atualizacao  dias_defasagem  qte_artigos_periodicos  \n",
       "0   05/06/2023          353              2                     \n",
       "1   14/02/2024           99              9                     \n",
       "2   20/03/2023          430              2                     \n",
       "3   14/03/2024           70             25                     \n",
       "4   24/04/2024           29              7                     \n",
       "5   11/09/2023          255              2                     \n",
       "6   09/05/2024           14            104                     \n",
       "7   19/05/2024            4             46                     \n",
       "8   01/04/2024           52              7                     \n",
       "9   07/05/2024           16             45                     \n",
       "10  07/12/2023          168             10                     \n",
       "11  24/06/2019         1795             43                     \n",
       "12  14/05/2024            9              6                     \n",
       "13  11/08/2023          286             64                     \n",
       "14  04/04/2024           49             23                     \n",
       "15  26/03/2024           58             64                     \n",
       "16  14/02/2024           99             11                     \n",
       "17  02/05/2024           21             12                     \n",
       "18  14/09/2023          252             24                     \n",
       "19  05/03/2024           79             74                     \n",
       "20  13/05/2024           10            109                     \n",
       "21  24/04/2024           29             29                     \n",
       "22  04/01/2024          140             45                     \n",
       "23  20/05/2024            3             87                     \n",
       "24  20/02/2024           93             18                     \n",
       "25  20/05/2024            3             27                     \n",
       "26  20/05/2024            3            147                     \n",
       "27  25/01/2024          119             18                     \n",
       "28  29/04/2024           24              7                     \n",
       "29  05/03/2024           79             45                     \n",
       "30  23/01/2023          486              4                     \n",
       "31  29/04/2024           24             42                     \n",
       "32  22/03/2024           62             61                     \n",
       "33  11/05/2024           12             95                     \n",
       "34  16/05/2024            7             54                     \n",
       "35  30/04/2024           23             32                     \n",
       "36  08/05/2024           15              6                     \n",
       "37  03/01/2024          141              8                     \n",
       "38  29/04/2024           24             33                     "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "atualizador = ArticlesCounter(dict_list_docents)\n",
    "dtf_atualizado = atualizador.extrair_data_atualizacao(dict_list_docents)\n",
    "dtf_atualizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bc70171",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verificar as chaves disponíveis em cada dicionário\n",
    "# for i,j in enumerate(dict_list_docents):\n",
    "#     print(f'{i:02} {j.keys()}')\n",
    "\n",
    "## Ver dados da planilha da plataforma Sucupira com dados de todo Qualis Periódicos\n",
    "# fonte_planilha = 'classificações_publicadas_todas_as_areas_avaliacao1672761192111.xlsx'\n",
    "# dados_qualis = pd.read_excel(os.path.join(LattesScraper.find_repo_root(),'_data','in_xls',fonte_planilha))\n",
    "# dados_qualis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbd686",
   "metadata": {},
   "source": [
    "#### Contar artigos estratificados pelo Qualis Periódicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ff30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os anos do período de interesse\n",
    "ano_inicio = 2017\n",
    "ano_final = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49d052e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de publicações (sem filtro de ano): 1447\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>Autor</th>\n",
       "      <th>Publicações Qualis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adriana Costa Bacelo</td>\n",
       "      <td>A2, NA, B2, B1, B3, B1, A1, B1, B2, B2, A1, NA, B2, B3, B3, NA, B3, NA, NA, NA, NA, NA, NA, NA, NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice Paula Di Sabatino Guimarães</td>\n",
       "      <td>A1, A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ana Camila Oliveira Alves</td>\n",
       "      <td>A3, A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ana Cláudia de Araújo Teixeira</td>\n",
       "      <td>A1, B1, B2, A1, A3, A1, B1, A1, A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anna Carolina Machado Marinho</td>\n",
       "      <td>A1, B2, A1, A3, B2, B3, C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Antonio Marcos Aires Barbosa</td>\n",
       "      <td>A2, B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anya Pimentel Gomes Fernandes Vieira Meyer</td>\n",
       "      <td>A4, A3, NA, A2, A1, A1, A1, A1, NA, B4, C, C, C, A1, A3, A3, A1, A3, A3, A1, A4, A1, A1, A1, A4, B2, A1, A1, C, B3, A1, B2, B1, A3, A2, A2, A1, A4, A4, A3, A1, A1, A1, A4, A3, B3, B1, B3, B1, A1, B1, A2, B1, A3, C, NA, C, B1, B2, A4, B1, B1, B1, NA, C, NA, C, B2, B2, C, B3, A1, A1, A1, B2, A2, A1, B2, B2, A1, B2, A1, A1, B2, A1, B3, B1, B2, B2, A1, A2, A2, A1, A1, A1, A1, A2, A1, A1, A1, NA, NA, NA, NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Carla Freire Celedonio Fernandes</td>\n",
       "      <td>A1, A2, B2, NA, C, A3, C, C, A2, A1, A3, A1, A1, A1, A4, A2, B1, A2, NA, A1, A2, A3, A1, A1, A1, A1, A4, A1, B1, A4, A1, A3, A3, A3, A3, A3, B4, A2, A3, A1, NA, B4, A3, A1, A1, A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Caroline Pereira Bittencourt Passaes</td>\n",
       "      <td>A1, A1, NA, A2, A1, A3, A2, A1, A2, A1, A1, A1, A1, A1, A1, B1, A1, A1, A1, A1, A2, A2, A1, B1, A3, A1, A3, A2, A2, B2, B2, A1, A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clarissa Romero Teixeira</td>\n",
       "      <td>A2, A1, A1, A2, A2, A2, A2, A2, A2, A1, A1, A1, A1, A1, B1, A1, A1, NA, A1, A1, A1, A1, A2, A2, A1, A4, A1, A1, A1, A1, A1, A1, A2, A1, A4, A2, A2, NA, A1, A1, A2, A3, NA, A4, A4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Claudia Stutz Zubieta</td>\n",
       "      <td>A2, A1, A1, NA, B4, A3, A4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dayane Alves Costa</td>\n",
       "      <td>B1, A4, A1, A2, B1, B4, B2, B4, B2, A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Donat Alexander de Chapeaurouge</td>\n",
       "      <td>NA, A2, NA, A1, A1, A2, A3, A1, A2, A2, A3, A2, A4, A2, A2, A1, A1, A2, A2, A2, A2, A2, B1, NA, A2, A4, A4, A2, A1, A3, A1, A2, A1, A1, B3, A1, A1, NA, NA, NA, NA, NA, NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Eduardo Ruback dos Santos</td>\n",
       "      <td>A1, A1, A1, A1, C, A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fabio Miyajima</td>\n",
       "      <td>A2, A3, A1, A1, A1, A3, A2, A2, A1, B1, A1, B1, A1, A2, A1, B1, A1, A2, A2, A2, A1, A3, A4, A2, A2, A2, A1, NA, B1, A2, A1, A2, A1, A2, NA, A1, NA, A1, A3, A1, NA, A1, A1, A1, A4, NA, A1, NA, A4, A1, A1, A1, A1, A2, A1, A1, A1, A2, A2, A2, NA, NA, B3, NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fernanda Savicki de Almeida</td>\n",
       "      <td>B4, C, NA, NA, B1, NA, B2, B4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fernando Braga Stehling Dias</td>\n",
       "      <td>A2, A1, A1, A1, A1, A2, A1, A2, A1, A1, A1, A1, A2, A2, B1, B1, A1, A2, A2, A2, A2, A4, A4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fernando Ferreira Carneiro</td>\n",
       "      <td>A1, A1, A1, A1, B1, B1, A4, B1, B1, A1, B1, B1, A1, B1, A4, B4, A4, A2, A2, B1, A3, A1, NA, B2, B1, A1, B2, B2, B2, A1, A3, B2, A1, B2, B3, A3, B3, A3, B2, A1, A1, A4, B1, B3, B2, B3, B2, B2, B2, B2, A1, A1, A1, A3, B1, B1, A1, B1, B1, B1, A3, C, A1, B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Galba Freire Moita</td>\n",
       "      <td>B4, B3, B3, B4, C, A4, A4, A4, B2, B1, B4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gilvan Pessoa Furtado</td>\n",
       "      <td>A2, A2, A1, B3, A1, A1, A1, A1, NA, B1, A1, A1, A2, B1, A2, A1, A1, A3, A4, A2, A2, NA, A3, A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Giovanny Augusto Camacho Antevere Mazzarotto</td>\n",
       "      <td>NA, B2, NA, B4, NA, A2, A1, A1, C, A4, A3, B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ivana Cristina de Holanda Cunha Barreto</td>\n",
       "      <td>NA, A3, B3, A1, A4, A4, A4, A2, B1, A1, B3, A3, A3, A1, A1, A4, A1, A1, A3, NA, A3, B4, B4, A3, A4, B2, A3, A1, A1, NA, A3, B1, A3, B2, A3, A1, B1, B1, B1, A4, A3, A3, A1, A3, B2, A3, B3, A3, B2, B2, NA, NA, A2, B3, NA, B3, B3, B3, B3, A1, NA, B3, B3, B3, B3, NA, B3, B3, B3, A3, B3, B3, B3, NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Jaime Ribeiro Filho</td>\n",
       "      <td>B1, A2, A4, A3, B4, A2, A2, A2, A3, A2, A4, A3, A3, A4, NA, NA, NA, A4, A3, A2, A1, A4, A2, A3, A4, A2, A1, A3, A2, A3, A1, A3, A3, A3, NA, NA, A2, A2, B4, A2, A3, A3, A3, A2, B2, A3, B2, C, B1, B1, A3, NA, A3, A3, B2, A3, A1, A2, A2, A3, A3, A1, A1, A1, A2, A3, A3, A1, B1, A1, C, A3, A2, A3, A3, A4, A2, B3, A3, A3, A2, A1, A3, A1, A2, A2, A1, A3, B2, A3, A1, A3, A3, A3, A1, A3, A4, A1, A2, A2, NA, B3, A3, A1, A1, A2, A2, C, B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>José Luís Passos Cordeiro</td>\n",
       "      <td>B2, A2, NA, A1, C, A4, NA, A1, A1, B2, B1, A1, B3, A3, A1, A1, B3, A2, NA, A2, A2, A2, A2, A2, B2, A2, B4, B4, B4, A4, B2, B2, A2, NA, A2, A3, A4, NA, NA, B3, NA, NA, NA, NA, NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>João Hermínio Martins da Silva</td>\n",
       "      <td>A4, A2, A2, A2, A1, A2, A1, A1, NA, A1, C, A4, B2, A2, A4, A3, A3, A1, A1, A2, A2, A3, A1, B2, A2, A1, B2, A1, A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Luiz Odorico Monteiro de Andrade</td>\n",
       "      <td>A4, NA, A4, A4, A3, B1, B1, B3, A1, A3, A3, A1, A1, A1, A3, A1, A1, A3, B3, B4, A4, A3, B2, B2, A1, B1, A3, A3, B3, A4, A1, A1, A3, A3, A3, A3, A3, A1, A1, A1, A1, A3, A1, A3, A4, B1, A4, NA, NA, B2, NA, NA, B2, NA, NA, NA, A4, NA, NA, A2, A1, NA, B3, B3, B3, B3, NA, NA, B3, B3, B3, B3, NA, NA, NA, NA, B3, A3, NA, NA, B3, NA, B3, B3, NA, B3, B3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Marcela Helena Gambim Fonseca</td>\n",
       "      <td>B3, A2, A4, A4, B1, B1, A1, B1, B1, B1, A2, A1, B1, A1, A3, A3, A1, A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Marcos Roberto Lourenzoni</td>\n",
       "      <td>A2, B1, A1, A2, A4, A3, A3, A3, A1, A4, A1, A1, A1, B1, A1, A2, A2, NA, A1, A2, B2, A2, A2, A1, A4, B2, A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Margareth Borges Coutinho Gallo</td>\n",
       "      <td>B1, A2, C, NA, A1, A2, C, A4, A4, NA, A1, B1, A4, B4, B4, A2, A2, A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Marlos de Medeiros Chaves</td>\n",
       "      <td>A1, A2, A4, C, A1, A1, C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Maximiliano Ponte</td>\n",
       "      <td>B2, A4, A4, C, B3, B3, B3, B1, A4, B1, B1, A1, B2, A3, B1, A3, A1, A3, A3, B1, A3, B3, A3, NA, B1, B1, A1, A4, A1, C, A1, A1, B2, B1, A2, C, C, B1, B2, A1, NA, B2, C, NA, A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Márcio Flávio Moura de Araújo</td>\n",
       "      <td>A2, NA, NA, B1, B3, B3, B1, B1, A3, A3, A1, A1, B1, C, B2, C, A2, A4, B2, A1, C, A2, A2, B2, B1, A2, NA, B1, C, A1, A1, A3, B2, B2, NA, C, C, A2, A2, C, A4, B2, A4, A4, A4, B2, A4, B1, A1, B1, A1, C, A1, C, A1, A3, A4, A2, A2, C, NA, A1, A4, B1, B2, A4, A4, A4, A1, A4, B1, C, C, C, NA, A3, A4, NA, A3, A2, A3, A2, B1, A2, B2, A1, A1, A4, B1, A3, A4, A3, A2, B1, A2, A4, B1, A4, A4, A2, B2, B2, A3, A4, A2, A4, A1, B2, B1, A3, C, A4, A4, A4, A4, B4, A2, B1, A3, A4, A4, B1, A4, B1, A2, A3, A4, A4, B1, A4, B1, B1, B1, B3, B1, B1, B1, B2, B1, B1, B1, B1, B1, B1, A4, A4, NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Raphael Trevizani</td>\n",
       "      <td>A1, A2, B2, A4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Regis Bernardo Brandim Gomes</td>\n",
       "      <td>A4, A2, A2, A1, A1, NA, A2, A2, B1, A4, C, A1, A1, A1, A1, A1, A3, A1, A2, A1, A1, A1, A1, A1, A1, A1, NA, A2, A1, A3, A2, A3, A4, NA, A1, B3, A1, A2, NA, A1, A2, A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Roberto Nicolete</td>\n",
       "      <td>NA, A2, B2, A4, A3, A1, C, A4, A4, A1, A3, A1, A1, A4, A3, A2, A2, A3, A1, A1, B2, C, A2, A4, A1, A3, A4, B2, A3, B1, NA, A2, A2, A4, A2, A1, A1, B1, B4, NA, A4, A2, A1, A1, B4, A3, A3, A4, A3, A4, A2, C, NA, A1, A1, A1, A1, B2, A1, A4, A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Roberto Wagner Júnior Freire de Freitas</td>\n",
       "      <td>B1, B3, A1, A1, C, B1, A3, A3, A2, A2, A4, A1, A1, A1, B1, C, B3, B1, A3, B2, A4, C, C, A1, C, A2, NA, C, A2, C, A4, A3, A4, A4, B1, A4, A2, A4, A1, A3, A2, C, A4, A4, A4, A4, A4, A4, B2, A4, B1, B1, A3, B1, B1, A4, A2, A4, B1, A2, A2, A1, A3, B1, A2, B1, A2, B1, A4, B1, B1, B1, A4, A1, B1, B1, A3, C, A4, B1, A3, B4, B1, A2, B1, A4, A4, A4, A3, B1, A2, A3, B2, B1, B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sharmênia de Araújo Soares Nuto</td>\n",
       "      <td>A4, B1, A2, A1, B1, B4, A1, A3, C, A1, A1, A1, A4, B2, NA, A1, A3, C, A1, A4, B3, B2, A4, A3, B1, B1, B1, A4, B1, B3, B1, B2, B3, B3, A1, NA, B2, B1, B3, B3, NA, C, A1, A1, B3, B2, B2, B2, A4, B2, A1, B4, NA, NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Vanira Matos Pessoa</td>\n",
       "      <td>A1, B1, B1, B1, A4, B1, B1, B1, B3, B1, B2, A1, B1, A4, A4, A4, A1, A3, B2, A1, B1, B2, A1, A3, B2, A1, A1, A3, B1, A1, B4, B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Venúcia Bruna Magalhães Pereira</td>\n",
       "      <td>A4, A3, A2, A2, A2, B3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Autor                                          \\\n",
       "0                           Adriana Costa Bacelo   \n",
       "1              Alice Paula Di Sabatino Guimarães   \n",
       "2                      Ana Camila Oliveira Alves   \n",
       "3                 Ana Cláudia de Araújo Teixeira   \n",
       "4                  Anna Carolina Machado Marinho   \n",
       "5                   Antonio Marcos Aires Barbosa   \n",
       "6     Anya Pimentel Gomes Fernandes Vieira Meyer   \n",
       "7               Carla Freire Celedonio Fernandes   \n",
       "8           Caroline Pereira Bittencourt Passaes   \n",
       "9                       Clarissa Romero Teixeira   \n",
       "10                         Claudia Stutz Zubieta   \n",
       "11                            Dayane Alves Costa   \n",
       "12               Donat Alexander de Chapeaurouge   \n",
       "13                     Eduardo Ruback dos Santos   \n",
       "14                                Fabio Miyajima   \n",
       "15                   Fernanda Savicki de Almeida   \n",
       "16                  Fernando Braga Stehling Dias   \n",
       "17                    Fernando Ferreira Carneiro   \n",
       "18                            Galba Freire Moita   \n",
       "19                         Gilvan Pessoa Furtado   \n",
       "20  Giovanny Augusto Camacho Antevere Mazzarotto   \n",
       "21       Ivana Cristina de Holanda Cunha Barreto   \n",
       "22                           Jaime Ribeiro Filho   \n",
       "23                     José Luís Passos Cordeiro   \n",
       "24                João Hermínio Martins da Silva   \n",
       "25              Luiz Odorico Monteiro de Andrade   \n",
       "26                 Marcela Helena Gambim Fonseca   \n",
       "27                     Marcos Roberto Lourenzoni   \n",
       "28               Margareth Borges Coutinho Gallo   \n",
       "29                     Marlos de Medeiros Chaves   \n",
       "30                             Maximiliano Ponte   \n",
       "31                 Márcio Flávio Moura de Araújo   \n",
       "32                             Raphael Trevizani   \n",
       "33                  Regis Bernardo Brandim Gomes   \n",
       "34                              Roberto Nicolete   \n",
       "35       Roberto Wagner Júnior Freire de Freitas   \n",
       "36               Sharmênia de Araújo Soares Nuto   \n",
       "37                           Vanira Matos Pessoa   \n",
       "38               Venúcia Bruna Magalhães Pereira   \n",
       "\n",
       "   Publicações Qualis                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             A2, NA, B2, B1, B3, B1, A1, B1, B2, B2, A1, NA, B2, B3, B3, NA, B3, NA, NA, NA, NA, NA, NA, NA, NA  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         A1, A2  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         A3, A3  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             A1, B1, B2, A1, A3, A1, B1, A1, A1  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      A1, B2, A1, A3, B2, B3, C  \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         A2, B2  \n",
       "6                                                                                                                                                                          A4, A3, NA, A2, A1, A1, A1, A1, NA, B4, C, C, C, A1, A3, A3, A1, A3, A3, A1, A4, A1, A1, A1, A4, B2, A1, A1, C, B3, A1, B2, B1, A3, A2, A2, A1, A4, A4, A3, A1, A1, A1, A4, A3, B3, B1, B3, B1, A1, B1, A2, B1, A3, C, NA, C, B1, B2, A4, B1, B1, B1, NA, C, NA, C, B2, B2, C, B3, A1, A1, A1, B2, A2, A1, B2, B2, A1, B2, A1, A1, B2, A1, B3, B1, B2, B2, A1, A2, A2, A1, A1, A1, A1, A2, A1, A1, A1, NA, NA, NA, NA  \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                            A1, A2, B2, NA, C, A3, C, C, A2, A1, A3, A1, A1, A1, A4, A2, B1, A2, NA, A1, A2, A3, A1, A1, A1, A1, A4, A1, B1, A4, A1, A3, A3, A3, A3, A3, B4, A2, A3, A1, NA, B4, A3, A1, A1, A2  \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                             A1, A1, NA, A2, A1, A3, A2, A1, A2, A1, A1, A1, A1, A1, A1, B1, A1, A1, A1, A1, A2, A2, A1, B1, A3, A1, A3, A2, A2, B2, B2, A1, A3  \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                             A2, A1, A1, A2, A2, A2, A2, A2, A2, A1, A1, A1, A1, A1, B1, A1, A1, NA, A1, A1, A1, A1, A2, A2, A1, A4, A1, A1, A1, A1, A1, A1, A2, A1, A4, A2, A2, NA, A1, A1, A2, A3, NA, A4, A4  \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    A2, A1, A1, NA, B4, A3, A4  \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        B1, A4, A1, A2, B1, B4, B2, B4, B2, A3  \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                    NA, A2, NA, A1, A1, A2, A3, A1, A2, A2, A3, A2, A4, A2, A2, A1, A1, A2, A2, A2, A2, A2, B1, NA, A2, A4, A4, A2, A1, A3, A1, A2, A1, A1, B3, A1, A1, NA, NA, NA, NA, NA, NA  \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         A1, A1, A1, A1, C, A1  \n",
       "14                                                                                                                                                                                                                                                                                                                                A2, A3, A1, A1, A1, A3, A2, A2, A1, B1, A1, B1, A1, A2, A1, B1, A1, A2, A2, A2, A1, A3, A4, A2, A2, A2, A1, NA, B1, A2, A1, A2, A1, A2, NA, A1, NA, A1, A3, A1, NA, A1, A1, A1, A4, NA, A1, NA, A4, A1, A1, A1, A1, A2, A1, A1, A1, A2, A2, A2, NA, NA, B3, NA  \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 B4, C, NA, NA, B1, NA, B2, B4  \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    A2, A1, A1, A1, A1, A2, A1, A2, A1, A1, A1, A1, A2, A2, B1, B1, A1, A2, A2, A2, A2, A4, A4  \n",
       "17                                                                                                                                                                                                                                                                                                                                 A1, A1, A1, A1, B1, B1, A4, B1, B1, A1, B1, B1, A1, B1, A4, B4, A4, A2, A2, B1, A3, A1, NA, B2, B1, A1, B2, B2, B2, A1, A3, B2, A1, B2, B3, A3, B3, A3, B2, A1, A1, A4, B1, B3, B2, B3, B2, B2, B2, B2, A1, A1, A1, A3, B1, B1, A1, B1, B1, B1, A3, C, A1, B1  \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     B4, B3, B3, B4, C, A4, A4, A4, B2, B1, B4  \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                A2, A2, A1, B3, A1, A1, A1, A1, NA, B1, A1, A1, A2, B1, A2, A1, A1, A3, A4, A2, A2, NA, A3, A1  \n",
       "20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 NA, B2, NA, B4, NA, A2, A1, A1, C, A4, A3, B2  \n",
       "21                                                                                                                                                                                                                                                                                        NA, A3, B3, A1, A4, A4, A4, A2, B1, A1, B3, A3, A3, A1, A1, A4, A1, A1, A3, NA, A3, B4, B4, A3, A4, B2, A3, A1, A1, NA, A3, B1, A3, B2, A3, A1, B1, B1, B1, A4, A3, A3, A1, A3, B2, A3, B3, A3, B2, B2, NA, NA, A2, B3, NA, B3, B3, B3, B3, A1, NA, B3, B3, B3, B3, NA, B3, B3, B3, A3, B3, B3, B3, NA  \n",
       "22                                                                                                                                               B1, A2, A4, A3, B4, A2, A2, A2, A3, A2, A4, A3, A3, A4, NA, NA, NA, A4, A3, A2, A1, A4, A2, A3, A4, A2, A1, A3, A2, A3, A1, A3, A3, A3, NA, NA, A2, A2, B4, A2, A3, A3, A3, A2, B2, A3, B2, C, B1, B1, A3, NA, A3, A3, B2, A3, A1, A2, A2, A3, A3, A1, A1, A1, A2, A3, A3, A1, B1, A1, C, A3, A2, A3, A3, A4, A2, B3, A3, A3, A2, A1, A3, A1, A2, A2, A1, A3, B2, A3, A1, A3, A3, A3, A1, A3, A4, A1, A2, A2, NA, B3, A3, A1, A1, A2, A2, C, B1  \n",
       "23                                                                                                                                                                                                                                                                                                                                                                                                             B2, A2, NA, A1, C, A4, NA, A1, A1, B2, B1, A1, B3, A3, A1, A1, B3, A2, NA, A2, A2, A2, A2, A2, B2, A2, B4, B4, B4, A4, B2, B2, A2, NA, A2, A3, A4, NA, NA, B3, NA, NA, NA, NA, NA  \n",
       "24                                                                                                                                                                                                                                                                                                                                                                                                                                                                             A4, A2, A2, A2, A1, A2, A1, A1, NA, A1, C, A4, B2, A2, A4, A3, A3, A1, A1, A2, A2, A3, A1, B2, A2, A1, B2, A1, A2  \n",
       "25                                                                                                                                                                                                                                    A4, NA, A4, A4, A3, B1, B1, B3, A1, A3, A3, A1, A1, A1, A3, A1, A1, A3, B3, B4, A4, A3, B2, B2, A1, B1, A3, A3, B3, A4, A1, A1, A3, A3, A3, A3, A3, A1, A1, A1, A1, A3, A1, A3, A4, B1, A4, NA, NA, B2, NA, NA, B2, NA, NA, NA, A4, NA, NA, A2, A1, NA, B3, B3, B3, B3, NA, NA, B3, B3, B3, B3, NA, NA, NA, NA, B3, A3, NA, NA, B3, NA, B3, B3, NA, B3, B3  \n",
       "26                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        B3, A2, A4, A4, B1, B1, A1, B1, B1, B1, A2, A1, B1, A1, A3, A3, A1, A1  \n",
       "27                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    A2, B1, A1, A2, A4, A3, A3, A3, A1, A4, A1, A1, A1, B1, A1, A2, A2, NA, A1, A2, B2, A2, A2, A1, A4, B2, A3  \n",
       "28                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          B1, A2, C, NA, A1, A2, C, A4, A4, NA, A1, B1, A4, B4, B4, A2, A2, A1  \n",
       "29                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      A1, A2, A4, C, A1, A1, C  \n",
       "30                                                                                                                                                                                                                                                                                                                                                                                                                 B2, A4, A4, C, B3, B3, B3, B1, A4, B1, B1, A1, B2, A3, B1, A3, A1, A3, A3, B1, A3, B3, A3, NA, B1, B1, A1, A4, A1, C, A1, A1, B2, B1, A2, C, C, B1, B2, A1, NA, B2, C, NA, A3  \n",
       "31  A2, NA, NA, B1, B3, B3, B1, B1, A3, A3, A1, A1, B1, C, B2, C, A2, A4, B2, A1, C, A2, A2, B2, B1, A2, NA, B1, C, A1, A1, A3, B2, B2, NA, C, C, A2, A2, C, A4, B2, A4, A4, A4, B2, A4, B1, A1, B1, A1, C, A1, C, A1, A3, A4, A2, A2, C, NA, A1, A4, B1, B2, A4, A4, A4, A1, A4, B1, C, C, C, NA, A3, A4, NA, A3, A2, A3, A2, B1, A2, B2, A1, A1, A4, B1, A3, A4, A3, A2, B1, A2, A4, B1, A4, A4, A2, B2, B2, A3, A4, A2, A4, A1, B2, B1, A3, C, A4, A4, A4, A4, B4, A2, B1, A3, A4, A4, B1, A4, B1, A2, A3, A4, A4, B1, A4, B1, B1, B1, B3, B1, B1, B1, B2, B1, B1, B1, B1, B1, B1, A4, A4, NA  \n",
       "32                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                A1, A2, B2, A4  \n",
       "33                                                                                                                                                                                                                                                                                                                                                                                                                         A4, A2, A2, A1, A1, NA, A2, A2, B1, A4, C, A1, A1, A1, A1, A1, A3, A1, A2, A1, A1, A1, A1, A1, A1, A1, NA, A2, A1, A3, A2, A3, A4, NA, A1, B3, A1, A2, NA, A1, A2, A1  \n",
       "34                                                                                                                                                                                                                                                                                                                                               NA, A2, B2, A4, A3, A1, C, A4, A4, A1, A3, A1, A1, A4, A3, A2, A2, A3, A1, A1, B2, C, A2, A4, A1, A3, A4, B2, A3, B1, NA, A2, A2, A4, A2, A1, A1, B1, B4, NA, A4, A2, A1, A1, B4, A3, A3, A4, A3, A4, A2, C, NA, A1, A1, A1, A1, B2, A1, A4, A3  \n",
       "35                                                                                                                                                                                                             B1, B3, A1, A1, C, B1, A3, A3, A2, A2, A4, A1, A1, A1, B1, C, B3, B1, A3, B2, A4, C, C, A1, C, A2, NA, C, A2, C, A4, A3, A4, A4, B1, A4, A2, A4, A1, A3, A2, C, A4, A4, A4, A4, A4, A4, B2, A4, B1, B1, A3, B1, B1, A4, A2, A4, B1, A2, A2, A1, A3, B1, A2, B1, A2, B1, A4, B1, B1, B1, A4, A1, B1, B1, A3, C, A4, B1, A3, B4, B1, A2, B1, A4, A4, A4, A3, B1, A2, A3, B2, B1, B1  \n",
       "36                                                                                                                                                                                                                                                                                                                                                                           A4, B1, A2, A1, B1, B4, A1, A3, C, A1, A1, A1, A4, B2, NA, A1, A3, C, A1, A4, B3, B2, A4, A3, B1, B1, B1, A4, B1, B3, B1, B2, B3, B3, A1, NA, B2, B1, B3, B3, NA, C, A1, A1, B3, B2, B2, B2, A4, B2, A1, B4, NA, NA  \n",
       "37                                                                                                                                                                                                                                                                                                                                                                                                                                                                A1, B1, B1, B1, A4, B1, B1, B1, B3, B1, B2, A1, B1, A4, A4, A4, A1, A3, B2, A1, B1, B2, A1, A3, B2, A1, A1, A3, B1, A1, B4, B2  \n",
       "38                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        A4, A3, A2, A2, A2, B3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atualizador.contar_qualis(dict_list_docents, ano_inicio, ano_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a81b8",
   "metadata": {},
   "source": [
    "#### Classificar artigos no período pelo Qualis Periódicos\n",
    "\n",
    "Obs.: 'Não encontrado' significa que o ISSN da revista da publicação não consta na lista de revistas avaliadas no Qualis Periódico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f98d76f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Ano</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adriana Costa Bacelo</th>\n",
       "      <td>B1, B2, B2</td>\n",
       "      <td></td>\n",
       "      <td>B1, A1</td>\n",
       "      <td></td>\n",
       "      <td>B3</td>\n",
       "      <td>B2, B1</td>\n",
       "      <td></td>\n",
       "      <td>A2, NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alice Paula Di Sabatino Guimarães</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A1, A2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ana Camila Oliveira Alves</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A3</td>\n",
       "      <td>A3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ana Cláudia de Araújo Teixeira</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>B1</td>\n",
       "      <td>A1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anna Carolina Machado Marinho</th>\n",
       "      <td></td>\n",
       "      <td>B2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A1, A3</td>\n",
       "      <td></td>\n",
       "      <td>B2</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antonio Marcos Aires Barbosa</th>\n",
       "      <td></td>\n",
       "      <td>B2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anya Pimentel Gomes Fernandes Vieira Meyer</th>\n",
       "      <td>A3, B3, B1, B3</td>\n",
       "      <td>A1, A1, A1, A4</td>\n",
       "      <td>A1, A4, A4, A3</td>\n",
       "      <td>C, B3, A1, B2, B1, A3, A2, A2</td>\n",
       "      <td>A3, A3, A1, A4, A1, A1, A1, A4, B2, A1, A1</td>\n",
       "      <td>C, C, C, A1, A3, A3, A1</td>\n",
       "      <td>NA, A2, A1, A1, A1, A1, NA, B4</td>\n",
       "      <td>A4, A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carla Freire Celedonio Fernandes</th>\n",
       "      <td>A2, A3, A1, A1, A1</td>\n",
       "      <td>A2, NA, A1</td>\n",
       "      <td>A2, B1</td>\n",
       "      <td>A1, A1, A4</td>\n",
       "      <td>A2, A1, A3, A1</td>\n",
       "      <td>C, A3, C, C</td>\n",
       "      <td>B2, NA</td>\n",
       "      <td>A1, A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caroline Pereira Bittencourt Passaes</th>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>B1, A1</td>\n",
       "      <td>A1, A1, A1, A1</td>\n",
       "      <td>A3, A2, A1, A2, A1, A1</td>\n",
       "      <td>A2, A1</td>\n",
       "      <td>A1, NA</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clarissa Romero Teixeira</th>\n",
       "      <td></td>\n",
       "      <td>A2, A2, A2, A2</td>\n",
       "      <td></td>\n",
       "      <td>A2</td>\n",
       "      <td></td>\n",
       "      <td>A2</td>\n",
       "      <td>A1, A1</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claudia Stutz Zubieta</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NA</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dayane Alves Costa</th>\n",
       "      <td>A1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A4</td>\n",
       "      <td></td>\n",
       "      <td>B1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donat Alexander de Chapeaurouge</th>\n",
       "      <td>NA</td>\n",
       "      <td>A2</td>\n",
       "      <td>NA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eduardo Ruback dos Santos</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A1, A1, A1</td>\n",
       "      <td></td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fabio Miyajima</th>\n",
       "      <td>A1, A2, NA, A1, NA, A1</td>\n",
       "      <td>NA, B1, A2, A1, A2</td>\n",
       "      <td>A2, A2, A2, A1</td>\n",
       "      <td>A2, A1, A3, A4</td>\n",
       "      <td>A1, A2, A1, B1, A1, A2, A2</td>\n",
       "      <td>A3, A1, A1, A1, A3, A2, A2, A1, B1, A1, B1</td>\n",
       "      <td>A2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fernanda Savicki de Almeida</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td></td>\n",
       "      <td>B4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fernando Braga Stehling Dias</th>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>A2</td>\n",
       "      <td>A1, A2, A1</td>\n",
       "      <td>A1, A1, A1</td>\n",
       "      <td>A2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fernando Ferreira Carneiro</th>\n",
       "      <td>B1, A3, A1, NA</td>\n",
       "      <td>B4, A4, A2, A2</td>\n",
       "      <td>A4</td>\n",
       "      <td>B1, A1, B1</td>\n",
       "      <td>B1, A1, B1</td>\n",
       "      <td>B1, B1, A4, B1</td>\n",
       "      <td>A1, A1</td>\n",
       "      <td>A1, A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Galba Freire Moita</th>\n",
       "      <td></td>\n",
       "      <td>B1</td>\n",
       "      <td>A4, A4, B2</td>\n",
       "      <td>C, A4</td>\n",
       "      <td>B3, B3, B4</td>\n",
       "      <td>B4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gilvan Pessoa Furtado</th>\n",
       "      <td>A2, B1</td>\n",
       "      <td>A1, A1</td>\n",
       "      <td>A1, NA, B1</td>\n",
       "      <td></td>\n",
       "      <td>A1, A1, A1</td>\n",
       "      <td>A1, B3</td>\n",
       "      <td>A2, A2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Giovanny Augusto Camacho Antevere Mazzarotto</th>\n",
       "      <td>A2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>B4, NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>B2</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivana Cristina de Holanda Cunha Barreto</th>\n",
       "      <td>A1, A1, NA, A3, B1, A3, B2</td>\n",
       "      <td>B4, A3, A4, B2, A3</td>\n",
       "      <td>A3, B4</td>\n",
       "      <td>A1, A3, NA</td>\n",
       "      <td>A3, A1, A1, A4, A1</td>\n",
       "      <td>A4, A4, A2, B1, A1, B3, A3</td>\n",
       "      <td>NA, A3, B3, A1, A4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaime Ribeiro Filho</th>\n",
       "      <td>A2, A1, A3, B2, A3, A1, A3, A3, A3</td>\n",
       "      <td>A1, A3, A1, A2</td>\n",
       "      <td>A3, A3, A2</td>\n",
       "      <td>A1, A1, A1, A2, A3, A3, A1, B1, A1, C, A3, A2, A3, A3, A4, A2, B3</td>\n",
       "      <td>A3, A3, A2, B2, A3, B2, C, B1, B1, A3, NA, A3, A3, B2, A3, A1, A2, A2, A3, A3</td>\n",
       "      <td>A1, A3, A2, A3, A1, A3, A3, A3, NA, NA, A2, A2, B4, A2, A3</td>\n",
       "      <td>B4, A2, A2, A2, A3, A2, A4, A3, A3, A4, NA, NA, NA, A4, A3, A2, A1, A4, A2, A3, A4, A2</td>\n",
       "      <td>B1, A2, A4, A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>José Luís Passos Cordeiro</th>\n",
       "      <td></td>\n",
       "      <td>A2, NA, A2, A2, A2, A2</td>\n",
       "      <td>A1, B3</td>\n",
       "      <td>A1, B2, B1, A1, B3, A3, A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1, C, A4, NA</td>\n",
       "      <td>A2, NA</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>João Hermínio Martins da Silva</th>\n",
       "      <td>A1, A2, A2, A3</td>\n",
       "      <td></td>\n",
       "      <td>A3, A3, A1</td>\n",
       "      <td>A2, A4</td>\n",
       "      <td>C, A4, B2</td>\n",
       "      <td>A2, A1, A2, A1, A1, NA, A1</td>\n",
       "      <td>A4, A2, A2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luiz Odorico Monteiro de Andrade</th>\n",
       "      <td>A1, B1, A3</td>\n",
       "      <td>A4, A3, B2, B2</td>\n",
       "      <td>B3, B4</td>\n",
       "      <td>A1, A3</td>\n",
       "      <td>A1, A1, A1, A3, A1</td>\n",
       "      <td>B1, B1, B3, A1, A3, A3</td>\n",
       "      <td>NA, A4, A4, A3</td>\n",
       "      <td>A4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcela Helena Gambim Fonseca</th>\n",
       "      <td></td>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td></td>\n",
       "      <td>A2, A1</td>\n",
       "      <td>B1, A1, B1, B1, B1</td>\n",
       "      <td>A2, A4, A4, B1</td>\n",
       "      <td>B3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcos Roberto Lourenzoni</th>\n",
       "      <td>B1, A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1, A1</td>\n",
       "      <td>A3, A1, A4</td>\n",
       "      <td>A3, A3</td>\n",
       "      <td>A1, A2, A4</td>\n",
       "      <td>A2, B1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Margareth Borges Coutinho Gallo</th>\n",
       "      <td></td>\n",
       "      <td>C, NA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>B1, A2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marlos de Medeiros Chaves</th>\n",
       "      <td></td>\n",
       "      <td>C, A1</td>\n",
       "      <td></td>\n",
       "      <td>A4</td>\n",
       "      <td>A2</td>\n",
       "      <td>A1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maximiliano Ponte</th>\n",
       "      <td>A3, A1, A3, A3</td>\n",
       "      <td>B1</td>\n",
       "      <td>B2, A3</td>\n",
       "      <td>B1, B1, A1</td>\n",
       "      <td>B3, B3, B3, B1, A4</td>\n",
       "      <td>C</td>\n",
       "      <td>B2, A4, A4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Márcio Flávio Moura de Araújo</th>\n",
       "      <td>B1, B2, A4, A4, A4, A1, A4</td>\n",
       "      <td>A1, C, A1, A3, A4, A2, A2, C, NA, A1, A4</td>\n",
       "      <td>A4, B2, A4, B1, A1, B1, A1, C</td>\n",
       "      <td>A3, B2, B2, NA, C, C, A2, A2, C, A4, B2, A4, A4</td>\n",
       "      <td>A2, A2, B2, B1, A2, NA, B1, C, A1, A1</td>\n",
       "      <td>B1, C, B2, C, A2, A4, B2, A1, C</td>\n",
       "      <td>B1, B3, B3, B1, B1, A3, A3, A1, A1</td>\n",
       "      <td>A2, NA, NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raphael Trevizani</th>\n",
       "      <td>A1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regis Bernardo Brandim Gomes</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A4, C</td>\n",
       "      <td>B1</td>\n",
       "      <td>NA, A2, A2</td>\n",
       "      <td>A1, A1</td>\n",
       "      <td>A4, A2, A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roberto Nicolete</th>\n",
       "      <td>NA, A2, A2</td>\n",
       "      <td>A3, B1</td>\n",
       "      <td>A4, B2</td>\n",
       "      <td>C, A2, A4, A1, A3</td>\n",
       "      <td>A2, A3, A1, A1, B2</td>\n",
       "      <td>A1, A3, A1, A1, A4, A3, A2</td>\n",
       "      <td>B2, A4, A3, A1, C, A4, A4</td>\n",
       "      <td>NA, A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roberto Wagner Júnior Freire de Freitas</th>\n",
       "      <td>A4, A4, A4, B2, A4</td>\n",
       "      <td>A4, A1, A3, A2, C, A4, A4, A4</td>\n",
       "      <td>A4, A3, A4, A4, B1, A4, A2</td>\n",
       "      <td>A3, B2, A4, C, C, A1, C, A2, NA, C, A2, C</td>\n",
       "      <td>A3, A2, A2, A4, A1, A1, A1, B1, C, B3, B1</td>\n",
       "      <td>C, B1, A3</td>\n",
       "      <td>B3, A1, A1</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharmênia de Araújo Soares Nuto</th>\n",
       "      <td>A3, B1</td>\n",
       "      <td>B2, A4</td>\n",
       "      <td>A4, B3</td>\n",
       "      <td>NA, A1, A3, C, A1</td>\n",
       "      <td>A3, C, A1, A1, A1, A4, B2</td>\n",
       "      <td>B1, B4, A1</td>\n",
       "      <td>A2, A1</td>\n",
       "      <td>A4, B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanira Matos Pessoa</th>\n",
       "      <td>A1, A3</td>\n",
       "      <td>A4, A4</td>\n",
       "      <td>A4</td>\n",
       "      <td>B1</td>\n",
       "      <td>B1, B2, A1</td>\n",
       "      <td>A4, B1, B1, B1, B3</td>\n",
       "      <td>A1, B1, B1, B1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venúcia Bruna Magalhães Pereira</th>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "      <td>A3</td>\n",
       "      <td></td>\n",
       "      <td>A4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ano                                          2017                                 \\\n",
       "Autor                                                                              \n",
       "Adriana Costa Bacelo                                                  B1, B2, B2   \n",
       "Alice Paula Di Sabatino Guimarães                                                  \n",
       "Ana Camila Oliveira Alves                                                          \n",
       "Ana Cláudia de Araújo Teixeira                                                     \n",
       "Anna Carolina Machado Marinho                                                      \n",
       "Antonio Marcos Aires Barbosa                                                       \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer                        A3, B3, B1, B3   \n",
       "Carla Freire Celedonio Fernandes                              A2, A3, A1, A1, A1   \n",
       "Caroline Pereira Bittencourt Passaes                                          A1   \n",
       "Clarissa Romero Teixeira                                                           \n",
       "Claudia Stutz Zubieta                                                              \n",
       "Dayane Alves Costa                                                            A1   \n",
       "Donat Alexander de Chapeaurouge                                               NA   \n",
       "Eduardo Ruback dos Santos                                                          \n",
       "Fabio Miyajima                                            A1, A2, NA, A1, NA, A1   \n",
       "Fernanda Savicki de Almeida                                                   NA   \n",
       "Fernando Braga Stehling Dias                                                  A1   \n",
       "Fernando Ferreira Carneiro                                        B1, A3, A1, NA   \n",
       "Galba Freire Moita                                                                 \n",
       "Gilvan Pessoa Furtado                                                     A2, B1   \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto                                  A2   \n",
       "Ivana Cristina de Holanda Cunha Barreto               A1, A1, NA, A3, B1, A3, B2   \n",
       "Jaime Ribeiro Filho                           A2, A1, A3, B2, A3, A1, A3, A3, A3   \n",
       "José Luís Passos Cordeiro                                                          \n",
       "João Hermínio Martins da Silva                                    A1, A2, A2, A3   \n",
       "Luiz Odorico Monteiro de Andrade                                      A1, B1, A3   \n",
       "Marcela Helena Gambim Fonseca                                                      \n",
       "Marcos Roberto Lourenzoni                                                 B1, A1   \n",
       "Margareth Borges Coutinho Gallo                                                    \n",
       "Marlos de Medeiros Chaves                                                          \n",
       "Maximiliano Ponte                                                 A3, A1, A3, A3   \n",
       "Márcio Flávio Moura de Araújo                         B1, B2, A4, A4, A4, A1, A4   \n",
       "Raphael Trevizani                                                             A1   \n",
       "Regis Bernardo Brandim Gomes                                                       \n",
       "Roberto Nicolete                                                      NA, A2, A2   \n",
       "Roberto Wagner Júnior Freire de Freitas                       A4, A4, A4, B2, A4   \n",
       "Sharmênia de Araújo Soares Nuto                                           A3, B1   \n",
       "Vanira Matos Pessoa                                                       A1, A3   \n",
       "Venúcia Bruna Magalhães Pereira                                               A2   \n",
       "\n",
       "Ano                                          2018                                       \\\n",
       "Autor                                                                                    \n",
       "Adriana Costa Bacelo                                                                     \n",
       "Alice Paula Di Sabatino Guimarães                                                        \n",
       "Ana Camila Oliveira Alves                                                                \n",
       "Ana Cláudia de Araújo Teixeira                                                           \n",
       "Anna Carolina Machado Marinho                                                       B2   \n",
       "Antonio Marcos Aires Barbosa                                                        B2   \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer                              A1, A1, A1, A4   \n",
       "Carla Freire Celedonio Fernandes                                            A2, NA, A1   \n",
       "Caroline Pereira Bittencourt Passaes                                                A1   \n",
       "Clarissa Romero Teixeira                                                A2, A2, A2, A2   \n",
       "Claudia Stutz Zubieta                                                                    \n",
       "Dayane Alves Costa                                                                       \n",
       "Donat Alexander de Chapeaurouge                                                     A2   \n",
       "Eduardo Ruback dos Santos                                                                \n",
       "Fabio Miyajima                                                      NA, B1, A2, A1, A2   \n",
       "Fernanda Savicki de Almeida                                                         NA   \n",
       "Fernando Braga Stehling Dias                                                        A1   \n",
       "Fernando Ferreira Carneiro                                              B4, A4, A2, A2   \n",
       "Galba Freire Moita                                                                  B1   \n",
       "Gilvan Pessoa Furtado                                                           A1, A1   \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto                                             \n",
       "Ivana Cristina de Holanda Cunha Barreto                             B4, A3, A4, B2, A3   \n",
       "Jaime Ribeiro Filho                                                     A1, A3, A1, A2   \n",
       "José Luís Passos Cordeiro                                       A2, NA, A2, A2, A2, A2   \n",
       "João Hermínio Martins da Silva                                                           \n",
       "Luiz Odorico Monteiro de Andrade                                        A4, A3, B2, B2   \n",
       "Marcela Helena Gambim Fonseca                                                       A1   \n",
       "Marcos Roberto Lourenzoni                                                           A1   \n",
       "Margareth Borges Coutinho Gallo                                                  C, NA   \n",
       "Marlos de Medeiros Chaves                                                        C, A1   \n",
       "Maximiliano Ponte                                                                   B1   \n",
       "Márcio Flávio Moura de Araújo                 A1, C, A1, A3, A4, A2, A2, C, NA, A1, A4   \n",
       "Raphael Trevizani                                                                        \n",
       "Regis Bernardo Brandim Gomes                                                             \n",
       "Roberto Nicolete                                                                A3, B1   \n",
       "Roberto Wagner Júnior Freire de Freitas                  A4, A1, A3, A2, C, A4, A4, A4   \n",
       "Sharmênia de Araújo Soares Nuto                                                 B2, A4   \n",
       "Vanira Matos Pessoa                                                             A4, A4   \n",
       "Venúcia Bruna Magalhães Pereira                                                     A2   \n",
       "\n",
       "Ano                                          2019                            \\\n",
       "Autor                                                                         \n",
       "Adriana Costa Bacelo                                                 B1, A1   \n",
       "Alice Paula Di Sabatino Guimarães                                             \n",
       "Ana Camila Oliveira Alves                                                     \n",
       "Ana Cláudia de Araújo Teixeira                                                \n",
       "Anna Carolina Machado Marinho                                                 \n",
       "Antonio Marcos Aires Barbosa                                                  \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer                   A1, A4, A4, A3   \n",
       "Carla Freire Celedonio Fernandes                                     A2, B1   \n",
       "Caroline Pereira Bittencourt Passaes                                 B1, A1   \n",
       "Clarissa Romero Teixeira                                                      \n",
       "Claudia Stutz Zubieta                                                         \n",
       "Dayane Alves Costa                                                            \n",
       "Donat Alexander de Chapeaurouge                                          NA   \n",
       "Eduardo Ruback dos Santos                                                     \n",
       "Fabio Miyajima                                               A2, A2, A2, A1   \n",
       "Fernanda Savicki de Almeida                                                   \n",
       "Fernando Braga Stehling Dias                                             A1   \n",
       "Fernando Ferreira Carneiro                                               A4   \n",
       "Galba Freire Moita                                               A4, A4, B2   \n",
       "Gilvan Pessoa Furtado                                            A1, NA, B1   \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto                                  \n",
       "Ivana Cristina de Holanda Cunha Barreto                              A3, B4   \n",
       "Jaime Ribeiro Filho                                              A3, A3, A2   \n",
       "José Luís Passos Cordeiro                                            A1, B3   \n",
       "João Hermínio Martins da Silva                                   A3, A3, A1   \n",
       "Luiz Odorico Monteiro de Andrade                                     B3, B4   \n",
       "Marcela Helena Gambim Fonseca                                            B1   \n",
       "Marcos Roberto Lourenzoni                                            A1, A1   \n",
       "Margareth Borges Coutinho Gallo                                               \n",
       "Marlos de Medeiros Chaves                                                     \n",
       "Maximiliano Ponte                                                    B2, A3   \n",
       "Márcio Flávio Moura de Araújo                 A4, B2, A4, B1, A1, B1, A1, C   \n",
       "Raphael Trevizani                                                             \n",
       "Regis Bernardo Brandim Gomes                                                  \n",
       "Roberto Nicolete                                                     A4, B2   \n",
       "Roberto Wagner Júnior Freire de Freitas          A4, A3, A4, A4, B1, A4, A2   \n",
       "Sharmênia de Araújo Soares Nuto                                      A4, B3   \n",
       "Vanira Matos Pessoa                                                      A4   \n",
       "Venúcia Bruna Magalhães Pereira                                          A3   \n",
       "\n",
       "Ano                                          2020                                                                \\\n",
       "Autor                                                                                                             \n",
       "Adriana Costa Bacelo                                                                                              \n",
       "Alice Paula Di Sabatino Guimarães                                                                                 \n",
       "Ana Camila Oliveira Alves                                                                                         \n",
       "Ana Cláudia de Araújo Teixeira                                                                                    \n",
       "Anna Carolina Machado Marinho                                                                                     \n",
       "Antonio Marcos Aires Barbosa                                                                                      \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer                                        C, B3, A1, B2, B1, A3, A2, A2   \n",
       "Carla Freire Celedonio Fernandes                                                                     A1, A1, A4   \n",
       "Caroline Pereira Bittencourt Passaes                                                             A1, A1, A1, A1   \n",
       "Clarissa Romero Teixeira                                                                                     A2   \n",
       "Claudia Stutz Zubieta                                                                                             \n",
       "Dayane Alves Costa                                                                                                \n",
       "Donat Alexander de Chapeaurouge                                                                                   \n",
       "Eduardo Ruback dos Santos                                                                                         \n",
       "Fabio Miyajima                                                                                   A2, A1, A3, A4   \n",
       "Fernanda Savicki de Almeida                                                                                       \n",
       "Fernando Braga Stehling Dias                                                                                 A2   \n",
       "Fernando Ferreira Carneiro                                                                           B1, A1, B1   \n",
       "Galba Freire Moita                                                                                        C, A4   \n",
       "Gilvan Pessoa Furtado                                                                                             \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto                                                                      \n",
       "Ivana Cristina de Holanda Cunha Barreto                                                              A1, A3, NA   \n",
       "Jaime Ribeiro Filho                           A1, A1, A1, A2, A3, A3, A1, B1, A1, C, A3, A2, A3, A3, A4, A2, B3   \n",
       "José Luís Passos Cordeiro                                                            A1, B2, B1, A1, B3, A3, A1   \n",
       "João Hermínio Martins da Silva                                                                           A2, A4   \n",
       "Luiz Odorico Monteiro de Andrade                                                                         A1, A3   \n",
       "Marcela Helena Gambim Fonseca                                                                                     \n",
       "Marcos Roberto Lourenzoni                                                                            A3, A1, A4   \n",
       "Margareth Borges Coutinho Gallo                                                                                   \n",
       "Marlos de Medeiros Chaves                                                                                    A4   \n",
       "Maximiliano Ponte                                                                                    B1, B1, A1   \n",
       "Márcio Flávio Moura de Araújo                                   A3, B2, B2, NA, C, C, A2, A2, C, A4, B2, A4, A4   \n",
       "Raphael Trevizani                                                                                                 \n",
       "Regis Bernardo Brandim Gomes                                                                              A4, C   \n",
       "Roberto Nicolete                                                                              C, A2, A4, A1, A3   \n",
       "Roberto Wagner Júnior Freire de Freitas                               A3, B2, A4, C, C, A1, C, A2, NA, C, A2, C   \n",
       "Sharmênia de Araújo Soares Nuto                                                               NA, A1, A3, C, A1   \n",
       "Vanira Matos Pessoa                                                                                          B1   \n",
       "Venúcia Bruna Magalhães Pereira                                                                                   \n",
       "\n",
       "Ano                                          2021                                                                            \\\n",
       "Autor                                                                                                                         \n",
       "Adriana Costa Bacelo                                                                                                     B3   \n",
       "Alice Paula Di Sabatino Guimarães                                                                                    A1, A2   \n",
       "Ana Camila Oliveira Alves                                                                                                A3   \n",
       "Ana Cláudia de Araújo Teixeira                                                                                                \n",
       "Anna Carolina Machado Marinho                                                                                        A1, A3   \n",
       "Antonio Marcos Aires Barbosa                                                                                                  \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer                                       A3, A3, A1, A4, A1, A1, A1, A4, B2, A1, A1   \n",
       "Carla Freire Celedonio Fernandes                                                                             A2, A1, A3, A1   \n",
       "Caroline Pereira Bittencourt Passaes                                                                 A3, A2, A1, A2, A1, A1   \n",
       "Clarissa Romero Teixeira                                                                                                      \n",
       "Claudia Stutz Zubieta                                                                                                    NA   \n",
       "Dayane Alves Costa                                                                                                       A4   \n",
       "Donat Alexander de Chapeaurouge                                                                                               \n",
       "Eduardo Ruback dos Santos                                                                                                     \n",
       "Fabio Miyajima                                                                                   A1, A2, A1, B1, A1, A2, A2   \n",
       "Fernanda Savicki de Almeida                                                                                               C   \n",
       "Fernando Braga Stehling Dias                                                                                     A1, A2, A1   \n",
       "Fernando Ferreira Carneiro                                                                                       B1, A1, B1   \n",
       "Galba Freire Moita                                                                                               B3, B3, B4   \n",
       "Gilvan Pessoa Furtado                                                                                            A1, A1, A1   \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto                                                                         B4, NA   \n",
       "Ivana Cristina de Holanda Cunha Barreto                                                                  A3, A1, A1, A4, A1   \n",
       "Jaime Ribeiro Filho                           A3, A3, A2, B2, A3, B2, C, B1, B1, A3, NA, A3, A3, B2, A3, A1, A2, A2, A3, A3   \n",
       "José Luís Passos Cordeiro                                                                                                A1   \n",
       "João Hermínio Martins da Silva                                                                                    C, A4, B2   \n",
       "Luiz Odorico Monteiro de Andrade                                                                         A1, A1, A1, A3, A1   \n",
       "Marcela Helena Gambim Fonseca                                                                                        A2, A1   \n",
       "Marcos Roberto Lourenzoni                                                                                            A3, A3   \n",
       "Margareth Borges Coutinho Gallo                                                                                      B1, A2   \n",
       "Marlos de Medeiros Chaves                                                                                                A2   \n",
       "Maximiliano Ponte                                                                                        B3, B3, B3, B1, A4   \n",
       "Márcio Flávio Moura de Araújo                                                         A2, A2, B2, B1, A2, NA, B1, C, A1, A1   \n",
       "Raphael Trevizani                                                                                                             \n",
       "Regis Bernardo Brandim Gomes                                                                                             B1   \n",
       "Roberto Nicolete                                                                                         A2, A3, A1, A1, B2   \n",
       "Roberto Wagner Júnior Freire de Freitas                                           A3, A2, A2, A4, A1, A1, A1, B1, C, B3, B1   \n",
       "Sharmênia de Araújo Soares Nuto                                                                   A3, C, A1, A1, A1, A4, B2   \n",
       "Vanira Matos Pessoa                                                                                              B1, B2, A1   \n",
       "Venúcia Bruna Magalhães Pereira                                                                                          A4   \n",
       "\n",
       "Ano                                          2022                                                         \\\n",
       "Autor                                                                                                      \n",
       "Adriana Costa Bacelo                                                                              B2, B1   \n",
       "Alice Paula Di Sabatino Guimarães                                                                          \n",
       "Ana Camila Oliveira Alves                                                                             A3   \n",
       "Ana Cláudia de Araújo Teixeira                                                                        B1   \n",
       "Anna Carolina Machado Marinho                                                                              \n",
       "Antonio Marcos Aires Barbosa                                                                               \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer                                       C, C, C, A1, A3, A3, A1   \n",
       "Carla Freire Celedonio Fernandes                                                             C, A3, C, C   \n",
       "Caroline Pereira Bittencourt Passaes                                                              A2, A1   \n",
       "Clarissa Romero Teixeira                                                                              A2   \n",
       "Claudia Stutz Zubieta                                                                                 A1   \n",
       "Dayane Alves Costa                                                                                         \n",
       "Donat Alexander de Chapeaurouge                                                                            \n",
       "Eduardo Ruback dos Santos                                                                     A1, A1, A1   \n",
       "Fabio Miyajima                                                A3, A1, A1, A1, A3, A2, A2, A1, B1, A1, B1   \n",
       "Fernanda Savicki de Almeida                                                                                \n",
       "Fernando Braga Stehling Dias                                                                  A1, A1, A1   \n",
       "Fernando Ferreira Carneiro                                                                B1, B1, A4, B1   \n",
       "Galba Freire Moita                                                                                    B4   \n",
       "Gilvan Pessoa Furtado                                                                             A1, B3   \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto                                                          NA   \n",
       "Ivana Cristina de Holanda Cunha Barreto                                       A4, A4, A2, B1, A1, B3, A3   \n",
       "Jaime Ribeiro Filho                           A1, A3, A2, A3, A1, A3, A3, A3, NA, NA, A2, A2, B4, A2, A3   \n",
       "José Luís Passos Cordeiro                                                                  A1, C, A4, NA   \n",
       "João Hermínio Martins da Silva                                                A2, A1, A2, A1, A1, NA, A1   \n",
       "Luiz Odorico Monteiro de Andrade                                                  B1, B1, B3, A1, A3, A3   \n",
       "Marcela Helena Gambim Fonseca                                                         B1, A1, B1, B1, B1   \n",
       "Marcos Roberto Lourenzoni                                                                     A1, A2, A4   \n",
       "Margareth Borges Coutinho Gallo                                                                            \n",
       "Marlos de Medeiros Chaves                                                                             A1   \n",
       "Maximiliano Ponte                                                                                      C   \n",
       "Márcio Flávio Moura de Araújo                                            B1, C, B2, C, A2, A4, B2, A1, C   \n",
       "Raphael Trevizani                                                                                          \n",
       "Regis Bernardo Brandim Gomes                                                                  NA, A2, A2   \n",
       "Roberto Nicolete                                                              A1, A3, A1, A1, A4, A3, A2   \n",
       "Roberto Wagner Júnior Freire de Freitas                                                        C, B1, A3   \n",
       "Sharmênia de Araújo Soares Nuto                                                               B1, B4, A1   \n",
       "Vanira Matos Pessoa                                                                   A4, B1, B1, B1, B3   \n",
       "Venúcia Bruna Magalhães Pereira                                                                            \n",
       "\n",
       "Ano                                          2023                                                                                     \\\n",
       "Autor                                                                                                                                  \n",
       "Adriana Costa Bacelo                                                                                                                   \n",
       "Alice Paula Di Sabatino Guimarães                                                                                                      \n",
       "Ana Camila Oliveira Alves                                                                                                              \n",
       "Ana Cláudia de Araújo Teixeira                                                                                                    A1   \n",
       "Anna Carolina Machado Marinho                                                                                                     B2   \n",
       "Antonio Marcos Aires Barbosa                                                                                                      A2   \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer                                                            NA, A2, A1, A1, A1, A1, NA, B4   \n",
       "Carla Freire Celedonio Fernandes                                                                                              B2, NA   \n",
       "Caroline Pereira Bittencourt Passaes                                                                                          A1, NA   \n",
       "Clarissa Romero Teixeira                                                                                                      A1, A1   \n",
       "Claudia Stutz Zubieta                                                                                                             A1   \n",
       "Dayane Alves Costa                                                                                                                B1   \n",
       "Donat Alexander de Chapeaurouge                                                                                                        \n",
       "Eduardo Ruback dos Santos                                                                                                              \n",
       "Fabio Miyajima                                                                                                                    A2   \n",
       "Fernanda Savicki de Almeida                                                                                                       B4   \n",
       "Fernando Braga Stehling Dias                                                                                                      A2   \n",
       "Fernando Ferreira Carneiro                                                                                                    A1, A1   \n",
       "Galba Freire Moita                                                                                                                     \n",
       "Gilvan Pessoa Furtado                                                                                                         A2, A2   \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto                                                                                      B2   \n",
       "Ivana Cristina de Holanda Cunha Barreto                                                                           NA, A3, B3, A1, A4   \n",
       "Jaime Ribeiro Filho                           B4, A2, A2, A2, A3, A2, A4, A3, A3, A4, NA, NA, NA, A4, A3, A2, A1, A4, A2, A3, A4, A2   \n",
       "José Luís Passos Cordeiro                                                                                                     A2, NA   \n",
       "João Hermínio Martins da Silva                                                                                            A4, A2, A2   \n",
       "Luiz Odorico Monteiro de Andrade                                                                                      NA, A4, A4, A3   \n",
       "Marcela Helena Gambim Fonseca                                                                                         A2, A4, A4, B1   \n",
       "Marcos Roberto Lourenzoni                                                                                                     A2, B1   \n",
       "Margareth Borges Coutinho Gallo                                                                                                        \n",
       "Marlos de Medeiros Chaves                                                                                                              \n",
       "Maximiliano Ponte                                                                                                         B2, A4, A4   \n",
       "Márcio Flávio Moura de Araújo                                                                     B1, B3, B3, B1, B1, A3, A3, A1, A1   \n",
       "Raphael Trevizani                                                                                                                      \n",
       "Regis Bernardo Brandim Gomes                                                                                                  A1, A1   \n",
       "Roberto Nicolete                                                                                           B2, A4, A3, A1, C, A4, A4   \n",
       "Roberto Wagner Júnior Freire de Freitas                                                                                   B3, A1, A1   \n",
       "Sharmênia de Araújo Soares Nuto                                                                                               A2, A1   \n",
       "Vanira Matos Pessoa                                                                                                   A1, B1, B1, B1   \n",
       "Venúcia Bruna Magalhães Pereira                                                                                                        \n",
       "\n",
       "Ano                                          2024             \n",
       "Autor                                                         \n",
       "Adriana Costa Bacelo                                  A2, NA  \n",
       "Alice Paula Di Sabatino Guimarães                             \n",
       "Ana Camila Oliveira Alves                                     \n",
       "Ana Cláudia de Araújo Teixeira                                \n",
       "Anna Carolina Machado Marinho                             A1  \n",
       "Antonio Marcos Aires Barbosa                                  \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer            A4, A3  \n",
       "Carla Freire Celedonio Fernandes                      A1, A2  \n",
       "Caroline Pereira Bittencourt Passaes                      A1  \n",
       "Clarissa Romero Teixeira                                  A2  \n",
       "Claudia Stutz Zubieta                                     A2  \n",
       "Dayane Alves Costa                                            \n",
       "Donat Alexander de Chapeaurouge                               \n",
       "Eduardo Ruback dos Santos                                 A1  \n",
       "Fabio Miyajima                                                \n",
       "Fernanda Savicki de Almeida                                   \n",
       "Fernando Braga Stehling Dias                                  \n",
       "Fernando Ferreira Carneiro                            A1, A1  \n",
       "Galba Freire Moita                                            \n",
       "Gilvan Pessoa Furtado                                         \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto              NA  \n",
       "Ivana Cristina de Holanda Cunha Barreto                       \n",
       "Jaime Ribeiro Filho                           B1, A2, A4, A3  \n",
       "José Luís Passos Cordeiro                                 B2  \n",
       "João Hermínio Martins da Silva                                \n",
       "Luiz Odorico Monteiro de Andrade                          A4  \n",
       "Marcela Helena Gambim Fonseca                             B3  \n",
       "Marcos Roberto Lourenzoni                                     \n",
       "Margareth Borges Coutinho Gallo                               \n",
       "Marlos de Medeiros Chaves                                     \n",
       "Maximiliano Ponte                                             \n",
       "Márcio Flávio Moura de Araújo                     A2, NA, NA  \n",
       "Raphael Trevizani                                             \n",
       "Regis Bernardo Brandim Gomes                      A4, A2, A2  \n",
       "Roberto Nicolete                                      NA, A2  \n",
       "Roberto Wagner Júnior Freire de Freitas                   B1  \n",
       "Sharmênia de Araújo Soares Nuto                       A4, B1  \n",
       "Vanira Matos Pessoa                                           \n",
       "Venúcia Bruna Magalhães Pereira                               "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atualizador.apurar_qualis_periodo(dict_list_docents, ano_inicio, ano_final).fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57866783",
   "metadata": {},
   "source": [
    "### Pontuar por ano ponderado pelo Qualis\n",
    "\n",
    "- Buscar pelos artigos completos publicados em periódicos de cada pesquisador\n",
    "- Buscar ISSN da revista na classificação do Qualis Periódicos da Capes (Plataforma Sucupira)\n",
    "- Ponderar pela pontuação que o programa de pós-graduação em análise atribui para cada estrato"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b958e62",
   "metadata": {},
   "source": [
    "### Contar publicação c/participação discente\n",
    "\n",
    "- Buscar por nomes de discentes nas publicações dos currículos dos docentes e \n",
    "- Calcular o percentual de publicações com participação de discente da lista fornecida pelo programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba17bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pontuacao = atualizador.apurar_pontos_periodo(dict_list_docents, ano_inicio, ano_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5721e21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Ano</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "      <th>Soma de Pontos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jaime Ribeiro Filho</th>\n",
       "      <td>575</td>\n",
       "      <td>320</td>\n",
       "      <td>200</td>\n",
       "      <td>1060</td>\n",
       "      <td>955</td>\n",
       "      <td>865</td>\n",
       "      <td>1155</td>\n",
       "      <td>200</td>\n",
       "      <td>5330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Márcio Flávio Moura de Araújo</th>\n",
       "      <td>285</td>\n",
       "      <td>570</td>\n",
       "      <td>315</td>\n",
       "      <td>385</td>\n",
       "      <td>475</td>\n",
       "      <td>260</td>\n",
       "      <td>380</td>\n",
       "      <td>80</td>\n",
       "      <td>2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fabio Miyajima</th>\n",
       "      <td>350</td>\n",
       "      <td>270</td>\n",
       "      <td>330</td>\n",
       "      <td>270</td>\n",
       "      <td>530</td>\n",
       "      <td>770</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anya Pimentel Gomes Fernandes Vieira Meyer</th>\n",
       "      <td>100</td>\n",
       "      <td>310</td>\n",
       "      <td>230</td>\n",
       "      <td>355</td>\n",
       "      <td>755</td>\n",
       "      <td>300</td>\n",
       "      <td>445</td>\n",
       "      <td>100</td>\n",
       "      <td>2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roberto Wagner Júnior Freire de Freitas</th>\n",
       "      <td>175</td>\n",
       "      <td>390</td>\n",
       "      <td>320</td>\n",
       "      <td>365</td>\n",
       "      <td>580</td>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>20</td>\n",
       "      <td>2120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roberto Nicolete</th>\n",
       "      <td>160</td>\n",
       "      <td>80</td>\n",
       "      <td>55</td>\n",
       "      <td>270</td>\n",
       "      <td>335</td>\n",
       "      <td>510</td>\n",
       "      <td>285</td>\n",
       "      <td>80</td>\n",
       "      <td>1775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivana Cristina de Holanda Cunha Barreto</th>\n",
       "      <td>335</td>\n",
       "      <td>180</td>\n",
       "      <td>65</td>\n",
       "      <td>150</td>\n",
       "      <td>370</td>\n",
       "      <td>340</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caroline Pereira Bittencourt Passaes</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>110</td>\n",
       "      <td>360</td>\n",
       "      <td>490</td>\n",
       "      <td>170</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carla Freire Celedonio Fernandes</th>\n",
       "      <td>410</td>\n",
       "      <td>170</td>\n",
       "      <td>100</td>\n",
       "      <td>220</td>\n",
       "      <td>320</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>170</td>\n",
       "      <td>1465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>João Hermínio Martins da Silva</th>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>120</td>\n",
       "      <td>55</td>\n",
       "      <td>520</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luiz Odorico Monteiro de Andrade</th>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>420</td>\n",
       "      <td>260</td>\n",
       "      <td>140</td>\n",
       "      <td>40</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>José Luís Passos Cordeiro</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>100</td>\n",
       "      <td>375</td>\n",
       "      <td>90</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharmênia de Araújo Soares Nuto</th>\n",
       "      <td>80</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>240</td>\n",
       "      <td>385</td>\n",
       "      <td>115</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fernando Ferreira Carneiro</th>\n",
       "      <td>170</td>\n",
       "      <td>205</td>\n",
       "      <td>40</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>100</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcos Roberto Lourenzoni</th>\n",
       "      <td>110</td>\n",
       "      <td>90</td>\n",
       "      <td>180</td>\n",
       "      <td>190</td>\n",
       "      <td>120</td>\n",
       "      <td>210</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fernando Braga Stehling Dias</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>260</td>\n",
       "      <td>270</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gilvan Pessoa Furtado</th>\n",
       "      <td>100</td>\n",
       "      <td>180</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>100</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clarissa Romero Teixeira</th>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maximiliano Ponte</th>\n",
       "      <td>270</td>\n",
       "      <td>20</td>\n",
       "      <td>75</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanira Matos Pessoa</th>\n",
       "      <td>150</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>125</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcela Helena Gambim Fonseca</th>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>180</td>\n",
       "      <td>10</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regis Bernardo Brandim Gomes</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>200</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eduardo Ruback dos Santos</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marlos de Medeiros Chaves</th>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adriana Costa Bacelo</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anna Carolina Machado Marinho</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>90</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claudia Stutz Zubieta</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venúcia Bruna Magalhães Pereira</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Galba Freire Moita</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alice Paula Di Sabatino Guimarães</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dayane Alves Costa</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ana Camila Oliveira Alves</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ana Cláudia de Araújo Teixeira</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Giovanny Augusto Camacho Antevere Mazzarotto</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Margareth Borges Coutinho Gallo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antonio Marcos Aires Barbosa</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raphael Trevizani</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donat Alexander de Chapeaurouge</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fernanda Savicki de Almeida</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ano                                           2017  2018  2019  2020  2021  \\\n",
       "Autor                                                                        \n",
       "Jaime Ribeiro Filho                           575   320   200   1060  955    \n",
       "Márcio Flávio Moura de Araújo                 285   570   315    385  475    \n",
       "Fabio Miyajima                                350   270   330    270  530    \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer    100   310   230    355  755    \n",
       "Roberto Wagner Júnior Freire de Freitas       175   390   320    365  580    \n",
       "Roberto Nicolete                              160    80    55    270  335    \n",
       "Ivana Cristina de Holanda Cunha Barreto       335   180    65    150  370    \n",
       "Caroline Pereira Bittencourt Passaes           90    90   110    360  490    \n",
       "Carla Freire Celedonio Fernandes              410   170   100    220  320    \n",
       "João Hermínio Martins da Silva                310     0   210    120   55    \n",
       "Luiz Odorico Monteiro de Andrade              170   130    15    150  420    \n",
       "José Luís Passos Cordeiro                       0   400   100    375   90    \n",
       "Sharmênia de Araújo Soares Nuto                80    55    50    240  385    \n",
       "Fernando Ferreira Carneiro                    170   205    40    130  130    \n",
       "Marcos Roberto Lourenzoni                     110    90   180    190  120    \n",
       "Fernando Braga Stehling Dias                   90    90    90     80  260    \n",
       "Gilvan Pessoa Furtado                         100   180   110      0  270    \n",
       "Clarissa Romero Teixeira                        0   320     0     80    0    \n",
       "Maximiliano Ponte                             270    20    75    130   90    \n",
       "Vanira Matos Pessoa                           150    80    40     20  125    \n",
       "Marcela Helena Gambim Fonseca                   0    90    20      0  170    \n",
       "Regis Bernardo Brandim Gomes                    0     0     0     40   20    \n",
       "Eduardo Ruback dos Santos                       0     0     0      0    0    \n",
       "Marlos de Medeiros Chaves                       0    90     0     40   80    \n",
       "Adriana Costa Bacelo                           50     0   110      0   10    \n",
       "Anna Carolina Machado Marinho                   0    15     0      0  150    \n",
       "Claudia Stutz Zubieta                           0     0     0      0    0    \n",
       "Venúcia Bruna Magalhães Pereira                80    80    60      0   40    \n",
       "Galba Freire Moita                              0    20    95     40   25    \n",
       "Alice Paula Di Sabatino Guimarães               0     0     0      0  170    \n",
       "Dayane Alves Costa                             90     0     0      0   40    \n",
       "Ana Camila Oliveira Alves                       0     0     0      0   60    \n",
       "Ana Cláudia de Araújo Teixeira                  0     0     0      0    0    \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto   80     0     0      0    5    \n",
       "Margareth Borges Coutinho Gallo                 0     0     0      0  100    \n",
       "Antonio Marcos Aires Barbosa                    0    15     0      0    0    \n",
       "Raphael Trevizani                              90     0     0      0    0    \n",
       "Donat Alexander de Chapeaurouge                 0    80     0      0    0    \n",
       "Fernanda Savicki de Almeida                     0     0     0      0    0    \n",
       "\n",
       "Ano                                           2022  2023  2024  Soma de Pontos  \n",
       "Autor                                                                           \n",
       "Jaime Ribeiro Filho                           865   1155  200   5330            \n",
       "Márcio Flávio Moura de Araújo                 260    380   80   2750            \n",
       "Fabio Miyajima                                770     80    0   2600            \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer    300    445  100   2595            \n",
       "Roberto Wagner Júnior Freire de Freitas        80    190   20   2120            \n",
       "Roberto Nicolete                              510    285   80   1775            \n",
       "Ivana Cristina de Holanda Cunha Barreto       340    200    0   1640            \n",
       "Caroline Pereira Bittencourt Passaes          170     90   90   1490            \n",
       "Carla Freire Celedonio Fernandes               60     15  170   1465            \n",
       "João Hermínio Martins da Silva                520    200    0   1415            \n",
       "Luiz Odorico Monteiro de Andrade              260    140   40   1325            \n",
       "José Luís Passos Cordeiro                     130     80   15   1190            \n",
       "Sharmênia de Araújo Soares Nuto               115    170   60   1155            \n",
       "Fernando Ferreira Carneiro                    100    180  180   1135            \n",
       "Marcos Roberto Lourenzoni                     210    100    0   1000            \n",
       "Fernando Braga Stehling Dias                  270     80    0    960            \n",
       "Gilvan Pessoa Furtado                         100    160    0    920            \n",
       "Clarissa Romero Teixeira                       80    180   80    740            \n",
       "Maximiliano Ponte                               0     95    0    680            \n",
       "Vanira Matos Pessoa                           110    150    0    675            \n",
       "Marcela Helena Gambim Fonseca                 170    180   10    640            \n",
       "Regis Bernardo Brandim Gomes                  160    180  200    600            \n",
       "Eduardo Ruback dos Santos                     270      0   90    360            \n",
       "Marlos de Medeiros Chaves                      90      0    0    300            \n",
       "Adriana Costa Bacelo                           35      0   80    285            \n",
       "Anna Carolina Machado Marinho                   0     15   90    270            \n",
       "Claudia Stutz Zubieta                          90     90   80    260            \n",
       "Venúcia Bruna Magalhães Pereira                 0      0    0    260            \n",
       "Galba Freire Moita                              5      0    0    185            \n",
       "Alice Paula Di Sabatino Guimarães               0      0    0    170            \n",
       "Dayane Alves Costa                              0     20    0    150            \n",
       "Ana Camila Oliveira Alves                      60      0    0    120            \n",
       "Ana Cláudia de Araújo Teixeira                 20     90    0    110            \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto    0     15    0    100            \n",
       "Margareth Borges Coutinho Gallo                 0      0    0    100            \n",
       "Antonio Marcos Aires Barbosa                    0     80    0     95            \n",
       "Raphael Trevizani                               0      0    0     90            \n",
       "Donat Alexander de Chapeaurouge                 0      0    0     80            \n",
       "Fernanda Savicki de Almeida                     0      5    0      5            "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pontuacao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e9c6c0",
   "metadata": {},
   "source": [
    "### Extrair quantidade de orientações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33443973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verificar orientações nos dados de docentes\n",
    "# [x.get('Orientações') for x in dict_list_docents if x.get('Orientações')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922feca2",
   "metadata": {},
   "source": [
    "# <b>F02: Obter dados de Discentes</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19872560",
   "metadata": {},
   "source": [
    "## Montar lista_busca para dados de Docentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39722ea",
   "metadata": {},
   "source": [
    "### Carregar nomes de planilha com dados de Discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "391dac31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>ativo</th>\n",
       "      <th>vinculo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALANA LIGIA SALDANHA FERNANDES</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALICE SOARES DE QUEIROZ</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALINE DE OLIVEIRA ALBUQUERQUE</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALINE PINTO MONTEIRO COSTA SOUSA</td>\n",
       "      <td>False</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALISON DE SOUSA REBOUÇAS</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alissan Karine Lima Martins</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMANDA CAVALCANTE FROTA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANA FLAVIA PONTES AGUIAR</td>\n",
       "      <td>False</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ANA JULIA FERREIRA LIMA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ANA JULIA FERREIRA LIMA</td>\n",
       "      <td>False</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ana Keyla Oliveira da Silva</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ANA MARILIA SOARES CRUZ</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ANA PATRICIA PEREIRA MORAIS</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ANA PAULA PIRES GADELHA DE LIMA</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ANA VIRGINIA FROTA GUIMARAES</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Andréa Silvia Walter de Aguiar</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ANDRIELLY HENRIQUES DOS SANTOS COSTA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ANGELA DONATO MAIA MALAQUIAS</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ANGELA DONATO MAIA MALAQUIAS</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ANTONIA VANDERLI ALVES DO NASCIMENTO</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BARBARA NEPOMUCENO GUIMARAES</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BEATRIZ CHAVES</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bruna de Sousa Lima</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BRUNHELD MAIA DUTRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CAMILA SILLOS ROSAS BRISIGHELLO</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CARLOS ANTONIO DE ARROXELAS SILVA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CARLOS EDUARDO DE SOUSA PRAXEDES</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Carollyne Ferreira Santiago</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CASSIO PINHEIRO OLIVEIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CRISTIAN VICSON GOMES PINHEIRO</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CRISTIANE FRANÇA MARTINS TEODORO</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cristiane Mourao Carvalhedo Mesquita</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DIEGO DA SILVA DE ALMEIDA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DIEGO RAMOS AGUIAR</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DISRAELI CAVALCANTE ARAUJO VASCONCELOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EDUARDO MENEZES GAIETA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ELLEN MARIA LIMA GONÇALVES</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ERIKA ROMERIA FORMIGA DE SOUSA</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Erlemus Ponte Soares</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>EVANILDO HENRIQUE MACEDO DA COSTA</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Evanizia Pinheiro de Oliveira</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FABIO JOSE GOMES DE SOUSA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Filipe Oliveira de Brito</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Francisca Raquel de Vasconcelos Silveira</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>GABRIEL ACACIO DE MOURA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Georgea Bezerra Carvalho</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>GERALDO RODRIGUES SARTORI</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>GERMANA SILVA VASCONCELOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Gilcelene de Castro Andrade</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gilmara Maria Batista Tavares da Silva</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Gilmara Maria Batista Tavares da Silva</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>GLAZIANE DA SILVA PAIVA BANDEIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>GRAYCE ALENCAR ALBUQUERQUE</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Graziela Jones de Oliveira</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>GUILHERME ANGELO LOBO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>HASSA PEREIRA LEMOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>HERQUIMEDES GLAUDYS DA SILVA AVELINO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>HEVERTON MENDES ARAUJO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>IGOR CABRAL STUDART</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ISABELLA LIMA BARBOSA CAMPELO</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>JEAN VIEIRA SAMPAIO</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>JOAO EUDES LEMOS DE BARROS</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>JOAO MATHEUS FONTELES SILVA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>JOAO PEDRO VIANA RODRIGUES</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>JOAQUIM CESAR DO NASCIMENTO SOUSA JUNIOR</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>JOSE MARIA XIMENES GUIMARAES</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>JOSE SAMUEL DOS SANTOS BARBOSA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>JOSETE MALHEIRO TAVARES</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>JUCILENE PEREIRA DE SOUSA</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>JULIANA MENESES DE SENA SILVA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>JULIANA RAMOS DE OLIVEIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>KAMILA MARIA OLIVEIRA SALES</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>KETLEN CHRISTINE OHSE</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Kilvia Helane Cardoso Mesquita</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>LAECIO PAULO SOUSA DOS SANTOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>LARISSE CADEIRA BRANDAO</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>LEA DIAS PIMENTEL GOMES VASCONCELOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>LENIR SANTOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>LETICIA BASTOS CONRADO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>LETICIA FERREIRA ESPINOSA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>LIANDRA ELLEN COELHO PEREIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Libia Lopes Martiniano</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Lílian Fernandes Amarante</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>LIVIA COELHO DE ASSIS</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Lorena Lodo Santiago</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Lorena Morais Nogueira</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>LUCA MILERIO ANDRADE</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>LUCAS ALMEIDA DE FREITAS</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Lucelia Gois de oliveira</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Luciana Carvalho de Albuquerque</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Luis Lopes Sombra Neto</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>MAISA PESSOA PINHEIRO</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>MARA MILVIA PONTES MELO RESENDE</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>MARCUS RAFAEL LOBO BEZERRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Maria Alexandrina Perez da Justa</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>MARIA JOSYCLEY NOVAIS LANDIM SOARES</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>MARILIA FAÇANHA TAVARES</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>MATHIAS COELHO BATISTA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Naila Saskia Melo Andrade</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NATALIA CAMPOS PARENTE</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Neyliane Maria Brito Costa</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>PATRICIA PEREIRA TAVARES DE ALCANTARA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Paulo Ricardo Nazario Viecili</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>PEDRO MIGUEL CARNEIRO JERONIMO</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>PLACIDO EYMARD GOMES SARAIVA FILHO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>RAFAELLE DANTAS BEZERRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Raquel Bomfim Castelo</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>REGINA GLAUCIA LUCENA AGUIAR FERREIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>REJANE FERREIRA COSTA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Renata Castelo da Nobrega</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>RENATO THALES MEDEIROS HOLANDA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>ROGERIO SAMPAIO DE OLIVEIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ROMULO ALVES DE ARAUJO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>RONNY PETTERSON DOS SANTOS ARAUJO</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SAMUEL LUCAS DE ALMEIDA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>SAMUEL MENESES FELICIO DE ARAUJO COSTA</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Sandhara Ribeiro Rodrigues</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>SANDY KAENA SOARES DE FREITAS</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>TAINA MARIA LIMA FREIRE</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Vandre Cabral Gomes Carneiro</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>VANESSA PINHEIRO GONÇALVES FERREIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>VANIA CARLA DE SOUSA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>VERA LUCIA DE AZEVEDO DANTAS</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>VERIDIANA PESSOA MIYAJIMA</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Vinicius Saraiva Barretto</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Vitória Taiana de Melo Lima Albuquerque</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>VIVIAN MAGALHAES BRANDÃO DOS SANTOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>YANA PAULA COELHO CORREIA SAMPAIO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Yasmim Mendes Rocha</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>YASMIM MENDES ROCHA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nome                                       ativo vinculo   \n",
       "0              ALANA LIGIA SALDANHA FERNANDES   True  Graduação\n",
       "1                     ALICE SOARES DE QUEIROZ   True   Mestrado\n",
       "2               ALINE DE OLIVEIRA ALBUQUERQUE   True  Doutorado\n",
       "3            ALINE PINTO MONTEIRO COSTA SOUSA  False   Mestrado\n",
       "4                    ALISON DE SOUSA REBOUÇAS   True  Doutorado\n",
       "5                 Alissan Karine Lima Martins  False  Graduação\n",
       "6                     AMANDA CAVALCANTE FROTA   True  Graduação\n",
       "7                    ANA FLAVIA PONTES AGUIAR  False   Mestrado\n",
       "8                     ANA JULIA FERREIRA LIMA   True  Doutorado\n",
       "9                     ANA JULIA FERREIRA LIMA  False  Doutorado\n",
       "10                Ana Keyla Oliveira da Silva   True  Graduação\n",
       "11                    ANA MARILIA SOARES CRUZ   True  Graduação\n",
       "12                ANA PATRICIA PEREIRA MORAIS   True    Pós-Doc\n",
       "13            ANA PAULA PIRES GADELHA DE LIMA   True  Profsaúde\n",
       "14               ANA VIRGINIA FROTA GUIMARAES   True  Doutorado\n",
       "15             Andréa Silvia Walter de Aguiar   True    Pós-Doc\n",
       "16       ANDRIELLY HENRIQUES DOS SANTOS COSTA   True  Graduação\n",
       "17               ANGELA DONATO MAIA MALAQUIAS   True  Graduação\n",
       "18               ANGELA DONATO MAIA MALAQUIAS  False  Graduação\n",
       "19       ANTONIA VANDERLI ALVES DO NASCIMENTO   True  Profsaúde\n",
       "20               BARBARA NEPOMUCENO GUIMARAES   True  Graduação\n",
       "21                             BEATRIZ CHAVES   True  Doutorado\n",
       "22                        Bruna de Sousa Lima  False  Graduação\n",
       "23                        BRUNHELD MAIA DUTRA   True  Doutorado\n",
       "24            CAMILA SILLOS ROSAS BRISIGHELLO   True   Mestrado\n",
       "25          CARLOS ANTONIO DE ARROXELAS SILVA   True   Mestrado\n",
       "26           CARLOS EDUARDO DE SOUSA PRAXEDES   True  Doutorado\n",
       "27                Carollyne Ferreira Santiago   True  Graduação\n",
       "28                   CASSIO PINHEIRO OLIVEIRA   True  Doutorado\n",
       "29             CRISTIAN VICSON GOMES PINHEIRO   True   Mestrado\n",
       "30           CRISTIANE FRANÇA MARTINS TEODORO   True    Pós-Doc\n",
       "31       Cristiane Mourao Carvalhedo Mesquita  False  Graduação\n",
       "32                  DIEGO DA SILVA DE ALMEIDA   True   Mestrado\n",
       "33                         DIEGO RAMOS AGUIAR   True  Graduação\n",
       "34     DISRAELI CAVALCANTE ARAUJO VASCONCELOS   True  Graduação\n",
       "35                     EDUARDO MENEZES GAIETA   True   Mestrado\n",
       "36                 ELLEN MARIA LIMA GONÇALVES   True  Graduação\n",
       "37             ERIKA ROMERIA FORMIGA DE SOUSA   True  Profsaúde\n",
       "38                       Erlemus Ponte Soares  False  Graduação\n",
       "39          EVANILDO HENRIQUE MACEDO DA COSTA   True  Profsaúde\n",
       "40              Evanizia Pinheiro de Oliveira  False  Graduação\n",
       "41                  FABIO JOSE GOMES DE SOUSA   True  Doutorado\n",
       "42                   Filipe Oliveira de Brito   True  Doutorado\n",
       "43   Francisca Raquel de Vasconcelos Silveira  False  Graduação\n",
       "44                    GABRIEL ACACIO DE MOURA   True  Doutorado\n",
       "45                   Georgea Bezerra Carvalho  False  Graduação\n",
       "46                  GERALDO RODRIGUES SARTORI   True    Pós-Doc\n",
       "47                  GERMANA SILVA VASCONCELOS   True    Pós-Doc\n",
       "48                Gilcelene de Castro Andrade  False  Graduação\n",
       "49     Gilmara Maria Batista Tavares da Silva  False  Graduação\n",
       "50     Gilmara Maria Batista Tavares da Silva   True  Graduação\n",
       "51           GLAZIANE DA SILVA PAIVA BANDEIRA   True    Pós-Doc\n",
       "52                 GRAYCE ALENCAR ALBUQUERQUE   True    Pós-Doc\n",
       "53                 Graziela Jones de Oliveira  False  Graduação\n",
       "54                      GUILHERME ANGELO LOBO   True  Graduação\n",
       "55                        HASSA PEREIRA LEMOS   True  Profsaúde\n",
       "56       HERQUIMEDES GLAUDYS DA SILVA AVELINO   True  Graduação\n",
       "57                     HEVERTON MENDES ARAUJO   True  Graduação\n",
       "58                        IGOR CABRAL STUDART   True  Doutorado\n",
       "59              ISABELLA LIMA BARBOSA CAMPELO   True    Pós-Doc\n",
       "60                        JEAN VIEIRA SAMPAIO   True   Mestrado\n",
       "61                 JOAO EUDES LEMOS DE BARROS   True  Graduação\n",
       "62                JOAO MATHEUS FONTELES SILVA   True  Graduação\n",
       "63                 JOAO PEDRO VIANA RODRIGUES   True  Doutorado\n",
       "64   JOAQUIM CESAR DO NASCIMENTO SOUSA JUNIOR   True   Mestrado\n",
       "65               JOSE MARIA XIMENES GUIMARAES   True    Pós-Doc\n",
       "66             JOSE SAMUEL DOS SANTOS BARBOSA   True   Mestrado\n",
       "67                    JOSETE MALHEIRO TAVARES   True  Graduação\n",
       "68                  JUCILENE PEREIRA DE SOUSA   True    Pós-Doc\n",
       "69              JULIANA MENESES DE SENA SILVA   True   Mestrado\n",
       "70                  JULIANA RAMOS DE OLIVEIRA   True  Doutorado\n",
       "71                KAMILA MARIA OLIVEIRA SALES   True    Pós-Doc\n",
       "72                      KETLEN CHRISTINE OHSE   True  Graduação\n",
       "73             Kilvia Helane Cardoso Mesquita   True    Pós-Doc\n",
       "74              LAECIO PAULO SOUSA DOS SANTOS   True  Doutorado\n",
       "75                    LARISSE CADEIRA BRANDAO   True  Doutorado\n",
       "76        LEA DIAS PIMENTEL GOMES VASCONCELOS   True  Doutorado\n",
       "77                               LENIR SANTOS   True    Pós-Doc\n",
       "78                     LETICIA BASTOS CONRADO   True  Graduação\n",
       "79                  LETICIA FERREIRA ESPINOSA   True  Graduação\n",
       "80               LIANDRA ELLEN COELHO PEREIRA   True   Mestrado\n",
       "81                     Libia Lopes Martiniano  False  Graduação\n",
       "82                  Lílian Fernandes Amarante  False  Graduação\n",
       "83                      LIVIA COELHO DE ASSIS   True  Doutorado\n",
       "84                       Lorena Lodo Santiago  False  Graduação\n",
       "85                     Lorena Morais Nogueira  False  Graduação\n",
       "86                       LUCA MILERIO ANDRADE   True  Doutorado\n",
       "87                   LUCAS ALMEIDA DE FREITAS   True   Mestrado\n",
       "88                   Lucelia Gois de oliveira  False  Graduação\n",
       "89            Luciana Carvalho de Albuquerque  False  Graduação\n",
       "90                     Luis Lopes Sombra Neto  False  Graduação\n",
       "91                      MAISA PESSOA PINHEIRO   True  Doutorado\n",
       "92            MARA MILVIA PONTES MELO RESENDE   True  Profsaúde\n",
       "93                 MARCUS RAFAEL LOBO BEZERRA   True  Doutorado\n",
       "94           Maria Alexandrina Perez da Justa  False  Graduação\n",
       "95        MARIA JOSYCLEY NOVAIS LANDIM SOARES   True   Mestrado\n",
       "96                    MARILIA FAÇANHA TAVARES   True   Mestrado\n",
       "97                     MATHIAS COELHO BATISTA   True   Mestrado\n",
       "98                  Naila Saskia Melo Andrade  False  Graduação\n",
       "99                     NATALIA CAMPOS PARENTE   True   Mestrado\n",
       "100                Neyliane Maria Brito Costa  False  Graduação\n",
       "101     PATRICIA PEREIRA TAVARES DE ALCANTARA   True  Graduação\n",
       "102             Paulo Ricardo Nazario Viecili  False  Graduação\n",
       "103            PEDRO MIGUEL CARNEIRO JERONIMO   True   Mestrado\n",
       "104        PLACIDO EYMARD GOMES SARAIVA FILHO   True  Graduação\n",
       "105                   RAFAELLE DANTAS BEZERRA   True   Mestrado\n",
       "106                     Raquel Bomfim Castelo  False  Graduação\n",
       "107     REGINA GLAUCIA LUCENA AGUIAR FERREIRA   True    Pós-Doc\n",
       "108                     REJANE FERREIRA COSTA   True   Mestrado\n",
       "109                 Renata Castelo da Nobrega  False  Graduação\n",
       "110            RENATO THALES MEDEIROS HOLANDA   True  Graduação\n",
       "111               ROGERIO SAMPAIO DE OLIVEIRA   True  Graduação\n",
       "112                    ROMULO ALVES DE ARAUJO   True  Graduação\n",
       "113         RONNY PETTERSON DOS SANTOS ARAUJO   True    Pós-Doc\n",
       "114                   SAMUEL LUCAS DE ALMEIDA   True  Graduação\n",
       "115    SAMUEL MENESES FELICIO DE ARAUJO COSTA   True  Profsaúde\n",
       "116                Sandhara Ribeiro Rodrigues  False  Graduação\n",
       "117             SANDY KAENA SOARES DE FREITAS  False  Graduação\n",
       "118                   TAINA MARIA LIMA FREIRE   True  Graduação\n",
       "119              Vandre Cabral Gomes Carneiro  False  Graduação\n",
       "120       VANESSA PINHEIRO GONÇALVES FERREIRA   True  Graduação\n",
       "121                      VANIA CARLA DE SOUSA   True  Graduação\n",
       "122              VERA LUCIA DE AZEVEDO DANTAS   True    Pós-Doc\n",
       "123                 VERIDIANA PESSOA MIYAJIMA   True    Pós-Doc\n",
       "124                 Vinicius Saraiva Barretto   True  Graduação\n",
       "125   Vitória Taiana de Melo Lima Albuquerque   True  Graduação\n",
       "126       VIVIAN MAGALHAES BRANDÃO DOS SANTOS   True  Doutorado\n",
       "127         YANA PAULA COELHO CORREIA SAMPAIO   True  Graduação\n",
       "128                       Yasmim Mendes Rocha   True  Graduação\n",
       "129                       YASMIM MENDES ROCHA   True  Doutorado"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preparer = EnvironmentSetup()\n",
    "discent_collab_counter = DiscentCollaborationCounter(dict_list_docents)\n",
    "\n",
    "# fonte_planilha = 'ppgcs_estudantes_2021-2024.xlsx'\n",
    "fonte_planilha = 'fioce_lista_alunos.xlsx'\n",
    "dados_discentes = pd.read_excel(os.path.join(LattesScraper.find_repo_root(),'_data','in_xls',fonte_planilha), header=0)\n",
    "dados_discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d00d9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 quantidade total de alunos, todos vínculos e status\n",
      "127 nomes únicos\n",
      "\n",
      "Tipos de vínculos ['Graduação', 'Mestrado', 'Doutorado', 'Pós-Doc', 'Profsaúde']\n",
      "Quantidades por Nível de graduação\n",
      "Graduação    61\n",
      "Doutorado    24\n",
      "Mestrado     21\n",
      "Pós-Doc      17\n",
      "Profsaúde     7\n",
      "Name: vinculo, dtype: int64\n",
      "\n",
      "  Tipos de status [True, False]\n",
      "Quantidades por Tipos de status\n",
      " True     100\n",
      "False     30\n",
      "Name: ativo, dtype: int64\n",
      "\n",
      "127 nomes de alunos em todos os status\n",
      " 1. Alana Ligia Saldanha Fernandes\n",
      " 2. Alice Soares De Queiroz\n",
      " 3. Aline De Oliveira Albuquerque\n",
      " 4. Aline Pinto Monteiro Costa Sousa\n",
      " 5. Alison De Sousa Rebouças\n",
      " 6. Alissan Karine Lima Martins\n",
      " 7. Amanda Cavalcante Frota\n",
      " 8. Ana Flavia Pontes Aguiar\n",
      " 9. Ana Julia Ferreira Lima\n",
      "10. Ana Keyla Oliveira Da Silva\n",
      "11. Ana Marilia Soares Cruz\n",
      "12. Ana Patricia Pereira Morais\n",
      "13. Ana Paula Pires Gadelha De Lima\n",
      "14. Ana Virginia Frota Guimaraes\n",
      "15. Andréa Silvia Walter De Aguiar\n",
      "16. Andrielly Henriques Dos Santos Costa\n",
      "17. Angela Donato Maia Malaquias\n",
      "18. Antonia Vanderli Alves Do Nascimento\n",
      "19. Barbara Nepomuceno Guimaraes\n",
      "20. Beatriz Chaves\n",
      "21. Bruna De Sousa Lima\n",
      "22. Brunheld Maia Dutra\n",
      "23. Camila Sillos Rosas Brisighello\n",
      "24. Carlos Antonio De Arroxelas Silva\n",
      "25. Carlos Eduardo De Sousa Praxedes\n",
      "26. Carollyne Ferreira Santiago\n",
      "27. Cassio Pinheiro Oliveira\n",
      "28. Cristian Vicson Gomes Pinheiro\n",
      "29. Cristiane França Martins Teodoro\n",
      "30. Cristiane Mourao Carvalhedo Mesquita\n",
      "31. Diego Da Silva De Almeida\n",
      "32. Diego Ramos Aguiar\n",
      "33. Disraeli Cavalcante Araujo Vasconcelos\n",
      "34. Eduardo Menezes Gaieta\n",
      "35. Ellen Maria Lima Gonçalves\n",
      "36. Erika Romeria Formiga De Sousa\n",
      "37. Erlemus Ponte Soares\n",
      "38. Evanildo Henrique Macedo Da Costa\n",
      "39. Evanizia Pinheiro De Oliveira\n",
      "40. Fabio Jose Gomes De Sousa\n",
      "41. Filipe Oliveira De Brito\n",
      "42. Francisca Raquel De Vasconcelos Silveira\n",
      "43. Gabriel Acacio De Moura\n",
      "44. Georgea Bezerra Carvalho\n",
      "45. Geraldo Rodrigues Sartori\n",
      "46. Germana Silva Vasconcelos\n",
      "47. Gilcelene De Castro Andrade\n",
      "48. Gilmara Maria Batista Tavares Da Silva\n",
      "49. Glaziane Da Silva Paiva Bandeira\n",
      "50. Grayce Alencar Albuquerque\n",
      "51. Graziela Jones De Oliveira\n",
      "52. Guilherme Angelo Lobo\n",
      "53. Hassa Pereira Lemos\n",
      "54. Herquimedes Glaudys Da Silva Avelino\n",
      "55. Heverton Mendes Araujo\n",
      "56. Igor Cabral Studart\n",
      "57. Isabella Lima Barbosa Campelo\n",
      "58. Jean Vieira Sampaio\n",
      "59. Joao Eudes Lemos De Barros\n",
      "60. Joao Matheus Fonteles Silva\n",
      "61. Joao Pedro Viana Rodrigues\n",
      "62. Joaquim Cesar Do Nascimento Sousa Junior\n",
      "63. Jose Maria Ximenes Guimaraes\n",
      "64. Jose Samuel Dos Santos Barbosa\n",
      "65. Josete Malheiro Tavares\n",
      "66. Jucilene Pereira De Sousa\n",
      "67. Juliana Meneses De Sena Silva\n",
      "68. Juliana Ramos De Oliveira\n",
      "69. Kamila Maria Oliveira Sales\n",
      "70. Ketlen Christine Ohse\n",
      "71. Kilvia Helane Cardoso Mesquita\n",
      "72. Laecio Paulo Sousa Dos Santos\n",
      "73. Larisse Cadeira Brandao\n",
      "74. Lea Dias Pimentel Gomes Vasconcelos\n",
      "75. Lenir Santos\n",
      "76. Leticia Bastos Conrado\n",
      "77. Leticia Ferreira Espinosa\n",
      "78. Liandra Ellen Coelho Pereira\n",
      "79. Libia Lopes Martiniano\n",
      "80. Lílian Fernandes Amarante\n",
      "81. Livia Coelho De Assis\n",
      "82. Lorena Lodo Santiago\n",
      "83. Lorena Morais Nogueira\n",
      "84. Luca Milerio Andrade\n",
      "85. Lucas Almeida De Freitas\n",
      "86. Lucelia Gois De Oliveira\n",
      "87. Luciana Carvalho De Albuquerque\n",
      "88. Luis Lopes Sombra Neto\n",
      "89. Maisa Pessoa Pinheiro\n",
      "90. Mara Milvia Pontes Melo Resende\n",
      "91. Marcus Rafael Lobo Bezerra\n",
      "92. Maria Alexandrina Perez Da Justa\n",
      "93. Maria Josycley Novais Landim Soares\n",
      "94. Marilia Façanha Tavares\n",
      "95. Mathias Coelho Batista\n",
      "96. Naila Saskia Melo Andrade\n",
      "97. Natalia Campos Parente\n",
      "98. Neyliane Maria Brito Costa\n",
      "99. Patricia Pereira Tavares De Alcantara\n",
      "100. Paulo Ricardo Nazario Viecili\n",
      "101. Pedro Miguel Carneiro Jeronimo\n",
      "102. Placido Eymard Gomes Saraiva Filho\n",
      "103. Rafaelle Dantas Bezerra\n",
      "104. Raquel Bomfim Castelo\n",
      "105. Regina Glaucia Lucena Aguiar Ferreira\n",
      "106. Rejane Ferreira Costa\n",
      "107. Renata Castelo Da Nobrega\n",
      "108. Renato Thales Medeiros Holanda\n",
      "109. Rogerio Sampaio De Oliveira\n",
      "110. Romulo Alves De Araujo\n",
      "111. Ronny Petterson Dos Santos Araujo\n",
      "112. Samuel Lucas De Almeida\n",
      "113. Samuel Meneses Felicio De Araujo Costa\n",
      "114. Sandhara Ribeiro Rodrigues\n",
      "115. Sandy Kaena Soares De Freitas\n",
      "116. Taina Maria Lima Freire\n",
      "117. Vandre Cabral Gomes Carneiro\n",
      "118. Vanessa Pinheiro Gonçalves Ferreira\n",
      "119. Vania Carla De Sousa\n",
      "120. Vera Lucia De Azevedo Dantas\n",
      "121. Veridiana Pessoa Miyajima\n",
      "122. Vinicius Saraiva Barretto\n",
      "123. Vitória Taiana De Melo Lima Albuquerque\n",
      "124. Vivian Magalhaes Brandão Dos Santos\n",
      "125. Yana Paula Coelho Correia Sampaio\n",
      "126. Yasmim Mendes Rocha\n",
      "\n",
      "126 nomes únicos de alunos para extrair currículos\n"
     ]
    }
   ],
   "source": [
    "# Ler dados do arquivo Excel do Setor de Recursos Humanos\n",
    "pathdata = '_data/in_xls/'\n",
    "datasheet = 'fioce_lista_alunos.xlsx'\n",
    "\n",
    "# Ler apenas os cabeçalhos do arquivo Excel\n",
    "headers = pd.read_excel(pathdata+datasheet, skiprows=0, header=0, nrows=0).columns\n",
    "# headers\n",
    "\n",
    "# Indicar quais colunas devem ser eliminadas na leitura\n",
    "def cols_to_keep(col_name):\n",
    "    return col_name not in []\n",
    "\n",
    "# Filtrar cabeçalhos com base na função\n",
    "selected_columns = [col for col in headers if cols_to_keep(col)]\n",
    "\n",
    "# Ler dados do arquivo Excel do Setor de Recursos Humanos\n",
    "fioce_alunos = pd.read_excel(pathdata+datasheet, skiprows=0, header=0, usecols=selected_columns)\n",
    "print(f'{len(fioce_alunos.index)} quantidade total de alunos, todos vínculos e status')\n",
    "print(f'{len(fioce_alunos[\"nome\"].unique()):3} nomes únicos')\n",
    "\n",
    "print('\\nTipos de vínculos',list(fioce_alunos['vinculo'].unique()))\n",
    "print(f\"Quantidades por Nível de graduação\\n{fioce_alunos['vinculo'].value_counts()}\")\n",
    "\n",
    "print('\\n  Tipos de status',list(fioce_alunos['ativo'].unique()))\n",
    "print('Quantidades por Tipos de status\\n',(fioce_alunos['ativo'].value_counts()))\n",
    "filtro1 = fioce_alunos['vinculo'].isin(['Graduação', 'Mestrado', 'Doutorado', 'Pós-Doc', 'Profsaúde'])\n",
    "filtro2 = fioce_alunos['ativo'].isin([True, False])\n",
    "# filtro2 = fioce_alunos['ativo'].isin([True])\n",
    "lista_nomes = fioce_alunos[(filtro1) & (filtro2)]['nome'].unique().tolist()\n",
    "\n",
    "print(f'\\n{len(lista_nomes)} nomes de alunos em todos os status')\n",
    "lista_busca_alunos = []\n",
    "for i,nome in enumerate(lista_nomes):\n",
    "    if nome.strip().title() not in lista_busca_alunos:\n",
    "        lista_busca_alunos.append(nome.strip().title())\n",
    "        print(f'{i+1:2}. {nome.title()}')\n",
    "\n",
    "print(f'\\n{len(lista_busca_alunos)} nomes únicos de alunos para extrair currículos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd233282",
   "metadata": {},
   "source": [
    "## <b>Processar extração de dados de Discentes</b>\n",
    "    (~80min/93nomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1f53916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 discentes relacionados aos programas\n",
      "Buscando currículos com qualquer nível de formação\n",
      " 1/126: Alana Ligia Saldanha Fernandes\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      " 2/126: Alice Soares De Queiroz\n",
      "       001 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      " 3/126: Aline De Oliveira Albuquerque\n",
      "        8 currículos homônimos: Aline De Oliveira Albuquerque\n",
      "                            Cruz | False | ['Aline Oliveira de Albuquerque ']\n",
      "                         Família | False | ['Aline Oliveira de Albuquerque ']\n",
      "                   Biotecnologia | False | ['Aline Oliveira de Albuquerque ']\n",
      "                           Ceará | False | ['Aline Oliveira de Albuquerque ']\n",
      "                            Cruz | False | ['Aline Albuquerque de Oliveira  Mestrado em Saúde Coletiva pela Universidade Federal de Juiz de Fora, Brasil(2016) Especialista em ´Políticas em Gestão da Saúde do Secretaria de Estado da Saúde , Brasil']\n",
      "                         Família | False | ['Aline Albuquerque de Oliveira  Mestrado em Saúde Coletiva pela Universidade Federal de Juiz de Fora, Brasil(2016) Especialista em ´Políticas em Gestão da Saúde do Secretaria de Estado da Saúde , Brasil']\n",
      "                   Biotecnologia | False | ['Aline Albuquerque de Oliveira  Mestrado em Saúde Coletiva pela Universidade Federal de Juiz de Fora, Brasil(2016) Especialista em ´Políticas em Gestão da Saúde do Secretaria de Estado da Saúde , Brasil']\n",
      "                           Ceará | False | ['Aline Albuquerque de Oliveira  Mestrado em Saúde Coletiva pela Universidade Federal de Juiz de Fora, Brasil(2016) Especialista em ´Políticas em Gestão da Saúde do Secretaria de Estado da Saúde , Brasil']\n",
      "                            Cruz | False | ['Aline de Albuquerque Oliveira  Doutorado em Farmacologia pela Universidade Federal do Ceará, Brasil(2010) Professor da Faculdade Metropolitana de Fortaleza , Brasil']\n",
      "                         Família | False | ['Aline de Albuquerque Oliveira  Doutorado em Farmacologia pela Universidade Federal do Ceará, Brasil(2010) Professor da Faculdade Metropolitana de Fortaleza , Brasil']\n",
      "                   Biotecnologia | False | ['Aline de Albuquerque Oliveira  Doutorado em Farmacologia pela Universidade Federal do Ceará, Brasil(2010) Professor da Faculdade Metropolitana de Fortaleza , Brasil']\n",
      "                           Ceará | True | ['Aline de Albuquerque Oliveira  Doutorado em Farmacologia pela Universidade Federal do Ceará, Brasil(2010) Professor da Faculdade Metropolitana de Fortaleza , Brasil']\n",
      "       018 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      " 4/126: Aline Pinto Monteiro Costa Sousa\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      " 5/126: Alison De Sousa Rebouças\n",
      "       001 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      " 6/126: Alissan Karine Lima Martins\n",
      "       063 artigos extraídos\n",
      "       DOI indisponível para 01 artigo extraído\n",
      "       Extração bem-sucedida\n",
      " 7/126: Amanda Cavalcante Frota\n",
      "       006 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      " 8/126: Ana Flavia Pontes Aguiar\n",
      "        2 currículos homônimos: Ana Flavia Pontes Aguiar\n",
      "                            Cruz | False | ['Ana Flávia Pontes Aguiar  Graduação em Administração pela Universidade de Fortaleza, Brasil(2015) Estágio do Araujo Abreu Engenharia , Brasil']\n",
      "                         Família | False | ['Ana Flávia Pontes Aguiar  Graduação em Administração pela Universidade de Fortaleza, Brasil(2015) Estágio do Araujo Abreu Engenharia , Brasil']\n",
      "                   Biotecnologia | False | ['Ana Flávia Pontes Aguiar  Graduação em Administração pela Universidade de Fortaleza, Brasil(2015) Estágio do Araujo Abreu Engenharia , Brasil']\n",
      "                           Ceará | False | ['Ana Flávia Pontes Aguiar  Graduação em Administração pela Universidade de Fortaleza, Brasil(2015) Estágio do Araujo Abreu Engenharia , Brasil']\n",
      "                            Cruz | False | ['Ana Flávia Pontes Aguiar  Especialização em Enfermagem Obstétrica pela Universidade Estadual Vale do Acaraú, Brasil(1999) Enfermeira da Maternidade Escola Assis Chateaubriand , Brasil']\n",
      "                         Família | False | ['Ana Flávia Pontes Aguiar  Especialização em Enfermagem Obstétrica pela Universidade Estadual Vale do Acaraú, Brasil(1999) Enfermeira da Maternidade Escola Assis Chateaubriand , Brasil']\n",
      "                   Biotecnologia | False | ['Ana Flávia Pontes Aguiar  Especialização em Enfermagem Obstétrica pela Universidade Estadual Vale do Acaraú, Brasil(1999) Enfermeira da Maternidade Escola Assis Chateaubriand , Brasil']\n",
      "                           Ceará | False | ['Ana Flávia Pontes Aguiar  Especialização em Enfermagem Obstétrica pela Universidade Estadual Vale do Acaraú, Brasil(1999) Enfermeira da Maternidade Escola Assis Chateaubriand , Brasil']\n",
      " 9/126: Ana Julia Ferreira Lima\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "        3 currículos homônimos: Ana Julia Ferreira Lima\n",
      "                            Cruz | False | ['Ana Júlia Lima Ferreira  Ensino Médio (2o grau) pela Escola Estadual Antônio Silva, Brasil(2021)']\n",
      "                         Família | False | ['Ana Júlia Lima Ferreira  Ensino Médio (2o grau) pela Escola Estadual Antônio Silva, Brasil(2021)']\n",
      "                   Biotecnologia | False | ['Ana Júlia Lima Ferreira  Ensino Médio (2o grau) pela Escola Estadual Antônio Silva, Brasil(2021)']\n",
      "                           Ceará | False | ['Ana Júlia Lima Ferreira  Ensino Médio (2o grau) pela Escola Estadual Antônio Silva, Brasil(2021)']\n",
      "                            Cruz | False | ['Ana Júlia Lima Ferreira  Ensino Médio (2o grau) pela Escola Estadual Olegário Maciel, Brasil(2021)']\n",
      "                         Família | False | ['Ana Júlia Lima Ferreira  Ensino Médio (2o grau) pela Escola Estadual Olegário Maciel, Brasil(2021)']\n",
      "                   Biotecnologia | False | ['Ana Júlia Lima Ferreira  Ensino Médio (2o grau) pela Escola Estadual Olegário Maciel, Brasil(2021)']\n",
      "                           Ceará | False | ['Ana Júlia Lima Ferreira  Ensino Médio (2o grau) pela Escola Estadual Olegário Maciel, Brasil(2021)']\n",
      "                            Cruz | True | ['Ana Júlia Ferreira Lima  Mestrado em Biotecnologia de Recursos Naturais pela Universidade Federal do Ceará, Brasil(2022) Estudante da Fundação Oswaldo Cruz , Brasil']\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "10/126: Ana Keyla Oliveira Da Silva\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "11/126: Ana Marilia Soares Cruz\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "12/126: Ana Patricia Pereira Morais\n",
      "       044 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "13/126: Ana Paula Pires Gadelha De Lima\n",
      "       004 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "14/126: Ana Virginia Frota Guimaraes\n",
      "       001 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "15/126: Andréa Silvia Walter De Aguiar\n",
      "       053 artigos extraídos\n",
      "       DOI indisponível em 02 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "16/126: Andrielly Henriques Dos Santos Costa\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "17/126: Angela Donato Maia Malaquias\n",
      "       004 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "18/126: Antonia Vanderli Alves Do Nascimento\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "19/126: Barbara Nepomuceno Guimaraes\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "20/126: Beatriz Chaves\n",
      "       162 currículos homônimos: Beatriz Chaves (com paginação)\n",
      "                            Cruz | True | ['Beatriz Chaves  Doutorado em Biologia Computacional e Sistemas pela Fundação Oswaldo Cruz, Brasil(2023) Pós doutorado da Fundação Oswaldo Cruz , Brasil']\n",
      "       005 artigos extraídos\n",
      "       DOI indisponível para 01 artigo extraído\n",
      "       Extração bem-sucedida\n",
      "21/126: Bruna De Sousa Lima\n",
      "       28 currículos homônimos: Bruna De Sousa Lima (com paginação)\n",
      "                            Cruz | False | ['Bruna de Sousa Lima  Ensino Profissional de nível técnico em Administração pelo Instituto Federal do Piauí Campus Piripiri, Brasil(2014)']\n",
      "                         Família | False | ['Bruna de Sousa Lima  Ensino Profissional de nível técnico em Administração pelo Instituto Federal do Piauí Campus Piripiri, Brasil(2014)']\n",
      "                   Biotecnologia | False | ['Bruna de Sousa Lima  Ensino Profissional de nível técnico em Administração pelo Instituto Federal do Piauí Campus Piripiri, Brasil(2014)']\n",
      "                           Ceará | False | ['Bruna de Sousa Lima  Ensino Profissional de nível técnico em Administração pelo Instituto Federal do Piauí Campus Piripiri, Brasil(2014)']\n",
      "                            Cruz | False | ['Bruna Lima de Sousa  Ensino Médio (2o grau) pela Escola Estadual de Educação Profissional Deputado José Maria Melo, Brasil(2013)']\n",
      "                         Família | False | ['Bruna Lima de Sousa  Ensino Médio (2o grau) pela Escola Estadual de Educação Profissional Deputado José Maria Melo, Brasil(2013)']\n",
      "                   Biotecnologia | False | ['Bruna Lima de Sousa  Ensino Médio (2o grau) pela Escola Estadual de Educação Profissional Deputado José Maria Melo, Brasil(2013)']\n",
      "                           Ceará | False | ['Bruna Lima de Sousa  Ensino Médio (2o grau) pela Escola Estadual de Educação Profissional Deputado José Maria Melo, Brasil(2013)']\n",
      "                            Cruz | False | ['Bruna De Lima Sousa  Graduação pela Universidade Federal do Sul e Sudeste do Pará, Brasil(2019)']\n",
      "                         Família | False | ['Bruna De Lima Sousa  Graduação pela Universidade Federal do Sul e Sudeste do Pará, Brasil(2019)']\n",
      "                   Biotecnologia | False | ['Bruna De Lima Sousa  Graduação pela Universidade Federal do Sul e Sudeste do Pará, Brasil(2019)']\n",
      "                           Ceará | False | ['Bruna De Lima Sousa  Graduação pela Universidade Federal do Sul e Sudeste do Pará, Brasil(2019)']\n",
      "                            Cruz | False | ['Bruna Lima De Sousa  Ensino Médio (2o grau) pelo Ascendino Reis, Brasil(2013)']\n",
      "                         Família | False | ['Bruna Lima De Sousa  Ensino Médio (2o grau) pelo Ascendino Reis, Brasil(2013)']\n",
      "                   Biotecnologia | False | ['Bruna Lima De Sousa  Ensino Médio (2o grau) pelo Ascendino Reis, Brasil(2013)']\n",
      "                           Ceará | False | ['Bruna Lima De Sousa  Ensino Médio (2o grau) pelo Ascendino Reis, Brasil(2013)']\n",
      "                            Cruz | False | ['Bruna Lima de Sousa  Ensino Médio (2o grau) pelo E.E.B PROFESSORA LAURA LIMA, Brasil(2018)']\n",
      "                         Família | False | ['Bruna Lima de Sousa  Ensino Médio (2o grau) pelo E.E.B PROFESSORA LAURA LIMA, Brasil(2018)']\n",
      "                   Biotecnologia | False | ['Bruna Lima de Sousa  Ensino Médio (2o grau) pelo E.E.B PROFESSORA LAURA LIMA, Brasil(2018)']\n",
      "                           Ceará | False | ['Bruna Lima de Sousa  Ensino Médio (2o grau) pelo E.E.B PROFESSORA LAURA LIMA, Brasil(2018)']\n",
      "                            Cruz | False | ['Bruna de sousa lima  Ensino Médio (2o grau) pelo eponina soares dos santos, Brasil(2012) tecnica em enfermagem da Fundação Hospitalar do Estado de Minas Gerais , Brasil']\n",
      "                         Família | False | ['Bruna de sousa lima  Ensino Médio (2o grau) pelo eponina soares dos santos, Brasil(2012) tecnica em enfermagem da Fundação Hospitalar do Estado de Minas Gerais , Brasil']\n",
      "                   Biotecnologia | False | ['Bruna de sousa lima  Ensino Médio (2o grau) pelo eponina soares dos santos, Brasil(2012) tecnica em enfermagem da Fundação Hospitalar do Estado de Minas Gerais , Brasil']\n",
      "                           Ceará | False | ['Bruna de sousa lima  Ensino Médio (2o grau) pelo eponina soares dos santos, Brasil(2012) tecnica em enfermagem da Fundação Hospitalar do Estado de Minas Gerais , Brasil']\n",
      "                            Cruz | False | ['Bruna de Sousa Lima  Especialização em Comunicação em Redes Sociais pela Universidade Nove de Julho, Brasil(2017) Diretora de Ensino do Serviço Social do Comércio , Brasil']\n",
      "                         Família | False | ['Bruna de Sousa Lima  Especialização em Comunicação em Redes Sociais pela Universidade Nove de Julho, Brasil(2017) Diretora de Ensino do Serviço Social do Comércio , Brasil']\n",
      "                   Biotecnologia | False | ['Bruna de Sousa Lima  Especialização em Comunicação em Redes Sociais pela Universidade Nove de Julho, Brasil(2017) Diretora de Ensino do Serviço Social do Comércio , Brasil']\n",
      "                           Ceará | False | ['Bruna de Sousa Lima  Especialização em Comunicação em Redes Sociais pela Universidade Nove de Julho, Brasil(2017) Diretora de Ensino do Serviço Social do Comércio , Brasil']\n",
      "                            Cruz | False | ['Bruna de Sousa Lima  Ensino Médio (2o grau) pela Escola de Ensino Médio Arsênio Ferreira Maia, Brasil(2017)']\n",
      "                         Família | False | ['Bruna de Sousa Lima  Ensino Médio (2o grau) pela Escola de Ensino Médio Arsênio Ferreira Maia, Brasil(2017)']\n",
      "                   Biotecnologia | False | ['Bruna de Sousa Lima  Ensino Médio (2o grau) pela Escola de Ensino Médio Arsênio Ferreira Maia, Brasil(2017)']\n",
      "                           Ceará | False | ['Bruna de Sousa Lima  Ensino Médio (2o grau) pela Escola de Ensino Médio Arsênio Ferreira Maia, Brasil(2017)']\n",
      "                            Cruz | True | ['Bruna de Sousa Lima  Ensino Profissional de nível técnico em Biotecnologia pela Escola Estadual de Educação Profissional Eusébio de Queiroz, Brasil(2016) Bolsista da Fundação Oswaldo Cruz , Brasil']\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "22/126: Brunheld Maia Dutra\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "23/126: Camila Sillos Rosas Brisighello\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "24/126: Carlos Antonio De Arroxelas Silva\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "25/126: Carlos Eduardo De Sousa Praxedes\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "26/126: Carollyne Ferreira Santiago\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "27/126: Cassio Pinheiro Oliveira\n",
      "       004 artigos extraídos\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "28/126: Cristian Vicson Gomes Pinheiro\n",
      "       002 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "29/126: Cristiane França Martins Teodoro\n",
      "30/126: Cristiane Mourao Carvalhedo Mesquita\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "31/126: Diego Da Silva De Almeida\n",
      "        6 currículos homônimos: Diego Da Silva De Almeida\n",
      "                            Cruz | False | ['Diego de Almeida da Silva  Graduação em Licenciatura em Física pelo IFSP - Campus Itapetininga, Brasil(2018)']\n",
      "                         Família | False | ['Diego de Almeida da Silva  Graduação em Licenciatura em Física pelo IFSP - Campus Itapetininga, Brasil(2018)']\n",
      "                   Biotecnologia | False | ['Diego de Almeida da Silva  Graduação em Licenciatura em Física pelo IFSP - Campus Itapetininga, Brasil(2018)']\n",
      "                           Ceará | False | ['Diego de Almeida da Silva  Graduação em Licenciatura em Física pelo IFSP - Campus Itapetininga, Brasil(2018)']\n",
      "                            Cruz | False | ['Diego de Almeida da Silva  Doutorado em Evolução e Diversidade pela Universidade Federal do ABC, Brasil(2022) Doutorando da Universidade Federal do ABC , Brasil']\n",
      "                         Família | False | ['Diego de Almeida da Silva  Doutorado em Evolução e Diversidade pela Universidade Federal do ABC, Brasil(2022) Doutorando da Universidade Federal do ABC , Brasil']\n",
      "                   Biotecnologia | False | ['Diego de Almeida da Silva  Doutorado em Evolução e Diversidade pela Universidade Federal do ABC, Brasil(2022) Doutorando da Universidade Federal do ABC , Brasil']\n",
      "                           Ceará | False | ['Diego de Almeida da Silva  Doutorado em Evolução e Diversidade pela Universidade Federal do ABC, Brasil(2022) Doutorando da Universidade Federal do ABC , Brasil']\n",
      "                            Cruz | True | ['Diego da Silva de Almeida  Mestrado em Biologia Computacional e Sistemas pela Fundação Oswaldo Cruz, Brasil(2023)']\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "32/126: Diego Ramos Aguiar\n",
      "        2 currículos homônimos: Diego Ramos Aguiar\n",
      "                            Cruz | False | ['Diego Maradona Ramos Aguiar  Ensino Médio (2o grau) pelo Sesi Ignez Pitta de Almeida, Brasil(2019) Estudante do Centro Universitário São Francisco de Barreiras , Brasil']\n",
      "                         Família | False | ['Diego Maradona Ramos Aguiar  Ensino Médio (2o grau) pelo Sesi Ignez Pitta de Almeida, Brasil(2019) Estudante do Centro Universitário São Francisco de Barreiras , Brasil']\n",
      "                   Biotecnologia | False | ['Diego Maradona Ramos Aguiar  Ensino Médio (2o grau) pelo Sesi Ignez Pitta de Almeida, Brasil(2019) Estudante do Centro Universitário São Francisco de Barreiras , Brasil']\n",
      "                           Ceará | False | ['Diego Maradona Ramos Aguiar  Ensino Médio (2o grau) pelo Sesi Ignez Pitta de Almeida, Brasil(2019) Estudante do Centro Universitário São Francisco de Barreiras , Brasil']\n",
      "                            Cruz | True | ['Diego Ramos Aguiar  Mestrado Profissional em Saúde da Família pela Fundação Osvaldo Cruz, Brasil(2022) Especialista em Prótese Dentária do Centro de Especialidades Odontológicas Regional de SobralCE , Brasil']\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "33/126: Disraeli Cavalcante Araujo Vasconcelos\n",
      "       004 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "34/126: Eduardo Menezes Gaieta\n",
      "       005 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "35/126: Ellen Maria Lima Gonçalves\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "36/126: Erika Romeria Formiga De Sousa\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "37/126: Erlemus Ponte Soares\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "38/126: Evanildo Henrique Macedo Da Costa\n",
      "       001 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "39/126: Evanizia Pinheiro De Oliveira\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "40/126: Fabio Jose Gomes De Sousa\n",
      "       002 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "41/126: Filipe Oliveira De Brito\n",
      "        4 currículos homônimos: Filipe Oliveira De Brito\n",
      "                            Cruz | False | ['Filipe Brito de Oliveira  Graduação em Letras - Língua Portuguesa pela Universidade Federal do Pará, Brasil(2017)']\n",
      "                         Família | False | ['Filipe Brito de Oliveira  Graduação em Letras - Língua Portuguesa pela Universidade Federal do Pará, Brasil(2017)']\n",
      "                   Biotecnologia | False | ['Filipe Brito de Oliveira  Graduação em Letras - Língua Portuguesa pela Universidade Federal do Pará, Brasil(2017)']\n",
      "                           Ceará | False | ['Filipe Brito de Oliveira  Graduação em Letras - Língua Portuguesa pela Universidade Federal do Pará, Brasil(2017)']\n",
      "                            Cruz | False | ['Filipe Oliveira de Brito  Mestrado em Saúde Pública pela Universidade Estadual do Ceará, Brasil(2018) Professor Auxiliar da Universidade de Fortaleza , Brasil']\n",
      "                         Família | False | ['Filipe Oliveira de Brito  Mestrado em Saúde Pública pela Universidade Estadual do Ceará, Brasil(2018) Professor Auxiliar da Universidade de Fortaleza , Brasil']\n",
      "                   Biotecnologia | False | ['Filipe Oliveira de Brito  Mestrado em Saúde Pública pela Universidade Estadual do Ceará, Brasil(2018) Professor Auxiliar da Universidade de Fortaleza , Brasil']\n",
      "                           Ceará | True | ['Filipe Oliveira de Brito  Mestrado em Saúde Pública pela Universidade Estadual do Ceará, Brasil(2018) Professor Auxiliar da Universidade de Fortaleza , Brasil']\n",
      "       006 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "42/126: Francisca Raquel De Vasconcelos Silveira\n",
      "       015 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "43/126: Gabriel Acacio De Moura\n",
      "       006 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "44/126: Georgea Bezerra Carvalho\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "45/126: Geraldo Rodrigues Sartori\n",
      "       020 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "46/126: Germana Silva Vasconcelos\n",
      "       025 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "47/126: Gilcelene De Castro Andrade\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "48/126: Gilmara Maria Batista Tavares Da Silva\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "49/126: Glaziane Da Silva Paiva Bandeira\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "50/126: Grayce Alencar Albuquerque\n",
      "       121 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "51/126: Graziela Jones De Oliveira\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "52/126: Guilherme Angelo Lobo\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "53/126: Hassa Pereira Lemos\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "54/126: Herquimedes Glaudys Da Silva Avelino\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "55/126: Heverton Mendes Araujo\n",
      "       004 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "56/126: Igor Cabral Studart\n",
      "       002 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "57/126: Isabella Lima Barbosa Campelo\n",
      "       014 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "58/126: Jean Vieira Sampaio\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "59/126: Joao Eudes Lemos De Barros\n",
      "       007 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "60/126: Joao Matheus Fonteles Silva\n",
      "       001 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "61/126: Joao Pedro Viana Rodrigues\n",
      "        3 currículos homônimos: Joao Pedro Viana Rodrigues\n",
      "                            Cruz | False | ['João Pedro Rodrigues viana  Ensino Médio (2o grau) pela Escola estadual Maria de Lourdes Campos Freitas Marques , Brasil(2020) Estagiário do Ministério público do trabalho 15 região , Brasil']\n",
      "                         Família | False | ['João Pedro Rodrigues viana  Ensino Médio (2o grau) pela Escola estadual Maria de Lourdes Campos Freitas Marques , Brasil(2020) Estagiário do Ministério público do trabalho 15 região , Brasil']\n",
      "                   Biotecnologia | False | ['João Pedro Rodrigues viana  Ensino Médio (2o grau) pela Escola estadual Maria de Lourdes Campos Freitas Marques , Brasil(2020) Estagiário do Ministério público do trabalho 15 região , Brasil']\n",
      "                           Ceará | False | ['João Pedro Rodrigues viana  Ensino Médio (2o grau) pela Escola estadual Maria de Lourdes Campos Freitas Marques , Brasil(2020) Estagiário do Ministério público do trabalho 15 região , Brasil']\n",
      "                            Cruz | False | ['João Pedro Viana Rodrigues  Mestrado em Ciências Farmacêuticas pela Universidade Federal do Ceará, Brasil(2020) Aluno de Doutorado da Universidade Federal do Ceará , Brasil']\n",
      "                         Família | False | ['João Pedro Viana Rodrigues  Mestrado em Ciências Farmacêuticas pela Universidade Federal do Ceará, Brasil(2020) Aluno de Doutorado da Universidade Federal do Ceará , Brasil']\n",
      "                   Biotecnologia | False | ['João Pedro Viana Rodrigues  Mestrado em Ciências Farmacêuticas pela Universidade Federal do Ceará, Brasil(2020) Aluno de Doutorado da Universidade Federal do Ceará , Brasil']\n",
      "                           Ceará | True | ['João Pedro Viana Rodrigues  Mestrado em Ciências Farmacêuticas pela Universidade Federal do Ceará, Brasil(2020) Aluno de Doutorado da Universidade Federal do Ceará , Brasil']\n",
      "       020 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "62/126: Joaquim Cesar Do Nascimento Sousa Junior\n",
      "       001 artigos extraídos\n",
      "       DOI indisponível para 01 artigo extraído\n",
      "       Extração bem-sucedida\n",
      "63/126: Jose Maria Ximenes Guimaraes\n",
      "       061 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "64/126: Jose Samuel Dos Santos Barbosa\n",
      "       001 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "65/126: Josete Malheiro Tavares\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "66/126: Jucilene Pereira De Sousa\n",
      "       004 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "67/126: Juliana Meneses De Sena Silva\n",
      "       001 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "68/126: Juliana Ramos De Oliveira\n",
      "       26 currículos homônimos: Juliana Ramos De Oliveira (com paginação)\n",
      "                            Cruz | False | ['Juliana de Oliveira Ramos  Graduação em Fonoaudiologia pela Universidade Veiga de Almeida, Brasil(2009)']\n",
      "                         Família | False | ['Juliana de Oliveira Ramos  Graduação em Fonoaudiologia pela Universidade Veiga de Almeida, Brasil(2009)']\n",
      "                   Biotecnologia | False | ['Juliana de Oliveira Ramos  Graduação em Fonoaudiologia pela Universidade Veiga de Almeida, Brasil(2009)']\n",
      "                           Ceará | False | ['Juliana de Oliveira Ramos  Graduação em Fonoaudiologia pela Universidade Veiga de Almeida, Brasil(2009)']\n",
      "                            Cruz | False | ['Juliana Ramos de Oliveira  Graduação em Ciências Biológicas pelo Módulo Centro Universitário, Brasil(2012)']\n",
      "                         Família | False | ['Juliana Ramos de Oliveira  Graduação em Ciências Biológicas pelo Módulo Centro Universitário, Brasil(2012)']\n",
      "                   Biotecnologia | False | ['Juliana Ramos de Oliveira  Graduação em Ciências Biológicas pelo Módulo Centro Universitário, Brasil(2012)']\n",
      "                           Ceará | False | ['Juliana Ramos de Oliveira  Graduação em Ciências Biológicas pelo Módulo Centro Universitário, Brasil(2012)']\n",
      "                            Cruz | False | ['Juliana Ramos de Oliveira  Ensino Médio (2o grau) pelo Alzira da Fonseca Breuel, Brasil(2004)']\n",
      "                         Família | False | ['Juliana Ramos de Oliveira  Ensino Médio (2o grau) pelo Alzira da Fonseca Breuel, Brasil(2004)']\n",
      "                   Biotecnologia | False | ['Juliana Ramos de Oliveira  Ensino Médio (2o grau) pelo Alzira da Fonseca Breuel, Brasil(2004)']\n",
      "                           Ceará | False | ['Juliana Ramos de Oliveira  Ensino Médio (2o grau) pelo Alzira da Fonseca Breuel, Brasil(2004)']\n",
      "                            Cruz | False | ['Juliana Ramos de Oliveira  Especialização em Psicopedagogia pela Universidade Metropolitana de Santos, Brasil(2013) Tutor EAD da Universidade Metropolitana de Santos , Brasil']\n",
      "                         Família | False | ['Juliana Ramos de Oliveira  Especialização em Psicopedagogia pela Universidade Metropolitana de Santos, Brasil(2013) Tutor EAD da Universidade Metropolitana de Santos , Brasil']\n",
      "                   Biotecnologia | False | ['Juliana Ramos de Oliveira  Especialização em Psicopedagogia pela Universidade Metropolitana de Santos, Brasil(2013) Tutor EAD da Universidade Metropolitana de Santos , Brasil']\n",
      "                           Ceará | False | ['Juliana Ramos de Oliveira  Especialização em Psicopedagogia pela Universidade Metropolitana de Santos, Brasil(2013) Tutor EAD da Universidade Metropolitana de Santos , Brasil']\n",
      "                            Cruz | False | ['Juliana de Oliveira Ramos  Formação Tecnico- Cientifíca da Pontifícia Universidade Católica de Minas Gerais , Brasil']\n",
      "                         Família | False | ['Juliana de Oliveira Ramos  Formação Tecnico- Cientifíca da Pontifícia Universidade Católica de Minas Gerais , Brasil']\n",
      "                   Biotecnologia | False | ['Juliana de Oliveira Ramos  Formação Tecnico- Cientifíca da Pontifícia Universidade Católica de Minas Gerais , Brasil']\n",
      "                           Ceará | False | ['Juliana de Oliveira Ramos  Formação Tecnico- Cientifíca da Pontifícia Universidade Católica de Minas Gerais , Brasil']\n",
      "                            Cruz | False | ['Juliana de Oliveira Ramos  Graduação em Gestão de Recursos Humanos pela Universidade Estácio de Sá, Brasil(2008)']\n",
      "                         Família | False | ['Juliana de Oliveira Ramos  Graduação em Gestão de Recursos Humanos pela Universidade Estácio de Sá, Brasil(2008)']\n",
      "                   Biotecnologia | False | ['Juliana de Oliveira Ramos  Graduação em Gestão de Recursos Humanos pela Universidade Estácio de Sá, Brasil(2008)']\n",
      "                           Ceará | False | ['Juliana de Oliveira Ramos  Graduação em Gestão de Recursos Humanos pela Universidade Estácio de Sá, Brasil(2008)']\n",
      "                            Cruz | False | ['Juliana de Oliveira Ramos  Ensino Médio (2o grau) pela Fundação de Apoio à Escola Técnica do Estado do Rio de Janeiro, Brasil(2011)']\n",
      "                         Família | False | ['Juliana de Oliveira Ramos  Ensino Médio (2o grau) pela Fundação de Apoio à Escola Técnica do Estado do Rio de Janeiro, Brasil(2011)']\n",
      "                   Biotecnologia | False | ['Juliana de Oliveira Ramos  Ensino Médio (2o grau) pela Fundação de Apoio à Escola Técnica do Estado do Rio de Janeiro, Brasil(2011)']\n",
      "                           Ceará | False | ['Juliana de Oliveira Ramos  Ensino Médio (2o grau) pela Fundação de Apoio à Escola Técnica do Estado do Rio de Janeiro, Brasil(2011)']\n",
      "                            Cruz | False | ['Juliana Ramos de Oliveira  Graduação em Geografia pela Universidade Federal Fluminense, Brasil(2022)']\n",
      "                         Família | False | ['Juliana Ramos de Oliveira  Graduação em Geografia pela Universidade Federal Fluminense, Brasil(2022)']\n",
      "                   Biotecnologia | False | ['Juliana Ramos de Oliveira  Graduação em Geografia pela Universidade Federal Fluminense, Brasil(2022)']\n",
      "                           Ceará | False | ['Juliana Ramos de Oliveira  Graduação em Geografia pela Universidade Federal Fluminense, Brasil(2022)']\n",
      "                            Cruz | False | ['Juliana Ramos de Oliveira  Ensino Médio (2o grau) pelo Colégio Estadual Odorico Tavares, Brasil(2009)']\n",
      "                         Família | False | ['Juliana Ramos de Oliveira  Ensino Médio (2o grau) pelo Colégio Estadual Odorico Tavares, Brasil(2009)']\n",
      "                   Biotecnologia | False | ['Juliana Ramos de Oliveira  Ensino Médio (2o grau) pelo Colégio Estadual Odorico Tavares, Brasil(2009)']\n",
      "                           Ceará | False | ['Juliana Ramos de Oliveira  Ensino Médio (2o grau) pelo Colégio Estadual Odorico Tavares, Brasil(2009)']\n",
      "                            Cruz | False | ['Juliana Ramos de Oliveira  Mestrado Profissional em Biotecnologia em Saúde Humana e Animal pela Universidade Estadual do Ceará, Brasil(2018)']\n",
      "                         Família | False | ['Juliana Ramos de Oliveira  Mestrado Profissional em Biotecnologia em Saúde Humana e Animal pela Universidade Estadual do Ceará, Brasil(2018)']\n",
      "                   Biotecnologia | True | ['Juliana Ramos de Oliveira  Mestrado Profissional em Biotecnologia em Saúde Humana e Animal pela Universidade Estadual do Ceará, Brasil(2018)']\n",
      "       002 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "69/126: Kamila Maria Oliveira Sales\n",
      "       004 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "70/126: Ketlen Christine Ohse\n",
      "       009 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "71/126: Kilvia Helane Cardoso Mesquita\n",
      "       002 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "72/126: Laecio Paulo Sousa Dos Santos\n",
      "       001 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "73/126: Larisse Cadeira Brandao\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "74/126: Lea Dias Pimentel Gomes Vasconcelos\n",
      "       007 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "75/126: Lenir Santos\n",
      "       33 currículos homônimos: Lenir Santos (com paginação)\n",
      "                            Cruz | False | ['Lenir Santos  Doutorado em Saúde Coletiva pela Universidade Estadual de Campinas, Brasil(2012) PRESIDENTE do Instituto de Direito Sanitário Aplicado , Brasil']\n",
      "                         Família | False | ['Lenir Santos  Doutorado em Saúde Coletiva pela Universidade Estadual de Campinas, Brasil(2012) PRESIDENTE do Instituto de Direito Sanitário Aplicado , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Santos  Doutorado em Saúde Coletiva pela Universidade Estadual de Campinas, Brasil(2012) PRESIDENTE do Instituto de Direito Sanitário Aplicado , Brasil']\n",
      "                           Ceará | False | ['Lenir Santos  Doutorado em Saúde Coletiva pela Universidade Estadual de Campinas, Brasil(2012) PRESIDENTE do Instituto de Direito Sanitário Aplicado , Brasil']\n",
      "                            Cruz | False | ['Lenir Santos Schettert  Especialização em Especialização em Educação pela Universidade Regional do Noroeste do Estado do Rio Grande do Sul, Brasil(1987) Cordenadora GTJA do Secretaria Estadual de Educação , Brasil']\n",
      "                         Família | False | ['Lenir Santos Schettert  Especialização em Especialização em Educação pela Universidade Regional do Noroeste do Estado do Rio Grande do Sul, Brasil(1987) Cordenadora GTJA do Secretaria Estadual de Educação , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Santos Schettert  Especialização em Especialização em Educação pela Universidade Regional do Noroeste do Estado do Rio Grande do Sul, Brasil(1987) Cordenadora GTJA do Secretaria Estadual de Educação , Brasil']\n",
      "                           Ceará | False | ['Lenir Santos Schettert  Especialização em Especialização em Educação pela Universidade Regional do Noroeste do Estado do Rio Grande do Sul, Brasil(1987) Cordenadora GTJA do Secretaria Estadual de Educação , Brasil']\n",
      "                            Cruz | False | ['Lenir Salva dos Santos  Graduação em Ciências Contábeis pelo Instituto Superior de Ciências Aplicadas, Brasil(1988)']\n",
      "                         Família | False | ['Lenir Salva dos Santos  Graduação em Ciências Contábeis pelo Instituto Superior de Ciências Aplicadas, Brasil(1988)']\n",
      "                   Biotecnologia | False | ['Lenir Salva dos Santos  Graduação em Ciências Contábeis pelo Instituto Superior de Ciências Aplicadas, Brasil(1988)']\n",
      "                           Ceará | False | ['Lenir Salva dos Santos  Graduação em Ciências Contábeis pelo Instituto Superior de Ciências Aplicadas, Brasil(1988)']\n",
      "                            Cruz | False | ['Lenir Dias dos Santos  Graduação em Gestao Publico pela Universidade Estadual de Goiás, Brasil(2003) Gerência Contabil da Prefeitura Municipal de Sao Luis de Montes Belos , Brasil']\n",
      "                         Família | False | ['Lenir Dias dos Santos  Graduação em Gestao Publico pela Universidade Estadual de Goiás, Brasil(2003) Gerência Contabil da Prefeitura Municipal de Sao Luis de Montes Belos , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Dias dos Santos  Graduação em Gestao Publico pela Universidade Estadual de Goiás, Brasil(2003) Gerência Contabil da Prefeitura Municipal de Sao Luis de Montes Belos , Brasil']\n",
      "                           Ceará | False | ['Lenir Dias dos Santos  Graduação em Gestao Publico pela Universidade Estadual de Goiás, Brasil(2003) Gerência Contabil da Prefeitura Municipal de Sao Luis de Montes Belos , Brasil']\n",
      "                            Cruz | False | ['Lenir dos Santos  Ensino Médio (2o grau) pelo Ronald da Silva Carvalho, Brasil(1987)']\n",
      "                         Família | False | ['Lenir dos Santos  Ensino Médio (2o grau) pelo Ronald da Silva Carvalho, Brasil(1987)']\n",
      "                   Biotecnologia | False | ['Lenir dos Santos  Ensino Médio (2o grau) pelo Ronald da Silva Carvalho, Brasil(1987)']\n",
      "                           Ceará | False | ['Lenir dos Santos  Ensino Médio (2o grau) pelo Ronald da Silva Carvalho, Brasil(1987)']\n",
      "                            Cruz | False | ['Lenir Firmino dos Santos  Graduação em Administração pela Faculdade Padrão, Brasil(2010)']\n",
      "                         Família | False | ['Lenir Firmino dos Santos  Graduação em Administração pela Faculdade Padrão, Brasil(2010)']\n",
      "                   Biotecnologia | False | ['Lenir Firmino dos Santos  Graduação em Administração pela Faculdade Padrão, Brasil(2010)']\n",
      "                           Ceará | False | ['Lenir Firmino dos Santos  Graduação em Administração pela Faculdade Padrão, Brasil(2010)']\n",
      "                            Cruz | False | ['Lenir Juvaldina dos Santos  Ensino Médio (2o grau) pela Universidade do Estado de Santa Catarina, Brasil(1986)']\n",
      "                         Família | False | ['Lenir Juvaldina dos Santos  Ensino Médio (2o grau) pela Universidade do Estado de Santa Catarina, Brasil(1986)']\n",
      "                   Biotecnologia | False | ['Lenir Juvaldina dos Santos  Ensino Médio (2o grau) pela Universidade do Estado de Santa Catarina, Brasil(1986)']\n",
      "                           Ceará | False | ['Lenir Juvaldina dos Santos  Ensino Médio (2o grau) pela Universidade do Estado de Santa Catarina, Brasil(1986)']\n",
      "                            Cruz | False | ['Lenir Santos de Andrade  Graduação em ENFERMAGEM pela Universidade do Estado do Pará, Brasil(2004) ENFERMEIRA da Fundação Nacional de Saúde , Brasil']\n",
      "                         Família | False | ['Lenir Santos de Andrade  Graduação em ENFERMAGEM pela Universidade do Estado do Pará, Brasil(2004) ENFERMEIRA da Fundação Nacional de Saúde , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Santos de Andrade  Graduação em ENFERMAGEM pela Universidade do Estado do Pará, Brasil(2004) ENFERMEIRA da Fundação Nacional de Saúde , Brasil']\n",
      "                           Ceará | False | ['Lenir Santos de Andrade  Graduação em ENFERMAGEM pela Universidade do Estado do Pará, Brasil(2004) ENFERMEIRA da Fundação Nacional de Saúde , Brasil']\n",
      "                            Cruz | False | ['Lenir Santos Sôlha Rodrigues  Especialização em Controle de Infecção Hospitalar pela Universidade Gama Filho, Brasil(2003) ENFERMEIRA CCIH do HOSPITAL SAMCI , Brasil']\n",
      "                         Família | False | ['Lenir Santos Sôlha Rodrigues  Especialização em Controle de Infecção Hospitalar pela Universidade Gama Filho, Brasil(2003) ENFERMEIRA CCIH do HOSPITAL SAMCI , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Santos Sôlha Rodrigues  Especialização em Controle de Infecção Hospitalar pela Universidade Gama Filho, Brasil(2003) ENFERMEIRA CCIH do HOSPITAL SAMCI , Brasil']\n",
      "                           Ceará | False | ['Lenir Santos Sôlha Rodrigues  Especialização em Controle de Infecção Hospitalar pela Universidade Gama Filho, Brasil(2003) ENFERMEIRA CCIH do HOSPITAL SAMCI , Brasil']\n",
      "                            Cruz | False | ['Lenir Karla Borges Santos  Ensino Médio (2o grau) pelo COLÉGIO BATISTA DANIEL DE LA TOUCHE, Brasil(2006)']\n",
      "                         Família | False | ['Lenir Karla Borges Santos  Ensino Médio (2o grau) pelo COLÉGIO BATISTA DANIEL DE LA TOUCHE, Brasil(2006)']\n",
      "                   Biotecnologia | False | ['Lenir Karla Borges Santos  Ensino Médio (2o grau) pelo COLÉGIO BATISTA DANIEL DE LA TOUCHE, Brasil(2006)']\n",
      "                           Ceará | False | ['Lenir Karla Borges Santos  Ensino Médio (2o grau) pelo COLÉGIO BATISTA DANIEL DE LA TOUCHE, Brasil(2006)']\n",
      "       Página a ser carregada: 2\n",
      "                            Cruz | False | ['Lenir Francisco Dos Santos  Graduação em Fonoaudiologia pelo CENTRO UNIVERSITÁRIO DO DISTRITO FEDERAL, Brasil(2017)']\n",
      "                         Família | False | ['Lenir Francisco Dos Santos  Graduação em Fonoaudiologia pelo CENTRO UNIVERSITÁRIO DO DISTRITO FEDERAL, Brasil(2017)']\n",
      "                   Biotecnologia | False | ['Lenir Francisco Dos Santos  Graduação em Fonoaudiologia pelo CENTRO UNIVERSITÁRIO DO DISTRITO FEDERAL, Brasil(2017)']\n",
      "                           Ceará | False | ['Lenir Francisco Dos Santos  Graduação em Fonoaudiologia pelo CENTRO UNIVERSITÁRIO DO DISTRITO FEDERAL, Brasil(2017)']\n",
      "                            Cruz | False | ['Lenir Santos Pereira Monteiro  Graduação em Pedagogia pela UNIVERSIDADE ESTADUAL DO TOCANTINS, Brasil(2007) PROFESSOR NÍVEL II da Prefeitura Municipal de Araguaína , Brasil']\n",
      "                         Família | False | ['Lenir Santos Pereira Monteiro  Graduação em Pedagogia pela UNIVERSIDADE ESTADUAL DO TOCANTINS, Brasil(2007) PROFESSOR NÍVEL II da Prefeitura Municipal de Araguaína , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Santos Pereira Monteiro  Graduação em Pedagogia pela UNIVERSIDADE ESTADUAL DO TOCANTINS, Brasil(2007) PROFESSOR NÍVEL II da Prefeitura Municipal de Araguaína , Brasil']\n",
      "                           Ceará | False | ['Lenir Santos Pereira Monteiro  Graduação em Pedagogia pela UNIVERSIDADE ESTADUAL DO TOCANTINS, Brasil(2007) PROFESSOR NÍVEL II da Prefeitura Municipal de Araguaína , Brasil']\n",
      "                            Cruz | False | ['Lenir Rodrigues Santos  Doutorado em DERECHO INTERNACIONAL pelo UNIVERSIDAD AUTÓNOMA DE ASUNCIÓN, Paraguai(2010) Defensora Pública do Defensoria pública do Estado de Roraima , Brasil']\n",
      "                         Família | False | ['Lenir Rodrigues Santos  Doutorado em DERECHO INTERNACIONAL pelo UNIVERSIDAD AUTÓNOMA DE ASUNCIÓN, Paraguai(2010) Defensora Pública do Defensoria pública do Estado de Roraima , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Rodrigues Santos  Doutorado em DERECHO INTERNACIONAL pelo UNIVERSIDAD AUTÓNOMA DE ASUNCIÓN, Paraguai(2010) Defensora Pública do Defensoria pública do Estado de Roraima , Brasil']\n",
      "                           Ceará | False | ['Lenir Rodrigues Santos  Doutorado em DERECHO INTERNACIONAL pelo UNIVERSIDAD AUTÓNOMA DE ASUNCIÓN, Paraguai(2010) Defensora Pública do Defensoria pública do Estado de Roraima , Brasil']\n",
      "                            Cruz | False | ['Lenir Dos Santos Oliveira  Graduação em Letras - Português pelo Centro Universitário Leonardo da Vinci, Brasil(2014) professora da Escola Estadual 12 de Abril , Brasil']\n",
      "                         Família | False | ['Lenir Dos Santos Oliveira  Graduação em Letras - Português pelo Centro Universitário Leonardo da Vinci, Brasil(2014) professora da Escola Estadual 12 de Abril , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Dos Santos Oliveira  Graduação em Letras - Português pelo Centro Universitário Leonardo da Vinci, Brasil(2014) professora da Escola Estadual 12 de Abril , Brasil']\n",
      "                           Ceará | False | ['Lenir Dos Santos Oliveira  Graduação em Letras - Português pelo Centro Universitário Leonardo da Vinci, Brasil(2014) professora da Escola Estadual 12 de Abril , Brasil']\n",
      "                            Cruz | False | ['Lenir Teixeira dos Santos  Especialização em Esp. em Metod. de Ens. para a Educ. Profissional pela Universidade do Estado da Bahia, Brasil(2015) Professora de História do Centro Estadual de Educação Profissional em Saúde e Gestão , Brasil']\n",
      "                         Família | False | ['Lenir Teixeira dos Santos  Especialização em Esp. em Metod. de Ens. para a Educ. Profissional pela Universidade do Estado da Bahia, Brasil(2015) Professora de História do Centro Estadual de Educação Profissional em Saúde e Gestão , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Teixeira dos Santos  Especialização em Esp. em Metod. de Ens. para a Educ. Profissional pela Universidade do Estado da Bahia, Brasil(2015) Professora de História do Centro Estadual de Educação Profissional em Saúde e Gestão , Brasil']\n",
      "                           Ceará | False | ['Lenir Teixeira dos Santos  Especialização em Esp. em Metod. de Ens. para a Educ. Profissional pela Universidade do Estado da Bahia, Brasil(2015) Professora de História do Centro Estadual de Educação Profissional em Saúde e Gestão , Brasil']\n",
      "                            Cruz | False | ['Lenir Ribeiro Barbosa Santos  Graduação em Ciêncis Biológicas pelo Instituto FAL , Brasil(2020) LABORTORISTA do SERVIÇO AUTÔNOMO ÁGUA E ESGOTO , Brasil']\n",
      "                         Família | False | ['Lenir Ribeiro Barbosa Santos  Graduação em Ciêncis Biológicas pelo Instituto FAL , Brasil(2020) LABORTORISTA do SERVIÇO AUTÔNOMO ÁGUA E ESGOTO , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Ribeiro Barbosa Santos  Graduação em Ciêncis Biológicas pelo Instituto FAL , Brasil(2020) LABORTORISTA do SERVIÇO AUTÔNOMO ÁGUA E ESGOTO , Brasil']\n",
      "                           Ceará | False | ['Lenir Ribeiro Barbosa Santos  Graduação em Ciêncis Biológicas pelo Instituto FAL , Brasil(2020) LABORTORISTA do SERVIÇO AUTÔNOMO ÁGUA E ESGOTO , Brasil']\n",
      "                            Cruz | False | ['Lenir Santos de Freitas  Graduação em LICENCIATURA PLENA EM PEDAGOGIA pela Universidade Anhanguera - Uniderp, Brasil(2015) Secretária Escolar do Secretaria Estadual de Educação , Brasil']\n",
      "                         Família | False | ['Lenir Santos de Freitas  Graduação em LICENCIATURA PLENA EM PEDAGOGIA pela Universidade Anhanguera - Uniderp, Brasil(2015) Secretária Escolar do Secretaria Estadual de Educação , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Santos de Freitas  Graduação em LICENCIATURA PLENA EM PEDAGOGIA pela Universidade Anhanguera - Uniderp, Brasil(2015) Secretária Escolar do Secretaria Estadual de Educação , Brasil']\n",
      "                           Ceará | False | ['Lenir Santos de Freitas  Graduação em LICENCIATURA PLENA EM PEDAGOGIA pela Universidade Anhanguera - Uniderp, Brasil(2015) Secretária Escolar do Secretaria Estadual de Educação , Brasil']\n",
      "                            Cruz | False | ['Fellipe Lenir dos Santos  Ensino Fundamental (1o grau) pela ESCOLA DE EDUCAÇÃO BÁSICA SANTA TERESINHA, Brasil(2020) menor aprendiz do SENAI - Departamento Regional de Santa Catarina , Brasil']\n",
      "                         Família | False | ['Fellipe Lenir dos Santos  Ensino Fundamental (1o grau) pela ESCOLA DE EDUCAÇÃO BÁSICA SANTA TERESINHA, Brasil(2020) menor aprendiz do SENAI - Departamento Regional de Santa Catarina , Brasil']\n",
      "                   Biotecnologia | False | ['Fellipe Lenir dos Santos  Ensino Fundamental (1o grau) pela ESCOLA DE EDUCAÇÃO BÁSICA SANTA TERESINHA, Brasil(2020) menor aprendiz do SENAI - Departamento Regional de Santa Catarina , Brasil']\n",
      "                           Ceará | False | ['Fellipe Lenir dos Santos  Ensino Fundamental (1o grau) pela ESCOLA DE EDUCAÇÃO BÁSICA SANTA TERESINHA, Brasil(2020) menor aprendiz do SENAI - Departamento Regional de Santa Catarina , Brasil']\n",
      "                            Cruz | False | ['Lenir dos Santos Moraes  Mestrado em Educação pela Universidade do Vale do Rio dos Sinos, Brasil(2010) Assessora Pedagógica da Rede ICM de Educação e Assistência Social , Brasil']\n",
      "                         Família | False | ['Lenir dos Santos Moraes  Mestrado em Educação pela Universidade do Vale do Rio dos Sinos, Brasil(2010) Assessora Pedagógica da Rede ICM de Educação e Assistência Social , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir dos Santos Moraes  Mestrado em Educação pela Universidade do Vale do Rio dos Sinos, Brasil(2010) Assessora Pedagógica da Rede ICM de Educação e Assistência Social , Brasil']\n",
      "                           Ceará | False | ['Lenir dos Santos Moraes  Mestrado em Educação pela Universidade do Vale do Rio dos Sinos, Brasil(2010) Assessora Pedagógica da Rede ICM de Educação e Assistência Social , Brasil']\n",
      "                            Cruz | False | ['Lenir Reinaldo dos Santos  Graduação em Farmácia pela Faculdade LS, Brasil(2021) Técnico de segurança do trabalho do Hospital da Criança de Brasília José Alencar , Brasil']\n",
      "                         Família | False | ['Lenir Reinaldo dos Santos  Graduação em Farmácia pela Faculdade LS, Brasil(2021) Técnico de segurança do trabalho do Hospital da Criança de Brasília José Alencar , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Reinaldo dos Santos  Graduação em Farmácia pela Faculdade LS, Brasil(2021) Técnico de segurança do trabalho do Hospital da Criança de Brasília José Alencar , Brasil']\n",
      "                           Ceará | False | ['Lenir Reinaldo dos Santos  Graduação em Farmácia pela Faculdade LS, Brasil(2021) Técnico de segurança do trabalho do Hospital da Criança de Brasília José Alencar , Brasil']\n",
      "       Erro na paginação dos elementos de resultados homônimos\n",
      "       Erro com: stale element reference: stale element not found\n",
      "       Nenhum termo de vínculo achado em 20/33 resultados verificados. Verificada até página 02/04\n",
      "76/126: Leticia Bastos Conrado\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "77/126: Leticia Ferreira Espinosa\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "78/126: Liandra Ellen Coelho Pereira\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "79/126: Libia Lopes Martiniano\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "80/126: Lílian Fernandes Amarante\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "81/126: Livia Coelho De Assis\n",
      "        2 currículos homônimos: Livia Coelho De Assis\n",
      "                            Cruz | False | ['Lívia Coêlho de Assis  Mestrado em Patologia pela Universidade Federal do Ceará, Brasil(2015) Técnico de laboratório da Universidade da Integração Internacional da Lusofonia Afro-Brasileira , Brasil']\n",
      "                         Família | False | ['Lívia Coêlho de Assis  Mestrado em Patologia pela Universidade Federal do Ceará, Brasil(2015) Técnico de laboratório da Universidade da Integração Internacional da Lusofonia Afro-Brasileira , Brasil']\n",
      "                   Biotecnologia | False | ['Lívia Coêlho de Assis  Mestrado em Patologia pela Universidade Federal do Ceará, Brasil(2015) Técnico de laboratório da Universidade da Integração Internacional da Lusofonia Afro-Brasileira , Brasil']\n",
      "                           Ceará | True | ['Lívia Coêlho de Assis  Mestrado em Patologia pela Universidade Federal do Ceará, Brasil(2015) Técnico de laboratório da Universidade da Integração Internacional da Lusofonia Afro-Brasileira , Brasil']\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       DOI indisponível para 01 artigo extraído\n",
      "       Extração bem-sucedida\n",
      "82/126: Lorena Lodo Santiago\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "83/126: Lorena Morais Nogueira\n",
      "        2 currículos homônimos: Lorena Morais Nogueira\n",
      "                            Cruz | False | ['Lorena Marcia Morais Nogueira  Graduação em Direito pela Universidade Salgado de Oliveira, Brasil(2016)']\n",
      "                         Família | False | ['Lorena Marcia Morais Nogueira  Graduação em Direito pela Universidade Salgado de Oliveira, Brasil(2016)']\n",
      "                   Biotecnologia | False | ['Lorena Marcia Morais Nogueira  Graduação em Direito pela Universidade Salgado de Oliveira, Brasil(2016)']\n",
      "                           Ceará | False | ['Lorena Marcia Morais Nogueira  Graduação em Direito pela Universidade Salgado de Oliveira, Brasil(2016)']\n",
      "                            Cruz | False | ['Lorena Morais Nogueira  Especialização em Especialização de Preceptoria em Medicina de Família e Comunidade pela Fundação Universidade Federal de Ciências da Saúde de Porto Alegre, Brasil(2018) Médica na Atenção Integral a Saúde da UNIMED de Fortaleza Cooperativa de Trabalho Médico , Brasil']\n",
      "                         Família | True | ['Lorena Morais Nogueira  Especialização em Especialização de Preceptoria em Medicina de Família e Comunidade pela Fundação Universidade Federal de Ciências da Saúde de Porto Alegre, Brasil(2018) Médica na Atenção Integral a Saúde da UNIMED de Fortaleza Cooperativa de Trabalho Médico , Brasil']\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "84/126: Luca Milerio Andrade\n",
      "       004 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "85/126: Lucas Almeida De Freitas\n",
      "        8 currículos homônimos: Lucas Almeida De Freitas\n",
      "                            Cruz | False | ['Lucas Almeida de Freitas  Graduação em Biotecnologia pela Universidade Federal do Ceará, Brasil(2022)']\n",
      "                         Família | False | ['Lucas Almeida de Freitas  Graduação em Biotecnologia pela Universidade Federal do Ceará, Brasil(2022)']\n",
      "                   Biotecnologia | True | ['Lucas Almeida de Freitas  Graduação em Biotecnologia pela Universidade Federal do Ceará, Brasil(2022)']\n",
      "       001 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "86/126: Lucelia Gois De Oliveira\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "87/126: Luciana Carvalho De Albuquerque\n",
      "        2 currículos homônimos: Luciana Carvalho De Albuquerque\n",
      "                            Cruz | False | ['Luciana Carvalho de Albuquerque  Graduação em Odontologia pela Universidade Federal do Ceará, Brasil(2000) CIRURGIÃ DENTISTA PSF da Prefeitura Municipal de Fortaleza , Brasil']\n",
      "                         Família | False | ['Luciana Carvalho de Albuquerque  Graduação em Odontologia pela Universidade Federal do Ceará, Brasil(2000) CIRURGIÃ DENTISTA PSF da Prefeitura Municipal de Fortaleza , Brasil']\n",
      "                   Biotecnologia | False | ['Luciana Carvalho de Albuquerque  Graduação em Odontologia pela Universidade Federal do Ceará, Brasil(2000) CIRURGIÃ DENTISTA PSF da Prefeitura Municipal de Fortaleza , Brasil']\n",
      "                           Ceará | True | ['Luciana Carvalho de Albuquerque  Graduação em Odontologia pela Universidade Federal do Ceará, Brasil(2000) CIRURGIÃ DENTISTA PSF da Prefeitura Municipal de Fortaleza , Brasil']\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "88/126: Luis Lopes Sombra Neto\n",
      "       013 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "89/126: Maisa Pessoa Pinheiro\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "       008 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "90/126: Mara Milvia Pontes Melo Resende\n",
      "91/126: Marcus Rafael Lobo Bezerra\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "92/126: Maria Alexandrina Perez Da Justa\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "93/126: Maria Josycley Novais Landim Soares\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "94/126: Marilia Façanha Tavares\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "95/126: Mathias Coelho Batista\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "96/126: Naila Saskia Melo Andrade\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "97/126: Natalia Campos Parente\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "98/126: Neyliane Maria Brito Costa\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "99/126: Patricia Pereira Tavares De Alcantara\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "100/126: Paulo Ricardo Nazario Viecili\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "101/126: Pedro Miguel Carneiro Jeronimo\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "102/126: Placido Eymard Gomes Saraiva Filho\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "103/126: Rafaelle Dantas Bezerra\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "104/126: Raquel Bomfim Castelo\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "105/126: Regina Glaucia Lucena Aguiar Ferreira\n",
      "       014 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "106/126: Rejane Ferreira Costa\n",
      "        4 currículos homônimos: Rejane Ferreira Costa\n",
      "                            Cruz | True | ['Rejane Ferreira Costa  Mestrado Profissional em Mestrado Profissional em Saúde da Família pela Fundação Osvaldo Cruz, Brasil(2023) Enfermeira ESF/ Secretaria Municipal de Saúde da Prefeitura Municipal de Eusébio , Brasil']\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "107/126: Renata Castelo Da Nobrega\n",
      "108/126: Renato Thales Medeiros Holanda\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "109/126: Rogerio Sampaio De Oliveira\n",
      "        2 currículos homônimos: Rogerio Sampaio De Oliveira\n",
      "                            Cruz | False | ['Rogério Sampaio de Oliveira  Ensino Médio (2o grau) pelo Dom Adriano Hipólito, Brasil(2018)']\n",
      "                         Família | False | ['Rogério Sampaio de Oliveira  Ensino Médio (2o grau) pelo Dom Adriano Hipólito, Brasil(2018)']\n",
      "                   Biotecnologia | False | ['Rogério Sampaio de Oliveira  Ensino Médio (2o grau) pelo Dom Adriano Hipólito, Brasil(2018)']\n",
      "                           Ceará | False | ['Rogério Sampaio de Oliveira  Ensino Médio (2o grau) pelo Dom Adriano Hipólito, Brasil(2018)']\n",
      "                            Cruz | False | ['Rogério Sampaio de Oliveira  Mestrado Profissional em Saúde da Criança e do Adolescente pela Universidade Estadual do Ceará, Brasil(2008) Médico da Prefeitura Municipal de Juazeiro do Norte , Brasil']\n",
      "                         Família | False | ['Rogério Sampaio de Oliveira  Mestrado Profissional em Saúde da Criança e do Adolescente pela Universidade Estadual do Ceará, Brasil(2008) Médico da Prefeitura Municipal de Juazeiro do Norte , Brasil']\n",
      "                   Biotecnologia | False | ['Rogério Sampaio de Oliveira  Mestrado Profissional em Saúde da Criança e do Adolescente pela Universidade Estadual do Ceará, Brasil(2008) Médico da Prefeitura Municipal de Juazeiro do Norte , Brasil']\n",
      "                           Ceará | True | ['Rogério Sampaio de Oliveira  Mestrado Profissional em Saúde da Criança e do Adolescente pela Universidade Estadual do Ceará, Brasil(2008) Médico da Prefeitura Municipal de Juazeiro do Norte , Brasil']\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "110/126: Romulo Alves De Araujo\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "111/126: Ronny Petterson Dos Santos Araujo\n",
      "       001 artigos extraídos\n",
      "       Elemento <span> com a classe 'citado' não encontrado.\n",
      "       Um erro impediu de extrair a produção:\n",
      "       local variable 'attributes_dict' referenced before assignment |   File \"c:\\Users\\marcos.aires\\ppgcs\\source\\domain\\lattes_scrapper.py\", line 3384, in process_producoes\n",
      "    \"ISSN\": attributes_dict.get('cvuri_params').get('issn')[0] if attributes_dict.get('cvuri_params').get('issn') else \"\",\n",
      "\n",
      "       Extração bem-sucedida\n",
      "112/126: Samuel Lucas De Almeida\n",
      "        3 currículos homônimos: Samuel Lucas De Almeida\n",
      "                            Cruz | False | ['Samuel Lucas de Almeida  Ensino Médio (2o grau) pela Escola Estadual Newman Queiroz, Brasil(2016)']\n",
      "                         Família | False | ['Samuel Lucas de Almeida  Ensino Médio (2o grau) pela Escola Estadual Newman Queiroz, Brasil(2016)']\n",
      "                   Biotecnologia | False | ['Samuel Lucas de Almeida  Ensino Médio (2o grau) pela Escola Estadual Newman Queiroz, Brasil(2016)']\n",
      "                           Ceará | False | ['Samuel Lucas de Almeida  Ensino Médio (2o grau) pela Escola Estadual Newman Queiroz, Brasil(2016)']\n",
      "                            Cruz | False | ['Samuel Lucas de Almeida  Ensino Médio (2o grau) pelo Colégio Ateneu do Ceará, Brasil(2015)']\n",
      "                         Família | False | ['Samuel Lucas de Almeida  Ensino Médio (2o grau) pelo Colégio Ateneu do Ceará, Brasil(2015)']\n",
      "                   Biotecnologia | False | ['Samuel Lucas de Almeida  Ensino Médio (2o grau) pelo Colégio Ateneu do Ceará, Brasil(2015)']\n",
      "                           Ceará | True | ['Samuel Lucas de Almeida  Ensino Médio (2o grau) pelo Colégio Ateneu do Ceará, Brasil(2015)']\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "113/126: Samuel Meneses Felicio De Araujo Costa\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "114/126: Sandhara Ribeiro Rodrigues\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "115/126: Sandy Kaena Soares De Freitas\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "116/126: Taina Maria Lima Freire\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "117/126: Vandre Cabral Gomes Carneiro\n",
      "       022 artigos extraídos\n",
      "       DOI indisponível em 05 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "118/126: Vanessa Pinheiro Gonçalves Ferreira\n",
      "119/126: Vania Carla De Sousa\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "120/126: Vera Lucia De Azevedo Dantas\n",
      "       006 artigos extraídos\n",
      "       Elemento <span> com a classe 'citado' não encontrado.\n",
      "       Extração bem-sucedida\n",
      "121/126: Veridiana Pessoa Miyajima\n",
      "       005 artigos extraídos\n",
      "       DOI indisponível em 02 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "122/126: Vinicius Saraiva Barretto\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "123/126: Vitória Taiana De Melo Lima Albuquerque\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "124/126: Vivian Magalhaes Brandão Dos Santos\n",
      "       006 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "125/126: Yana Paula Coelho Correia Sampaio\n",
      "       006 artigos extraídos\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "126/126: Yasmim Mendes Rocha\n",
      "        2 currículos homônimos: Yasmim Mendes Rocha\n",
      "                            Cruz | False | ['Yasmim Lorrane Mendes Rocha  Graduação em Serviço Social pela Universidade Anhanguera - Uniderp, Brasil(2018)']\n",
      "                         Família | False | ['Yasmim Lorrane Mendes Rocha  Graduação em Serviço Social pela Universidade Anhanguera - Uniderp, Brasil(2018)']\n",
      "                   Biotecnologia | False | ['Yasmim Lorrane Mendes Rocha  Graduação em Serviço Social pela Universidade Anhanguera - Uniderp, Brasil(2018)']\n",
      "                           Ceará | False | ['Yasmim Lorrane Mendes Rocha  Graduação em Serviço Social pela Universidade Anhanguera - Uniderp, Brasil(2018)']\n",
      "                            Cruz | False | ['Yasmim Mendes Rocha  Mestrado em Ciências Farmacêuticas pela Universidade Federal do Ceará, Brasil(2022) Estudante Pesquisador da Universidade Federal do Ceará , Brasil']\n",
      "                         Família | False | ['Yasmim Mendes Rocha  Mestrado em Ciências Farmacêuticas pela Universidade Federal do Ceará, Brasil(2022) Estudante Pesquisador da Universidade Federal do Ceará , Brasil']\n",
      "                   Biotecnologia | False | ['Yasmim Mendes Rocha  Mestrado em Ciências Farmacêuticas pela Universidade Federal do Ceará, Brasil(2022) Estudante Pesquisador da Universidade Federal do Ceará , Brasil']\n",
      "                           Ceará | True | ['Yasmim Mendes Rocha  Mestrado em Ciências Farmacêuticas pela Universidade Federal do Ceará, Brasil(2022) Estudante Pesquisador da Universidade Federal do Ceará , Brasil']\n",
      "       008 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "Arquivo salvo em c:\\Users\\marcos.aires\\ppgcs\\_data\\in_csv\\temp_dict_list.json\n",
      "\n",
      "01:09:54 para busca de 126 nomes com extração de dados de 107 dicionários\n"
     ]
    }
   ],
   "source": [
    "discent_collab_counter = DiscentCollaborationCounter(dict_list_docents)\n",
    "print(f'{len(lista_busca_alunos)} discentes relacionados aos programas')\n",
    "\n",
    "lista_normalizada_discentes=[]\n",
    "for i in lista_busca_alunos:\n",
    "    lista_normalizada_discentes.append(discent_collab_counter.iniciais_nome(i))\n",
    "\n",
    "t1 = time.time()\n",
    "termos_busca = ['Cruz', 'Família', 'Biotecnologia', 'Ceará']\n",
    "scraper = LattesScraper(termos_busca, \n",
    "                        'bolt://localhost:7687', 'neo4j', 'password', \n",
    "                        only_doctors=False)\n",
    "\n",
    "# Extrai e monta JSON com a lista de dicionários\n",
    "discents_dict_list = scraper.scrape(lista_busca_alunos, termos_busca)\n",
    "print(f'\\n{scraper.tempo(t1,time.time())} para busca de {len(lista_busca_alunos)} nomes com extração de dados de {len(discents_dict_list)} dicionários')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae95f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 dicionários montados\n",
      " 0C 000A 000T Dif:000 None \n",
      " 1C 001A 001T Dif:000 None \n",
      " 2C 018A 018T Dif:000 None \n",
      " 3C 000A 000T Dif:000 None \n",
      " 4C 001A 001T Dif:000 None \n",
      " 5C 063A 063T Dif:000 None \n",
      " 6C 006A 006T Dif:000 None \n",
      " 7C 000A 000T Dif:000 None \n",
      " 8C 000A 000T Dif:000 None \n",
      " 9C 000A 000T Dif:000 None \n",
      "10C 044A 044T Dif:000 None \n",
      "11C 004A 004T Dif:000 None \n",
      "12C 001A 001T Dif:000 None \n",
      "13C 053A 053T Dif:000 None \n",
      "14C 000A 000T Dif:000 None \n",
      "15C 004A 004T Dif:000 None \n",
      "16C 000A 000T Dif:000 None \n",
      "17C 000A 000T Dif:000 None \n",
      "18C 005A 005T Dif:000 None \n",
      "19C 000A 000T Dif:000 None \n",
      "20C 000A 000T Dif:000 None \n",
      "21C 000A 000T Dif:000 None \n",
      "22C 016A 000T Dif:-16 None \n",
      "23C 002A 000T Dif:0-2 None \n",
      "24C 000A 000T Dif:000 None \n",
      "25C 004A 004T Dif:000 None \n",
      "26C 002A 002T Dif:000 None \n",
      "27C 001A 000T Dif:0-1 None \n",
      "28C 000A 000T Dif:000 None \n",
      "29C 001A 000T Dif:0-1 None \n",
      "30C 004A 004T Dif:000 None \n",
      "31C 005A 005T Dif:000 None \n",
      "32C 000A 000T Dif:000 None \n",
      "33C 001A 000T Dif:0-1 None \n",
      "34C 001A 000T Dif:0-1 None \n",
      "35C 001A 001T Dif:000 None \n",
      "36C 000A 000T Dif:000 None \n",
      "37C 002A 002T Dif:000 None \n",
      "38C 006A 006T Dif:000 None \n",
      "39C 015A 015T Dif:000 None \n",
      "40C 006A 006T Dif:000 None \n",
      "41C 002A 000T Dif:0-2 None \n",
      "42C 020A 020T Dif:000 None \n",
      "43C 025A 025T Dif:000 None \n",
      "44C 000A 000T Dif:000 None \n",
      "45C 000A 000T Dif:000 None \n",
      "46C 005A 000T Dif:0-5 None \n",
      "47C 121A 121T Dif:000 None \n",
      "48C 000A 000T Dif:000 None \n",
      "49C 000A 000T Dif:000 None \n",
      "50C 004A 000T Dif:0-4 None \n",
      "51C 000A 000T Dif:000 None \n",
      "52C 004A 004T Dif:000 None \n",
      "53C 002A 002T Dif:000 None \n",
      "54C 014A 014T Dif:000 None \n",
      "55C 001A 000T Dif:0-1 None \n",
      "56C 007A 007T Dif:000 None \n",
      "57C 001A 001T Dif:000 None \n",
      "58C 020A 020T Dif:000 None \n",
      "59C 001A 001T Dif:000 None \n",
      "60C 061A 061T Dif:000 None \n",
      "61C 001A 001T Dif:000 None \n",
      "62C 013A 000T Dif:-13 None \n",
      "63C 004A 004T Dif:000 None \n",
      "64C 001A 001T Dif:000 None \n",
      "65C 002A 002T Dif:000 None \n",
      "66C 004A 004T Dif:000 None \n",
      "67C 009A 009T Dif:000 None \n",
      "68C 002A 002T Dif:000 None \n",
      "69C 001A 001T Dif:000 None \n",
      "70C 001A 000T Dif:0-1 None \n",
      "71C 007A 007T Dif:000 None \n",
      "72C 001A 000T Dif:0-1 None \n",
      "73C 000A 000T Dif:000 None \n",
      "74C 000A 000T Dif:000 None \n",
      "75C 000A 000T Dif:000 None \n",
      "76C 001A 000T Dif:0-1 None \n",
      "77C 002A 000T Dif:0-2 None \n",
      "78C 000A 000T Dif:000 None \n",
      "79C 000A 000T Dif:000 None \n",
      "80C 004A 004T Dif:000 None \n",
      "81C 001A 001T Dif:000 None \n",
      "82C 000A 000T Dif:000 None \n",
      "83C 000A 000T Dif:000 None \n",
      "84C 013A 013T Dif:000 None \n",
      "85C 008A 008T Dif:000 None \n",
      "86C 002A 000T Dif:0-2 None \n",
      "87C 014A 014T Dif:000 None \n",
      "88C 000A 000T Dif:000 None \n",
      "89C 000A 000T Dif:000 None \n",
      "90C 002A 000T Dif:0-2 None \n",
      "91C 000A 000T Dif:000 None \n",
      "92C 000A 001T Dif:001 None \n",
      "93C 000A 000T Dif:000 None \n",
      "94C 001A 000T Dif:0-1 None \n",
      "95C 001A 000T Dif:0-1 None \n",
      "96C 003A 000T Dif:0-3 None \n",
      "97C 000A 000T Dif:000 None \n",
      "98C 022A 022T Dif:000 None \n",
      "99C 000A 000T Dif:000 None \n",
      "100C 006A 006T Dif:000 None \n",
      "101C 005A 005T Dif:000 None \n",
      "102C 000A 000T Dif:000 None \n",
      "103C 001A 000T Dif:0-1 None \n",
      "104C 006A 006T Dif:000 None \n",
      "105C 006A 006T Dif:000 None \n",
      "106C 008A 008T Dif:000 None \n",
      "\n",
      "Total de artigos em todos períodos: 707\n",
      "Total de títulos em todos períodos: 646\n"
     ]
    }
   ],
   "source": [
    "## Contagem de artigos para simples confererência\n",
    "print(f'{len(discents_dict_list)} dicionários montados')\n",
    "qte_artigos=0\n",
    "qte_titulos=0\n",
    "for k,i in enumerate(discents_dict_list):\n",
    "    try:\n",
    "        qte_jcr = len(i.get('Produções').get('Artigos completos publicados em periódicos'))\n",
    "    except:\n",
    "        qte_jcr = 0\n",
    "    try:\n",
    "        qte_jcr2 = len(i['JCR2'])\n",
    "    except:\n",
    "        qte_jcr2 = 0\n",
    "\n",
    "    qte_artigos+=qte_jcr\n",
    "    qte_titulos+=qte_jcr2\n",
    "    status=qte_jcr2-qte_jcr\n",
    "    print(f\"{k:>2}C {qte_jcr:>03}A {qte_jcr2:>03}T Dif:{status:>03} {i.get('Identificação').get('name')} \")\n",
    "\n",
    "print(f'\\nTotal de artigos em todos períodos: {qte_artigos}')\n",
    "print(f'Total de títulos em todos períodos: {qte_titulos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee9510",
   "metadata": {},
   "source": [
    "### Identificar currículos remanescentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19d50745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 currículos a buscar no total\n",
      "107 currículos já extraídos\n",
      "(01) Alana Lígia Saldanha Fernandes\n",
      "(02) Alice Soares de Queiroz\n",
      "(1) Não extraído: Aline de Albuquerque Oliveira\n",
      "(03) Aline Pinto Monteiro Costa Sousa\n",
      "(04) Alison de Sousa Rebouças\n",
      "(05) Alissan Karine Lima Martins\n",
      "(06) Amanda Cavalcante Frota\n",
      "(07) Ana Júlia Ferreira Lima\n",
      "(08) Ana Keyla Oliveira da Silva\n",
      "(09) Ana Marilia Soares Cruz\n",
      "(10) Ana Patrícia Pereira Morais\n",
      "(11) Ana Paula Pires Gadelha de Lima\n",
      "(12) Ana Virgínia Frota Guimarães\n",
      "(13) Andréa Silvia Walter de Aguiar\n",
      "(14) Andrielly Henriques dos Santos Costa\n",
      "(15) Angela Donato Maia Malaquias\n",
      "(16) Antonia Vanderli Alves do Nascimento\n",
      "(17) Barbara Nepomuceno Guimarães\n",
      "(18) Beatriz Chaves\n",
      "(19) Bruna de Sousa Lima\n",
      "(20) Brunheld Maia Dutra\n",
      "(21) Camila Sillos Rosas Brisighello\n",
      "(22) Carlos Antônio de Arroxelas Silva\n",
      "(23) Carlos Eduardo de Sousa Praxedes\n",
      "(24) Carollyne Ferreira Santiago\n",
      "(25) Cassio Pinheiro Oliveira\n",
      "(26) Cristian Vicson Gomes Pinheiro\n",
      "(27) Cristiane Mourao Carvalhedo Mesquita\n",
      "(28) Diego da Silva de Almeida\n",
      "(29) Diego Ramos Aguiar\n",
      "(30) Disraeli Cavalcante Araujo Vasconcelos\n",
      "(31) Eduardo Menezes Gaieta\n",
      "(32) Ellen Maria Lima Gonçalves\n",
      "(33) Érika Roméria Formiga de Sousa\n",
      "(34) Erlemus Ponte Soares\n",
      "(35) Evanildo Henrique Macêdo da Costa\n",
      "(36) Evanizia Pinheiro de Oliveira\n",
      "(37) Fábio José Gomes de Sousa\n",
      "(38) Filipe Oliveira de Brito\n",
      "(39) Francisca Raquel de Vasconcelos Silveira\n",
      "(40) Gabriel Acácio de Moura\n",
      "(41) Georgea Bezerra Carvalho\n",
      "(42) Geraldo Rodrigues Sartori\n",
      "(43) Germana Silva Vasconcelos\n",
      "(44) Gilcelene de Castro Andrade\n",
      "(45) Gilmara Maria Batista Tavares da Silva\n",
      "(46) Glaziane da Silva Paiva Bandeira\n",
      "(47) Grayce Alencar Albuquerque\n",
      "(48) Graziela Jones de Oliveira\n",
      "(49) Guilherme Angelo Lobo\n",
      "(50) Hassã Pereira Lemos\n",
      "(51) Herqüimedes Glaudys da Silva Avelino\n",
      "(52) Héverton Mendes Araújo\n",
      "(53) Igor Cabral Studart\n",
      "(54) Isabella Lima Barbosa Campelo\n",
      "(55) Jean Vieira Sampaio\n",
      "(56) João Eudes Lemos de Barros\n",
      "(57) João Matheus Fonteles Silva\n",
      "(58) João Pedro Viana Rodrigues\n",
      "(59) Joaquim Cesar do Nascimento Sousa Júnior\n",
      "(60) Jose Maria Ximenes Guimaraes\n",
      "(61) Jose Samuel dos santos barbosa\n",
      "(62) Josete Malheiro Tavares\n",
      "(63) Jucilene Pereira de Sousa\n",
      "(64) Juliana Meneses de Sena Silva\n",
      "(65) Juliana Ramos de Oliveira\n",
      "(66) Kamila Maria Oliveira Sales\n",
      "(67) Ketlen Christine Ohse\n",
      "(68) Kilvia Helane Cardoso Mesquita\n",
      "(69) Laécio Paulo Sousa dos Santos\n",
      "(70) Larisse Cadeira Brandão\n",
      "(71) Léa Dias Pimentel Gomes Vasconcelos\n",
      "(72) Leticia Bastos Conrado\n",
      "(73) Letícia Ferreira Espinosa\n",
      "(74) Liandra Éllen Coelho Pereira\n",
      "(75) Líbia Lopes Martiniano\n",
      "(76) Lílian Fernandes Amarante\n",
      "(77) Lívia Coêlho de Assis\n",
      "(78) Lorena Lodo Santiago\n",
      "(79) Lorena Morais Nogueira\n",
      "(80) Luca Milério Andrade\n",
      "(81) Lucas Almeida de Freitas\n",
      "(2) Não extraído: Lucélia Góis de Oliveira Arruda\n",
      "(82) Luciana Carvalho de Albuquerque\n",
      "(83) Luis Lopes Sombra Neto\n",
      "(84) Maísa Pessoa Pinheiro\n",
      "(85) Raquel Bomfim Castelo\n",
      "(86) Regina Glaucia Lucena Aguiar Ferreira\n",
      "(87) Rejane Ferreira Costa\n",
      "(88) Renato Thales Medeiros Holanda\n",
      "(89) Rogério Sampaio de Oliveira\n",
      "(3) Não extraído: Rômulo Mendanha de Araújo Alves\n",
      "(90) Ronny Petterson dos Santos Araújo\n",
      "(91) Samuel Lucas de Almeida\n",
      "(92) Samuel Meneses Felicio de Araujo Costa\n",
      "(93) Sandhara Ribeiro Rodrigues\n",
      "(94) Sandy Kaena Soares de Freitas\n",
      "(95) Tainá Maria Lima Freire\n",
      "(96) Vandré Cabral Gomes Carneiro\n",
      "(97) Vânia Carla de Sousa\n",
      "(98) Vera Lúcia de Azevedo Dantas\n",
      "(99) Veridiana Pessoa Miyajima\n",
      "(100) Vinícius Saraiva Barretto\n",
      "(101) Vitória Taiana de Melo Lima Albuquerque\n",
      "(102) Vivian Magalhães Brandão dos Santos\n",
      "(103) Yana Paula Coêlho Correia Sampaio\n",
      "(104) Yasmim Mendes Rocha\n",
      "\n",
      "22 currículos não extraídos\n",
      "   Aline De Oliveira Albuquerque\n",
      "   Ana Flavia Pontes Aguiar\n",
      "   Cristiane França Martins Teodoro\n",
      "   Lenir Santos\n",
      "   Lucelia Gois De Oliveira\n",
      "   Mara Milvia Pontes Melo Resende\n",
      "   Marcus Rafael Lobo Bezerra\n",
      "   Maria Alexandrina Perez Da Justa\n",
      "   Maria Josycley Novais Landim Soares\n",
      "   Marilia Façanha Tavares\n",
      "   Mathias Coelho Batista\n",
      "   Naila Saskia Melo Andrade\n",
      "   Natalia Campos Parente\n",
      "   Neyliane Maria Brito Costa\n",
      "   Patricia Pereira Tavares De Alcantara\n",
      "   Paulo Ricardo Nazario Viecili\n",
      "   Pedro Miguel Carneiro Jeronimo\n",
      "   Placido Eymard Gomes Saraiva Filho\n",
      "   Rafaelle Dantas Bezerra\n",
      "   Renata Castelo Da Nobrega\n",
      "   Romulo Alves De Araujo\n",
      "   Vanessa Pinheiro Gonçalves Ferreira\n"
     ]
    }
   ],
   "source": [
    "termos_busca = ['Cruz', 'Família', 'Biotecnologia', 'Ceará']\n",
    "lista_restante = scraper.avaliar_remanescentes(lista_busca_alunos, discents_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff94827d",
   "metadata": {},
   "source": [
    "### Adicionar nomes ou novos termos, se necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27ddca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Aline De Oliveira Albuquerque\n",
      "   Ana Flavia Pontes Aguiar\n",
      "   Cristiane França Martins Teodoro\n",
      "   Lenir Santos\n",
      "   Lucelia Gois De Oliveira\n",
      "   Mara Milvia Pontes Melo Resende\n",
      "   Marcus Rafael Lobo Bezerra\n",
      "   Maria Alexandrina Perez Da Justa\n",
      "   Maria Josycley Novais Landim Soares\n",
      "   Marilia Façanha Tavares\n",
      "   Mathias Coelho Batista\n",
      "   Naila Saskia Melo Andrade\n",
      "   Natalia Campos Parente\n",
      "   Neyliane Maria Brito Costa\n",
      "   Patricia Pereira Tavares De Alcantara\n",
      "   Paulo Ricardo Nazario Viecili\n",
      "   Pedro Miguel Carneiro Jeronimo\n",
      "   Placido Eymard Gomes Saraiva Filho\n",
      "   Rafaelle Dantas Bezerra\n",
      "   Renata Castelo Da Nobrega\n",
      "   Romulo Alves De Araujo\n",
      "   Vanessa Pinheiro Gonçalves Ferreira\n"
     ]
    }
   ],
   "source": [
    "# lista_restante.append('Caroline Pereira Bittencourt Passaes')\n",
    "for i in lista_restante:\n",
    "    print(f'   {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a0e284",
   "metadata": {},
   "source": [
    "### Extrair currículos remanescentes ou adicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a58b181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resta extrair 22 currículos:\n",
      "['Aline De Oliveira Albuquerque', 'Ana Flavia Pontes Aguiar', 'Cristiane França Martins Teodoro', 'Lenir Santos', 'Lucelia Gois De Oliveira', 'Mara Milvia Pontes Melo Resende', 'Marcus Rafael Lobo Bezerra', 'Maria Alexandrina Perez Da Justa', 'Maria Josycley Novais Landim Soares', 'Marilia Façanha Tavares', 'Mathias Coelho Batista', 'Naila Saskia Melo Andrade', 'Natalia Campos Parente', 'Neyliane Maria Brito Costa', 'Patricia Pereira Tavares De Alcantara', 'Paulo Ricardo Nazario Viecili', 'Pedro Miguel Carneiro Jeronimo', 'Placido Eymard Gomes Saraiva Filho', 'Rafaelle Dantas Bezerra', 'Renata Castelo Da Nobrega', 'Romulo Alves De Araujo', 'Vanessa Pinheiro Gonçalves Ferreira']\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Buscando currículos com qualquer nível de formação\n",
      " 1/22: Aline De Oliveira Albuquerque\n",
      "        8 currículos homônimos: Aline De Oliveira Albuquerque\n",
      "                            Cruz | False | ['Aline Oliveira de Albuquerque ']\n",
      "                         Família | False | ['Aline Oliveira de Albuquerque ']\n",
      "                   Biotecnologia | False | ['Aline Oliveira de Albuquerque ']\n",
      "                           Ceará | False | ['Aline Oliveira de Albuquerque ']\n",
      "                            Cruz | False | ['Aline Albuquerque de Oliveira  Mestrado em Saúde Coletiva pela Universidade Federal de Juiz de Fora, Brasil(2016) Especialista em ´Políticas em Gestão da Saúde do Secretaria de Estado da Saúde , Brasil']\n",
      "                         Família | False | ['Aline Albuquerque de Oliveira  Mestrado em Saúde Coletiva pela Universidade Federal de Juiz de Fora, Brasil(2016) Especialista em ´Políticas em Gestão da Saúde do Secretaria de Estado da Saúde , Brasil']\n",
      "                   Biotecnologia | False | ['Aline Albuquerque de Oliveira  Mestrado em Saúde Coletiva pela Universidade Federal de Juiz de Fora, Brasil(2016) Especialista em ´Políticas em Gestão da Saúde do Secretaria de Estado da Saúde , Brasil']\n",
      "                           Ceará | False | ['Aline Albuquerque de Oliveira  Mestrado em Saúde Coletiva pela Universidade Federal de Juiz de Fora, Brasil(2016) Especialista em ´Políticas em Gestão da Saúde do Secretaria de Estado da Saúde , Brasil']\n",
      "                            Cruz | False | ['Aline de Albuquerque Oliveira  Doutorado em Farmacologia pela Universidade Federal do Ceará, Brasil(2010) Professor da Faculdade Metropolitana de Fortaleza , Brasil']\n",
      "                         Família | False | ['Aline de Albuquerque Oliveira  Doutorado em Farmacologia pela Universidade Federal do Ceará, Brasil(2010) Professor da Faculdade Metropolitana de Fortaleza , Brasil']\n",
      "                   Biotecnologia | False | ['Aline de Albuquerque Oliveira  Doutorado em Farmacologia pela Universidade Federal do Ceará, Brasil(2010) Professor da Faculdade Metropolitana de Fortaleza , Brasil']\n",
      "                           Ceará | True | ['Aline de Albuquerque Oliveira  Doutorado em Farmacologia pela Universidade Federal do Ceará, Brasil(2010) Professor da Faculdade Metropolitana de Fortaleza , Brasil']\n",
      "       018 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      " 2/22: Ana Flavia Pontes Aguiar\n",
      "        2 currículos homônimos: Ana Flavia Pontes Aguiar\n",
      "                            Cruz | False | ['Ana Flávia Pontes Aguiar  Graduação em Administração pela Universidade de Fortaleza, Brasil(2015) Estágio do Araujo Abreu Engenharia , Brasil']\n",
      "                         Família | False | ['Ana Flávia Pontes Aguiar  Graduação em Administração pela Universidade de Fortaleza, Brasil(2015) Estágio do Araujo Abreu Engenharia , Brasil']\n",
      "                   Biotecnologia | False | ['Ana Flávia Pontes Aguiar  Graduação em Administração pela Universidade de Fortaleza, Brasil(2015) Estágio do Araujo Abreu Engenharia , Brasil']\n",
      "                           Ceará | False | ['Ana Flávia Pontes Aguiar  Graduação em Administração pela Universidade de Fortaleza, Brasil(2015) Estágio do Araujo Abreu Engenharia , Brasil']\n",
      "                            Cruz | False | ['Ana Flávia Pontes Aguiar  Especialização em Enfermagem Obstétrica pela Universidade Estadual Vale do Acaraú, Brasil(1999) Enfermeira da Maternidade Escola Assis Chateaubriand , Brasil']\n",
      "                         Família | False | ['Ana Flávia Pontes Aguiar  Especialização em Enfermagem Obstétrica pela Universidade Estadual Vale do Acaraú, Brasil(1999) Enfermeira da Maternidade Escola Assis Chateaubriand , Brasil']\n",
      "                   Biotecnologia | False | ['Ana Flávia Pontes Aguiar  Especialização em Enfermagem Obstétrica pela Universidade Estadual Vale do Acaraú, Brasil(1999) Enfermeira da Maternidade Escola Assis Chateaubriand , Brasil']\n",
      "                           Ceará | False | ['Ana Flávia Pontes Aguiar  Especialização em Enfermagem Obstétrica pela Universidade Estadual Vale do Acaraú, Brasil(1999) Enfermeira da Maternidade Escola Assis Chateaubriand , Brasil']\n",
      " 3/22: Cristiane França Martins Teodoro\n",
      "       Erro ao inserir o nome com função fill_name(), tentando novamente...\n",
      " 4/22: Lenir Santos\n",
      "       33 currículos homônimos: Lenir Santos (com paginação)\n",
      "                            Cruz | False | ['Lenir Santos  Doutorado em Saúde Coletiva pela Universidade Estadual de Campinas, Brasil(2012) PRESIDENTE do Instituto de Direito Sanitário Aplicado , Brasil']\n",
      "                         Família | False | ['Lenir Santos  Doutorado em Saúde Coletiva pela Universidade Estadual de Campinas, Brasil(2012) PRESIDENTE do Instituto de Direito Sanitário Aplicado , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Santos  Doutorado em Saúde Coletiva pela Universidade Estadual de Campinas, Brasil(2012) PRESIDENTE do Instituto de Direito Sanitário Aplicado , Brasil']\n",
      "                           Ceará | False | ['Lenir Santos  Doutorado em Saúde Coletiva pela Universidade Estadual de Campinas, Brasil(2012) PRESIDENTE do Instituto de Direito Sanitário Aplicado , Brasil']\n",
      "                            Cruz | False | ['Lenir Santos Schettert  Especialização em Especialização em Educação pela Universidade Regional do Noroeste do Estado do Rio Grande do Sul, Brasil(1987) Cordenadora GTJA do Secretaria Estadual de Educação , Brasil']\n",
      "                         Família | False | ['Lenir Santos Schettert  Especialização em Especialização em Educação pela Universidade Regional do Noroeste do Estado do Rio Grande do Sul, Brasil(1987) Cordenadora GTJA do Secretaria Estadual de Educação , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Santos Schettert  Especialização em Especialização em Educação pela Universidade Regional do Noroeste do Estado do Rio Grande do Sul, Brasil(1987) Cordenadora GTJA do Secretaria Estadual de Educação , Brasil']\n",
      "                           Ceará | False | ['Lenir Santos Schettert  Especialização em Especialização em Educação pela Universidade Regional do Noroeste do Estado do Rio Grande do Sul, Brasil(1987) Cordenadora GTJA do Secretaria Estadual de Educação , Brasil']\n",
      "                            Cruz | False | ['Lenir Salva dos Santos  Graduação em Ciências Contábeis pelo Instituto Superior de Ciências Aplicadas, Brasil(1988)']\n",
      "                         Família | False | ['Lenir Salva dos Santos  Graduação em Ciências Contábeis pelo Instituto Superior de Ciências Aplicadas, Brasil(1988)']\n",
      "                   Biotecnologia | False | ['Lenir Salva dos Santos  Graduação em Ciências Contábeis pelo Instituto Superior de Ciências Aplicadas, Brasil(1988)']\n",
      "                           Ceará | False | ['Lenir Salva dos Santos  Graduação em Ciências Contábeis pelo Instituto Superior de Ciências Aplicadas, Brasil(1988)']\n",
      "                            Cruz | False | ['Lenir Dias dos Santos  Graduação em Gestao Publico pela Universidade Estadual de Goiás, Brasil(2003) Gerência Contabil da Prefeitura Municipal de Sao Luis de Montes Belos , Brasil']\n",
      "                         Família | False | ['Lenir Dias dos Santos  Graduação em Gestao Publico pela Universidade Estadual de Goiás, Brasil(2003) Gerência Contabil da Prefeitura Municipal de Sao Luis de Montes Belos , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Dias dos Santos  Graduação em Gestao Publico pela Universidade Estadual de Goiás, Brasil(2003) Gerência Contabil da Prefeitura Municipal de Sao Luis de Montes Belos , Brasil']\n",
      "                           Ceará | False | ['Lenir Dias dos Santos  Graduação em Gestao Publico pela Universidade Estadual de Goiás, Brasil(2003) Gerência Contabil da Prefeitura Municipal de Sao Luis de Montes Belos , Brasil']\n",
      "                            Cruz | False | ['Lenir dos Santos  Ensino Médio (2o grau) pelo Ronald da Silva Carvalho, Brasil(1987)']\n",
      "                         Família | False | ['Lenir dos Santos  Ensino Médio (2o grau) pelo Ronald da Silva Carvalho, Brasil(1987)']\n",
      "                   Biotecnologia | False | ['Lenir dos Santos  Ensino Médio (2o grau) pelo Ronald da Silva Carvalho, Brasil(1987)']\n",
      "                           Ceará | False | ['Lenir dos Santos  Ensino Médio (2o grau) pelo Ronald da Silva Carvalho, Brasil(1987)']\n",
      "                            Cruz | False | ['Lenir Firmino dos Santos  Graduação em Administração pela Faculdade Padrão, Brasil(2010)']\n",
      "                         Família | False | ['Lenir Firmino dos Santos  Graduação em Administração pela Faculdade Padrão, Brasil(2010)']\n",
      "                   Biotecnologia | False | ['Lenir Firmino dos Santos  Graduação em Administração pela Faculdade Padrão, Brasil(2010)']\n",
      "                           Ceará | False | ['Lenir Firmino dos Santos  Graduação em Administração pela Faculdade Padrão, Brasil(2010)']\n",
      "                            Cruz | False | ['Lenir Juvaldina dos Santos  Ensino Médio (2o grau) pela Universidade do Estado de Santa Catarina, Brasil(1986)']\n",
      "                         Família | False | ['Lenir Juvaldina dos Santos  Ensino Médio (2o grau) pela Universidade do Estado de Santa Catarina, Brasil(1986)']\n",
      "                   Biotecnologia | False | ['Lenir Juvaldina dos Santos  Ensino Médio (2o grau) pela Universidade do Estado de Santa Catarina, Brasil(1986)']\n",
      "                           Ceará | False | ['Lenir Juvaldina dos Santos  Ensino Médio (2o grau) pela Universidade do Estado de Santa Catarina, Brasil(1986)']\n",
      "                            Cruz | False | ['Lenir Santos de Andrade  Graduação em ENFERMAGEM pela Universidade do Estado do Pará, Brasil(2004) ENFERMEIRA da Fundação Nacional de Saúde , Brasil']\n",
      "                         Família | False | ['Lenir Santos de Andrade  Graduação em ENFERMAGEM pela Universidade do Estado do Pará, Brasil(2004) ENFERMEIRA da Fundação Nacional de Saúde , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Santos de Andrade  Graduação em ENFERMAGEM pela Universidade do Estado do Pará, Brasil(2004) ENFERMEIRA da Fundação Nacional de Saúde , Brasil']\n",
      "                           Ceará | False | ['Lenir Santos de Andrade  Graduação em ENFERMAGEM pela Universidade do Estado do Pará, Brasil(2004) ENFERMEIRA da Fundação Nacional de Saúde , Brasil']\n",
      "                            Cruz | False | ['Lenir Santos Sôlha Rodrigues  Especialização em Controle de Infecção Hospitalar pela Universidade Gama Filho, Brasil(2003) ENFERMEIRA CCIH do HOSPITAL SAMCI , Brasil']\n",
      "                         Família | False | ['Lenir Santos Sôlha Rodrigues  Especialização em Controle de Infecção Hospitalar pela Universidade Gama Filho, Brasil(2003) ENFERMEIRA CCIH do HOSPITAL SAMCI , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Santos Sôlha Rodrigues  Especialização em Controle de Infecção Hospitalar pela Universidade Gama Filho, Brasil(2003) ENFERMEIRA CCIH do HOSPITAL SAMCI , Brasil']\n",
      "                           Ceará | False | ['Lenir Santos Sôlha Rodrigues  Especialização em Controle de Infecção Hospitalar pela Universidade Gama Filho, Brasil(2003) ENFERMEIRA CCIH do HOSPITAL SAMCI , Brasil']\n",
      "                            Cruz | False | ['Lenir Karla Borges Santos  Ensino Médio (2o grau) pelo COLÉGIO BATISTA DANIEL DE LA TOUCHE, Brasil(2006)']\n",
      "                         Família | False | ['Lenir Karla Borges Santos  Ensino Médio (2o grau) pelo COLÉGIO BATISTA DANIEL DE LA TOUCHE, Brasil(2006)']\n",
      "                   Biotecnologia | False | ['Lenir Karla Borges Santos  Ensino Médio (2o grau) pelo COLÉGIO BATISTA DANIEL DE LA TOUCHE, Brasil(2006)']\n",
      "                           Ceará | False | ['Lenir Karla Borges Santos  Ensino Médio (2o grau) pelo COLÉGIO BATISTA DANIEL DE LA TOUCHE, Brasil(2006)']\n",
      "       Página a ser carregada: 2\n",
      "                            Cruz | False | ['Lenir Francisco Dos Santos  Graduação em Fonoaudiologia pelo CENTRO UNIVERSITÁRIO DO DISTRITO FEDERAL, Brasil(2017)']\n",
      "                         Família | False | ['Lenir Francisco Dos Santos  Graduação em Fonoaudiologia pelo CENTRO UNIVERSITÁRIO DO DISTRITO FEDERAL, Brasil(2017)']\n",
      "                   Biotecnologia | False | ['Lenir Francisco Dos Santos  Graduação em Fonoaudiologia pelo CENTRO UNIVERSITÁRIO DO DISTRITO FEDERAL, Brasil(2017)']\n",
      "                           Ceará | False | ['Lenir Francisco Dos Santos  Graduação em Fonoaudiologia pelo CENTRO UNIVERSITÁRIO DO DISTRITO FEDERAL, Brasil(2017)']\n",
      "                            Cruz | False | ['Lenir Santos Pereira Monteiro  Graduação em Pedagogia pela UNIVERSIDADE ESTADUAL DO TOCANTINS, Brasil(2007) PROFESSOR NÍVEL II da Prefeitura Municipal de Araguaína , Brasil']\n",
      "                         Família | False | ['Lenir Santos Pereira Monteiro  Graduação em Pedagogia pela UNIVERSIDADE ESTADUAL DO TOCANTINS, Brasil(2007) PROFESSOR NÍVEL II da Prefeitura Municipal de Araguaína , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Santos Pereira Monteiro  Graduação em Pedagogia pela UNIVERSIDADE ESTADUAL DO TOCANTINS, Brasil(2007) PROFESSOR NÍVEL II da Prefeitura Municipal de Araguaína , Brasil']\n",
      "                           Ceará | False | ['Lenir Santos Pereira Monteiro  Graduação em Pedagogia pela UNIVERSIDADE ESTADUAL DO TOCANTINS, Brasil(2007) PROFESSOR NÍVEL II da Prefeitura Municipal de Araguaína , Brasil']\n",
      "                            Cruz | False | ['Lenir Rodrigues Santos  Doutorado em DERECHO INTERNACIONAL pelo UNIVERSIDAD AUTÓNOMA DE ASUNCIÓN, Paraguai(2010) Defensora Pública do Defensoria pública do Estado de Roraima , Brasil']\n",
      "                         Família | False | ['Lenir Rodrigues Santos  Doutorado em DERECHO INTERNACIONAL pelo UNIVERSIDAD AUTÓNOMA DE ASUNCIÓN, Paraguai(2010) Defensora Pública do Defensoria pública do Estado de Roraima , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Rodrigues Santos  Doutorado em DERECHO INTERNACIONAL pelo UNIVERSIDAD AUTÓNOMA DE ASUNCIÓN, Paraguai(2010) Defensora Pública do Defensoria pública do Estado de Roraima , Brasil']\n",
      "                           Ceará | False | ['Lenir Rodrigues Santos  Doutorado em DERECHO INTERNACIONAL pelo UNIVERSIDAD AUTÓNOMA DE ASUNCIÓN, Paraguai(2010) Defensora Pública do Defensoria pública do Estado de Roraima , Brasil']\n",
      "                            Cruz | False | ['Lenir Dos Santos Oliveira  Graduação em Letras - Português pelo Centro Universitário Leonardo da Vinci, Brasil(2014) professora da Escola Estadual 12 de Abril , Brasil']\n",
      "                         Família | False | ['Lenir Dos Santos Oliveira  Graduação em Letras - Português pelo Centro Universitário Leonardo da Vinci, Brasil(2014) professora da Escola Estadual 12 de Abril , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Dos Santos Oliveira  Graduação em Letras - Português pelo Centro Universitário Leonardo da Vinci, Brasil(2014) professora da Escola Estadual 12 de Abril , Brasil']\n",
      "                           Ceará | False | ['Lenir Dos Santos Oliveira  Graduação em Letras - Português pelo Centro Universitário Leonardo da Vinci, Brasil(2014) professora da Escola Estadual 12 de Abril , Brasil']\n",
      "                            Cruz | False | ['Lenir Teixeira dos Santos  Especialização em Esp. em Metod. de Ens. para a Educ. Profissional pela Universidade do Estado da Bahia, Brasil(2015) Professora de História do Centro Estadual de Educação Profissional em Saúde e Gestão , Brasil']\n",
      "                         Família | False | ['Lenir Teixeira dos Santos  Especialização em Esp. em Metod. de Ens. para a Educ. Profissional pela Universidade do Estado da Bahia, Brasil(2015) Professora de História do Centro Estadual de Educação Profissional em Saúde e Gestão , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Teixeira dos Santos  Especialização em Esp. em Metod. de Ens. para a Educ. Profissional pela Universidade do Estado da Bahia, Brasil(2015) Professora de História do Centro Estadual de Educação Profissional em Saúde e Gestão , Brasil']\n",
      "                           Ceará | False | ['Lenir Teixeira dos Santos  Especialização em Esp. em Metod. de Ens. para a Educ. Profissional pela Universidade do Estado da Bahia, Brasil(2015) Professora de História do Centro Estadual de Educação Profissional em Saúde e Gestão , Brasil']\n",
      "                            Cruz | False | ['Lenir Ribeiro Barbosa Santos  Graduação em Ciêncis Biológicas pelo Instituto FAL , Brasil(2020) LABORTORISTA do SERVIÇO AUTÔNOMO ÁGUA E ESGOTO , Brasil']\n",
      "                         Família | False | ['Lenir Ribeiro Barbosa Santos  Graduação em Ciêncis Biológicas pelo Instituto FAL , Brasil(2020) LABORTORISTA do SERVIÇO AUTÔNOMO ÁGUA E ESGOTO , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Ribeiro Barbosa Santos  Graduação em Ciêncis Biológicas pelo Instituto FAL , Brasil(2020) LABORTORISTA do SERVIÇO AUTÔNOMO ÁGUA E ESGOTO , Brasil']\n",
      "                           Ceará | False | ['Lenir Ribeiro Barbosa Santos  Graduação em Ciêncis Biológicas pelo Instituto FAL , Brasil(2020) LABORTORISTA do SERVIÇO AUTÔNOMO ÁGUA E ESGOTO , Brasil']\n",
      "                            Cruz | False | ['Lenir Santos de Freitas  Graduação em LICENCIATURA PLENA EM PEDAGOGIA pela Universidade Anhanguera - Uniderp, Brasil(2015) Secretária Escolar do Secretaria Estadual de Educação , Brasil']\n",
      "                         Família | False | ['Lenir Santos de Freitas  Graduação em LICENCIATURA PLENA EM PEDAGOGIA pela Universidade Anhanguera - Uniderp, Brasil(2015) Secretária Escolar do Secretaria Estadual de Educação , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Santos de Freitas  Graduação em LICENCIATURA PLENA EM PEDAGOGIA pela Universidade Anhanguera - Uniderp, Brasil(2015) Secretária Escolar do Secretaria Estadual de Educação , Brasil']\n",
      "                           Ceará | False | ['Lenir Santos de Freitas  Graduação em LICENCIATURA PLENA EM PEDAGOGIA pela Universidade Anhanguera - Uniderp, Brasil(2015) Secretária Escolar do Secretaria Estadual de Educação , Brasil']\n",
      "                            Cruz | False | ['Fellipe Lenir dos Santos  Ensino Fundamental (1o grau) pela ESCOLA DE EDUCAÇÃO BÁSICA SANTA TERESINHA, Brasil(2020) menor aprendiz do SENAI - Departamento Regional de Santa Catarina , Brasil']\n",
      "                         Família | False | ['Fellipe Lenir dos Santos  Ensino Fundamental (1o grau) pela ESCOLA DE EDUCAÇÃO BÁSICA SANTA TERESINHA, Brasil(2020) menor aprendiz do SENAI - Departamento Regional de Santa Catarina , Brasil']\n",
      "                   Biotecnologia | False | ['Fellipe Lenir dos Santos  Ensino Fundamental (1o grau) pela ESCOLA DE EDUCAÇÃO BÁSICA SANTA TERESINHA, Brasil(2020) menor aprendiz do SENAI - Departamento Regional de Santa Catarina , Brasil']\n",
      "                           Ceará | False | ['Fellipe Lenir dos Santos  Ensino Fundamental (1o grau) pela ESCOLA DE EDUCAÇÃO BÁSICA SANTA TERESINHA, Brasil(2020) menor aprendiz do SENAI - Departamento Regional de Santa Catarina , Brasil']\n",
      "                            Cruz | False | ['Lenir dos Santos Moraes  Mestrado em Educação pela Universidade do Vale do Rio dos Sinos, Brasil(2010) Assessora Pedagógica da Rede ICM de Educação e Assistência Social , Brasil']\n",
      "                         Família | False | ['Lenir dos Santos Moraes  Mestrado em Educação pela Universidade do Vale do Rio dos Sinos, Brasil(2010) Assessora Pedagógica da Rede ICM de Educação e Assistência Social , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir dos Santos Moraes  Mestrado em Educação pela Universidade do Vale do Rio dos Sinos, Brasil(2010) Assessora Pedagógica da Rede ICM de Educação e Assistência Social , Brasil']\n",
      "                           Ceará | False | ['Lenir dos Santos Moraes  Mestrado em Educação pela Universidade do Vale do Rio dos Sinos, Brasil(2010) Assessora Pedagógica da Rede ICM de Educação e Assistência Social , Brasil']\n",
      "                            Cruz | False | ['Lenir Reinaldo dos Santos  Graduação em Farmácia pela Faculdade LS, Brasil(2021) Técnico de segurança do trabalho do Hospital da Criança de Brasília José Alencar , Brasil']\n",
      "                         Família | False | ['Lenir Reinaldo dos Santos  Graduação em Farmácia pela Faculdade LS, Brasil(2021) Técnico de segurança do trabalho do Hospital da Criança de Brasília José Alencar , Brasil']\n",
      "                   Biotecnologia | False | ['Lenir Reinaldo dos Santos  Graduação em Farmácia pela Faculdade LS, Brasil(2021) Técnico de segurança do trabalho do Hospital da Criança de Brasília José Alencar , Brasil']\n",
      "                           Ceará | False | ['Lenir Reinaldo dos Santos  Graduação em Farmácia pela Faculdade LS, Brasil(2021) Técnico de segurança do trabalho do Hospital da Criança de Brasília José Alencar , Brasil']\n",
      "       Erro na paginação dos elementos de resultados homônimos\n",
      "       Erro com: stale element reference: stale element not found\n",
      "       Nenhum termo de vínculo achado em 20/33 resultados verificados. Verificada até página 02/04\n",
      " 5/22: Lucelia Gois De Oliveira\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      " 6/22: Mara Milvia Pontes Melo Resende\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      " 7/22: Marcus Rafael Lobo Bezerra\n",
      "       006 artigos extraídos\n",
      "       DOI indisponível para 01 artigo extraído\n",
      "       Extração bem-sucedida\n",
      " 8/22: Maria Alexandrina Perez Da Justa\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      " 9/22: Maria Josycley Novais Landim Soares\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "10/22: Marilia Façanha Tavares\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Seção de idiomas não encontrada\n",
      "       Extração bem-sucedida\n",
      "11/22: Mathias Coelho Batista\n",
      "       004 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "12/22: Naila Saskia Melo Andrade\n",
      "       002 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "13/22: Natalia Campos Parente\n",
      "       004 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "14/22: Neyliane Maria Brito Costa\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "15/22: Patricia Pereira Tavares De Alcantara\n",
      "       025 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "16/22: Paulo Ricardo Nazario Viecili\n",
      "       028 artigos extraídos\n",
      "       DOI indisponível para 01 artigo extraído\n",
      "       Extração bem-sucedida\n",
      "17/22: Pedro Miguel Carneiro Jeronimo\n",
      "       003 artigos extraídos\n",
      "       DOI indisponível para 01 artigo extraído\n",
      "       Extração bem-sucedida\n",
      "18/22: Placido Eymard Gomes Saraiva Filho\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "19/22: Rafaelle Dantas Bezerra\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "20/22: Renata Castelo Da Nobrega\n",
      "21/22: Romulo Alves De Araujo\n",
      "       Requisição ao CNPq sem resposta, tooltips das publicações indisponíveis.\n",
      "       Extração bem-sucedida\n",
      "22/22: Vanessa Pinheiro Gonçalves Ferreira\n",
      "Arquivo salvo em c:\\Users\\marcos.aires\\ppgcs\\_data\\in_csv\\temp_dict_list.json\n",
      "\n",
      "00:10:14 para busca de 22 nomes com extração de dados de 17 dicionários\n",
      "Total de dicionários na lista completa: 121\n",
      "Arquivo JSON salvo em: c:\\Users\\marcos.aires\\ppgcs\\_data\\in_csv\\combined_dict_list.json\n"
     ]
    }
   ],
   "source": [
    "# lista_dict_combinado = extract_remanescents(lista_restante, dict_list_actual)\n",
    "lista_dict_combinado = scraper.extract_remanescents(lista_restante, discents_dict_list, termos_busca)\n",
    "filepath = os.path.join(folder_data_input,'dict_list_discents.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f30b62ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 dicionários de discentes extraídos\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(lista_dict_combinado)} dicionários de discentes extraídos')\n",
    "try:\n",
    "    exemplo = [x.get('Produções') for x in lista_dict_combinado][0].get('Artigos completos publicados em periódicos')[0]\n",
    "    if exemplo:\n",
    "        print('\\n\\nExemplo de dados dos artigos:')\n",
    "        print(exemplo)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6063e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 dicionários com currículos completos extraídos\n",
      "\n",
      "\n",
      "Exemplo de dados dos artigos:\n"
     ]
    }
   ],
   "source": [
    "from lattes_scrapper import GetQualis\n",
    "stratifier = GetQualis()\n",
    "\n",
    "# Acrescentar Qualis periódicos aos dicionários de docentes\n",
    "print('\\nAdicionando Qualis Periódicos')\n",
    "pathfilename = os.path.join(folder_data_input,'discents_dict_list.json')\n",
    "stratifier.buscar_qualis_e_atualizar_arquivo(lista_dict_combinado, pathfilename)\n",
    "scraper.save_to_json(lista_dict_combinado, pathfilename)\n",
    "\n",
    "print(f'{len(lista_dict_combinado)} dicionários com currículos completos extraídos')\n",
    "print('\\n\\nExemplo de dados dos artigos:')\n",
    "try:\n",
    "    exemplo = [x.get('Produções') for x in lista_dict_combinado][0].get('Artigos completos publicados em periódicos')[0]\n",
    "    if exemplo:\n",
    "        print('\\n\\nExemplo de dados dos artigos:')\n",
    "        print(exemplo)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd1f79a",
   "metadata": {},
   "source": [
    "# F02a: Carregar extração prévia de Discentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc99d37",
   "metadata": {},
   "source": [
    "### Listar arquivos salvos na pasta de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d44b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['combined_dict_list.json',\n",
       " 'dict_list_discents_combined.json',\n",
       " 'dict_list_temp.json',\n",
       " 'discents_dict_list.json',\n",
       " 'docents_dict_list.json',\n",
       " 'indicadores.csv',\n",
       " 'nomesdocentes.csv',\n",
       " 'portal_fiocruz_tecnologias.csv',\n",
       " 'ppgcs',\n",
       " 'qlattes',\n",
       " 'temp_dict_list.json',\n",
       " 'veiculos.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_data_input = os.path.join(os.getcwd(),'_data','in_csv')\n",
    "os.listdir(folder_data_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e72eea",
   "metadata": {},
   "source": [
    "### Carregar dados completos dos Discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83177667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 Total de currículos extaídos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Alana Lígia Saldanha Fernandes',\n",
       " 'Alice Soares de Queiroz',\n",
       " 'Aline de Albuquerque Oliveira',\n",
       " 'Aline Pinto Monteiro Costa Sousa',\n",
       " 'Alison de Sousa Rebouças',\n",
       " 'Alissan Karine Lima Martins',\n",
       " 'Amanda Cavalcante Frota',\n",
       " 'Ana Júlia Ferreira Lima',\n",
       " 'Ana Keyla Oliveira da Silva',\n",
       " 'Ana Marilia Soares Cruz',\n",
       " 'Ana Patrícia Pereira Morais',\n",
       " 'Ana Paula Pires Gadelha de Lima',\n",
       " 'Ana Virgínia Frota Guimarães',\n",
       " 'Andréa Silvia Walter de Aguiar',\n",
       " 'Andrielly Henriques dos Santos Costa',\n",
       " 'Angela Donato Maia Malaquias',\n",
       " 'Antonia Vanderli Alves do Nascimento',\n",
       " 'Barbara Nepomuceno Guimarães',\n",
       " 'Beatriz Chaves',\n",
       " 'Bruna de Sousa Lima',\n",
       " 'Brunheld Maia Dutra',\n",
       " 'Camila Sillos Rosas Brisighello',\n",
       " 'Carlos Antônio de Arroxelas Silva',\n",
       " 'Carlos Eduardo de Sousa Praxedes',\n",
       " 'Carollyne Ferreira Santiago',\n",
       " 'Cassio Pinheiro Oliveira',\n",
       " 'Cristian Vicson Gomes Pinheiro',\n",
       " 'Cristiane Mourao Carvalhedo Mesquita',\n",
       " 'Diego da Silva de Almeida',\n",
       " 'Diego Ramos Aguiar',\n",
       " 'Disraeli Cavalcante Araujo Vasconcelos',\n",
       " 'Eduardo Menezes Gaieta',\n",
       " 'Ellen Maria Lima Gonçalves',\n",
       " 'Érika Roméria Formiga de Sousa',\n",
       " 'Erlemus Ponte Soares',\n",
       " 'Evanildo Henrique Macêdo da Costa',\n",
       " 'Evanizia Pinheiro de Oliveira',\n",
       " 'Fábio José Gomes de Sousa',\n",
       " 'Filipe Oliveira de Brito',\n",
       " 'Francisca Raquel de Vasconcelos Silveira',\n",
       " 'Gabriel Acácio de Moura',\n",
       " 'Georgea Bezerra Carvalho',\n",
       " 'Geraldo Rodrigues Sartori',\n",
       " 'Germana Silva Vasconcelos',\n",
       " 'Gilcelene de Castro Andrade',\n",
       " 'Gilmara Maria Batista Tavares da Silva',\n",
       " 'Glaziane da Silva Paiva Bandeira',\n",
       " 'Grayce Alencar Albuquerque',\n",
       " 'Graziela Jones de Oliveira',\n",
       " 'Guilherme Angelo Lobo',\n",
       " 'Hassã Pereira Lemos',\n",
       " 'Herqüimedes Glaudys da Silva Avelino',\n",
       " 'Héverton Mendes Araújo',\n",
       " 'Igor Cabral Studart',\n",
       " 'Isabella Lima Barbosa Campelo',\n",
       " 'Jean Vieira Sampaio',\n",
       " 'João Eudes Lemos de Barros',\n",
       " 'João Matheus Fonteles Silva',\n",
       " 'João Pedro Viana Rodrigues',\n",
       " 'Joaquim Cesar do Nascimento Sousa Júnior',\n",
       " 'Jose Maria Ximenes Guimaraes',\n",
       " 'Jose Samuel dos santos barbosa',\n",
       " 'Josete Malheiro Tavares',\n",
       " 'Jucilene Pereira de Sousa',\n",
       " 'Juliana Meneses de Sena Silva',\n",
       " 'Juliana Ramos de Oliveira',\n",
       " 'Kamila Maria Oliveira Sales',\n",
       " 'Ketlen Christine Ohse',\n",
       " 'Kilvia Helane Cardoso Mesquita',\n",
       " 'Laécio Paulo Sousa dos Santos',\n",
       " 'Larisse Cadeira Brandão',\n",
       " 'Léa Dias Pimentel Gomes Vasconcelos',\n",
       " 'Leticia Bastos Conrado',\n",
       " 'Letícia Ferreira Espinosa',\n",
       " 'Liandra Éllen Coelho Pereira',\n",
       " 'Líbia Lopes Martiniano',\n",
       " 'Lílian Fernandes Amarante',\n",
       " 'Lívia Coêlho de Assis',\n",
       " 'Lorena Lodo Santiago',\n",
       " 'Lorena Morais Nogueira',\n",
       " 'Luca Milério Andrade',\n",
       " 'Lucas Almeida de Freitas',\n",
       " 'Lucélia Góis de Oliveira Arruda',\n",
       " 'Luciana Carvalho de Albuquerque',\n",
       " 'Luis Lopes Sombra Neto',\n",
       " 'Maísa Pessoa Pinheiro',\n",
       " 'Raquel Bomfim Castelo',\n",
       " 'Regina Glaucia Lucena Aguiar Ferreira',\n",
       " 'Rejane Ferreira Costa',\n",
       " 'Renato Thales Medeiros Holanda',\n",
       " 'Rogério Sampaio de Oliveira',\n",
       " 'Rômulo Mendanha de Araújo Alves',\n",
       " 'Ronny Petterson dos Santos Araújo',\n",
       " 'Samuel Lucas de Almeida',\n",
       " 'Samuel Meneses Felicio de Araujo Costa',\n",
       " 'Sandhara Ribeiro Rodrigues',\n",
       " 'Sandy Kaena Soares de Freitas',\n",
       " 'Tainá Maria Lima Freire',\n",
       " 'Vandré Cabral Gomes Carneiro',\n",
       " 'Vânia Carla de Sousa',\n",
       " 'Vera Lúcia de Azevedo Dantas',\n",
       " 'Veridiana Pessoa Miyajima',\n",
       " 'Vinícius Saraiva Barretto',\n",
       " 'Vitória Taiana de Melo Lima Albuquerque',\n",
       " 'Vivian Magalhães Brandão dos Santos',\n",
       " 'Yana Paula Coêlho Correia Sampaio',\n",
       " 'Yasmim Mendes Rocha',\n",
       " 'Mara Milvia Pontes Melo Resende',\n",
       " 'Marcus Rafael Lobo Bezerra',\n",
       " 'Maria Alexandrina Perez da Justa',\n",
       " 'Maria Josycley Novais Landim Soares',\n",
       " 'Marília Façanha Tavares',\n",
       " 'Mathias Coelho Batista',\n",
       " 'Naila Saskia Melo Andrade',\n",
       " 'Natália Campos Parente',\n",
       " 'Neyliane Maria Brito Costa',\n",
       " 'Patrícia Pereira Tavares de Alcantara',\n",
       " 'Paulo Ricardo Nazário Viecili',\n",
       " 'Pedro Miguel Carneiro Jeronimo',\n",
       " 'Plácido Eymard Gomes Saraiva Filho',\n",
       " 'Rafaelle Dantas Bezerra']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'discents_dict_list.json'\n",
    "pathfilename = os.path.join(folder_data_input, filename)\n",
    "dict_list_discents, formatted_creation_date, formatted_modification_date, time_count, unit = jfm.load_from_json(pathfilename)\n",
    "print(f'{len(dict_list_discents)} Total de currículos extaídos')\n",
    "[i.get('Identificação').get('Nome') for i in dict_list_discents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7838e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar orientações nos dados de docentes\n",
    "# [x.get('Orientações') for x in dict_list_discents if x.get('Orientações')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cd37f",
   "metadata": {},
   "source": [
    "# <b>F03: Avaliar colaboração discente/docentes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91c7954f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'discents_dict_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m discent_collab_counter \u001b[38;5;241m=\u001b[39m DiscentCollaborationCounter(\u001b[43mdiscents_dict_list\u001b[49m)\n\u001b[0;32m      2\u001b[0m colaboracoes, percentuais \u001b[38;5;241m=\u001b[39m discent_collab_counter\u001b[38;5;241m.\u001b[39mget_articles_coauthorings(dict_list_docents, ano_inicio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2017\u001b[39m, ano_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2024\u001b[39m)\n\u001b[0;32m      3\u001b[0m df_pontuacao[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolab_disc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m percentuais\n",
      "\u001b[1;31mNameError\u001b[0m: name 'discents_dict_list' is not defined"
     ]
    }
   ],
   "source": [
    "discent_collab_counter = DiscentCollaborationCounter(discents_dict_list)\n",
    "colaboracoes, percentuais = discent_collab_counter.get_articles_coauthorings(dict_list_docents, ano_inicio=2017, ano_final=2024)\n",
    "df_pontuacao['colab_disc'] = percentuais\n",
    "filepath = os.path.join(os.path.join(\"./\",\"_data\",\"powerbi\",'ppgcs_prodpubl_2017_2024.xlsx'))\n",
    "df_pontuacao.to_excel(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f886d8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 pesquisadores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Ano</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "      <th>Soma de Pontos</th>\n",
       "      <th>colab_disc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jaime Ribeiro Filho</th>\n",
       "      <td>575</td>\n",
       "      <td>320</td>\n",
       "      <td>200</td>\n",
       "      <td>1060</td>\n",
       "      <td>955</td>\n",
       "      <td>865</td>\n",
       "      <td>1155</td>\n",
       "      <td>200</td>\n",
       "      <td>5330</td>\n",
       "      <td>14.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Márcio Flávio Moura de Araújo</th>\n",
       "      <td>285</td>\n",
       "      <td>570</td>\n",
       "      <td>315</td>\n",
       "      <td>385</td>\n",
       "      <td>475</td>\n",
       "      <td>260</td>\n",
       "      <td>380</td>\n",
       "      <td>80</td>\n",
       "      <td>2750</td>\n",
       "      <td>14.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fabio Miyajima</th>\n",
       "      <td>350</td>\n",
       "      <td>270</td>\n",
       "      <td>330</td>\n",
       "      <td>270</td>\n",
       "      <td>530</td>\n",
       "      <td>770</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anya Pimentel Gomes Fernandes Vieira Meyer</th>\n",
       "      <td>100</td>\n",
       "      <td>310</td>\n",
       "      <td>230</td>\n",
       "      <td>355</td>\n",
       "      <td>755</td>\n",
       "      <td>300</td>\n",
       "      <td>445</td>\n",
       "      <td>100</td>\n",
       "      <td>2595</td>\n",
       "      <td>14.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roberto Wagner Júnior Freire de Freitas</th>\n",
       "      <td>175</td>\n",
       "      <td>390</td>\n",
       "      <td>320</td>\n",
       "      <td>365</td>\n",
       "      <td>580</td>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>20</td>\n",
       "      <td>2120</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roberto Nicolete</th>\n",
       "      <td>160</td>\n",
       "      <td>80</td>\n",
       "      <td>55</td>\n",
       "      <td>270</td>\n",
       "      <td>335</td>\n",
       "      <td>510</td>\n",
       "      <td>285</td>\n",
       "      <td>80</td>\n",
       "      <td>1775</td>\n",
       "      <td>15.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivana Cristina de Holanda Cunha Barreto</th>\n",
       "      <td>335</td>\n",
       "      <td>180</td>\n",
       "      <td>65</td>\n",
       "      <td>150</td>\n",
       "      <td>370</td>\n",
       "      <td>340</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1640</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caroline Pereira Bittencourt Passaes</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>110</td>\n",
       "      <td>360</td>\n",
       "      <td>490</td>\n",
       "      <td>170</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>1490</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carla Freire Celedonio Fernandes</th>\n",
       "      <td>410</td>\n",
       "      <td>170</td>\n",
       "      <td>100</td>\n",
       "      <td>220</td>\n",
       "      <td>320</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>170</td>\n",
       "      <td>1465</td>\n",
       "      <td>48.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>João Hermínio Martins da Silva</th>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>120</td>\n",
       "      <td>55</td>\n",
       "      <td>520</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1415</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luiz Odorico Monteiro de Andrade</th>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>420</td>\n",
       "      <td>260</td>\n",
       "      <td>140</td>\n",
       "      <td>40</td>\n",
       "      <td>1325</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>José Luís Passos Cordeiro</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>100</td>\n",
       "      <td>375</td>\n",
       "      <td>90</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>1190</td>\n",
       "      <td>8.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharmênia de Araújo Soares Nuto</th>\n",
       "      <td>80</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>240</td>\n",
       "      <td>385</td>\n",
       "      <td>115</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>1155</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fernando Ferreira Carneiro</th>\n",
       "      <td>170</td>\n",
       "      <td>205</td>\n",
       "      <td>40</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>100</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>1135</td>\n",
       "      <td>8.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcos Roberto Lourenzoni</th>\n",
       "      <td>110</td>\n",
       "      <td>90</td>\n",
       "      <td>180</td>\n",
       "      <td>190</td>\n",
       "      <td>120</td>\n",
       "      <td>210</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fernando Braga Stehling Dias</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>260</td>\n",
       "      <td>270</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>9.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gilvan Pessoa Furtado</th>\n",
       "      <td>100</td>\n",
       "      <td>180</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>100</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>14.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clarissa Romero Teixeira</th>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>740</td>\n",
       "      <td>22.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maximiliano Ponte</th>\n",
       "      <td>270</td>\n",
       "      <td>20</td>\n",
       "      <td>75</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>680</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanira Matos Pessoa</th>\n",
       "      <td>150</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>125</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>675</td>\n",
       "      <td>11.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcela Helena Gambim Fonseca</th>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>180</td>\n",
       "      <td>10</td>\n",
       "      <td>640</td>\n",
       "      <td>14.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regis Bernardo Brandim Gomes</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>200</td>\n",
       "      <td>600</td>\n",
       "      <td>9.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eduardo Ruback dos Santos</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>360</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marlos de Medeiros Chaves</th>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adriana Costa Bacelo</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>285</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anna Carolina Machado Marinho</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>90</td>\n",
       "      <td>270</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claudia Stutz Zubieta</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>260</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venúcia Bruna Magalhães Pereira</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Galba Freire Moita</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alice Paula Di Sabatino Guimarães</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dayane Alves Costa</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ana Camila Oliveira Alves</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ana Cláudia de Araújo Teixeira</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Giovanny Augusto Camacho Antevere Mazzarotto</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Margareth Borges Coutinho Gallo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antonio Marcos Aires Barbosa</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raphael Trevizani</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donat Alexander de Chapeaurouge</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fernanda Savicki de Almeida</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ano                                           2017  2018  2019  2020  2021  \\\n",
       "Autor                                                                        \n",
       "Jaime Ribeiro Filho                           575   320   200   1060  955    \n",
       "Márcio Flávio Moura de Araújo                 285   570   315    385  475    \n",
       "Fabio Miyajima                                350   270   330    270  530    \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer    100   310   230    355  755    \n",
       "Roberto Wagner Júnior Freire de Freitas       175   390   320    365  580    \n",
       "Roberto Nicolete                              160    80    55    270  335    \n",
       "Ivana Cristina de Holanda Cunha Barreto       335   180    65    150  370    \n",
       "Caroline Pereira Bittencourt Passaes           90    90   110    360  490    \n",
       "Carla Freire Celedonio Fernandes              410   170   100    220  320    \n",
       "João Hermínio Martins da Silva                310     0   210    120   55    \n",
       "Luiz Odorico Monteiro de Andrade              170   130    15    150  420    \n",
       "José Luís Passos Cordeiro                       0   400   100    375   90    \n",
       "Sharmênia de Araújo Soares Nuto                80    55    50    240  385    \n",
       "Fernando Ferreira Carneiro                    170   205    40    130  130    \n",
       "Marcos Roberto Lourenzoni                     110    90   180    190  120    \n",
       "Fernando Braga Stehling Dias                   90    90    90     80  260    \n",
       "Gilvan Pessoa Furtado                         100   180   110      0  270    \n",
       "Clarissa Romero Teixeira                        0   320     0     80    0    \n",
       "Maximiliano Ponte                             270    20    75    130   90    \n",
       "Vanira Matos Pessoa                           150    80    40     20  125    \n",
       "Marcela Helena Gambim Fonseca                   0    90    20      0  170    \n",
       "Regis Bernardo Brandim Gomes                    0     0     0     40   20    \n",
       "Eduardo Ruback dos Santos                       0     0     0      0    0    \n",
       "Marlos de Medeiros Chaves                       0    90     0     40   80    \n",
       "Adriana Costa Bacelo                           50     0   110      0   10    \n",
       "Anna Carolina Machado Marinho                   0    15     0      0  150    \n",
       "Claudia Stutz Zubieta                           0     0     0      0    0    \n",
       "Venúcia Bruna Magalhães Pereira                80    80    60      0   40    \n",
       "Galba Freire Moita                              0    20    95     40   25    \n",
       "Alice Paula Di Sabatino Guimarães               0     0     0      0  170    \n",
       "Dayane Alves Costa                             90     0     0      0   40    \n",
       "Ana Camila Oliveira Alves                       0     0     0      0   60    \n",
       "Ana Cláudia de Araújo Teixeira                  0     0     0      0    0    \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto   80     0     0      0    5    \n",
       "Margareth Borges Coutinho Gallo                 0     0     0      0  100    \n",
       "Antonio Marcos Aires Barbosa                    0    15     0      0    0    \n",
       "Raphael Trevizani                              90     0     0      0    0    \n",
       "Donat Alexander de Chapeaurouge                 0    80     0      0    0    \n",
       "Fernanda Savicki de Almeida                     0     0     0      0    0    \n",
       "\n",
       "Ano                                           2022  2023  2024  \\\n",
       "Autor                                                            \n",
       "Jaime Ribeiro Filho                           865   1155  200    \n",
       "Márcio Flávio Moura de Araújo                 260    380   80    \n",
       "Fabio Miyajima                                770     80    0    \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer    300    445  100    \n",
       "Roberto Wagner Júnior Freire de Freitas        80    190   20    \n",
       "Roberto Nicolete                              510    285   80    \n",
       "Ivana Cristina de Holanda Cunha Barreto       340    200    0    \n",
       "Caroline Pereira Bittencourt Passaes          170     90   90    \n",
       "Carla Freire Celedonio Fernandes               60     15  170    \n",
       "João Hermínio Martins da Silva                520    200    0    \n",
       "Luiz Odorico Monteiro de Andrade              260    140   40    \n",
       "José Luís Passos Cordeiro                     130     80   15    \n",
       "Sharmênia de Araújo Soares Nuto               115    170   60    \n",
       "Fernando Ferreira Carneiro                    100    180  180    \n",
       "Marcos Roberto Lourenzoni                     210    100    0    \n",
       "Fernando Braga Stehling Dias                  270     80    0    \n",
       "Gilvan Pessoa Furtado                         100    160    0    \n",
       "Clarissa Romero Teixeira                       80    180   80    \n",
       "Maximiliano Ponte                               0     95    0    \n",
       "Vanira Matos Pessoa                           110    150    0    \n",
       "Marcela Helena Gambim Fonseca                 170    180   10    \n",
       "Regis Bernardo Brandim Gomes                  160    180  200    \n",
       "Eduardo Ruback dos Santos                     270      0   90    \n",
       "Marlos de Medeiros Chaves                      90      0    0    \n",
       "Adriana Costa Bacelo                           35      0   80    \n",
       "Anna Carolina Machado Marinho                   0     15   90    \n",
       "Claudia Stutz Zubieta                          90     90   80    \n",
       "Venúcia Bruna Magalhães Pereira                 0      0    0    \n",
       "Galba Freire Moita                              5      0    0    \n",
       "Alice Paula Di Sabatino Guimarães               0      0    0    \n",
       "Dayane Alves Costa                              0     20    0    \n",
       "Ana Camila Oliveira Alves                      60      0    0    \n",
       "Ana Cláudia de Araújo Teixeira                 20     90    0    \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto    0     15    0    \n",
       "Margareth Borges Coutinho Gallo                 0      0    0    \n",
       "Antonio Marcos Aires Barbosa                    0     80    0    \n",
       "Raphael Trevizani                               0      0    0    \n",
       "Donat Alexander de Chapeaurouge                 0      0    0    \n",
       "Fernanda Savicki de Almeida                     0      5    0    \n",
       "\n",
       "Ano                                           Soma de Pontos  colab_disc  \n",
       "Autor                                                                     \n",
       "Jaime Ribeiro Filho                           5330             14.89      \n",
       "Márcio Flávio Moura de Araújo                 2750             14.29      \n",
       "Fabio Miyajima                                2600              5.26      \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer    2595             14.58      \n",
       "Roberto Wagner Júnior Freire de Freitas       2120             10.00      \n",
       "Roberto Nicolete                              1775             15.15      \n",
       "Ivana Cristina de Holanda Cunha Barreto       1640              5.88      \n",
       "Caroline Pereira Bittencourt Passaes          1490              0.00      \n",
       "Carla Freire Celedonio Fernandes              1465             48.00      \n",
       "João Hermínio Martins da Silva                1415              0.00      \n",
       "Luiz Odorico Monteiro de Andrade              1325              3.70      \n",
       "José Luís Passos Cordeiro                     1190              8.70      \n",
       "Sharmênia de Araújo Soares Nuto               1155              0.00      \n",
       "Fernando Ferreira Carneiro                    1135              8.70      \n",
       "Marcos Roberto Lourenzoni                     1000             20.00      \n",
       "Fernando Braga Stehling Dias                   960              9.09      \n",
       "Gilvan Pessoa Furtado                          920             14.29      \n",
       "Clarissa Romero Teixeira                       740             22.22      \n",
       "Maximiliano Ponte                              680              5.26      \n",
       "Vanira Matos Pessoa                            675             11.11      \n",
       "Marcela Helena Gambim Fonseca                  640             14.29      \n",
       "Regis Bernardo Brandim Gomes                   600              9.09      \n",
       "Eduardo Ruback dos Santos                      360             25.00      \n",
       "Marlos de Medeiros Chaves                      300             20.00      \n",
       "Adriana Costa Bacelo                           285             30.00      \n",
       "Anna Carolina Machado Marinho                  270             20.00      \n",
       "Claudia Stutz Zubieta                          260              0.00      \n",
       "Venúcia Bruna Magalhães Pereira                260              0.00      \n",
       "Galba Freire Moita                             185             10.00      \n",
       "Alice Paula Di Sabatino Guimarães              170             50.00      \n",
       "Dayane Alves Costa                             150            100.00      \n",
       "Ana Camila Oliveira Alves                      120             50.00      \n",
       "Ana Cláudia de Araújo Teixeira                 110             50.00      \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto   100              0.00      \n",
       "Margareth Borges Coutinho Gallo                100             25.00      \n",
       "Antonio Marcos Aires Barbosa                    95            100.00      \n",
       "Raphael Trevizani                               90              0.00      \n",
       "Donat Alexander de Chapeaurouge                 80             33.33      \n",
       "Fernanda Savicki de Almeida                      5              0.00      "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'{len(df_pontuacao.index)} pesquisadores')\n",
    "df_pontuacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b12f804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(os.path.join(\"./\",\"_data\",\"powerbi\",'fioce_prodpubl_discentcollab_2017_2024.xlsx'))\n",
    "df_pontuacao.to_excel(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17da8026",
   "metadata": {},
   "source": [
    "# <b>F04: Acrescentar avaliação Qualis Periódicos</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36721f73",
   "metadata": {},
   "source": [
    "### Abrir dados salvos localmente de Docentes e Discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8802f09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos disponíveis na pasta para dados de entrada:\n",
      "  combined_dict_list.json\n",
      "  dict_list_discents_combined.json\n",
      "  dict_list_temp.json\n",
      "  discents_dict_list.json\n",
      "  docents_dict_list.json\n",
      "  temp_dict_list.json\n",
      "\n",
      "39 currículos carregados na lista de dicionários de docentes 'docents_dict_list.json'\n",
      "Arquivo criado inicialmente em 23/05/2024 06:06:04 carregado com sucesso\n",
      "Extração realizada em 23/05/2024 21:49:55 a -159.0 minutos\n",
      "\n",
      "121 currículos carregados na lista de dicionários de discentes 'discents_dict_list.json'\n",
      "Arquivo criado inicialmente em 23/05/2024 06:06:04 carregado com sucesso\n",
      "Extração realizada em 23/05/2024 21:50:33 a -159.6 minutos\n",
      "\n",
      "Exemplo dos dados das publicações de docentes:\n",
      "{'DOI': 'http://dx.doi.org/10.1038/s41467-023-44389-3',\n",
      " 'ISSN': '20411723',\n",
      " 'ano': '2024',\n",
      " 'autores': 'PASSAES, CAROLINE2024PASSAES, CAROLINE; DESJARDINS, DELPHINE ; '\n",
      "            'CHAPEL, ANAÏS ; MONCEAUX, VALÉRIE ; LEMAITRE, JULIEN ; MÉLARD, '\n",
      "            'ADELINE ; PERDOMO-CELIS, FEDERICO ; PLANCHAIS, CYRIL ; GOURVÈS, '\n",
      "            'MAËL ; DIMANT, NASTASIA ; DAVID, ANNIE ; DEREUDDRE-BOSQUET, '\n",
      "            'NATHALIE ; BARRAIL-TRAN, AURÉLIE ; GOUGET, HÉLÈNE ; GUILLAUME, '\n",
      "            'CÉLINE ; RELOUZAT, FRANCIS ; LAMBOTTE, OLIVIER ; GUEDJ, JÉRÉMIE ; '\n",
      "            'MÜLLER-TRUTWIN, MICHAELA ; MOUQUET, HUGO . Early antiretroviral '\n",
      "            'therapy favors post-treatment SIV control associated with the '\n",
      "            'expansion of enhanced memory CD8+ T-cells. Nature Communications, '\n",
      "            'v. 15, p. 178, 2024.',\n",
      " 'data_issn': '20411723',\n",
      " 'fator_impacto_jcr': '16.6',\n",
      " 'revista': 'Nature Communications',\n",
      " 'titulo': 'Early antiretroviral therapy favors post-treatment SIV control '\n",
      "           'associated with the expansion of enhanced memory CD8  T-cells'}\n",
      "\n",
      "Exemplo dos dados das publicações de discentes:\n",
      "{'DOI': 'http://dx.doi.org/10.5935/1518-0557.20240030',\n",
      " 'ISSN': '15180557',\n",
      " 'Qualis': 'A4',\n",
      " 'ano': '2024',\n",
      " 'autores': 'MOURA, G. A.2024MOURA, G. A. ; LOURENCO, M. L. ; ROCHA, Y. M. ; '\n",
      "            'RODRIGUES, J. P. V. ; PINHEIRO, C. V. ;QUEIROZ, Alice Soares de; '\n",
      "            'MIRANDA, D. P. ; TORQUATO FILHO, S. E. ;NICOLETE, ROBERTO. ',\n",
      " 'data_issn': '15180557',\n",
      " 'fator_impacto_jcr': '1.5',\n",
      " 'revista': 'JORNAL BRASILEIRO DE REPRODUÇÃO ASSISTIDA',\n",
      " 'titulo': 'ASSESSMENT OF DIFFERENTIALLY EXPRESSED GENES FROM IN VITRO MATURED '\n",
      "           'HUMAN OOCYTES: A BIOINFORMATICS APPROACH'}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd, os, re, sys, time, pytz, json, subprocess\n",
    "\n",
    "## Configurar exibição do pandas para melhor visualizar os dados\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('colheader_justify', 'left')\n",
    "pd.set_option('display.max_rows', 600)\n",
    "\n",
    "def find_repo_root(path='.', depth=10):\n",
    "    ''' \n",
    "    Busca o arquivo .git e retorna string com a pasta raiz do repositório\n",
    "    '''\n",
    "    # Prevent infinite recursion by limiting depth\n",
    "    if depth < 0:\n",
    "        return None\n",
    "    path = Path(path).absolute()\n",
    "    if (path / '.git').is_dir():\n",
    "        return path\n",
    "    return find_repo_root(path.parent, depth-1)\n",
    "\n",
    "delay = 10\n",
    "\n",
    "## Definir a pasta de base do repositório local\n",
    "base_repo_dir = find_repo_root()\n",
    "\n",
    "## Sempre construir os caminhos usando os.path.join para compatibilidade WxL\n",
    "folder_utils = os.path.join(base_repo_dir, 'utils')\n",
    "folder_domain = os.path.join(base_repo_dir, 'source', 'domain')\n",
    "folder_data_xls = os.path.join(base_repo_dir, '_data', 'in_xls')\n",
    "folder_data_input = os.path.join(base_repo_dir, '_data', 'in_csv')\n",
    "folder_data_output = os.path.join(base_repo_dir, '_data', 'output')\n",
    "\n",
    "## Adicionar pastas locais ao sys.path para importar pacotes criados localmente\n",
    "sys.path.append(folder_utils)\n",
    "sys.path.append(folder_domain)\n",
    "from scraper_pasteur import PasteurScraper\n",
    "from environment_setup import EnvironmentSetup\n",
    "from scraper_sucupira import SucupiraScraper\n",
    "from scraper_sucupira_edge import SucupiraScraperEdge\n",
    "from chromedriver_manager import ChromeDriverManager\n",
    "from neo4j_persister import Neo4jPersister\n",
    "from lattes_scrapper import JSONFileManager, LattesScraper, HTMLParser, SoupParser, GetQualis, ArticlesCounter, DiscentCollaborationCounter, DictToHDF5, attribute_to_be_non_empty\n",
    "\n",
    "# Carregar o conteúdo do arquivo 'dict_list.json' para a variável dict_list\n",
    "jfm = JSONFileManager()\n",
    "jfm.list_json(folder_data_input)\n",
    "\n",
    "# Carregar o conteúdo do arquivo da extração de docentes para a variável dict_list_docents\n",
    "filename_docents = 'docents_dict_list.json'\n",
    "dict_list_docents, formatted_creation_date, formatted_modification_date, time_count, unit = jfm.load_from_json(os.path.join(folder_data_input,filename_docents))\n",
    "\n",
    "print(f\"\\n{len(dict_list_docents)} currículos carregados na lista de dicionários de docentes '{filename_docents}'\")\n",
    "print(f\"Arquivo criado inicialmente em {formatted_creation_date} carregado com sucesso\")\n",
    "print(f\"Extração realizada em {formatted_modification_date} a {time_count} {unit}\")\n",
    "\n",
    "# Carregar o conteúdo do arquivo da extração de discentes para a variável dict_list_discents\n",
    "filename_discents = 'discents_dict_list.json'\n",
    "dict_list_discents, formatted_creation_date_discents, formatted_modification_date_discents, time_count, unit = jfm.load_from_json(os.path.join(folder_data_input,filename_discents))\n",
    "\n",
    "print(f\"\\n{len(dict_list_discents)} currículos carregados na lista de dicionários de discentes '{filename_discents}'\")\n",
    "print(f\"Arquivo criado inicialmente em {formatted_creation_date_discents} carregado com sucesso\")\n",
    "print(f\"Extração realizada em {formatted_modification_date_discents} a {time_count} {unit}\")\n",
    "\n",
    "print('\\nExemplo dos dados das publicações de docentes:')\n",
    "# Verificar se o dado Qualis está presente no arquivo de dados de docentes\n",
    "pprint([x.get('Produções') for x in dict_list_docents][-1].get('Artigos completos publicados em periódicos')[0])\n",
    "\n",
    "# Verificar se o dado Qualis está presente no arquivo de dados de discentes\n",
    "print('\\nExemplo dos dados das publicações de discentes:')\n",
    "pprint([x.get('Produções') for x in dict_list_discents][1].get('Artigos completos publicados em periódicos')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7a804",
   "metadata": {},
   "source": [
    "### Atualizar dado dos Qualis Periódicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8747fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemplo atualizado dos dados das publicações de docentes:\n",
      "{'DOI': 'http://dx.doi.org/10.1038/s41467-023-44389-3',\n",
      " 'ISSN': '20411723',\n",
      " 'Qualis': 'A1',\n",
      " 'ano': '2024',\n",
      " 'autores': 'PASSAES, CAROLINE2024PASSAES, CAROLINE; DESJARDINS, DELPHINE ; '\n",
      "            'CHAPEL, ANAÏS ; MONCEAUX, VALÉRIE ; LEMAITRE, JULIEN ; MÉLARD, '\n",
      "            'ADELINE ; PERDOMO-CELIS, FEDERICO ; PLANCHAIS, CYRIL ; GOURVÈS, '\n",
      "            'MAËL ; DIMANT, NASTASIA ; DAVID, ANNIE ; DEREUDDRE-BOSQUET, '\n",
      "            'NATHALIE ; BARRAIL-TRAN, AURÉLIE ; GOUGET, HÉLÈNE ; GUILLAUME, '\n",
      "            'CÉLINE ; RELOUZAT, FRANCIS ; LAMBOTTE, OLIVIER ; GUEDJ, JÉRÉMIE ; '\n",
      "            'MÜLLER-TRUTWIN, MICHAELA ; MOUQUET, HUGO . Early antiretroviral '\n",
      "            'therapy favors post-treatment SIV control associated with the '\n",
      "            'expansion of enhanced memory CD8+ T-cells. Nature Communications, '\n",
      "            'v. 15, p. 178, 2024.',\n",
      " 'data_issn': '20411723',\n",
      " 'fator_impacto_jcr': '16.6',\n",
      " 'revista': 'Nature Communications',\n",
      " 'titulo': 'Early antiretroviral therapy favors post-treatment SIV control '\n",
      "           'associated with the expansion of enhanced memory CD8  T-cells'}\n",
      "\n",
      "Exemplo atualizado dos dados das publicações de discentes:\n",
      "{'DOI': 'http://dx.doi.org/10.5935/1518-0557.20240030',\n",
      " 'ISSN': '15180557',\n",
      " 'Qualis': 'A4',\n",
      " 'ano': '2024',\n",
      " 'autores': 'MOURA, G. A.2024MOURA, G. A. ; LOURENCO, M. L. ; ROCHA, Y. M. ; '\n",
      "            'RODRIGUES, J. P. V. ; PINHEIRO, C. V. ;QUEIROZ, Alice Soares de; '\n",
      "            'MIRANDA, D. P. ; TORQUATO FILHO, S. E. ;NICOLETE, ROBERTO. ',\n",
      " 'data_issn': '15180557',\n",
      " 'fator_impacto_jcr': '1.5',\n",
      " 'revista': 'JORNAL BRASILEIRO DE REPRODUÇÃO ASSISTIDA',\n",
      " 'titulo': 'ASSESSMENT OF DIFFERENTIALLY EXPRESSED GENES FROM IN VITRO MATURED '\n",
      "           'HUMAN OOCYTES: A BIOINFORMATICS APPROACH'}\n"
     ]
    }
   ],
   "source": [
    "stratifier = GetQualis()\n",
    "\n",
    "print('\\nAdicionando Qualis Periódicos a publicações dos docentes')\n",
    "pathfilename = os.path.join(folder_data_input,'docents_dict_list.json')\n",
    "json_data_discents = stratifier.buscar_qualis_e_atualizar_arquivo(dict_list_docents, pathfilename)\n",
    "\n",
    "print('\\nAdicionando Qualis Periódicos a publicações dos discentes')\n",
    "pathfilename = os.path.join(folder_data_input,'discents_dict_list.json')\n",
    "json_data_discents = stratifier.buscar_qualis_e_atualizar_arquivo(dict_list_discents, pathfilename)\n",
    "\n",
    "print('\\nExemplo atualizado dos dados das publicações de docentes:')\n",
    "# Verificar se o dado Qualis está presente no arquivo de dados de docentes\n",
    "pprint([x.get('Produções') for x in dict_list_docents][-1].get('Artigos completos publicados em periódicos')[0])\n",
    "\n",
    "print('\\nExemplo atualizado dos dados das publicações de discentes:')\n",
    "# Verificar se o dado Qualis está presente no arquivo de dados de discentes\n",
    "pprint([x.get('Produções') for x in dict_list_discents][1].get('Artigos completos publicados em periódicos')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec67ce0",
   "metadata": {},
   "source": [
    "# <b>F05: Montar Grafo e analisar redes</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07508efc",
   "metadata": {},
   "source": [
    "### Persistir dados dos docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e29eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"password\"\n",
    "persister = Neo4jPersister(uri, user, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_areas_nodes(dict_list_docents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b26275",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_docent_nodes(dict_list_docents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef7b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_producoes_pesquisador(dict_list_docents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a42d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_pesquisador_grande_area_relationships(dict_list_docents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c878292",
   "metadata": {},
   "source": [
    "### Persistir dados de discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_producoes_pesquisador(dict_list_discents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_areas_nodes(dict_list_discents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_discent_nodes(dict_list_discents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_pesquisador_grande_area_relationships(dict_list_discents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97413d8",
   "metadata": {},
   "source": [
    "### Persistir dados de orientações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "persister.persist_advices_relationships(dict_list_docents)\n",
    "print(f'\\n{preparer.tempo(t1,time.time())} para persistir dados de todas orientações nos dados de docentes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2243df4d",
   "metadata": {},
   "source": [
    "### Persistir dados de revistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ccb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persiste dados da lista Sucupira no Neo4j dados de > 35.000 revistas\n",
    "t1 = time.time()\n",
    "persister.persistir_revistas_da_planilha()\n",
    "print(f'\\n{preparer.tempo(t1,time.time())} para persistir dados de todas revistas da Plataforma Sucupira')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x.keys() for x in dict_list_docents]\n",
    "[x.get('Produções') for x in dict_list_docents][1].get('Artigos completos publicados em periódicos')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14621d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.get('Orientações') for x in dict_list_docents][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60164ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.get('Orientações') for x in dict_list_discents][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b056f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\n{preparer.tempo(t00,time.time())} para recuperar, processar e persistir dados.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be0009",
   "metadata": {},
   "source": [
    "# Outros testes e experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a77e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_tipo_instancias_arvore(estrutura, nivel=1, identacao=\"\"):\n",
    "    \"\"\"\n",
    "    Função recursiva que avalia o tipo e a quantidade de instâncias em cada nível da estrutura, exibindo-a em formato de árvore.\n",
    "\n",
    "    Args:\n",
    "        estrutura (list|dict): A estrutura a ser avaliada.\n",
    "        nivel (int): Nível atual da recurssão (inicia em 1).\n",
    "        identacao (str): String de indentação para cada nível (inicia vazia).\n",
    "\n",
    "    Returns:\n",
    "        None: A função imprime os resultados na tela e não retorna nada.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(estrutura, list):\n",
    "        print(f\"{identacao}N{nivel}. Lista: {len(estrutura)} elementos\")\n",
    "        for item in estrutura:\n",
    "            avaliar_tipo_instancias_arvore(item, nivel + 1, identacao + \"    \")\n",
    "\n",
    "    elif isinstance(estrutura, dict):\n",
    "        print(f\"{identacao}N{nivel}. Mapa: {estrutura.keys()}\")\n",
    "        for chave, valor in estrutura.items():\n",
    "            print(f\"{identacao}  {chave}:\")\n",
    "            avaliar_tipo_instancias_arvore(valor, nivel + 1, identacao + \"    \")\n",
    "\n",
    "    elif isinstance(estrutura, str):\n",
    "        print(f\"{identacao}N{nivel}. String: {estrutura}\")\n",
    "\n",
    "for dict_pesq in dict_list[:3]:\n",
    "    avaliar_tipo_instancias_arvore(dict_pesq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc6c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_pesq in dict_list:\n",
    "    if isinstance(dict_pesq, list):\n",
    "        print(f'L1. Lista: {dict_pesq}')\n",
    "    elif isinstance(dict_pesq, dict):\n",
    "        print(f'L1. Mapa: {dict_pesq.keys()}')\n",
    "        for tipo in dict_pesq.values():\n",
    "            if isinstance(tipo, list):\n",
    "                print(f'    L2. Lista: {tipo}')\n",
    "            elif isinstance(tipo, dict):\n",
    "                print(f'    L2. Mapa: {tipo}')\n",
    "                for subtipo in tipo.values():\n",
    "                    if isinstance(subtipo, list):\n",
    "                        print(f'        L3. Lista: {len(subtipo)} elementos')\n",
    "                        for subsubtipo in subtipo:\n",
    "                            if isinstance(subsubtipo, list):\n",
    "                                print(f'            L4. Lista: {subsubtipo}')\n",
    "                            elif isinstance(subsubtipo, dict):\n",
    "                                print(f'            L4. Mapa: {subsubtipo.keys()}')\n",
    "                                for subsubsubtipo in subsubtipo.values():\n",
    "                                    if isinstance(subsubsubtipo, list):\n",
    "                                        print(f'                L5. Lista: {subsubsubtipo}')\n",
    "                                    elif isinstance(subsubsubtipo, dict):\n",
    "                                        print(f'                L5. Mapa: {subsubsubtipo.keys()}')\n",
    "                                    elif isinstance(subsubsubtipo, str):\n",
    "                                        print(f'                L5. String: {subsubsubtipo}')                                  \n",
    "                            elif isinstance(subsubtipo, str):\n",
    "                                print(f'            L4. String: {subsubtipo}')     \n",
    "                    elif isinstance(subtipo, dict):\n",
    "                        print(f'        L3. Mapa: {subtipo.keys()}')\n",
    "                        for subsubtipo in subtipo.values():\n",
    "                            if isinstance(subsubtipo, list):\n",
    "                                print(f'            L4. Lista: {subsubtipo}')\n",
    "                            elif isinstance(subsubtipo, dict):\n",
    "                                print(f'            L4. Mapa: {subsubtipo.keys()}')\n",
    "                            elif isinstance(subsubtipo, str):\n",
    "                                print(f'            L4. String: {subsubtipo}')                             \n",
    "                    elif isinstance(tipo, str):\n",
    "                        print(f'        L3. String: {subtipo}')                \n",
    "            elif isinstance(tipo, str):\n",
    "                print(f'    L2. String: {tipo}')\n",
    "    elif isinstance(dict_pesq, str):\n",
    "        print(f'L1. String: {dict_pesq}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list[20:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991a5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_list[20].get('Identificação').items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_list[5].get('Idiomas'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e49f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(x.get('Descrição') for x in dict_list[5].get('Linhas de Pesquisa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7213c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_list[5].get('Áreas').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0886075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tipos=[]\n",
    "for pesq in dict_list:\n",
    "    for t, s in pesq.get('Produções').items():\n",
    "        if t not in tipos:\n",
    "            tipos.append(t)\n",
    "            print(t, type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_list[1].get('Produções').get('Artigos completos publicados em periódicos')[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb7c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_list[5].get('Atuação Profissional'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_list[5].get('Formação').items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e1f72",
   "metadata": {},
   "source": [
    "## Classe para gerar dados para grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "# import json\n",
    "\n",
    "# class Neo4jConnection:\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "\n",
    "#     def persist_data(self, data):\n",
    "#         with self._driver.session() as session:\n",
    "#             for person_data in data:\n",
    "#                 person_id = person_data['Identificação']['ID Lattes']\n",
    "#                 prepared_data, relationships = self._prepare_data(person_data, person_id)\n",
    "#                 session.write_transaction(self._create_person_node, person_id, prepared_data)\n",
    "#                 self._create_relationships(session, person_id, relationships)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _create_person_node(tx, person_id, person_data):\n",
    "#         tx.run(\n",
    "#             \"MERGE (p:Person {id_lattes: $person_id}) \"\n",
    "#             \"SET p += $person_data\",\n",
    "#             person_id=person_id,\n",
    "#             person_data=person_data\n",
    "#         )\n",
    "\n",
    "#     def _prepare_data(self, data, person_id):\n",
    "#         prepared_data = {}\n",
    "#         relationships = []\n",
    "#         for key, value in data.items():\n",
    "#             if isinstance(value, dict):\n",
    "#                 label = key.capitalize().replace(' ', '_')\n",
    "#                 prepared_data.update({f'{label}_{k}': v for k, v in value.items()})\n",
    "#                 sub_prepared_data, sub_relationships = self._prepare_data(value, person_id)\n",
    "#                 prepared_data.update(sub_prepared_data)\n",
    "#                 relationships.extend(sub_relationships)\n",
    "#                 relationships.append((label, {'label': 'Person', 'person_id': person_id}))\n",
    "#             elif isinstance(value, list):\n",
    "#                 for idx, item in enumerate(value):\n",
    "#                     if isinstance(item, dict):\n",
    "#                         nested_label = f'{key}_{idx}'\n",
    "#                         nested_prepared_data, nested_relationships = self._prepare_data(item, person_id)\n",
    "#                         prepared_data.update({f'{nested_label}_{k}': v for k, v in item.items()})\n",
    "#                         prepared_data.update(nested_prepared_data)\n",
    "#                         relationships.extend(nested_relationships)\n",
    "#                         relationships.append((nested_label, {'label': key.capitalize().replace(' ', '_'), 'person_id': person_id}))\n",
    "#                     elif isinstance(item, str):\n",
    "#                         # Tratar strings\n",
    "#                         if \":\" in item:\n",
    "#                             label, value = item.split(\":\", 1)\n",
    "#                             prepared_data[f'{key}_{idx}'] = value.strip()\n",
    "#                             relationships.append((label.strip(), {'label': key.capitalize().replace(' ', '_'), 'person_id': person_id}))\n",
    "#                         else:\n",
    "#                             prepared_data[f'{key}_{idx}'] = item.strip()\n",
    "#         return prepared_data, relationships\n",
    "\n",
    "#     def _create_relationships(self, session, person_id, relationships):\n",
    "#         for label, parent_id in relationships:\n",
    "#             query = (\n",
    "#                 f\"MATCH (p:Person {{id_lattes: '{person_id}'}}) \"\n",
    "#                 f\"MATCH (n:{label} {{id_lattes: '{person_id}_{label}'}}) \"\n",
    "#                 f\"MERGE (p)-[:HAS_{label}]->(n)\"\n",
    "#             )\n",
    "#             if parent_id:\n",
    "#                 query += (\n",
    "#                     f\" MERGE (parent:{parent_id['label']} {{id_lattes: '{parent_id['person_id']}'}}) \"\n",
    "#                     f\"MERGE (parent)-[:HAS_{label}]->(n)\"\n",
    "#                 )\n",
    "#             session.run(query)\n",
    "\n",
    "# # Dados de conexão com o banco de dados Neo4j\n",
    "# uri = \"bolt://localhost:7687\"\n",
    "# user = \"neo4j\"\n",
    "# password = \"password\"\n",
    "\n",
    "# # Conecta-se ao banco de dados Neo4j e persiste os dados\n",
    "# connection = Neo4jConnection(uri, user, password)\n",
    "# connection.persist_data(dict_list)\n",
    "# connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85580969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# from neo4j import GraphDatabase\n",
    "# import ast\n",
    "\n",
    "# class GraphPreparer:\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._uri = uri\n",
    "#         self._user = user\n",
    "#         self._password = password\n",
    "#         self._driver = None\n",
    "\n",
    "#     def connect(self):\n",
    "#         self._driver = GraphDatabase.driver(self._uri, auth=(self._user, self._password))\n",
    "\n",
    "#     def prepare_data_from_file(self, file_path):\n",
    "#         nodes = []\n",
    "#         relationships = []\n",
    "\n",
    "#         with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#             data = json.load(file)\n",
    "\n",
    "#         for person_data in data:\n",
    "#             print(person_data.keys())\n",
    "#             person_id = person_data['Identificação'].get('ID Lattes')\n",
    "#             nodes.append(('Pesquisador', {'id_lattes': person_id}))\n",
    "            \n",
    "#             for language in person_data.get('Idiomas', []):\n",
    "#                 language_name = language['Idioma']\n",
    "#                 proficiency = language['Proficiência']\n",
    "#                 nodes.append(('Idioma', {'nome_idioma': language_name, 'proficiencia': proficiency}))\n",
    "#                 relationships.append(('Pesquisador', {'id_lattes': person_id}, 'FALA', {'nome_idioma': language_name}))\n",
    "            \n",
    "#             for academic_info in person_data.get('Formação', {}).get('Acadêmica', []):\n",
    "#                 description = academic_info['Descrição']\n",
    "#                 nodes.append(('Curso', {'descricao': description}))\n",
    "#                 relationships.append(('Pesquisador', {'id_lattes': person_id}, 'REALIZOU', {'descricao': description}))\n",
    "                \n",
    "#             for professional_info in person_data.get('Atuação Profissional', []):\n",
    "#                 institution = professional_info['Instituição']\n",
    "#                 description = professional_info['Descrição']\n",
    "#                 relationships.append(('Pesquisador', {'id_lattes': person_id}, 'ATUA', {'instituicao': institution, 'descricao': description}))\n",
    "\n",
    "#         return nodes, relationships\n",
    "\n",
    "#     def persist_data(self, data_for_neo4j):\n",
    "#         try:\n",
    "#             with self._driver.session() as session:\n",
    "#                 for data in data_for_neo4j:\n",
    "#                     if data[0] == 'Node':\n",
    "#                         label, properties = data[1:]\n",
    "#                         session.write_transaction(self._create_node, label, **properties)\n",
    "#                     elif data[0] == 'Relationship':\n",
    "#                         start_label, rel_type, end_label = data[1:]\n",
    "#                         session.write_transaction(self._create_relationship, start_label, rel_type, end_label)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error persisting data: {e}\")\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _create_node(tx, label, **properties):\n",
    "#         query = f\"CREATE (n:{label} $props)\"\n",
    "#         tx.run(query, props=properties)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _create_relationship(tx, start_label, rel_type, end_label):\n",
    "#         query = \"MATCH (a:{start_label}), (b:{end_label}) \" \\\n",
    "#                 \"CREATE (a)-[r:{rel_type}]->(b)\"\n",
    "#         tx.run(query, start_label=start_label, rel_type=rel_type, end_label=end_label)\n",
    "\n",
    "#     def close(self):\n",
    "#         if self._driver is not None:\n",
    "#             self._driver.close()\n",
    "\n",
    "# # Exemplo de utilização:\n",
    "# graph_preparer = GraphPreparer(uri=\"bolt://localhost:7687\", user=\"neo4j\", password=\"password\")\n",
    "# graph_preparer.connect()\n",
    "\n",
    "# filepath = os.path.join(folder_data_input,'dict_list.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca32e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_list[0]['Idioma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ecf0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes, relationships = graph_preparer.prepare_data_from_file(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78acb05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_for_neo4j = nodes + relationships\n",
    "# graph_preparer.persist_data(data_for_neo4j)\n",
    "\n",
    "# graph_preparer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1823211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "# from datetime import datetime\n",
    "\n",
    "# uri = \"bolt://localhost:7687\"\n",
    "# user = \"neo4j\"\n",
    "# password = \"password\"\n",
    "# graph_preparer = GraphPreparer(uri, user, password) # Instanciar classe GraphPreparer\n",
    "# graph_preparer.connect() # Conectar ao banco de dados Neo4j\n",
    "# graph_preparer.process_data(dict_list) # Processar e persistir dados\n",
    "\n",
    "# # Transformar os dados para o formato adequado do Neo4j\n",
    "# dados_para_neo4j = graph_preparer.transform_data_for_neo4j(dict_list)\n",
    "# graph_preparer.persist_nodes_and_relationships(dados_para_neo4j) # PersistiR nós e relações no Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e803731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52fd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados_para_neo4j[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def42ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "# # Agora você pode inserir os dados no Neo4j utilizando sua biblioteca de acesso ao banco de dados Neo4j, por exemplo:\n",
    "# neo4j_driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))\n",
    "# with neo4j_driver.session() as session:\n",
    "#     for item in data_for_neo4j:\n",
    "#         label, properties = item\n",
    "#         cypher_query = f\"CREATE (:{label} $properties)\"\n",
    "#         session.run(cypher_query, properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc9672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Função para criar nós e relações\n",
    "# def create_nodes_and_relationships(tx, nodes_and_relationships):\n",
    "#     for item in nodes_and_relationships:\n",
    "#         if len(item) == 3:  # Se for uma relação\n",
    "#             origin_node, rel_type, dest_node = item\n",
    "#             tx.run(\n",
    "#                 f\"MATCH (a), (b) WHERE a.name = $origin_node AND b.name = $dest_node \"\n",
    "#                 \"CREATE (a)-[r:\" + rel_type + \"]->(b)\",\n",
    "#                 origin_node=origin_node, dest_node=dest_node\n",
    "#             )\n",
    "\n",
    "# # Conectando ao banco de dados Neo4j e executando a transação\n",
    "# with GraphDatabase.driver(uri, auth=(user, password)) as driver:\n",
    "#     with driver.session() as session:\n",
    "#         session.write_transaction(create_nodes_and_relationships, relacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed9787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# class Neo4jGraphGenerator:\n",
    "#     def __init__(self, dict_list):\n",
    "#         self.dict_list = dict_list\n",
    "#         self.graph_data = {'nodes': [], 'relationships': []}\n",
    "\n",
    "#     def generate_graph_json(self):\n",
    "#         for item in self.dict_list:\n",
    "#             id_lattes = item.get('Identificação', {}).get('ID Lattes')\n",
    "#             pesquisador = item.get('Identificação', {}).get('Nome')\n",
    "            \n",
    "#             # Adicionar nó de pessoa (Person)\n",
    "#             person_node = {'id': id_lattes, 'label': 'Person', 'name': pesquisador}\n",
    "#             self.graph_data['nodes'].append(person_node)\n",
    "\n",
    "#             areas = item.get('Áreas', {})\n",
    "#             for area in areas.values():\n",
    "#                 # Adicionar nó de Grande Área (GrandeArea)\n",
    "#                 grande_area_node = {'id': area['Grande Área'], 'label': 'GrandeArea', 'description': area['Grande Área']}\n",
    "#                 self.graph_data['nodes'].append(grande_area_node)\n",
    "#                 self.graph_data['relationships'].append({'source': id_lattes, 'target': area['Grande Área'], 'type': 'BELONGS_TO'})\n",
    "                \n",
    "#                 for subarea in area.get('Subáreas', []):\n",
    "#                     # Adicionar nó de Área (Area)\n",
    "#                     area_node = {'id': subarea['Área'], 'label': 'Area', 'description': subarea['Área']}\n",
    "#                     self.graph_data['nodes'].append(area_node)\n",
    "#                     self.graph_data['relationships'].append({'source': area['Grande Área'], 'target': subarea['Área'], 'type': 'BELONGS_TO'})\n",
    "                    \n",
    "#                     # Adicionar nó de Subárea (Subarea)\n",
    "#                     subarea_node = {'id': subarea['Subárea'], 'label': 'Subarea', 'description': subarea['Subárea']}\n",
    "#                     self.graph_data['nodes'].append(subarea_node)\n",
    "#                     self.graph_data['relationships'].append({'source': subarea['Área'], 'target': subarea['Subárea'], 'type': 'BELONGS_TO'})\n",
    "\n",
    "#         return json.dumps(self.graph_data, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da358b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = Neo4jGraphGenerator(dict_list)\n",
    "# generator.generate_graph_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03290d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import re\n",
    "# from neo4j import GraphDatabase\n",
    "\n",
    "# class AreasHandler:\n",
    "\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "        \n",
    "#     def consult_areas_atuacao(self, name):\n",
    "#         with self._driver.session() as session:\n",
    "#             result = session.run(\"MATCH (p:Person {name: $name}) RETURN p.`Áreas de atuação` as areas_atuacao\", name=name)\n",
    "#             record = result.single()\n",
    "#             if record:\n",
    "#                 return record['areas_atuacao']\n",
    "#             return None\n",
    "\n",
    "#     def debug_and_convert(self, areas_str):\n",
    "#         try:\n",
    "#             return json.loads(areas_str)\n",
    "#         except json.JSONDecodeError:\n",
    "#             print(f\"Failed to deserialize JSON string: {areas_str}\")\n",
    "#             return None\n",
    "\n",
    "#     def extract_subarea(self, area_detail):\n",
    "#         # Extract the 'Subárea' content from the area detail\n",
    "#         match = re.search(r'Subárea: ([^/]+)', area_detail)\n",
    "#         if match:\n",
    "#             return match.group(1).strip()\n",
    "#         return None\n",
    "\n",
    "#     def extract_areas(self, area_detail):\n",
    "#         # Extract the 'Grande Área', 'Área', and 'Subárea' contents from the area detail\n",
    "#         grande_area_match = re.search(r'Grande área: ([^/]+)', area_detail)\n",
    "#         area_match = re.search(r'Área: ([^/]+)', area_detail)\n",
    "#         subarea_match = re.search(r'Subárea: ([^/]+)', area_detail)\n",
    "        \n",
    "#         grande_area = grande_area_match.group(1).strip() if grande_area_match else None\n",
    "#         area = area_match.group(1).strip() if area_match else None\n",
    "#         subarea = subarea_match.group(1).strip() if subarea_match else None\n",
    "        \n",
    "#         return grande_area, area, subarea\n",
    "\n",
    "#     def create_areas_relations(self, name):\n",
    "#         # Get 'Áreas de atuação' properties\n",
    "#         areas_properties = self.consult_areas_atuacao(name)\n",
    "\n",
    "#         # Convert the serialized JSON strings back into dictionaries\n",
    "#         try:\n",
    "#             deserialized_areas_properties = self.debug_and_convert(areas_properties)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error deserializing 'Áreas de atuação' properties: {e}\")\n",
    "#             return\n",
    "\n",
    "#         successful_areas_creations = 0\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             for _, area_detail in deserialized_areas_properties.items():\n",
    "#                 try:\n",
    "#                     # Extracting Grande Área, Área, and Subárea from the details\n",
    "#                     match = re.match(r'Grande área: (.*?) / Área: (.*?) / Subárea: (.*?)(?:/Especialidade: (.*?))?\\.?$', area_detail)\n",
    "#                     if not match:\n",
    "#                         print(f\"Unexpected format for 'Áreas de atuação' detail: {area_detail}\")\n",
    "#                         continue\n",
    "#                     grande_area, area, subarea = match.groups()[:3]\n",
    "\n",
    "#                     # Creating or merging nodes for Subárea, Área, and Grande Área\n",
    "#                     session.run(\"MERGE (s:Subárea {name: $subarea})\", subarea=subarea)\n",
    "#                     session.run(\"MERGE (a:Área {name: $area})\", area=area)\n",
    "#                     session.run(\"MERGE (ga:GrandeÁrea {name: $grande_area})\", grande_area=grande_area)\n",
    "\n",
    "#                     # Creating or merging relationships. Using MERGE ensures no duplicate relationships are created.\n",
    "#                     session.run(\"MATCH (p:Person {name: $name}), (s:Subárea {name: $subarea}) MERGE (p)-[r:ATUA_EM]->(s)\", name=name, subarea=subarea)\n",
    "#                     session.run(\"MATCH (ga:GrandeÁrea {name: $grande_area}), (a:Área {name: $area}) MERGE (ga)-[r:CONTÉM_ÁREA]->(a)\", grande_area=grande_area, area=area)\n",
    "#                     session.run(\"MATCH (a:Área {name: $area}), (s:Subárea {name: $subarea}) MERGE (a)-[r:CONTEM_SUBÁREA]->(s)\", area=area, subarea=subarea)\n",
    "\n",
    "#                     successful_areas_creations += 1\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing 'Áreas de atuação' detail '{area_detail}': {e}\")\n",
    "\n",
    "#             # Inform the user about areas\n",
    "#             print(f\"{successful_areas_creations} 'Áreas de atuação' relations successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fdc77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uri = \"bolt://localhost:7687\"\n",
    "# user = \"neo4j\"\n",
    "# password = \"password\"\n",
    "\n",
    "# handleareas = AreasHandler(uri, user, password)\n",
    "# name = 'Antonio Marcos Aires Barbosa'\n",
    "# handleareas.consult_areas_atuacao(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefb3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5003e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "# import urllib.parse\n",
    "# import json\n",
    "# import re\n",
    "\n",
    "# class AdvisorHandler:\n",
    "\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "\n",
    "#     @staticmethod\n",
    "#     def convert_to_primitives(input_data):\n",
    "#         if input_data is None:\n",
    "#             return None\n",
    "#         if isinstance(input_data, dict):\n",
    "#             for key, value in input_data.items():\n",
    "#                 if isinstance(value, dict):  \n",
    "#                     input_data[key] = json.dumps(AdvisorHandler.convert_to_primitives(value), ensure_ascii=False)\n",
    "#                 else:\n",
    "#                     input_data[key] = AdvisorHandler.convert_to_primitives(value)\n",
    "#             return input_data\n",
    "#         elif isinstance(input_data, list):\n",
    "#             return [AdvisorHandler.convert_to_primitives(item) for item in input_data]\n",
    "#         elif isinstance(input_data, str):\n",
    "#             if 'http://' in input_data or 'https://' in input_data:\n",
    "#                 parts = input_data.split(\" \")\n",
    "#                 new_parts = [urllib.parse.quote(part) if part.startswith(('http://', 'https://')) else part for part in parts]\n",
    "#                 return \" \".join(new_parts)\n",
    "#             return input_data\n",
    "#         elif isinstance(input_data, (int, float, bool)):\n",
    "#             return input_data\n",
    "#         else:\n",
    "#             return str(input_data)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def debug_and_convert(input_data):\n",
    "#         try:\n",
    "#             return AdvisorHandler.convert_to_primitives(input_data)\n",
    "#         except:\n",
    "#             print(\"Conversion failed for:\", input_data)\n",
    "#             raise\n",
    "\n",
    "#     def consult_orientacoes(self, name):\n",
    "#         with self._driver.session() as session:\n",
    "#             query = (\n",
    "#                 \"MATCH (p:Person {name: $name})\"\n",
    "#                 \"RETURN p.Orientações AS orientacoes\"\n",
    "#             )\n",
    "#             result = session.run(query, name=name)\n",
    "#             orient_data = result.single()[\"orientacoes\"]\n",
    "#             if orient_data is None:\n",
    "#                 raise ValueError(f\"No data found for 'Orientações' attribute for Person '{name}'\")\n",
    "#             orient_properties_list = json.loads(orient_data)\n",
    "#             return orient_properties_list\n",
    "\n",
    "#     def create_advisor_relations(self, name):\n",
    "#         # Get Orientações properties\n",
    "#         orient_properties = self.consult_orientacoes(name)\n",
    "\n",
    "#         # Convert the serialized JSON strings back into dictionaries\n",
    "#         try:\n",
    "#             deserialized_orient_properties = self.debug_and_convert(orient_properties)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error deserializing Orientações properties: {e}\")\n",
    "#             return\n",
    "\n",
    "#         # Advisory relationship mapping\n",
    "#         advisory_types = {\n",
    "#             \"Dissertação de mestrado\": \"ORIENTOU_MESTRADO\",\n",
    "#             \"Tese de doutorado\": \"ORIENTOU_DOUTORADO\",\n",
    "#             \"Trabalho de conclusão de curso de graduação\": \"ORIENTOU_GRADUAÇÃO\"\n",
    "#         }\n",
    "\n",
    "#         successful_advisory_creations = 0\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             for orientacao_category, advisories in deserialized_orient_properties.items():\n",
    "#                 if isinstance(advisories, str):\n",
    "#                     try:\n",
    "#                         advisories = json.loads(advisories)\n",
    "#                     except json.JSONDecodeError:\n",
    "#                         print(f\"Failed to deserialize JSON string in 'Orientações' for category '{orientacao_category}': {advisories}\")\n",
    "#                         continue\n",
    "\n",
    "#                 if not isinstance(advisories, dict):\n",
    "#                     print(f\"Unexpected data type in 'Orientações' for category '{orientacao_category}': {advisories}\")\n",
    "#                     continue\n",
    "\n",
    "#                 for advisory_type, relationships in advisories.items():\n",
    "#                     relation_label = advisory_types.get(advisory_type)\n",
    "#                     if not relation_label:\n",
    "#                         continue  # skip if the advisory type is not one of the specified ones\n",
    "\n",
    "#                     for _, detail in json.loads(relationships).items():\n",
    "#                         try:\n",
    "#                             student_name = detail.split(\".\")[0]\n",
    "#                             title = detail.split(\".\")[1]\n",
    "                            \n",
    "#                             # Extract the year from the detail string\n",
    "#                             year_match = re.search(r'(\\d{4})', detail)\n",
    "#                             year = year_match.group(1) if year_match else None\n",
    "\n",
    "#                             # Create or merge the Orientações node\n",
    "#                             node_query = (\n",
    "#                                 \"MERGE (a:Orientações {Title: $title}) \"\n",
    "#                                 \"ON CREATE SET a.StudentName = $student_name, a.Tipo = $advisory_type, a.Year = $year \"\n",
    "#                                 \"ON MATCH SET a.Tipo = $advisory_type, a.Year = $year \"  # Ensure the 'Tipo' and 'Year' are always updated\n",
    "#                                 \"RETURN a\"\n",
    "#                             )\n",
    "#                             session.run(node_query, title=title, student_name=student_name, advisory_type=advisory_type, year=year)\n",
    "\n",
    "#                             # Create or update the advisory relationship\n",
    "#                             relation_query = (\n",
    "#                                 f\"MATCH (p:Person {{name: $name}}), (a:Orientações {{Title: $title}}) \"\n",
    "#                                 f\"MERGE (p)-[r:{relation_label}]->(a) \"\n",
    "#                             )\n",
    "#                             session.run(relation_query, name=name, title=title)\n",
    "\n",
    "#                             successful_advisory_creations += 1\n",
    "#                         except Exception as e:\n",
    "#                             print(f\"Error processing advisory '{detail}': {e}\")\n",
    "\n",
    "#         # Inform the user about advisories\n",
    "#         print(f\"{successful_advisory_creations} orientações atualizadas com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "\n",
    "# class DataRemovalHandler:\n",
    "\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         \"\"\"\n",
    "#         Inicializa a classe DataRemovalHandler com informações de conexão ao banco de dados Neo4j.\n",
    "\n",
    "#         Parâmetros:\n",
    "#         - uri (str): URI de conexão ao Neo4j.\n",
    "#         - user (str): Nome de usuário para autenticação.\n",
    "#         - password (str): Senha para autenticação.\n",
    "#         \"\"\"\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         \"\"\"\n",
    "#         Fecha a conexão com o banco de dados Neo4j.\n",
    "#         \"\"\"\n",
    "#         self._driver.close()\n",
    "\n",
    "#     def delete_nodes_by_label(self, label):\n",
    "#         \"\"\"\n",
    "#         Deleta todos os nós associados a um label específico no Neo4j.\n",
    "\n",
    "#         Parâmetro:\n",
    "#         - label (str): O label dos nós a serem deletados.\n",
    "\n",
    "#         Retorna:\n",
    "#         - int: O número de nós deletados.\n",
    "#         \"\"\"\n",
    "#         with self._driver.session() as session:\n",
    "#             # Esta consulta combina com todos os nós do label especificado e os deleta\n",
    "#             result = session.run(f\"MATCH (n:{label}) DETACH DELETE n RETURN count(n) as deleted_count\")\n",
    "#             deleted_count = result.single()[\"deleted_count\"]\n",
    "#             return deleted_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e663506",
   "metadata": {},
   "source": [
    "## Interação dados do e-Lattes\n",
    "\n",
    "- Fazer análise com lista dos nomes no e-lattes e baixar os arquivos gerados\n",
    "- Salvar na pasta _data/in_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090dde8d-29f4-4736-b400-beb9627220af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Funções origem para classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install levenshtein\n",
    "# !pip3 install editdistance\n",
    "# !pip3 install seaborn\n",
    "# !pip3 install pyjarowinkler\n",
    "\n",
    "# import os\n",
    "# import re\n",
    "# import csv\n",
    "# import json\n",
    "# import time\n",
    "# import json\n",
    "# import zipfile\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from string import Formatter\n",
    "# from datetime import date, timedelta\n",
    "# from datetime import datetime as dt\n",
    "# from unidecode import unidecode\n",
    "# from plotly.subplots import make_subplots\n",
    "# from pyjarowinkler.distance import get_jaro_distance\n",
    "# from IPython.display import clear_output, display, HTML\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('colheader_justify', 'left')\n",
    "\n",
    "# class PreparadorDePublicacoes:\n",
    "#     def __init__(self):\n",
    "#         self.data = []\n",
    "#         self.colunas = ['idLattes', 'nome', 'tipo', 'titulo_do_capitulo', 'idioma', 'titulo_do_livro', 'ano', 'doi', 'pais_de_publicacao', 'isbn', \n",
    "#         'nome_da_editora', 'numero_da_edicao_revisao', 'organizadores', 'paginas', 'autores', 'autores-endogeno', 'autores-endogeno-nome', 'tags', \n",
    "#         'Hash', 'tipo_producao', 'natureza', 'titulo', 'nome_do_evento', 'ano_do_trabalho', 'pais_do_evento', 'cidade_do_evento', 'classificacao', \n",
    "#         'periodico', 'volume', 'issn', 'estrato_qualis', 'editora', 'numero_de_paginas', 'numero_de_volumes']\n",
    "\n",
    "#     def extrair_dados(self, registro, tipo_producao):\n",
    "#         linha = {coluna: None for coluna in self.colunas}\n",
    "#         linha['tipo_producao'] = tipo_producao  # Define o tipo de produção com base na chave do dicionário\n",
    "        \n",
    "#         # Mapear diretamente os campos do registro para a linha, assegurando que todos os campos desejados sejam extraídos\n",
    "#         for campo in ['titulo', 'idioma', 'periodico', 'ano', 'volume', 'issn', 'estrato_qualis', 'pais_de_publicacao', 'paginas', 'doi']:\n",
    "#             linha[campo] = registro.get(campo, '')\n",
    "\n",
    "#         # Tratar os autores como uma string concatenada se eles existirem\n",
    "#         linha['autores'] = '; '.join(registro.get('autores', []))\n",
    "\n",
    "#         # Tratar os campos 'autores-endogeno' e 'autores-endogeno-nome'\n",
    "#         if 'autores-endogeno' in registro and registro['autores-endogeno']:\n",
    "#             id_endogeno = registro['autores-endogeno'][0]\n",
    "#             linha['idLattes'] = id_endogeno\n",
    "#             linha['nome'] = registro['autores-endogeno-nome'][0].get(id_endogeno, None)\n",
    "        \n",
    "#         # Adicionar os outros campos conforme necessário aqui\n",
    "#         # Por exemplo, tratamento de 'tags', 'Hash', etc., quando necessário\n",
    "\n",
    "#         return linha\n",
    "\n",
    "#     def processar_publicacoes(self):\n",
    "#         linhas = []\n",
    "#         # Itera diretamente sobre cada registro em self.data\n",
    "#         for registro in self.data:\n",
    "#             linha = self.extrair_dados(registro, registro.get('tipo_producao', 'Desconhecido'))\n",
    "#             linhas.append(linha)\n",
    "#         return linhas\n",
    "\n",
    "#     def extract_zips(self, pathzip):\n",
    "#         destination = os.path.join(os.getcwd(), '_data', 'in_json')\n",
    "#         if not os.path.exists(destination):\n",
    "#             os.makedirs(destination)\n",
    "#             print(f\"Criada pasta para armazenar dados descompactados: {destination}\")\n",
    "#         else:\n",
    "#             print(f\"Descompactando arquivos para: {destination}\")\n",
    "\n",
    "#         with zipfile.ZipFile(pathzip, 'r') as zip_ref:\n",
    "#             zip_ref.extractall(destination)\n",
    "        \n",
    "#         print(\"Descompactação concluída...\")\n",
    "#         return destination  # Retorna o caminho onde os arquivos foram descompactados\n",
    "\n",
    "#     def find_and_merge_publication_json_files(self, pathjson):\n",
    "#         all_data = []\n",
    "#         for filename in os.listdir(pathjson):\n",
    "#             if 'publication.json' in filename:\n",
    "#                 print(f\"Extraindo dados do arquivo '{filename}'...\")\n",
    "#                 with open(os.path.join(pathjson, filename), 'r', encoding='utf-8') as file:\n",
    "#                     file_data = json.load(file)\n",
    "#                     for tipo_producao in file_data:  # Para cada tipo de produção no arquivo\n",
    "#                         for ano in file_data[tipo_producao]:  # Para cada ano dentro de um tipo de produção\n",
    "#                             for registro in file_data[tipo_producao][ano]:  # Itera sobre cada registro\n",
    "#                                 # Adicionar ou atualizar o campo 'tipo_producao' em cada registro\n",
    "#                                 registro_atualizado = registro.copy()  # Fazer cópia para evitar modificar o original\n",
    "#                                 registro_atualizado['tipo_producao'] = tipo_producao  # Atualizar ou adicionar o campo 'tipo_producao'\n",
    "#                                 all_data.append(registro_atualizado)  # Adicionar o registro atualizado à lista\n",
    "\n",
    "#         # Salva a lista unificada em um novo arquivo JSON\n",
    "#         unified_json_path = os.path.join(pathjson, 'unified_pub.json')\n",
    "#         with open(unified_json_path, 'w', encoding='utf-8') as unified_file:\n",
    "#             json.dump(all_data, unified_file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "#         print(f\"Arquivo unificado criado em: {unified_json_path}\")\n",
    "\n",
    "#         # Atualiza self.data com os dados unidos\n",
    "#         self.data = all_data\n",
    "\n",
    "#     def merge_publication_json_files(self, pathjson):\n",
    "#         \"\"\"\n",
    "#         This function receives a path to a JSON folder, accesses the folder's contents, searches for files\n",
    "#         containing 'publication.json' in their filename, merges their contents and saves the resulting\n",
    "#         data as a CSV file in destination folder.\n",
    "#         \"\"\"\n",
    "#         data = []\n",
    "#         # Looping through the files in the given path\n",
    "#         for filename in os.listdir(pathjson):\n",
    "#             if 'publication.json' in filename:\n",
    "#                 print(f\"Extraindo dados do arquivo {filename}...\")\n",
    "#                 # Opening the file and appending its data to the list\n",
    "#                 with open(os.path.join(pathjson, filename), 'r', encoding='utf-8') as file:\n",
    "#                     data.append(json.load(file))\n",
    "\n",
    "#         # Creating the output directory if it doesn't exist\n",
    "#         destination = os.path.join(os.getcwd(), '_data','powerbi')\n",
    "#         if not os.path.exists(destination):\n",
    "#             os.mkdir(destination)\n",
    "\n",
    "#         # Writing the merged data to a CSV file\n",
    "#         print(f\"Criando arquivo CSV...\")\n",
    "#         with open(os.path.join(destination, 'publication.csv'), 'w', encoding='utf-8', newline='') as csv_file:\n",
    "#             writer = csv.writer(csv_file)\n",
    "#             # Writing the header based on the keys of the first item in the list\n",
    "#             writer.writerow(data[0].keys())\n",
    "#             # Looping through the items in the list and writing them as rows in the CSV file\n",
    "#             for item in data:\n",
    "#                 writer.writerow(item.values())\n",
    "\n",
    "#     def exportar_para_csv(self, nome_arquivo='publicacoes.csv'):\n",
    "#         linhas = self.processar_publicacoes()\n",
    "#         df = pd.DataFrame(linhas, columns=self.colunas)\n",
    "#         filepathcsv = os.path.join(\"./\",\"_data\",\"powerbi\",nome_arquivo)\n",
    "#         df.to_csv(filepathcsv, index=False)\n",
    "#         print(f'Arquivo criado com sucesso em {filepathcsv}')\n",
    "\n",
    "#     def ler_csv_dados(self, pathdata,filename):\n",
    "#         filepath = os.path.join(pathdata,filename)\n",
    "#         df_pub=pd.read_csv(filepath)\n",
    "#         tipos = df_pub['tipo_producao'].value_counts()\n",
    "#         qualis=df_pub['estrato_qualis'].value_counts()  \n",
    "#         quantidade_nan = df_pub['estrato_qualis'].isna().sum()\n",
    "#         tipos_qualis = qualis.count()\n",
    "#         percentual_nan=np.round(quantidade_nan/tipos.sum()*100,1)\n",
    "#         print(f\"\\n{tipos.sum()} linhas no total, distribuídas nos seguintes tipos de produção:\")\n",
    "#         print(f\"{quantidade_nan} linhas ({percentual_nan}% do total de linhas) com NaN no campo estrato_qualis\")\n",
    "#         print(tipos)\n",
    "#         ano_min=df_pub['ano'].min()\n",
    "#         ano_max=df_pub['ano'].max()\n",
    "#         print(f\"\\n{tipos.get('PERIODICO', 0)} publicações em periódicos, no período de {int(ano_min)} a {int(ano_max)}\")\n",
    "#         percentual=np.round(qualis.sum()/tipos.get('PERIODICO', 0)*100,1)\n",
    "#         print(f\"{qualis.sum()} publicações ({percentual}%) classificadas no qualis periodicos conforme estratificação:\")\n",
    "#         quantidade_nan_periodico = df_pub[df_pub['tipo_producao'] == 'PERIODICO']['estrato_qualis'].isna().sum()\n",
    "#         percentual_nan_periodico = np.round(quantidade_nan_periodico/tipos.get('PERIODICO', 0)*100,1)\n",
    "#         print(f\"{quantidade_nan_periodico} publicações em periódicos ({percentual_nan_periodico}%) com valor 'NaN' no estrato_qualis\\n\")\n",
    "#         print(qualis)\n",
    "#         return df_pub\n",
    "\n",
    "#     def ler_xls_dados(self, pathdata,filename):\n",
    "#         filepath = os.path.join(pathdata,filename)\n",
    "#         df_pub=pd.read_excel(filepath)\n",
    "#         tipos = df_pub['tipo_producao'].value_counts()\n",
    "#         qualis=df_pub['estrato_qualis'].value_counts()\n",
    "#         tipos_qualis = qualis.count()\n",
    "#         print(f\"\\n{tipos.sum()} linhas no total, distribuídas nos seguintes tipos de produção:\")\n",
    "#         print(tipos)\n",
    "#         ano_min=df_pub['ano'].min()\n",
    "#         ano_max=df_pub['ano'].max()\n",
    "#         print(f\"\\n{tipos.get('PERIODICO', 0)} publicações em periódicos, no período de {int(ano_min)} a {int(ano_max)}\")\n",
    "#         percentual=np.round(qualis.sum()/tipos.get('PERIODICO', 0)*100,1)\n",
    "#         print(f\"{qualis.sum()} publicações ({percentual}%) classificadas no qualis periodicos conforme estratificação:\")\n",
    "#         print(qualis)\n",
    "#         return df_pub\n",
    "\n",
    "#     def sigla_producao(self, tipo_producao, separador=\"\"):\n",
    "#         \"\"\"\n",
    "#         Função para converter os valores da coluna 'tipo_producao' em siglas, desconsiderando preposições,\n",
    "#         fazendo split de 'tipo_producao' em palavras também pelo caractere \"_\".\n",
    "        \n",
    "#         Parâmetros:\n",
    "#         - tipo_producao: O valor da coluna 'tipo_producao'.\n",
    "#         - separador: O caractere para separar as iniciais. Padrão é \"_\".\n",
    "        \n",
    "#         Retorna:\n",
    "#         - Uma string que é a sigla formada pelas iniciais das palavras em 'tipo_producao', desconsiderando preposições.\n",
    "#         \"\"\"\n",
    "#         # Lista de preposições para serem ignoradas\n",
    "#         preposicoes = ['e', 'de', 'do', 'da', 'dos', 'das', 'em', 'na', 'no', 'nas', 'nos', 'por', 'para', 'com']\n",
    "\n",
    "#         # Mapeamento de exemplo conforme as siglas fornecidas\n",
    "#         mapeamento_siglas = {\n",
    "#             \"DTPB\": 1, #DEMAIS_TIPOS_DE_PRODUCAO_BIBLIOGRAFICA \n",
    "#             \"TJ\": 2, #TEXTO_EM_JORNAIS\n",
    "#             \"E\": 3, #EVENTO\n",
    "#             \"CL\": 4, #CAPITULO_DE_LIVRO\n",
    "#             \"L\": 5, #LIVRO\n",
    "#             \"AA\": 6, #ARTIGO_ACEITO\n",
    "#             \"P\": 7, #PERIODICO\n",
    "#         }\n",
    "\n",
    "#         # Fazendo split por espaço e por underscore\n",
    "#         palavras = tipo_producao.replace('_', ' ').replace('-', ' ').split()\n",
    "\n",
    "#         # Inicializar a lista de iniciais\n",
    "#         iniciais = []\n",
    "\n",
    "#         for palavra in palavras:\n",
    "#             # Verificar se a palavra não é uma preposição e não está vazia\n",
    "#             if palavra.lower() not in preposicoes and palavra:\n",
    "#                 # Adicionar a inicial em maiúsculo à lista de iniciais\n",
    "#                 iniciais.append(palavra[0].upper())\n",
    "\n",
    "#         # Juntar as iniciais para formar a sigla\n",
    "#         sigla = \"\".join(iniciais)\n",
    "\n",
    "#         # Aplicar o mapeamento para encontrar o número correspondente à sigla\n",
    "#         numero = mapeamento_siglas.get(sigla, \"\")\n",
    "\n",
    "#         # Retornar a string formatada com o número e a sigla\n",
    "#         return f\"{numero}-{sigla}\"  \n",
    "\n",
    "#     def sigla_qualis(self, estrato_qualis, separador=\"\"):\n",
    "#         \"\"\"\n",
    "#         Função para converter os valores da coluna 'estrato_qualis' em siglas com números de ordenação,\n",
    "        \n",
    "#         Parâmetros:\n",
    "#         - estrato_qualis: O valor da coluna 'estrato_qualis'.\n",
    "#         - separador: O caractere para separar as iniciais. Padrão é \"_\".\n",
    "        \n",
    "#         Retorna:\n",
    "#         - Uma string que é a sigla formada pelas iniciais das palavras em 'estrato_qualis' antecedida por seu número de ordenação.\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Mapeamento de exemplo conforme as siglas fornecidas\n",
    "#         mapeamento_siglas = {\n",
    "#             \"C\": 1,\n",
    "#             \"B4\": 2,\n",
    "#             \"B3\": 3,\n",
    "#             \"B2\": 4,\n",
    "#             \"B1\": 5,\n",
    "#             \"B2\": 6,\n",
    "#             \"B1\": 7,\n",
    "#             \"A4\": 8,\n",
    "#             \"A3\": 9,\n",
    "#             \"A2\": 10,\n",
    "#             \"A1\": 11,\n",
    "#         }\n",
    "\n",
    "#         # Aplicar o mapeamento para encontrar o número correspondente à sigla\n",
    "#         numero = mapeamento_siglas.get(estrato_qualis, \"\")\n",
    "\n",
    "#         # Retornar a string formatada com o número e a sigla\n",
    "#         return f\"{numero}-{estrato_qualis}\"\n",
    "\n",
    "#     def agrupar_publicacoes(self, filename):\n",
    "#         # Caminho para o arquivo CSV\n",
    "#         pathfilename = os.path.join(os.getcwd(), '_data', 'powerbi', filename)\n",
    "#         df = pd.read_csv(pathfilename)\n",
    "\n",
    "#         # Use .loc para modificar o DataFrame diretamente e evitar o aviso\n",
    "#         df.loc[:, 'sigla_producao'] = df['tipo_producao'].apply(lambda x: self.sigla_producao(x))\n",
    "#         df_publicacoes = df[['idLattes','ano','sigla_producao']]\n",
    "\n",
    "#         # Agrupar por 'ano', 'natureza' e orientador e contar as ocorrências\n",
    "#         contagem_publicacoes = df_publicacoes.groupby(['ano','sigla_producao','idLattes']).size().reset_index(name='contagem')\n",
    "\n",
    "#         # Retornar a contagem de orientações por tipo e por ano\n",
    "#         return contagem_publicacoes\n",
    "\n",
    "#     def agrupar_qualis(self, filename):\n",
    "#         # Caminho para o arquivo CSV\n",
    "#         pathfilename = os.path.join(os.getcwd(), '_data', 'powerbi', filename)\n",
    "#         df = pd.read_csv(pathfilename)\n",
    "\n",
    "#         # # Use .loc para modificar o DataFrame diretamente e evitar o aviso\n",
    "#         df.loc[:, 'estrato_qualis'] = df['estrato_qualis'].apply(lambda x: self.sigla_qualis(x))\n",
    "#         df_publicacoes = df[['idLattes','ano','estrato_qualis']]\n",
    "\n",
    "#         # Remover todas as linhas que contêm pelo menos um valor NaN\n",
    "#         df_publicacoes_limpo = df_publicacoes.dropna()\n",
    "\n",
    "#         # Agrupar por 'ano', 'natureza' e orientador e contar as ocorrências\n",
    "#         contagem_qualis = df_publicacoes_limpo.groupby(['ano','estrato_qualis','idLattes']).size().reset_index(name='contagem')\n",
    "\n",
    "#         # Retornar a contagem de orientações por tipo e por ano\n",
    "#         return contagem_qualis\n",
    "\n",
    "#     def plotar_producoes_barras_empilhadas(self, filename):\n",
    "#         contagem_publicacoes = self.agrupar_publicacoes(filename)\n",
    "#         fig = make_subplots(rows=1, cols=1)\n",
    "#         anos = sorted(contagem_publicacoes['ano'].unique())\n",
    "\n",
    "#         mapeamento_siglas_para_numeros = {\n",
    "#             \"1-DTPB\": 1, # Demais tipos de produção bibliográfica\n",
    "#             \"2-TJ\": 2, # Texto em jornais\n",
    "#             \"3-E\": 3, # Evento\n",
    "#             \"4-CL\": 4, # Capítulo de Livro\n",
    "#             \"5-L\": 5, # Livro\n",
    "#             \"6-AA\": 6, # Artigo Aceito\n",
    "#             \"7-P\": 7, # Periódico\n",
    "#         }\n",
    "\n",
    "#         naturezas_ordenadas = sorted(contagem_publicacoes['sigla_producao'].unique(), key=lambda x: mapeamento_siglas_para_numeros.get(x, 999))\n",
    "\n",
    "#         for natureza in naturezas_ordenadas:\n",
    "#             contagem_por_ano = []\n",
    "#             labels_por_ano = [] # Para armazenar os rótulos de dados\n",
    "#             for ano in anos:\n",
    "#                 contagem = contagem_publicacoes[(contagem_publicacoes['ano'] == ano) & (contagem_publicacoes['sigla_producao'] == natureza)]['contagem'].sum()\n",
    "#                 if mapeamento_siglas_para_numeros.get(natureza, 999) in [1, 2, 3, 4]:\n",
    "#                     contagem = -contagem\n",
    "#                 contagem_por_ano.append(contagem)\n",
    "#                 labels_por_ano.append(str(contagem)) # Convertendo a contagem em string para usar como rótulo\n",
    "            \n",
    "#             # Adicionar a barra ao gráfico com rótulos de dados\n",
    "#             fig.add_trace(go.Bar(x=anos, y=contagem_por_ano, name=natureza, text=labels_por_ano, textposition='auto'))\n",
    "\n",
    "#         # Atualizar o layout para permitir barras empilhadas, ajustar o eixo Y para mostrar valores negativos, e garantir que todos os anos sejam mostrados no eixo X\n",
    "#         fig.update_layout(\n",
    "#             barmode='relative',\n",
    "#             title_text='Contagem de Produções por Tipo e Ano (Produção de divulgação plotadas abaixo do eixo X)',\n",
    "#             xaxis_title=\"Ano\",\n",
    "#             yaxis_title=\"Quantidade de Produções Biliográficas\",\n",
    "#             yaxis=dict(zeroline=True, zerolinewidth=2, zerolinecolor='black'),\n",
    "#         )        \n",
    "#         # Garantir que todos os anos apareçam na barra de rótulos do eixo X\n",
    "#         fig.update_xaxes(tickmode='array', tickvals=anos)\n",
    "#         fig.show()\n",
    "\n",
    "\n",
    "#     def plotar_qualis_barras_empilhadas(self, filename):\n",
    "#         contagem_publicacoes = self.agrupar_qualis(filename)\n",
    "#         contagem_publicacoes.replace(\"-nan\", np.nan, inplace=True)\n",
    "#         contagem_publicacoes.dropna(inplace=True)\n",
    "#         fig = make_subplots(rows=1, cols=1)\n",
    "#         anos = sorted(contagem_publicacoes['ano'].unique())\n",
    "\n",
    "#         mapeamento_siglas_para_numeros = {\n",
    "#             \"1-C\": 1, \"2-B4\": 2, \"3-B3\": 3, \"4-B2\": 4, \"5-B1\": 5,\n",
    "#             \"6-B2\": 6, \"7-B1\": 7, \"8-A4\": 8, \"9-A3\": 9, \"10-A2\": 10, \"11-A1\": 11,\n",
    "#         }\n",
    "#         naturezas_ordenadas = sorted(contagem_publicacoes['estrato_qualis'].unique(), key=lambda x: mapeamento_siglas_para_numeros.get(x, 999))\n",
    "        \n",
    "#         # Obter a paleta de cores 'Greens'\n",
    "#         cores = px.colors.sequential.Greens\n",
    "#         # Certificar que temos cores suficientes para todas as barras, repetindo a paleta se necessário\n",
    "#         num_barras = len(naturezas_ordenadas)\n",
    "#         cores_repetidas = cores * (num_barras // len(cores) + 1)\n",
    "        \n",
    "#         for index, natureza in enumerate(naturezas_ordenadas):\n",
    "#             contagem_por_ano = []\n",
    "#             for ano in anos:\n",
    "#                 contagem = contagem_publicacoes[(contagem_publicacoes['ano'] == ano) & (contagem_publicacoes['estrato_qualis'] == natureza)]['contagem'].sum()\n",
    "#                 if mapeamento_siglas_para_numeros.get(natureza, 999) in [1, 2, 3, 4, 5, 6, 7]:\n",
    "#                     contagem = -contagem\n",
    "#                 contagem_por_ano.append(contagem)\n",
    "            \n",
    "#             # Usar uma cor da paleta para cada barra\n",
    "#             fig.add_trace(go.Bar(x=anos, y=contagem_por_ano, name=natureza, marker_color=cores_repetidas[index]))\n",
    "\n",
    "#         fig.update_layout(\n",
    "#             barmode='relative',\n",
    "#             title_text='Contagem de Produções por Estrato Qualis e Ano (Qualis abaixo de B plotado do eixo X)',\n",
    "#             xaxis_title=\"Ano\",\n",
    "#             yaxis_title=\"Quantidade de Publicações\",\n",
    "#             yaxis=dict(zeroline=True, zerolinewidth=2, zerolinecolor='black'),\n",
    "#         )\n",
    "#         # Garantir que todos os anos apareçam na barra de rótulos do eixo X\n",
    "#         fig.update_xaxes(tickmode='array', tickvals=anos)        \n",
    "#         fig.show()\n",
    "\n",
    "# class PreparadorDeOrientacoes():\n",
    "#     def __init__(self):\n",
    "#         self.data = []\n",
    "#         self.colunas = ['id_lattes_orientadores', 'tipo_orientacao', 'natureza', 'titulo', 'idioma', 'ano', 'id_lattes_aluno', 'nome_aluno', 'instituicao', 'pais', 'curso', 'codigo_do_curso', 'bolsa', 'agencia_financiadora', 'codigo_agencia_financiadora', 'nome_orientadores', 'tags', 'Hash']\n",
    "#         self.pathjson = os.path.join('_data','in_json')\n",
    "#         # self.filename = '863.advise.json'\n",
    "\n",
    "#         # Abrir o arquivo e carregando o JSON\n",
    "#     def open_file(self, filename):\n",
    "#         with open(os.path.join(self.pathjson, filename), 'r', encoding='utf-8') as file:\n",
    "#             data = json.load(file)\n",
    "        \n",
    "#         linhas_achatadas = self.extrair_orientacoes(data)\n",
    "#         df = pd.DataFrame(linhas_achatadas)\n",
    "#         df.to_csv('orientacoes_achatadas.csv', index=False)\n",
    "#         return df\n",
    "    \n",
    "#     def agrupar_orientacoes(self, filename):\n",
    "#         # Caminho para o arquivo JSON\n",
    "#         pathfilename = os.path.join('_data', 'in_json', filename)\n",
    "#         # dict_orientacoes = pd.read_json(pathfilename)\n",
    "\n",
    "#         # Carregar o JSON e aplicar a função\n",
    "#         with open(pathfilename, 'r', encoding='utf-8') as file:\n",
    "#             data = json.load(file)\n",
    "\n",
    "#         linhas_achatadas = self.extrair_orientacoes(data)\n",
    "#         df = pd.DataFrame(linhas_achatadas)\n",
    "\n",
    "#         # Salvar os dados achatados em um CSV\n",
    "#         df.to_csv('orientacoes_achatadas.csv', index=False)\n",
    "\n",
    "#         # Use .loc para modificar o DataFrame diretamente e evitar o aviso\n",
    "#         df.loc[:, 'sigla_natureza'] = df['natureza'].apply(lambda x: self.sigla_natureza(x))\n",
    "#         df_orientacoes = df[['id_lattes_orientadores','ano','sigla_natureza']]\n",
    "\n",
    "#         # Agrupar por 'ano', 'natureza' e orientador e contar as ocorrências\n",
    "#         contagem_orientacoes = df_orientacoes.groupby(['ano','sigla_natureza','id_lattes_orientadores']).size().reset_index(name='contagem')\n",
    "\n",
    "#         # Retornar a contagem de orientações por tipo e por ano\n",
    "#         return contagem_orientacoes\n",
    "\n",
    "#     # Prosseguir com a definição e uso da função para extrair as orientações\n",
    "#     def extrair_orientacoes(self, json_data):\n",
    "#         colunas = self.colunas\n",
    "#         linhas = []\n",
    "\n",
    "#         # Iterar sobre cada tipo de orientação e ano\n",
    "#         for tipo_orientacao, anos in json_data.items():\n",
    "#             for ano, orientacoes in anos.items():\n",
    "#                 for orientacao in orientacoes:\n",
    "#                     # Preparar um dicionário para cada linha de acordo com as colunas definidas\n",
    "#                     linha = {}\n",
    "#                     # Adicionar dados específicos da orientação\n",
    "#                     for campo in orientacao:\n",
    "#                         if campo in colunas:\n",
    "#                             linha[campo] = orientacao[campo]\n",
    "#                     # Tratar 'id_lattes_orientadores' como uma lista, juntar os IDs com vírgula se houver mais de um\n",
    "#                     linha['id_lattes_orientadores'] = ', '.join(orientacao.get('id_lattes_orientadores', []))\n",
    "#                     # Adicionar o tipo de orientação como uma coluna\n",
    "#                     linha['tipo_orientacao'] = tipo_orientacao\n",
    "#                     # Adicionar o ano, garantindo que sobreponha qualquer valor de 'ano' nos dados individuais\n",
    "#                     linha['ano'] = ano\n",
    "#                     linhas.append(linha)\n",
    "\n",
    "#         return linhas\n",
    "\n",
    "#     def sigla_natureza(self, natureza, separador=\"\"):\n",
    "#         \"\"\"\n",
    "#         Função para converter os valores da coluna 'natureza' em siglas, desconsiderando preposições,\n",
    "#         fazendo split de 'natureza' em palavras também pelo caractere \"_\".\n",
    "        \n",
    "#         Parâmetros:\n",
    "#         - natureza: O valor da coluna 'natureza'.\n",
    "#         - separador: O caractere para separar as iniciais. Padrão é \"_\".\n",
    "        \n",
    "#         Retorna:\n",
    "#         - Uma string que é a sigla formada pelas iniciais das palavras em 'natureza', desconsiderando preposições.\n",
    "#         \"\"\"\n",
    "#         # Lista de preposições para serem ignoradas\n",
    "#         preposicoes = ['e', 'de', 'do', 'da', 'dos', 'das', 'em', 'na', 'no', 'nas', 'nos', 'por', 'para', 'com']\n",
    "\n",
    "#         # Mapeamento de exemplo conforme as siglas fornecidas\n",
    "#         mapeamento_siglas = {\n",
    "#             \"OON\": 1, #Orientações de Outra Natureza\n",
    "#             \"IC\": 2, #Iniciação Científica\n",
    "#             \"MCCAE\": 3, #Monografia de Conclusão Curso de Atualização ou Especialização\n",
    "#             \"SPD\": 4, #\n",
    "#             \"TCCG\": 5, #Trabalho de Conclusão de Curso de Graduação\n",
    "#             \"DM\": 6, #Dissertação de Mestrado\n",
    "#             \"TD\": 7, #Tese de Doutorado\n",
    "#         }\n",
    "\n",
    "#         # Fazendo split por espaço e por underscore\n",
    "#         palavras = natureza.replace('_', ' ').replace('-', ' ').split()\n",
    "\n",
    "#         # Inicializar a lista de iniciais\n",
    "#         iniciais = []\n",
    "\n",
    "#         for palavra in palavras:\n",
    "#             # Verificar se a palavra não é uma preposição e não está vazia\n",
    "#             if palavra.lower() not in preposicoes and palavra:\n",
    "#                 # Adicionar a inicial em maiúsculo à lista de iniciais\n",
    "#                 iniciais.append(palavra[0].upper())\n",
    "\n",
    "#         # Juntar as iniciais para formar a sigla\n",
    "#         sigla = \"\".join(iniciais)\n",
    "\n",
    "#         # Aplicar o mapeamento para encontrar o número correspondente à sigla\n",
    "#         numero = mapeamento_siglas.get(sigla, \"Desconhecido\")\n",
    "\n",
    "#         # Retornar a string formatada com o número e a sigla\n",
    "#         return f\"{numero}-{sigla}\"     \n",
    "\n",
    "#     def plotar_orientacoes_barras_agrupadas(self, filename):\n",
    "#         # montar dataframe com agrupamento de orientações por tipo por ano no programa\n",
    "#         contagem_orientacoes = self.agrupar_orientacoes(filename)\n",
    "\n",
    "#         # Criar uma figura com subplots\n",
    "#         fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "#         # Encontrar anos e naturezas únicos para as orientações\n",
    "#         anos = sorted(contagem_orientacoes['ano'].unique())\n",
    "\n",
    "#         # Mapeamento de exemplo conforme as siglas fornecidas\n",
    "#         mapeamento_siglas = {\n",
    "#             \"OON\": 1,\n",
    "#             \"IC\": 2,\n",
    "#             \"MCCAE\": 3,\n",
    "#             \"SPD\": 4,\n",
    "#             \"TCCG\": 5,\n",
    "#             \"DM\": 6,\n",
    "#             \"TD\": 7,\n",
    "#         }\n",
    "\n",
    "#         # Ordenar as naturezas com base nos números associados em mapeamento_siglas\n",
    "#         mapeamento_siglas_para_numeros = {sigla: int(sigla.split('-')[0]) for sigla in contagem_orientacoes['sigla_natureza'].unique()}\n",
    "#         naturezas_ordenadas = sorted(contagem_orientacoes['sigla_natureza'].unique(), key=lambda x: mapeamento_siglas_para_numeros.get(x, 999))\n",
    "\n",
    "#         # Criar uma barra para cada tipo de orientação em cada ano\n",
    "#         for natureza in naturezas_ordenadas:\n",
    "#             contagem_por_ano = []\n",
    "#             for ano in anos:\n",
    "#                 # Somar as contagens para cada ano e natureza\n",
    "#                 contagem = contagem_orientacoes[(contagem_orientacoes['ano'] == ano) & (contagem_orientacoes['sigla_natureza'] == natureza)]['contagem'].sum()\n",
    "#                 contagem_por_ano.append(contagem)\n",
    "            \n",
    "#             # Adicionar a barra ao gráfico\n",
    "#             fig.add_trace(go.Bar(x=anos, y=contagem_por_ano, name=natureza))\n",
    "\n",
    "#         # Atualizar o layout para permitir barras agrupadas\n",
    "#         fig.update_layout(barmode='group', title_text='Contagem de Orientações no Programa por Tipo e Ano', xaxis_title=\"Ano\", yaxis_title=\"Quantidade de Orientações\")\n",
    "\n",
    "#         # Mostrar o gráfico\n",
    "#         fig.show()\n",
    "\n",
    "\n",
    "#     def plotar_orientacoes_barras_empilhadas(self, filename):\n",
    "#         # montar dataframe com agrupamento de orientações por tipo por ano no programa\n",
    "#         contagem_orientacoes = self.agrupar_orientacoes(filename)\n",
    "        \n",
    "#         # Criar uma figura com subplots\n",
    "#         fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "#         # Encontrar anos únicos para as orientações\n",
    "#         anos = sorted(contagem_orientacoes['ano'].unique())\n",
    "\n",
    "#         # Mapeamento para siglas de tipos de orientações\n",
    "#         mapeamento_siglas = {\n",
    "#             \"OON\": 1,\n",
    "#             \"IC\": 2,\n",
    "#             \"MCCAE\": 3,\n",
    "#             \"SPD\": 4,\n",
    "#             \"TCCG\": 5,\n",
    "#             \"DM\": 6,\n",
    "#             \"TD\": 7,\n",
    "#         }\n",
    "\n",
    "#         # Mapeamento para ordenar siglas por duração/complexidade\n",
    "#         mapeamento_siglas_para_numeros = {\n",
    "#             \"1-OON\": 1,\n",
    "#             \"2-IC\": 2,\n",
    "#             \"3-MCCAE\": 3,\n",
    "#             \"4-SPD\": 4,\n",
    "#             \"5-TCCG\": 5,\n",
    "#             \"6-DM\": 6,\n",
    "#             \"7-TD\": 7,\n",
    "#         }\n",
    "\n",
    "#         # Ordenar as naturezas baseando-se no número extraído da sigla\n",
    "#         naturezas_ordenadas = sorted(contagem_orientacoes['sigla_natureza'].unique(), key=lambda x: mapeamento_siglas_para_numeros.get(x, 999))\n",
    "\n",
    "#         # Criar uma barra para cada tipo de orientação em cada ano, seguindo a ordem definida\n",
    "#         for natureza in naturezas_ordenadas:\n",
    "#             contagem_por_ano = []\n",
    "#             for ano in anos:\n",
    "#                 # Somar as contagens para cada ano e natureza\n",
    "#                 contagem = contagem_orientacoes[(contagem_orientacoes['ano'] == ano) & (contagem_orientacoes['sigla_natureza'] == natureza)]['contagem'].sum()\n",
    "#                 # Se a sigla estiver associada ao número 1 ou 2, tornar a contagem negativa\n",
    "#                 if mapeamento_siglas_para_numeros.get(natureza, 999) in [1, 2, 3, 4]:\n",
    "#                     contagem = -contagem\n",
    "#                 contagem_por_ano.append(contagem)\n",
    "            \n",
    "#             # Adicionar a barra ao gráfico\n",
    "#             fig.add_trace(go.Bar(x=anos, y=contagem_por_ano, name=natureza))\n",
    "\n",
    "#         # Atualizar o layout para permitir barras empilhadas e ajustar o eixo Y para mostrar valores negativos\n",
    "#         fig.update_layout(\n",
    "#             barmode='relative',  # Usar 'relative' para empilhar incluindo valores negativos\n",
    "#             title_text='Contagem de Orientações por Tipo e Ano (Orientações de curta duração plotadas abaixo do eixo X)',\n",
    "#             xaxis_title=\"Ano\",\n",
    "#             yaxis_title=\"Quantidade de Orientações\",\n",
    "#             yaxis=dict(zeroline=True, zerolinewidth=2, zerolinecolor='black'),  # Destacar a linha zero\n",
    "#         )\n",
    "\n",
    "#         # Mostrar o gráfico\n",
    "#         fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8007a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"./\"\n",
    "# print(f\"     Pasta corrente: {path}\")\n",
    "# pathjson = os.path.join(path,'_data','in_json')\n",
    "# print(f\"Pasta arquivos JSON: {pathjson}\")\n",
    "# try:\n",
    "#     pathdata = os.path.join(path,'_data','powerbi')\n",
    "#     print(f\" Pasta de dados CSV: {pathdata}\")\n",
    "# except:\n",
    "#     print('Pasta de dados ainda não existe.')\n",
    "\n",
    "# print(\"\\nConteúdo da pasta JSON:\")\n",
    "# list(os.listdir(pathjson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Descompactar arquivo zipado na pasta JSON\n",
    "# prep_pub = PreparadorDePublicacoes()\n",
    "# pathfilezip = '_data/in_zip/890.files.zip'\n",
    "# destination = prep_pub.extract_zips(pathfilezip)\n",
    "\n",
    "# ## Unir todos aquivos de publicações (caso haja mais de um com final publication.json na pasta serão mesclados):\n",
    "# prep_pub.find_and_merge_publication_json_files(pathjson)\n",
    "\n",
    "# ## Mapear arquivo de dados para PowerBI a partir do JSON unificado\n",
    "# linhas = prep_pub.processar_publicacoes()\n",
    "# prep_pub.exportar_para_csv()\n",
    "\n",
    "# ## Ler e montar análise exploratória\n",
    "# filename='publicacoes.csv'\n",
    "# df_pub = prep_pub.ler_csv_dados(pathdata,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61df53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename='890.advise.json'\n",
    "# pathjson = os.path.join('_data','in_json')\n",
    "# pathfilename = os.path.join(pathjson,filename)\n",
    "# print(pathfilename)\n",
    "# dict_orientacoes = pd.read_json(pathfilename)\n",
    "# print(f'{len(dict_orientacoes):02} dicionários com dados de orientações')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_orientacoes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c4685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep_ort = PreparadorDeOrientacoes()\n",
    "# prep_ort.plotar_orientacoes_barras_agrupadas(filename)\n",
    "# prep_ort.plotar_orientacoes_barras_empilhadas(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathcsv = os.path.join('_data','powerbi')\n",
    "# os.listdir(pathcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be258ab8",
   "metadata": {},
   "source": [
    "## Demais passos\n",
    "\n",
    "Calcular índice de publicação em conjunto com alunos do programa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1574aac1",
   "metadata": {},
   "source": [
    "- Levantar nome dos discentes do programa\n",
    "- Levantar os nomes de autores nas publicações de docentes\n",
    "- Identificar por similadidade as publicações onde constam nome de alunos do programa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb00d652",
   "metadata": {},
   "source": [
    "    Padronizar nomes de autores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94552058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def limpar_nomes(linha_texto):\n",
    "#     '''\n",
    "#     Retira erros e sujeira da string formada pela lista de nomes de autor dos artigos retirada do Lattes\n",
    "#      Recebe: Uma string com os nomes de autor\n",
    "#     Retorna: Uma string com os nomes de autor, removidas preposições, acentos, e demais erros pontuais\n",
    "#     '''\n",
    "#     import unicodedata\n",
    "#     import re\n",
    "#     # print('               Analisando:',linha_texto)\n",
    "#     string = linha_texto.replace('Network for Genomic Surveillance in South Africa;Network for Genomic Surveillance in South Africa (NGS-SA);10.1002/jmv.27190;','')\n",
    "#     string = string.replace('Autores: ','').replace('(Org)','').replace('(Org.)','').replace('et. al.','').replace('et al','').replace('(Org).','').replace('.','').replace('\\'','')\n",
    "#     string = string.replace(',,,',',').replace(',,',',').replace(';',', ').replace('-',' ').replace('S?', 'SA').replace('S?', 'SA').replace('ARA?JO', 'ARAUJO').replace('FL?VIO','FLAVIO').replace('F?BIO','FABIO').replace('VIT?RIO','VITORIO')\n",
    "#     string = re.sub(r'[0-9]+', '', string)\n",
    "#     partes_string = string.split(' ')\n",
    "\n",
    "#     ## Retirar partes de nomes caso sejam preposições\n",
    "#     preposicoes = ['da', 'de', 'do', 'das', 'dos', ' e ']\n",
    "#     string = ' '.join(x for x in partes_string if x.lower() not in preposicoes)\n",
    "\n",
    "#     ## Retirar símbolos não unicode, como acentuação gráfica e cedilha\n",
    "#     string = ''.join(ch for ch in unicodedata.normalize('NFKD', string) if not unicodedata.combining(ch))\n",
    "    \n",
    "#     ## Retirar iniciais juntas, separando-as com espaço em branco\n",
    "#     letras_duasconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2}$')            # Duas Letras consoantes maiúsculas juntas do início ao final da string\n",
    "#     letras_tresconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3}$')            # Três Letras consoantes maiúsculas juntas do início ao final da string\n",
    "#     letras_duasconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2},$')       # Duas Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "#     letras_tresconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3},$')       # Três Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "    \n",
    "#     partes_nome=[]\n",
    "#     for j in string.split(' '):\n",
    "#         div_ltrduasconsnts = letras_duasconsnts.findall(j)\n",
    "#         div_ltrtriplicadas = letras_tresconsnts.findall(j)\n",
    "#         div_ltrduasconsntsvirg = letras_duasconsntsvirg.findall(j)\n",
    "#         div_ltrtresconsntsvirg = letras_tresconsntsvirg.findall(j)\n",
    "#         if div_ltrduasconsnts or div_ltrtriplicadas:\n",
    "#             iniciais_separadas = ' '.join(x for x in j)\n",
    "#             partes_nome.append(iniciais_separadas)\n",
    "#         elif div_ltrduasconsntsvirg or div_ltrtresconsntsvirg:\n",
    "#             iniciais_separadas = ' '.join(x for x in j[:-1])\n",
    "#             partes_nome.append(iniciais_separadas+',')\n",
    "#         else:\n",
    "#             partes_nome.append(j)\n",
    "#     string = ' '.join(x for x in partes_nome).strip()\n",
    "#     return string\n",
    "\n",
    "\n",
    "\n",
    "# def padronizar_nome(linha_texto):\n",
    "#     '''\n",
    "#     Procura sobrenomes e abreviaturas e monta nome completo\n",
    "#      Recebe: String com todos os sobrenomes e nomes, abreviados ou não\n",
    "#     Retorna: Nome completo no formato padronizado em SOBRENOME AGNOME, Partes de nomes\n",
    "#       Autor: Marcos Aires (Mar.2022)\n",
    "#     '''\n",
    "#     import unicodedata\n",
    "#     import re\n",
    "#     # print('               Analisando:',linha_texto)\n",
    "#     partes_string = linha_texto.split(' ')\n",
    "\n",
    "#     ## Retirar partes de nomes caso sejam preposições\n",
    "#     preposicoes = ['da', 'de', 'do', 'das', 'dos', ' e ']\n",
    "#     string = ' '.join(x for x in partes_string if x.lower() not in preposicoes)\n",
    "\n",
    "#     ## Retirar símbolos não unicode, como acentuação gráfica e cedilha\n",
    "#     string = ''.join(ch for ch in unicodedata.normalize('NFKD', string) if not unicodedata.combining(ch))\n",
    "    \n",
    "#     ## Expressões regulares para encontrar padrões de divisão de nomes de autores\n",
    "#     sobrenome_inicio   = re.compile(r'^[A-ZÀ-ú-a-z]+,')                  # Sequência de letras maiúsculas no início da string\n",
    "#     sobrenome_composto = re.compile(r'^[A-ZÀ-ú-a-z]+[ ][A-ZÀ-ú-a-z]+,')  # Duas sequências de letras no início da string, separadas por espaço, seguidas por vírgula\n",
    "#     letra_abrevponto   = re.compile(r'^[A-Z][.]')                        # Uma letra maiúscula no início da string, seguida por ponto\n",
    "#     letra_abrevespaco  = re.compile(r'^[A-Z][ ]')                        # Uma letra maiúscula no início da string, seguida por espaço\n",
    "#     letras_dobradas    = re.compile(r'[A-Z]{2}')                         # Duas letras maiúsculas juntas\n",
    "#     letras_dobradasini = re.compile(r'[A-Z]{2}[ ]')                      # Duas letras maiúsculas juntas, seguidas por espaço\n",
    "#     letras_dobradasfim = re.compile(r'[ ][A-Z]{2}')                      # Duas letras maiúsculas juntas, precedidas por espaço\n",
    "\n",
    "#     ## Expressões regulares para encontrar iniciais juntas, separando-as com espaço em branco\n",
    "#     letras_duasconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2}$')            # Duas Letras consoantes maiúsculas juntas do início ao final da string\n",
    "#     letras_tresconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3}$')            # Três Letras consoantes maiúsculas juntas do início ao final da string\n",
    "#     letras_duasconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2},$')       # Duas Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "#     letras_tresconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3},$')       # Três Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "\n",
    "#     ## Agnomes e preprosições a tratar, agnomes vão em maiúsculas para sobrenome e preposições vão em minúsculas para restante das partes de nomes\n",
    "#     nomes=[]\n",
    "#     agnomes       = ['NETO','JUNIOR','FILHO','SEGUNDO','TERCEIRO','SOBRINHO']\n",
    "#     preposicoes   = ['de','da','do','das','dos', ' e ']\n",
    "#     nome_completo = ''\n",
    "    \n",
    "#     ## Ajustar lista de termos, identificar sobrenomes compostos e ajustar sobrenome com ou sem presença de vírgula\n",
    "#     div_sobrenome   = sobrenome_inicio.findall(string)\n",
    "#     div_sbrcomposto = sobrenome_composto.findall(string)\n",
    "    \n",
    "#     # print('-'*100)\n",
    "#     # print('                 Recebido:',string)\n",
    "    \n",
    "#     ## Caso haja vírgulas na string, tratar sobrenomes e sobrenomes compostos\n",
    "#     if div_sobrenome != [] or div_sbrcomposto != []:\n",
    "#         # print('CASO_01: Há víruglas na string')\n",
    "#         div = string.split(', ')\n",
    "#         sobrenome     = div[0].strip().upper()\n",
    "#         try:\n",
    "#             div_espaco    = div[1].split(' ')\n",
    "#         except:\n",
    "#             div_espaco    = ['']\n",
    "#         primeiro      = div_espaco[0].strip('.').strip()\n",
    "        \n",
    "#         # print('     Dividir por vírgulas:',div)\n",
    "#         # print('      Primeira DivVirgula:',sobrenome)\n",
    "#         # print('Segunda DivVrg/DivEspaços:',div_espaco)\n",
    "#         # print('      Primeira DivEspaços:',primeiro)\n",
    "               \n",
    "#         # Caso primeiro nome seja somente duas letras maiúsculas juntas, trata-se de duas iniciais\n",
    "#         if len(primeiro)==2 or letras_tresconsnts.findall(primeiro) or letras_duasconsnts.findall(primeiro):\n",
    "#             # print('CASO_01.a: Há duas letras ou três letras consoantes juntas, são iniciais')\n",
    "#             primeiro_nome=primeiro[0].strip()\n",
    "#             # print('          C01.a1_PrimNome:',primeiro_nome)\n",
    "#             nomes.append(primeiro[1].strip().upper())\n",
    "#             try:\n",
    "#                 nomes.append(primeiro[2].strip().upper())\n",
    "#             except:\n",
    "#                 pass\n",
    "#             try:\n",
    "#                 nomes.append(primeiro[3].strip().upper())\n",
    "#             except:\n",
    "#                 pass            \n",
    "#         else:\n",
    "#             # print('CASO_01.b: Primeiro nome maior que 2 caracteres')\n",
    "#             primeiro_nome = div_espaco[0].strip().title()\n",
    "#             # print('          C01.a2_PrimNome:',primeiro_nome)\n",
    "        \n",
    "#         ## Montagem da lista de partes de nomes do meio\n",
    "#         for nome in div_espaco:\n",
    "#             # print('CASO_01.c: Para cada parte de nome da divisão por espaços após divisão por vírgula')\n",
    "#             if nome not in nomes and nome.lower()!=primeiro_nome.lower() and nome.lower() not in primeiro_nome.lower() and nome!=sobrenome:   \n",
    "#                 # print('CASO_01.c1: Se o nome não está nem como primeiro nome, nem sobrenomes')\n",
    "#                 # print(nome, len(nome))\n",
    "                \n",
    "#                 ## Avaliar se é abreviatura seguida de ponto e remover o ponto\n",
    "#                 if len(nome)<=2 and nome.lower() not in preposicoes:\n",
    "#                     # print('    C01.c1.1_Nome<=02:',nome)\n",
    "#                     for inicial in nome:\n",
    "#                         # print(inicial)\n",
    "#                         if inicial not in nomes and inicial not in primeiro_nome:\n",
    "#                             nomes.append(inicial.replace('.','').strip().title())\n",
    "#                 elif len(nome)==3 and nome.lower() not in preposicoes:\n",
    "#                         # print('    C01.c1.2_Nome==03:',nome)\n",
    "#                         for inicial in nome:\n",
    "#                             if inicial not in nomes and inicial not in primeiro_nome:\n",
    "#                                 nomes.append(inicial.replace('.','').strip().title())\n",
    "#                 else:\n",
    "#                     if nome not in nomes and nome!=primeiro_nome and nome!=sobrenome and nome!='':\n",
    "#                         if nome.lower() in preposicoes:\n",
    "#                             nomes.append(nome.replace('.','').strip().lower())\n",
    "#                         else:\n",
    "#                             nomes.append(nome.replace('.','').strip().title())\n",
    "#                         # print(nome,'|',primeiro_nome)\n",
    "                        \n",
    "#         ## Caso haja sobrenome composto que não esteja nos agnomes considerar somente primeira parte como sobrenome\n",
    "#         if div_sbrcomposto !=[] and sobrenome.split(' ')[1] not in agnomes and sobrenome.split(' ')[0].lower() not in preposicoes:\n",
    "#             # print('CASO_01.d: Sobrenome composto sem agnomes')\n",
    "#             # print(div_sbrcomposto)\n",
    "#             # print('Sobrenome composto:',sobrenome)\n",
    "            \n",
    "#             nomes.append(sobrenome.split(' ')[1].title())\n",
    "#             sobrenome = sobrenome.split(' ')[0].upper().strip()\n",
    "#             # print('Sobrenome:',sobrenome)\n",
    "            \n",
    "#             for i in nomes:\n",
    "#                 if i.lower() in sobrenome.lower():\n",
    "#                     nomes.remove(i)\n",
    "#             # print('    Nomes:',nomes)\n",
    "        \n",
    "#         ## Caso haja preposição como agnome desconsiderar e passar para final dos nomes\n",
    "#         if div_sbrcomposto !=[] and sobrenome.split(' ')[0].lower() in preposicoes:\n",
    "#             # print('CASO_01.e: Preposição no Sobrenome passar para o final dos nomes')\n",
    "#             # print('   div_sbrcomposto:', div_sbrcomposto)\n",
    "#             # print('Sobrenome composto:',div_sbrcomposto)\n",
    "            \n",
    "#             nomes.append(div_sbrcomposto[0].split(' ')[0].lower())\n",
    "#             # print('    Nomes:',nomes)\n",
    "#             sobrenome = div_sbrcomposto[0].split(' ')[1].upper().strip(',').strip()\n",
    "#             # print('Sobrenome:',sobrenome)\n",
    "            \n",
    "#             for i in nomes:\n",
    "#                 # print('CASO_01.e1: Para cada nome avaliar se o sobrenome está na lista')\n",
    "#                 if i.lower() in sobrenome.lower():\n",
    "#                     nomes.remove(i)\n",
    "#             # print('  Nomes:',nomes)\n",
    "        \n",
    "#         # print('Ao final do Caso 01')\n",
    "#         # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "#         # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "#         # print('           Lista de nomes:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "#     ## Caso não haja vírgulas na string considera sobrenome o último nome da string dividida com espaço vazio\n",
    "#     else:\n",
    "#         # print('CASO_02: Não há víruglas na string')\n",
    "#         try:\n",
    "#             div = string.split(' ')\n",
    "#             # print('      Divisões por espaço:',div)\n",
    "            \n",
    "#             if div[-1] in agnomes: # nome final é um agnome\n",
    "#                 sobrenome     = div[-2].upper().strip()+' '+div[-1].upper().strip()\n",
    "#                 for i in div[1:-2]:\n",
    "#                     if i not in sobrenome and i not in preposicoes:\n",
    "#                         nomes.append(i.title().strip())\n",
    "#                     if i in preposicoes:\n",
    "#                         nomes.append(i.lower().strip())\n",
    "#             else:\n",
    "#                 if len(div[-1]) > 2:\n",
    "#                     sobrenome     = div[-1].upper().strip()\n",
    "#                     primeiro_nome = div[1].title().strip()\n",
    "#                     for i in div[1:-1]:\n",
    "#                         if i != sobrenome and i not in preposicoes:\n",
    "#                             nomes.append(i.title().strip())\n",
    "#                         if i in preposicoes:\n",
    "#                             nomes.append(i.lower().strip())\n",
    "#                 else:\n",
    "#                     sobrenome     = div[-2].upper().strip()\n",
    "#                     for i in div[-1]:\n",
    "#                         nomes.append(i.title())\n",
    "#                     primeiro_nome = nomes[0].title().strip()\n",
    "#                     for i in div[1:-1]:\n",
    "#                         if i != sobrenome and i not in preposicoes:\n",
    "#                             nomes.append(i.title().strip())\n",
    "#                         if i in preposicoes:\n",
    "#                             nomes.append(i.lower().strip())\n",
    "#         except:\n",
    "#             sobrenome = div[-1].upper().strip()\n",
    "#             for i in div[1:-1]:\n",
    "#                     if i != sobrenome and i not in preposicoes:\n",
    "#                         nomes.append(i.title().strip())\n",
    "#                     if i in preposicoes:\n",
    "#                         nomes.append(i.lower().strip())\n",
    "            \n",
    "#         if sobrenome.lower() != div[0].lower().strip():\n",
    "#             primeiro_nome=div[0].title().strip()\n",
    "#         else:\n",
    "#             primeiro_nome=''\n",
    "        \n",
    "#         # print('Ao final do Caso 02')\n",
    "#         # print('    Sobrenome sem vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "#         # print('Primeiro nome sem vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "#         # print('Nomes do meio sem vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "#     ## Encontrar e tratar como abreviaturas termos com apenas uma ou duas letras iniciais juntas, com ou sem ponto\n",
    "#     for j in nomes:\n",
    "#         # print('CASO_03: Avaliar cada nome armazenado na variável nomes')\n",
    "#         # Procura padrões com expressões regulares na string\n",
    "#         div_sobrenome      = sobrenome_inicio.findall(j)\n",
    "#         div_sbrcomposto    = sobrenome_composto.findall(j)\n",
    "#         div_abrevponto     = letra_abrevponto.findall(j)\n",
    "#         div_abrevespaco    = letra_abrevespaco.findall(j)\n",
    "#         div_ltrdobradasini = letras_dobradasini.findall(j)\n",
    "#         div_ltrdobradasfim = letras_dobradasfim.findall(j)\n",
    "#         div_ltrdobradas    = letras_dobradas.findall(j)\n",
    "#         div_ltrduasconsnts = letras_duasconsnts.findall(j)\n",
    "#         div_ltrtriplicadas = letras_tresconsnts.findall(j)\n",
    "#         tamanho=len(j)\n",
    "#         # print('\\n', div_ltrdobradasini, div_ltrdobradasfim, tamanho, 'em:',j,len(j))\n",
    "        \n",
    "#         ## Caso houver abreviatura com uma letra em maiúscula nos nomes\n",
    "#         if div_abrevponto !=[] or tamanho==1:\n",
    "#             # print('CASO_03.1: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "#             nome = j.replace('.','').strip()\n",
    "#             if nome not in nomes and nome != sobrenome and nome != primeiro_nome:\n",
    "#                 # print('CASO_03.1a: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "#                 nomes.append(nome.upper())\n",
    "        \n",
    "#         ## Caso houver duas inicias juntas em maiúsculas\n",
    "#         elif div_ltrdobradasini !=[] or div_ltrdobradasfim !=[] or div_ltrdobradas !=[] :\n",
    "#             # print('CASO_03.2: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "#             for letra in j:\n",
    "#                 # print('CASO_03.2a: Avaliar cada inicial do nome')\n",
    "#                 if letra not in nomes and letra != sobrenome and letra != primeiro_nome:\n",
    "#                     # print('CASO_03.2a.1: Se não estiver adicionar inicial aos nomes')\n",
    "#                     nomes.append(letra.upper())\n",
    "        \n",
    "#         # Caso haja agnomes ao sobrenome\n",
    "#         elif sobrenome in agnomes:\n",
    "#             # print('CASO_03.3: Há agnomes nos sobrenomes')\n",
    "#             sobrenome = nomes[-1].upper()+' '+sobrenome\n",
    "#             # print(sobrenome.split(' '))\n",
    "#             # print('Sobrenome composto:',sobrenome)\n",
    "#             for i in nomes:\n",
    "#                 if i.lower() in sobrenome.lower():\n",
    "#                     nomes.remove(i)\n",
    "#             # print('Nomes do meio:',nomes)\n",
    "            \n",
    "#         else:\n",
    "#             # print('CASO_03.4: Não há agnomes nos sobrenomes')\n",
    "#             if j not in nomes and j not in sobrenome and j != primeiro_nome:\n",
    "#                 if len(nomes) == 1:\n",
    "#                     nomes.append(j.upper())\n",
    "#                 elif 1 < len(nomes) <= 3:\n",
    "#                     nomes.append(j.lower())\n",
    "#                 else:\n",
    "#                     nomes.append(j.title())\n",
    "         \n",
    "#         # print('Ao final do Caso 03')\n",
    "#         # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "#         # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "#         # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "#     nomes_meio=' '.join([str for str in nomes]).strip()\n",
    "#     # print('        Qte nomes do meio:',nomes,len(nomes))\n",
    "    \n",
    "#     if primeiro_nome.lower() == sobrenome.lower():\n",
    "#         # print('CASO_04: Primeiro nome é igual ao sobrenome')\n",
    "#         try:\n",
    "#             primeiro_nome=nomes_meio.split(' ')[0]\n",
    "#         except:\n",
    "#             pass\n",
    "#         try:\n",
    "#             nomes_meio.remove(sobrenome)\n",
    "#         except:\n",
    "#             pass\n",
    "    \n",
    "#         # print('Ao final do caso 04')\n",
    "#         # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "#         # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "#         # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "#     ## Caso sobrenome seja só de 1 letra passá-lo para nomes e considerar o próximo nome como sobrenome\n",
    "#     for i in range(len(div)):\n",
    "#         if len(sobrenome)==1 or sobrenome.lower() in preposicoes:\n",
    "#             # print('CASO_05: Mudar sobrenomes até o adequado')\n",
    "#             div    = string.split(', ')\n",
    "#             # print('Divisão por vírgulas:',div)\n",
    "#             avaliar0       = div[0].split(' ')[0].strip()\n",
    "#             if 1< len(avaliar0) < 3:\n",
    "#                 # print('CASO_05.1: 1 < Sobrenome < 3 fica em minúsculas')\n",
    "#                 sbrn0          = avaliar0.lower()\n",
    "#             else:\n",
    "#                 # print('CASO_05.2: Sobrenome de tamanho 1 ou maior que 3 fica em maiúsculas')\n",
    "#                 sbrn0          = avaliar0.title()\n",
    "#             # print('sbrn0:',sbrn0, len(sbrn0))\n",
    "            \n",
    "#             try:\n",
    "#                 avaliar1=div[0].split(' ')[1].strip()\n",
    "#                 # print('avaliar0',avaliar0)\n",
    "#                 # print('avaliar1',avaliar1)\n",
    "#                 if 1 < len(avaliar1) <=3:\n",
    "#                     sbrn1     = avaliar1.lower()\n",
    "#                 else:\n",
    "#                     sbrn1     = avaliar1.title()\n",
    "#                 # print('sbrn1:',sbrn1, len(sbrn1))\n",
    "\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "#             if div != []:\n",
    "#                 # print('CASO_05.3: Caso haja divisão por vírgulas na string')\n",
    "#                 try:\n",
    "#                     div_espaco     = div[1].split(' ')\n",
    "#                 except:\n",
    "#                     div_espaco     = div[0].split(' ')\n",
    "#                 sobrenome      = div_espaco[0].strip().upper()\n",
    "#                 try:\n",
    "#                     primeiro_nome  = div_espaco[1].title().strip()\n",
    "#                 except:\n",
    "#                     primeiro_nome  = div_espaco[0].title().strip()\n",
    "#                 if len(sbrn0) == 1:\n",
    "#                     # print('CASO_05.3a: Avalia primeiro sobrenome de tamanho 1')\n",
    "#                     # print('Vai pros nomes:',str(sbrn0).title())\n",
    "#                     nomes_meio = nomes_meio+str(' '+sbrn0.title())\n",
    "#                     # print('   NomesMeio:',nomes_meio)\n",
    "\n",
    "#                 elif 1 < len(sbrn0) <= 3:\n",
    "#                     # print('CASO_05.3b: Avalia primeiro sobrenome 1< tamanho <=3')\n",
    "#                     # print('Vão pros nomes sbrn0:',sbrn0, 'e sbrn1:',sbrn1)\n",
    "\n",
    "#                     div_tresconsoantes = letras_tresconsnts.findall(sobrenome)\n",
    "#                     if div_tresconsoantes != []:\n",
    "#                         # print('CASO_05.4: Três consoantes como sobrenome')\n",
    "#                         for letra in sobrenome:\n",
    "#                             nomes.append(letra)\n",
    "\n",
    "#                         if len(sobrenome) >2:\n",
    "#                             sobrenome=nomes[0]\n",
    "#                         else:\n",
    "#                             sobrenome=nomes[1]\n",
    "#                         nomes.remove(sobrenome)\n",
    "#                         primeiro_nome=nomes[0]\n",
    "#                         nomes_meio=' '.join([str for str in nomes[1:]]).strip()\n",
    "#                         nome_completo=sobrenome.upper()+', '+nomes_meio                \n",
    "                    \n",
    "#                     try:                       \n",
    "#                         # print(' 05.3b    Lista de Nomes:',nomes_meio)\n",
    "#                         nomes_meio=nomes_meio.replace(sbrn0,'')\n",
    "#                         # print(' 05.3b ReplaceSobrenome0:',nomes_meio)\n",
    "#                         nomes_meio=nomes_meio.replace(sbrn1,'')\n",
    "#                         # print(' 05.3b ReplaceSobrenome1:',nomes_meio)\n",
    "#                     except Exception as e:\n",
    "#                         # print('   Erro ReplaceSobrenome:',e)\n",
    "#                         pass\n",
    "#                     try:\n",
    "#                         nomes_meio.replace(primeiro_nome.title(),'')\n",
    "#                         nomes_meio.replace(primeiro_nome.lower(),'')\n",
    "#                         nomes_meio.replace(primeiro_nome,'')\n",
    "#                         # print(' 05.3b Replace PrimNome:',nomes_meio)\n",
    "#                     except Exception as e:\n",
    "#                         print('Erro no try PrimeiroNome:',e)\n",
    "#                         pass\n",
    "#                     nomes_meio = nomes_meio.replace(sobrenome,'')\n",
    "#                     try:\n",
    "#                         for n,i in enumerate(avaliar1):\n",
    "#                             nomes.append(i.upper())\n",
    "#                             sbrn1     = avaliar1[0]\n",
    "#                         else:\n",
    "#                             sbrn1     = avaliar1.title()\n",
    "#                         # print('sbrn1:',sbrn1, len(sbrn1))\n",
    "#                         nomes_meio = nomes_meio+str(' '+sbrn0)+str(' '+sbrn1)\n",
    "#                     except:\n",
    "#                         nomes_meio = nomes_meio+str(' '+sbrn0)\n",
    "#                     nomes      = nomes_meio.strip().strip(',').split(' ')\n",
    "#                     # print(' 05.3b NomesMeio:',nomes_meio)\n",
    "#                     # print(' 05.3b     Nomes:',nome)\n",
    "\n",
    "#                 else:\n",
    "#                     # print('CASO_05.3c: Avalia primeiro sobrenome >3')\n",
    "#                     nomes_meio = nomes_meio+str(' '+div[0].strip().title())\n",
    "#                     nomes      = nomes_meio.strip().split(' ')\n",
    "#                     # print(' 05.3c NomesMeio:',nomes_meio)\n",
    "#                     # print(' 05.3c     Nomes:',nomes)\n",
    "\n",
    "#                 nomes_meio=nomes_meio.replace(sobrenome,'').replace(',','').strip()\n",
    "#                 nomes_meio=nomes_meio.replace(primeiro_nome,'').strip()\n",
    "\n",
    "#             # print('Ao final do caso 05')\n",
    "#             # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "#             # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "#             # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "#     if sobrenome != '' and primeiro_nome !='':\n",
    "#         nome_completo=sobrenome.upper().replace(',','')+', '+primeiro_nome.replace(',','')+' '+nomes_meio.replace(sobrenome,'').replace(',','')\n",
    "#     elif sobrenome != '':\n",
    "#         nome_completo=sobrenome.upper().replace(',','')+', '+nomes_meio.replace(sobrenome,'').replace(',','')\n",
    "#     else:\n",
    "#         nome_completo=sobrenome.upper()\n",
    "    \n",
    "# #     print('Após ajustes finais')\n",
    "# #     print('     Sobrenome:',sobrenome)\n",
    "# #     print(' Primeiro Nome:',primeiro_nome)\n",
    "# #     print('         Nomes:',nomes)\n",
    "# #     print('     NomesMeio:',nomes_meio)        \n",
    "        \n",
    "# #     print('                Resultado:',nome_completo)\n",
    "    \n",
    "#     return nome_completo.strip()\n",
    "\n",
    "\n",
    "\n",
    "# def padronizar_titulo(titulo_bruto):\n",
    "#     '''\n",
    "#     Retira acentos, expressão (Org.) e espaços vazios do título da publicação\n",
    "#     Autor: Marcos Aires (Fev.2022)\n",
    "#     '''\n",
    "#     import re\n",
    "#     import unicodedata\n",
    "    \n",
    "#     ## Retirar caracteres não unicode\n",
    "#     string = ''.join(ch for ch in unicodedata.normalize('NFKD', titulo_bruto) if not unicodedata.combining(ch))\n",
    "#     string = string.replace('(Org)','').replace('(Org.)','').replace('(Org).','').replace('.',' ').replace('-',' ').replace('\\'',' ').lower()\n",
    "    \n",
    "#     substitui_iniciais=[('rl,', 'r l,'), ('hs,', 'h s,'), ('gc,', 'g c,'), ('sf,', 's f,'), ('fo,', 'f o,'), (' oa,', ' o a,'), ('mss,', 'm s s,'), \n",
    "#                         ('lagares, ma', 'lagares, m a'), ('cota, gf', 'cota, g f'), ('cota gf,', 'cota, g f,'), ('diotaiut,', 'diotaiuti,'), ('grenfell, r f q','queiroz, rafaella fortini grenfell')]\n",
    "#     for i in substitui_iniciais:\n",
    "#         string = string.replace(i[0], i[1])\n",
    "    \n",
    "#     ## Retirar preposições\n",
    "#     preposicoes = ['da', 'de', 'do', 'das', 'dos']\n",
    "#     partes_string = string.split(' ')\n",
    "#     string = ' '.join(x for x in partes_string if x.lower() not in preposicoes)\n",
    "    \n",
    "#     titulo_padronizado = string.strip().strip('\"')\n",
    "    \n",
    "#     return titulo_padronizado\n",
    "\n",
    "\n",
    "\n",
    "# def iniciais_nome(linha_texto):\n",
    "#     '''\n",
    "#     Função para retornar sobrenome+iniciais das partes de nome, na forma: SOBRENOME, X Y Z\n",
    "#      Recebe: String com nome\n",
    "#     Retorna: Tupla com nome e sua versão padronizada em sobrenome+agnome em maiúsculas, seguida de vírgula e das iniciais das demais partes de nome\n",
    "#       Autor: Marcos Aires (Mar.2022)\n",
    "#     '''\n",
    "#     import unicodedata\n",
    "#     import re\n",
    "#     # print('               Analisando:',linha_texto)\n",
    "    \n",
    "#     ## Retirar caracteres não unicode\n",
    "#     string = ''.join(ch for ch in unicodedata.normalize('NFKD', linha_texto) if not unicodedata.combining(ch))\n",
    "#     string = string.replace('(Org)','').replace('(Org.)','').replace('(Org).','').replace('.','')\n",
    "    \n",
    "#     ## Retirar preposições\n",
    "#     preposicoes   = ['da','de','do','das','dos']\n",
    "#     partes_string = string.split(' ')\n",
    "#     string = ' '.join(x for x in partes_string if x.lower() not in preposicoes)\n",
    "        \n",
    "#     ## Expressões regulares para encontrar padrões de divisão de nomes de autores\n",
    "#     sobrenome_inicio   = re.compile(r'^[A-ZÀ-ú-a-z]+,')                 # Sequência de letras maiúsculas no início da string\n",
    "#     sobrenome_composto = re.compile(r'^[A-ZÀ-ú-a-z]+[ ][A-ZÀ-ú-a-z]+,') # Duas sequências de letras no início da string, separadas por espaço, seguidas por vírgula\n",
    "#     letra_abrevponto   = re.compile(r'^[A-Z][.]')                       # Uma letra maiúscula no início da string, seguida por ponto\n",
    "#     letra_abrevespaco  = re.compile(r'^[A-Z][ ]')                       # Uma letra maiúscula no início da string, seguida por espaço\n",
    "#     letras_dobradas    = re.compile(r'[A-Z]{2}')                        # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "#     letras_dobradasini = re.compile(r'[A-Z]{2}[ ]')                     # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "#     letras_dobradasfim = re.compile(r'[ ][A-Z]{2}')                     # Duas letras maiúsculas juntas no final da string, precedida por espaço\n",
    "        \n",
    "#     nomes=[]\n",
    "#     agnomes       = ['NETO','JUNIOR','FILHO','SEGUNDO','TERCEIRO', 'SOBRINHO']\n",
    "#     nome_completo = ''\n",
    "    \n",
    "#     ## Ajustar lista de termos, identificar sobrenomes compostos e ajustar sobrenome com ou sem presença de vírgula\n",
    "#     div_sobrenome      = sobrenome_inicio.findall(string)\n",
    "#     div_sbrcomposto    = sobrenome_composto.findall(string)\n",
    "    \n",
    "#     ## Caso haja vírgulas na string, tratar sobrenomes e sobrenomes compostos\n",
    "#     if div_sobrenome != [] or div_sbrcomposto != []:\n",
    "#         div   = string.split(', ')\n",
    "#         sobrenome     = div[0].strip().upper()\n",
    "#         try:\n",
    "#             div_espaco    = div[1].split(' ')\n",
    "#         except:\n",
    "#             div_espaco  = ['']\n",
    "#         primeiro      = div_espaco[0].strip('.')\n",
    "        \n",
    "#         ## Caso primeiro nome sejam somente duas letras maiúsculas juntas, trata-se de duas iniciais\n",
    "#         if len(primeiro)==2:\n",
    "#             primeiro_nome=primeiro[0].strip()\n",
    "#             nomes.append(primeiro[1].strip())\n",
    "#         else:\n",
    "#             primeiro_nome = div_espaco[0].strip().title()\n",
    "        \n",
    "#         ## Montagem da lista de nomes do meio\n",
    "#         for nome in div_espaco:\n",
    "#             if nome not in nomes and nome.lower()!=primeiro_nome.lower() and nome.lower() not in primeiro_nome.lower() and nome!=sobrenome:   \n",
    "#                 # print(nome, len(nome))\n",
    "                \n",
    "#                 ## Avaliar se é abreviatura seguida de ponto e remover o ponto\n",
    "#                 if len(nome)<=2 and nome.lower() not in preposicoes:\n",
    "#                     for inicial in nome:\n",
    "#                         # print(inicial)\n",
    "#                         if inicial not in nomes and inicial not in primeiro_nome:\n",
    "#                             nomes.append(inicial.replace('.','').strip().title())\n",
    "#                 else:\n",
    "#                     if nome not in nomes and nome!=primeiro_nome and nome!=sobrenome and nome!='':\n",
    "#                         if nome.lower() in preposicoes:\n",
    "#                             nomes.append(nome.replace('.','').strip().lower())\n",
    "#                         else:\n",
    "#                             nomes.append(nome.replace('.','').strip().title())\n",
    "#                         # print(nome,'|',primeiro_nome)\n",
    "                        \n",
    "#         ## Caso haja sobrenome composto que não esteja nos agnomes considerar somente primeira parte como sobrenome\n",
    "#         if div_sbrcomposto !=[] and sobrenome.split(' ')[1] not in agnomes:\n",
    "#             # print(div_sbrcomposto)\n",
    "#             # print('Sobrenome composto:',sobrenome)\n",
    "#             nomes.append(sobrenome.split(' ')[1].title())\n",
    "#             sobrenome = sobrenome.split(' ')[0].upper()\n",
    "#             # print('Sobrenome:',sobrenome.split(' '))\n",
    "#             for i in nomes:\n",
    "#                 if i.lower() in sobrenome.lower():\n",
    "#                     nomes.remove(i)\n",
    "#             # print('Nomes do meio:',nomes)\n",
    "        \n",
    "#         # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "#         # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "#         # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "#     ## Caso não haja vírgulas na string considera sobrenome o último nome da string dividida com espaço vazio\n",
    "#     else:\n",
    "#         try:\n",
    "#             div       = string.split(' ')\n",
    "#             if div[-2] in agnomes:\n",
    "#                 sobrenome = div[-2].upper()+' '+div[-1].strip().upper()\n",
    "#                 for i in nomes[1:-2]:\n",
    "#                     if i not in sobrenome and i not in preposicoes:\n",
    "#                         nomes.append(i.strip().title())\n",
    "#                     if i in preposicoes:\n",
    "#                         nomes.append(i.strip().lower())\n",
    "#             else:\n",
    "#                 sobrenome = div[-1].strip().upper()\n",
    "#                 for i in div[1:-1]:\n",
    "#                     if i not in sobrenome and i not in preposicoes:\n",
    "#                         nomes.append(i.strip().title())\n",
    "#                     if i in preposicoes:\n",
    "#                         nomes.append(i.strip().lower())\n",
    "#         except:\n",
    "#             sobrenome = div[-1].strip().upper()\n",
    "#             for i in div[1:-1]:\n",
    "#                     if i not in sobrenome and i not in preposicoes:\n",
    "#                         nomes.append(i.strip().title())\n",
    "#                     if i in preposicoes:\n",
    "#                         nomes.append(i.strip().lower())\n",
    "            \n",
    "#         if sobrenome.lower() != div[0].strip().lower():\n",
    "#             primeiro_nome=div[0].strip().title()\n",
    "#         else:\n",
    "#             primeiro_nome=''\n",
    "        \n",
    "#         # print('    Sobrenome sem vírgula:',sobrenome)\n",
    "#         # print('Primeiro nome sem vírgula:',primeiro_nome)\n",
    "#         # print('Nomes do meio sem vírgula:',nomes)\n",
    "    \n",
    "#     # Encontrar e tratar como abreviaturas termos com apenas uma ou duas letras iniciais juntas, com ou sem ponto\n",
    "#     for j in nomes:\n",
    "#         # Procura padrões com expressões regulares na string\n",
    "#         div_sobrenome      = sobrenome_inicio.findall(j)\n",
    "#         div_sbrcomposto    = sobrenome_composto.findall(j)\n",
    "#         div_abrevponto     = letra_abrevponto.findall(j)\n",
    "#         div_abrevespaco    = letra_abrevespaco.findall(j)\n",
    "#         div_ltrdobradasini = letras_dobradasini.findall(j)\n",
    "#         div_ltrdobradasfim = letras_dobradasfim.findall(j)\n",
    "#         div_ltrdobradas    = letras_dobradas.findall(j)\n",
    "#         tamanho=len(j)\n",
    "#         # print('\\n', div_ltrdobradasini, div_ltrdobradasfim, tamanho, 'em:',j,len(j))\n",
    "        \n",
    "#         #caso houver abreviatura com uma letra em maiúscula nos nomes\n",
    "#         if div_abrevponto !=[] or tamanho==1:\n",
    "#             cada_nome = j.replace('.','').strip()\n",
    "#             if cada_nome not in nomes and cada_nome != sobrenome and nome != primeiro_nome:\n",
    "#                 nomes.append(cada_nome)\n",
    "        \n",
    "#         #caso houver duas inicias juntas em maiúsculas\n",
    "#         elif div_ltrdobradasini !=[] or div_ltrdobradasfim !=[] or div_ltrdobradas !=[] :\n",
    "#             for letra in j:\n",
    "#                 if letra not in nomes and letra != sobrenome and letra != primeiro_nome:\n",
    "#                     nomes.append(letra)\n",
    "        \n",
    "#         #caso haja agnomes ao sobrenome\n",
    "#         elif sobrenome in agnomes:\n",
    "#             sobrenome = nomes[-1].upper()+' '+sobrenome\n",
    "#             # print(sobrenome.split(' '))\n",
    "#             # print('Sobrenome composto:',sobrenome)\n",
    "#             for i in nomes:\n",
    "#                 if i.lower() in sobrenome.lower():\n",
    "#                     nomes.remove(i)\n",
    "#             # print('Nomes do meio:',nomes)\n",
    "            \n",
    "#         else:\n",
    "#             if j not in nomes and j not in sobrenome and j != primeiro_nome:\n",
    "#                 nomes.append(j)\n",
    "    \n",
    "#     nomes_meio=' '.join([str[0] for str in nomes]).strip()\n",
    "#     # print('Qte nomes do meio',len(nomes),nomes)\n",
    "#     if sobrenome != '' and primeiro_nome !='':\n",
    "#         sobrenome_iniciais = sobrenome+', '+primeiro_nome[0]+' '+nomes_meio\n",
    "#     elif sobrenome != '':\n",
    "#         sobrenome_iniciais = sobrenome\n",
    "    \n",
    "#     return sobrenome_iniciais.strip()\n",
    "\n",
    "\n",
    "# ## Agregar aprendizado supervisionado humano à medida que forem sendo identificados erros na situação atual\n",
    "# lista_extra = [\n",
    "#                 # ('ALBUQUERQUE, Adriano B', 'ALBUQUERQUE, Adriano Bessa'),\n",
    "#                 # ('ALBUQUERQUE, Adriano', 'ALBUQUERQUE, Adriano Bessa'),\n",
    "#                 # ('COELHO, Andre L V', 'COELHO, Andre Luis Vasconcelos'),\n",
    "#                 # ('DUARTE, Joao B F', 'DUARTE, Joao Batista Furlan'),\n",
    "#                 # ('FILHO, Raimir H','HOLANDA FILHO, Raimir'),\n",
    "#                 # ('FILHO, Raimir','HOLANDA FILHO, Raimir'),\n",
    "#                 # ('FORMIGO, A','FORMICO, Maria Andreia Rodrigues'),\n",
    "#                 # ('FORMICO, A','FORMICO, Maria Andreia Rodrigues'),\n",
    "#                 # ('FURLAN, J B D', 'FURLAN, Joao Batista Duarte'),\n",
    "#                 # ('FURTADO, Elizabeth', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "#                 # ('FURTADO, Elizabeth S', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "#                 # ('FURTADO, Elizabeth Sucupira','FURTADO, Maria Elizabeth Sucupira'),\n",
    "#                 # ('FURTADO, M E S', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "#                 # ('FURTADO, Vasco', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "#                 # ('FURTADO, J P', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "#                 # ('FURTADO, J V P', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "#                 # ('FURTADO, Vasco', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "#                 # ('FURTADO, Elizabeth','FURTADO, Maria Elizabeth Sucupira'),\n",
    "#                 # ('HOLANDA, Raimir', 'HOLANDA FILHO, Raimir'),\n",
    "#                 # ('LEITE, G S', 'LEITE, Gleidson Sobreira'),\n",
    "#                 # ('PEQUENO, T H C', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "#                 # ('PEQUENO, Tarcisio','PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "#                 # ('PEQUENO, Tarcisio Cavalcante', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "#                 # ('PINHEIRO, Placido R', 'PINHEIRO, Placido Rogerio'),\n",
    "#                 # ('PINHEIRO, Vladia', 'PINHEIRO, Vladia Celia Monteiro'),\n",
    "#                 # ('RODRIGUES, M A F', 'RODRIGUES, Maria Andreia Formico'),\n",
    "#                 # ('RODRIGUES, Andreia', 'RODRIGUES, Maria Andreia Formico'),\n",
    "#                 # ('JOAO, Batista F Duarte,', 'FURLAN, Joao Batista Duarte'),\n",
    "#                 # ('MACEDO, Antonio Roberto M de', 'MACEDO, Antonio Roberto Menescal de'),\n",
    "#                 # ('MACEDO, D V', 'MACEDO, Daniel Valente'),\n",
    "#                 # ('MENDONCA, Nabor C', 'MENDONCA, Nabor das Chagas'),\n",
    "#                 # ('PEQUENO, Tarcisio', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "#                 # ('PEQUENO, Tarcisio H', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "#                 # ('PINHEIRO, Mirian C D', 'PINHEIRO, Miriam Caliope Dantas'),\n",
    "#                 # ('PINHEIRO, Mirian Caliope Dantas', 'PINHEIRO, Miriam Caliope Dantas'),\n",
    "#                 # ('PINHEIRO, P G C D', 'PINHEIRO, Pedro Gabriel Caliope Dantas'),\n",
    "#                 # ('PINHEIRO, Pedro G C', 'PINHEIRO, Pedro Gabriel Caliope Dantas'),\n",
    "#                 # ('PINHEIRO, Placido R', 'PINHEIRO, Placido Rogerio'),\n",
    "#                 # ('PINHEIRO, Vladia', 'PINHEIRO, Vladia Celia Monteiro'),\n",
    "#                 # ('ROGERIO, Placido Pinheiro', 'PINHEIRO, Placido Rogerio'),\n",
    "#                 # ('REBOUCRAS FILHO, Pedro', 'REBOUCAS FILHO, Pedro Pedrosa'),\n",
    "#                 # ('SAMPAIO, A', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "#                 # ('SAMPAIO, Americo', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "#                 # ('SAMPAIO, Americo Falcone', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "#                 # ('SUCUPIRA, Elizabeth Furtado','FURTADO, Maria Elizabeth Sucupira'),\n",
    "#                 ]\n",
    "\n",
    "\n",
    "# def converter_lista_set(lista):\n",
    "#     set1 = set(lista)\n",
    "#     return set1\n",
    "\n",
    "\n",
    "# def jaccard_similarity(set1, set2):\n",
    "#     '''\n",
    "#     Recebe dois conjuntos como entradas e retorna a similaridade Jaccard entre eles. \n",
    "#     1. calcula a interseção dos dois conjuntos usando a função de interseção e, \n",
    "#     2. calcula a união dos dois conjuntos usando a função de união. \n",
    "#     3. retorna a razão entre o comprimento da interseção e o comprimento da união, que é a similaridade de Jaccard.\n",
    "#     '''\n",
    "#     intersection = set1.intersection(set2)\n",
    "#     union        = set1.union(set2)\n",
    "#     return len(intersection) / len(union)\n",
    "\n",
    "\n",
    "# def similares(lista_autores, lista_grupo, limite_jarowinkler, distancia_levenshtein, lista_extra):\n",
    "#     \"\"\"Função para aplicar padronização no nome de autor da lista de pesquisadores e buscar similaridade na lista de coautores\n",
    "#      Recebe: Lista de pesquisadores do grupo em análise gerada pela lista de nomes dos coautores das publicações em análise\n",
    "#     Utiliza: get_jaro_distance(), editdistance()\n",
    "#     Retorna: Lista de autores com fusão de nomes cuja similaridade esteja dentro dos limites definidos nesta função\n",
    "#       Autor: Marcos Aires (Fev.2022)\n",
    "      \n",
    "#     Refazer: Inserir crítica de, mantendo sequência ordem alfabética, retornar no final nome mais extenso em caso de similaridade;\n",
    "#     \"\"\"\n",
    "#     from pyjarowinkler.distance import get_jaro_distance\n",
    "#     from IPython.display import clear_output\n",
    "#     import editdistance\n",
    "#     import numpy as np\n",
    "#     import time\n",
    "    \n",
    "#     t0=time.time()\n",
    "    \n",
    "#     # limite_jarowinkler=0.85\n",
    "#     # distancia_levenshtein=6\n",
    "#     similares_jwl=[]\n",
    "#     similares_regras=[]\n",
    "#     similares=[]\n",
    "#     tempos=[]\n",
    "    \n",
    "#     count=0\n",
    "#     t1=time.time()\n",
    "#     for i in lista_autores:\n",
    "#         count+=1\n",
    "#         if count > 0:\n",
    "#             tp=time.time()-t1\n",
    "#             tmed=tp/count*2\n",
    "#             tempos.append(tp)\n",
    "#         # print(\"Analisar similaridades com: \", nome_padronizado)\n",
    "        \n",
    "#         count1=0\n",
    "#         for nome in lista_autores:\n",
    "#             if count1 > 0:\n",
    "#                 resta=len(lista_autores)-count\n",
    "#                 print(f'Analisando {count1:3}/{len(lista_autores)} resta analisar {resta:3} nomes. Previsão de término em {np.round(tmed*resta/60,1)} minutos')\n",
    "#             else:\n",
    "#                 print(f'Analisando {count1:3}/{len(lista_autores)} resta analisar {len(lista_autores)-count1} nomes.')\n",
    "            \n",
    "#             t2=time.time()\n",
    "#             count1+=1            \n",
    "\n",
    "#             try:\n",
    "#                 similaridade_jarowinkler = get_jaro_distance(i, nome)\n",
    "#                 print(f'{i:40} | {nome:40} | Jaro-Winkler: {np.round(similaridade_jarowinkler,2):4} Levenshtein: {editdistance.eval(i, nome)}')\n",
    "#                 similaridade_levenshtein = editdistance.eval(i, nome)\n",
    "\n",
    "#                 # inferir similaridade para nomes que estejam acima do limite ponderado definido, mas não idênticos e não muito distantes em edição\n",
    "#                 if  similaridade_jarowinkler > limite_jarowinkler and similaridade_jarowinkler!=1 and similaridade_levenshtein < distancia_levenshtein:\n",
    "#                     # Crítica no nome mais extenso como destino no par (origem, destino)\n",
    "                    \n",
    "#                     similares_jwl.append((i,nome))\n",
    "\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "#             clear_output(wait=True)\n",
    "    \n",
    "#     # Conjunto de regras de validação de similaridade\n",
    "#     # Monta uma lista de nomes a serem retirados antes de montar a lista de troca\n",
    "#     trocar=[]\n",
    "#     retirar=[]\n",
    "#     for i in similares_jwl:\n",
    "#         sobrenome_i = i[0].split(',')[0]\n",
    "#         sobrenome_j = i[1].split(',')[0]\n",
    "\n",
    "#         try:\n",
    "#             iniciais_i  = iniciais_nome(i[0]).split(',')[1].strip()\n",
    "#         except:\n",
    "#             iniciais_i  = ''\n",
    "\n",
    "#         try:\n",
    "#             iniciais_j  = iniciais_nome(i[1]).split(',')[1].strip()\n",
    "#         except:\n",
    "#             iniciais_j  = ''\n",
    "\n",
    "#         try:\n",
    "#             primnome_i = i[0].split(',')[1].strip().split(' ')[0].strip()\n",
    "#         except:\n",
    "#             primnome_i = ''\n",
    "\n",
    "#         try:\n",
    "#             primnome_j = i[1].split(',')[1].strip().split(' ')[0].strip()\n",
    "#         except:\n",
    "#             primnome_j = ''    \n",
    "\n",
    "#         try:\n",
    "#             inicial_i = i[0].split(',')[1].strip()[0]\n",
    "#         except:\n",
    "#             inicial_i = ''\n",
    "\n",
    "#         try:\n",
    "#             resto_i   = i[0].split(',')[1].strip().split(' ')[0][1:]\n",
    "#         except:\n",
    "#             resto_i   = ''\n",
    "\n",
    "#         try:\n",
    "#             inicial_j = i[1].split(',')[1].strip()[0]\n",
    "#         except:\n",
    "#             inicial_j = ''\n",
    "\n",
    "#         try:\n",
    "#             resto_j   = i[1].split(',')[1].strip().split(' ')[0][1:]\n",
    "#         except:\n",
    "#             resto_j = ''\n",
    "\n",
    "#         # Se a distância de edição entre os sobrenomes\n",
    "#         if editdistance.eval(sobrenome_i, sobrenome_j) > 2 or inicial_i!=inicial_j:\n",
    "#             retirar.append(i)\n",
    "#         else:\n",
    "#             if primnome_i!=primnome_j and len(primnome_i)>1:\n",
    "#                 retirar.append(i)\n",
    "#             if primnome_i!=primnome_j and len(primnome_i)>1 and len(primnome_j)>1:\n",
    "#                 retirar.append(i)\n",
    "#             if resto_i!=resto_j and resto_i!='':\n",
    "#                 retirar.append(i)\n",
    "#             if len(i[1]) < len(i[0]):\n",
    "#                 retirar.append(i)\n",
    "#             if len(iniciais_i) != len(iniciais_j):\n",
    "#                 retirar.append(i)\n",
    "\n",
    "#     for i in similares_jwl:\n",
    "#         if i not in retirar:\n",
    "#             trocar.append(i)\n",
    "\n",
    "#         if iniciais_nome(i[0]) in iniciais_nome(i[1]) and len(i[0]) < len(i[1]):\n",
    "#             trocar.append(i)\n",
    "\n",
    "#         if iniciais_nome(i[0]) == iniciais_nome(i[1]) and len(i[0]) < len(i[1]):\n",
    "#              trocar.append(i)\n",
    "    \n",
    "#     trocar=trocar+lista_extra\n",
    "#     trocar.sort()\n",
    "    \n",
    "#     return trocar\n",
    "\n",
    "\n",
    "\n",
    "# def extrair_variantes(df_dadosgrupo):\n",
    "#     ''' Utiliza campo de Nome em Citações do currículo como filtro para obter variantes do nome de cada membro\n",
    "#      Recebe: Dataframe com os dados brutos do grupo de pesquisa agrupados; lista de nomes de pesquisadores de interesse\n",
    "#     Retorna: Lista de tuplas com pares a serem trocados da variante pelo nome padronizado na forma (origem, destino)\n",
    "#     '''\n",
    "#     filtro1   = 'Nome'\n",
    "#     lista_nomes = df_dadosgrupo[(df_dadosgrupo.ROTULOS == filtro1)]['CONTEUDOS'].values\n",
    "\n",
    "#     variantes=[]\n",
    "#     filtro='Nome em citações bibliográficas'\n",
    "#     variantes=df_dadosgrupo[(df_dadosgrupo.ROTULOS == filtro)]['CONTEUDOS'].to_list()\n",
    "\n",
    "#     trocar=[]\n",
    "#     for j in range(len(variantes)):\n",
    "#         padrao_destino = padronizar_nome(lista_nomes[j])\n",
    "#         trocar.append((lista_nomes[j], padrao_destino))\n",
    "#         for k in variantes[j]:\n",
    "#             padrao_origem = padronizar_nome(k)\n",
    "#             trocar.append((k, padrao_destino))\n",
    "#             trocar.append((padrao_origem, padrao_destino))\n",
    "    \n",
    "#     return trocar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fbfc46",
   "metadata": {},
   "source": [
    "    Apurar colaborações docente/discente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d78c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def converter_lista_set(lista):\n",
    "#     set1 = set(lista)\n",
    "#     return set1\n",
    "\n",
    "# def montardf_producao(lista_csv):\n",
    "#     print(f'{len(lista_csv):02} nomes a extrair')\n",
    "#     df_public=pd.DataFrame()\n",
    "#     for nome_csv in lista_csv:\n",
    "#         if 'colaboradores' in nome_csv.lower():\n",
    "#             tipo='colaboradores'\n",
    "#         else:\n",
    "#             tipo='permanentes'\n",
    "        \n",
    "#         df_pub = pd.read_csv(pathcsv+nome_csv)\n",
    "#         print(len(df_pub.index))\n",
    "#         print(df_pub.keys())\n",
    "\n",
    "#         pat='\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'\n",
    "#         df_temp1 = df_pub.Data.str.split(pat=pat,expand=True)\n",
    "#         df_temp1.columns = (['TITULO','RevAut'])\n",
    "\n",
    "#         pat1='\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'\n",
    "#         df_temp2 = df_temp1.RevAut.str.split(pat=pat1,expand=True)\n",
    "#         df_temp2.columns = (['REVISTA','AUTORES'])\n",
    "\n",
    "#         df_temp0 = df_pub.drop(['Data'], axis=1)\n",
    "#         df_pub=df_temp0.merge(df_temp1['TITULO'],left_index=True,right_index=True)\n",
    "#         df_pub=df_pub.merge(df_temp2,left_index=True,right_index=True)\n",
    "#         try:\n",
    "#             df_pub.drop(['Issn','Natureza'], axis=1, inplace=True)\n",
    "#         except:\n",
    "#             pass\n",
    "#         try:\n",
    "#             df_pub.drop(['Tipo','Idioma'], axis=1, inplace=True)\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#         df_public = pd.concat([df_public, df_pub], ignore_index=True)\n",
    "#         print(len(df_public.index))\n",
    "#         print(df_public.keys())\n",
    "        \n",
    "#     ## Extrai o período com base nos dados\n",
    "#     inicio = min(df_public['Ano'])\n",
    "#     final  = max(df_public['Ano'])\n",
    "    \n",
    "#     total_artigos=len(df_public.index)\n",
    "#     # print(f'{total_artigos:4} publicações de artigos de docentes do programa no período de {inicio} a {final} carregadas...') \n",
    "    \n",
    "#     return df_public\n",
    "\n",
    "# def ler_nomesdocentes():    \n",
    "#     print(pathcsv)\n",
    "#     import os, sys\n",
    "\n",
    "#     lista_csv=[]\n",
    "#     dirs = os.listdir(pathcsv)\n",
    "#     for file in dirs:\n",
    "#         if 'nomes_docentes' in file:\n",
    "#             lista_csv.append(file)\n",
    "#     lista_csv.sort()\n",
    "    \n",
    "#     for i in lista_csv:\n",
    "#         print(i)\n",
    "\n",
    "#     return lista_csv\n",
    "\n",
    "\n",
    "# ## ler arquivo com as orientações para gerar a lista de discentes\n",
    "# def ler_lista_orientacoes():\n",
    "#     try:\n",
    "#         l1='lista_orientadores-discentes.csv'\n",
    "#         df_orientacoes = pd.read_csv(pathcsv+l1, delimiter=';', header=None)\n",
    "        \n",
    "#         lista_orientadores = df_orientacoes.iloc[:,0].unique()\n",
    "#         lista_discentes    = df_orientacoes.iloc[:,1].unique()\n",
    "#         print(f'{len(lista_orientadores):4} orientadores, com {len(lista_discentes)} discentes encontrados')\n",
    "#     except Exception as e:\n",
    "#         print('Erro ao gerar lista de orientações:')\n",
    "#         print(e)\n",
    "#         return df_orientacoes\n",
    "        \n",
    "#     return lista_orientadores, lista_discentes \n",
    "\n",
    "\n",
    "# ## montar um dataframe com nome dos discentes de cada orientador\n",
    "# def montardf_orientacoes():\n",
    "#     try:\n",
    "#         l1='lista_orientadores-discentes.csv'\n",
    "#         df_orientacoes = pd.read_csv(pathcsv+l1, delimiter=';', header=None)\n",
    "#         df_orientacoes.columns=['ORIENTADOR','DISCENTE']\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print('Erro ao dividir dataframe de orientações:')\n",
    "#         print(e)\n",
    "#         return\n",
    "        \n",
    "#     return df_orientacoes\n",
    "\n",
    "\n",
    "\n",
    "# def montardf_docentes_permanentes_colaboradores():\n",
    "#     try:\n",
    "#         l1='lista_docentes_colaboradores.csv'\n",
    "#         l2='lista_docentes_permanentes.csv'\n",
    "#         df_docclbr = pd.read_csv(os.path.join(pathcsv,l1), header=None)\n",
    "#         df_docperm = pd.read_csv(os.path.join(pathcsv,l2), header=None)\n",
    "#         df_docentes = pd.concat([df_docperm, df_docclbr], ignore_index=True)\n",
    "#         print(f'{len(df_docentes.index):4} docentes permanentes e colaboradores encontrados')\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "        \n",
    "#     return df_docentes\n",
    "\n",
    "\n",
    "# def jaccard_similarity(set1, set2):\n",
    "#     '''\n",
    "#     Recebe dois conjuntos (sets) como entradas e retorna a similaridade Jaccard entre eles e avalia: \n",
    "#     1. calcula a interseção dos dois conjuntos usando a função de interseção \n",
    "#     2. calcula a união dos dois conjuntos usando a função de união \n",
    "#     3. retorna a razão entre o comprimento da interseção e o comprimento da união, que é a similaridade de Jaccard.\n",
    "#     '''\n",
    "#     intersection = set1.intersection(set2)\n",
    "#     union        = set1.union(set2)\n",
    "#     return len(intersection) / len(union)\n",
    "    \n",
    "# def montardf_docentes(lista_nomes1=False, lista_nomes2=False):\n",
    "#     # print(lista_nomes1)\n",
    "#     # print(lista_nomes2)\n",
    "\n",
    "#     ## Montagem do dataframe de participação docente\n",
    "#     if (lista_nomes1 and lista_nomes2) != False:\n",
    "#         ## Criar dataframe com os nomes do grupo de docentes permanentes\n",
    "#         file_path = os.path.join(pathcsv,'lista_docentes_permanentes.csv')\n",
    "#         df_docentes_permanentes   = pd.read_csv(file_path, header=None)\n",
    "#         # df_docentes_permanentes['GRUPO']='Permanente'\n",
    "#         # try:\n",
    "#         #     df_docentes_permanentes.drop(columns=([1,2]), inplace=True)\n",
    "#         # except:\n",
    "#         #     pass\n",
    "#         # df_docentes_permanentes.columns = ['DOCENTE','GRUPO']\n",
    "#         df_docentes_permanentes.columns = ['DOCENTE','IDLATES','PROGRAMA','GRUPO']\n",
    "\n",
    "#         ## Criar dataframe com os nomes do grupo de docentes colaboradores\n",
    "#         file_path = os.path.join(pathcsv,'lista_docentes_colaboradores.csv')\n",
    "#         df_docentes_colaboradores = pd.read_csv(file_path, header=None)\n",
    "#         # df_docentes_colaboradores['GRUPO']='Colaborador'\n",
    "#         # try:\n",
    "#         #     df_docentes_colaboradores.drop(columns=([1,2]), inplace=True)\n",
    "#         # except:\n",
    "#         #     pass\n",
    "#         df_docentes_colaboradores.columns = ['DOCENTE','IDLATES','PROGRAMA','GRUPO']\n",
    "\n",
    "#         ## Criar um dataframe único com todos grupos de docentes juntos\n",
    "#         df_docentes = pd.concat([df_docentes_permanentes, df_docentes_colaboradores]).reset_index(drop=True)\n",
    "#         return df_docentes\n",
    "\n",
    "#     elif 'permanentes' in lista_nomes1.lower():\n",
    "#         ## Criar dataframe com os nomes do grupo de docentes permanentes\n",
    "#         file_path = os.path.join(pathcsv,lista_nomes1)       \n",
    "#         df_docentes_permanentes   = pd.read_csv(file_path, header=None)\n",
    "#         # df_docentes_permanentes['GRUPO']='Permanente'\n",
    "#         # try:\n",
    "#         #     df_docentes_permanentes.drop(columns=([1,2]), inplace=True)\n",
    "#         # except:\n",
    "#         #     pass\n",
    "#         df_docentes_permanentes.columns = ['DOCENTE','IDLATES','PROGRAMA','GRUPO']\n",
    "#         return df_docentes_permanentes\n",
    "\n",
    "#     elif 'colaboradores' in lista_nomes1.lower():\n",
    "#         ## Criar dataframe com os nomes do grupo de docentes colaboradores\n",
    "#         file_path = os.path.join(pathcsv,lista_nomes1)\n",
    "#         df_docentes_colaboradores = pd.read_csv(file_path, header=None)\n",
    "#         # df_docentes_colaboradores['GRUPO']='Colaborador'\n",
    "#         # try:\n",
    "#         #     df_docentes_colaboradores.drop(columns=([1,2]), inplace=True)\n",
    "#         # except:\n",
    "#         #     pass\n",
    "#         df_docentes_colaboradores.columns = ['DOCENTE','IDLATES','PROGRAMA','GRUPO']\n",
    "#         return df_docentes_colaboradores\n",
    "#     else:\n",
    "#         print('Erro ao montar dataframe de docentes, verifique os nomes de arquivo.')\n",
    "#         return\n",
    "        \n",
    "# def montar_listas(lista_csv, csv_permanentes=None, csv_colaboradores=None):\n",
    "#     if csv_permanentes == None and csv_colaboradores == None:\n",
    "#         csv_permanentes   = 'lista_docentes_permanentes.csv'\n",
    "#         csv_colaboradores = 'lista_docentes_colaboradores.csv'\n",
    "#         print(f'\\nNomes de docentes não informados, utilizando caminho e nomes padrão:')\n",
    "#         print(f'     Docentes   permanentes de {pathcsv}{csv_permanentes}')\n",
    "#         print(f'     Docentes colaboradores de {pathcsv}{csv_colaboradores}')\n",
    "#         try:\n",
    "#             file_path = os.path.join(pathcsv,csv_permanentes)\n",
    "#             df_docperm = pd.read_csv(file_path, header=None)\n",
    "#             file_path = os.path.join(pathcsv,csv_colaboradores)\n",
    "#             df_docclbr = pd.read_csv(file_path, header=None)\n",
    "#             lista_docentes = pd.concat([df_docperm, df_docclbr], ignore_index=True)[0].values\n",
    "#             print(f'{len(lista_docentes):4} docentes permanentes e colaboradores encontrados')\n",
    "#         except Exception as e:\n",
    "#             print(f'Erro ao ler listas de docentes, verificar se os arquivos CSV estão na pasta {pathcsv}')\n",
    "#             print(e)\n",
    "#     elif 'permanentes' in csv_permanentes.lower():\n",
    "#         print(f'\\nArquivo docentes   permanentes informado: {csv_permanentes}')\n",
    "#         try:\n",
    "#             file_path = os.path.join(pathcsv,csv_permanentes)\n",
    "#             lista_docentes = pd.read_csv(file_path, header=None)[0].values\n",
    "#             print(f'{len(lista_docentes)} docentes permanentes encontrados')\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#     elif 'colaboradores' in csv_permanentes.lower():\n",
    "#         print(f'\\nArquivo docentes colaboradores informado: {csv_colaboradores}')\n",
    "#         try:\n",
    "#             file_path = os.path.join(pathcsv,csv_permanentes)\n",
    "#             lista_docentes = pd.read_csv(file_path, header=None)[0].values\n",
    "#             print(f'{len(lista_docentes)} docentes colaboradores encontrados')\n",
    "#         except Exception as e:\n",
    "#             print(e)    \n",
    "#     else:\n",
    "#         print('Erro ao ler listas de docentes, verificar listas')\n",
    "\n",
    "#     df_prod   = montardf_producao(lista_csv)\n",
    "    \n",
    "#     ## Montar a lista de autores com limpar_nomes remove caracteres, preposições e separa iniciais com espaço\n",
    "#     lista_listas = df_prod['AUTORES'].tolist()\n",
    "#     lista_autores_artigos = []\n",
    "#     for i in lista_listas:\n",
    "#         lista_autores_artigos.append(limpar_nomes(i))\n",
    "    \n",
    "#     ## Ler nomes de discentes e orientadores\n",
    "#     lista_orientadores, lista_discentes = ler_lista_orientacoes()\n",
    "    \n",
    "#     return lista_autores_artigos, lista_docentes, lista_orientadores, lista_discentes\n",
    "\n",
    "# def montardf_participacao_docente_discente(df_prod, dic_nomes_docentes, dic_nomes_discentes):\n",
    "#     ## Montar dataframe de participação docente\n",
    "#     df_participacao_docente = pd.DataFrame(dic_nomes_docentes).T\n",
    "#     df_participacao_docente.columns = ['DOCENTE','INDICES_ARTIGOS']\n",
    "#     df_participacao_docente['AUTORIAS'] = [len(x) for x in df_participacao_docente['INDICES_ARTIGOS']]\n",
    "\n",
    "#     ## Montar dataframe de participação discente\n",
    "#     df_participacao_discente = pd.DataFrame(dic_nomes_discentes).T\n",
    "#     df_participacao_discente.columns = ['DISCENTE','INDICES_ARTIGOS']\n",
    "#     df_participacao_discente['AUTORIAS'] = [len(x) for x in df_participacao_discente['INDICES_ARTIGOS']]\n",
    "\n",
    "#     ## Criar lista com os artigos onde foi encontado nome de algum docente\n",
    "#     artigos_com_docentes=[]\n",
    "#     for m in df_participacao_docente['INDICES_ARTIGOS']:\n",
    "#         for n in m:\n",
    "#             if n not in artigos_com_docentes:\n",
    "#                 artigos_com_docentes.append(n)\n",
    "#     artigos_com_docentes.sort()\n",
    "                \n",
    "#     ## Criar lista com os artigos onde foi encontado nome de algum discente\n",
    "#     artigos_com_discentes=[]\n",
    "#     for m in df_participacao_discente['INDICES_ARTIGOS']:\n",
    "#         for n in m:\n",
    "#             if n not in artigos_com_discentes:\n",
    "#                 artigos_com_discentes.append(n)\n",
    "#     artigos_com_discentes.sort()\n",
    "                \n",
    "        \n",
    "#     ## Criar lista com os artigos onde NÃO foi encontado nome de discente\n",
    "#     lista_semparticipacaodiscente=[]\n",
    "#     for i in range(len(df_prod.index)):\n",
    "#         if i not in artigos_com_discentes and i not in lista_semparticipacaodiscente:\n",
    "#             lista_semparticipacaodiscente.append(i)\n",
    "            \n",
    "#     ## Criar lista com os artigos onde NÃO foi encontado nome de docente\n",
    "#     lista_semparticipacaodocente=[]\n",
    "#     for i in range(len(df_prod.index)):\n",
    "#         if i not in artigos_com_docentes and i not in lista_semparticipacaodocente:\n",
    "#             lista_semparticipacaodocente.append(i)\n",
    "\n",
    "#     ## Apresentar resultados das buscas por nomes de autores docentes e discentes\n",
    "#     lista_titulos = pd.Series(df_prod['TITULO'].values).unique().tolist()\n",
    "#     print(len(lista_titulos),'títulos únicos de artigo encontrados')\n",
    "#     pdoc = np.round(100*len(artigos_com_docentes)/len(df_prod.index),2)\n",
    "#     spdoc = np.round(100*len(lista_semparticipacaodocente)/len(df_prod.index),2)\n",
    "#     print(f'{len(artigos_com_docentes):4} ({pdoc:6}%) artigos com nome de  docente encontrado, faltando {len(lista_semparticipacaodocente):3} ({spdoc:5}%)')\n",
    "\n",
    "#     pdis = np.round(100*len(artigos_com_discentes)/len(df_prod.index),2)\n",
    "#     spdis = np.round(100*len(lista_semparticipacaodiscente)/len(df_prod.index),2)\n",
    "#     print(f'{len(artigos_com_discentes):4} ({pdis:6}%) artigos com nome de discente encontrado, faltando {len(lista_semparticipacaodiscente):3} ({spdis:5}%)')\n",
    "\n",
    "#     return df_participacao_docente, df_participacao_discente, lista_semparticipacaodocente, lista_semparticipacaodiscente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616ca80e",
   "metadata": {},
   "source": [
    "    Ler arquivos de dados do disco local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea93d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ler arquivos de publicação de artigos na pasta de arquivos CSV\n",
    "# def ler_artigostodosperiodos():    \n",
    "#     print(pathcsv)\n",
    "#     import os, sys\n",
    "\n",
    "#     lista_csv=[]\n",
    "#     dirs = os.listdir(pathcsv)\n",
    "#     for file in dirs:\n",
    "#         if 'Artigos' in file:\n",
    "#             lista_csv.append(file)\n",
    "#     lista_csv.sort()\n",
    "    \n",
    "#     for i in lista_csv:\n",
    "#         print(i)\n",
    "\n",
    "#     return lista_csv\n",
    "\n",
    "\n",
    "\n",
    "# ## ler arquivos de publicação de de período determinado\n",
    "# def ler_csvptg(inicio=False, final=False, tipo=False, grupo=False):    \n",
    "#     import os, sys\n",
    "\n",
    "#     print(pathcsv)\n",
    "#     lista_csv=[]\n",
    "#     dirs = os.listdir(pathcsv)\n",
    "#     for file in dirs:\n",
    "#         if (str(inicio) or str(final)) == False:\n",
    "#             if tipo.lower() == False:\n",
    "#                 if grupo.lower() == False:\n",
    "#                     lista_csv.append(file)\n",
    "\n",
    "#         elif (str(inicio) and str(final)) in file.lower():\n",
    "#             if unidecode(tipo).lower() in unidecode(file).lower():\n",
    "#                 if unidecode(grupo).lower() in unidecode(file).lower():\n",
    "#                     lista_csv.append(file)\n",
    "#     lista_csv.sort()\n",
    "    \n",
    "#     for i in lista_csv:\n",
    "#         print(i)\n",
    "\n",
    "#     return lista_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f505b4",
   "metadata": {},
   "source": [
    "### Funções para avaliar a PCD e Pontuação de Impacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eef1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def montardf_impacto_docente_discente(df_prod, dic_nomes_docentes, dic_nomes_discentes, inicio, final):\n",
    "#     artigos_com_discentes=[]\n",
    "#     artigos_com_docentes=[]\n",
    "#     lista_semparticipacaodiscente=[]\n",
    "#     lista_semparticipacaodocente=[]\n",
    "\n",
    "#     try:\n",
    "#         ## Montar dataframe de participação docente\n",
    "#         df_impacto_docente = pd.DataFrame(dic_nomes_docentes).T\n",
    "#         df_impacto_docente.columns = ['DOCENTE','INDICES_ARTIGOS','EXTRATOS_QUALIS']\n",
    "#         df_impacto_docente['AUTORIAS'] = [len(x) for x in df_impacto_docente['INDICES_ARTIGOS']]\n",
    "\n",
    "#         ## Criar lista com os artigos onde foi encontado nome de algum docente\n",
    "#         for m in df_impacto_docente['INDICES_ARTIGOS']:\n",
    "#             for n in m:\n",
    "#                 if n not in artigos_com_docentes:\n",
    "#                     artigos_com_docentes.append(n)\n",
    "#         artigos_com_docentes.sort()\n",
    "\n",
    "#         ## Criar lista com os artigos onde NÃO foi encontado nome de docente\n",
    "#         for i in range(len(df_prod.index)):\n",
    "#             if i not in artigos_com_docentes and i not in lista_semparticipacaodocente:\n",
    "#                 lista_semparticipacaodocente.append(i)\n",
    "#     except:\n",
    "#         df_impacto_docente = pd.DataFrame()\n",
    "#         print('Não foi possível encontrar nenhuma ocorrência dos nomes dos docentes com este conjunto de dados')\n",
    "#         pass\n",
    "\n",
    "#     try:\n",
    "#         ## Montar dataframe de participação discente\n",
    "#         df_impacto_discente = pd.DataFrame(dic_nomes_discentes).T\n",
    "#         df_impacto_discente.columns = ['DISCENTE','INDICES_ARTIGOS','EXTRATOS_QUALIS']\n",
    "#         df_impacto_discente['AUTORIAS'] = [len(x) for x in df_impacto_discente['INDICES_ARTIGOS']]\n",
    "\n",
    "#         ## Criar lista com os artigos onde foi encontado nome de algum discente\n",
    "#         for m in df_impacto_discente['INDICES_ARTIGOS']:\n",
    "#             for n in m:\n",
    "#                 if n not in artigos_com_discentes:\n",
    "#                     artigos_com_discentes.append(n)\n",
    "#         artigos_com_discentes.sort()\n",
    "#     except:\n",
    "#         df_impacto_discente = pd.DataFrame()\n",
    "#         print('Não foi possível encontrar nenhuma ocorrência dos nomes dos discentes com este conjunto de dados')\n",
    "#         pass\n",
    "                \n",
    "#     ## Criar lista com os artigos onde NÃO foi encontado nome de discente\n",
    "#     for i in range(len(df_prod.index)):\n",
    "#         if i not in artigos_com_discentes and i not in lista_semparticipacaodiscente:\n",
    "#             lista_semparticipacaodiscente.append(i)\n",
    "\n",
    "#     ## Apresentar resultados das buscas por nomes de autores docentes e discentes\n",
    "#     lista_titulos = pd.Series(df_prod['TITULO'].values).unique().tolist()\n",
    "#     print(len(lista_titulos),'títulos únicos de artigo encontrados')\n",
    "#     pdoc  = np.round(100*len(artigos_com_docentes)/len(df_prod.index),2)\n",
    "#     spdoc = np.round(100*len(lista_semparticipacaodocente)/len(df_prod.index),2)\n",
    "#     print(f'{len(artigos_com_docentes):4} ({pdoc:6}%) artigos com nome de  docente encontrado, faltando {len(lista_semparticipacaodocente):3} ({spdoc:5}%)')\n",
    "\n",
    "#     pdis = np.round(100*len(artigos_com_discentes)/len(df_prod.index),2)\n",
    "#     spdis = np.round(100*len(lista_semparticipacaodiscente)/len(df_prod.index),2)\n",
    "#     print(f'{len(artigos_com_discentes):4} ({pdis:6}%) artigos com nome de discente encontrado, faltando {len(lista_semparticipacaodiscente):3} ({spdis:5}%)')\n",
    "\n",
    "#     ## A1=100, A2=80, B1=60, B2=40, B3=20, B4=10, B5=2\n",
    "#     soma_impacto=[]\n",
    "#     for linha in df_impacto_docente['EXTRATOS_QUALIS']:\n",
    "#         impacto=0\n",
    "#         for extrato in linha:\n",
    "#             if extrato == 'A1':\n",
    "#                 impacto+=100\n",
    "#             elif extrato == 'A2':\n",
    "#                 impacto+=80\n",
    "#             elif extrato == 'B1':\n",
    "#                 impacto+=60\n",
    "#             elif extrato == 'B2':\n",
    "#                 impacto+=40\n",
    "#             elif extrato == 'B3':\n",
    "#                 impacto+=20\n",
    "#             elif extrato == 'B4':\n",
    "#                 impacto+=10\n",
    "#             elif extrato == 'B5':\n",
    "#                 impacto+=2\n",
    "#             elif extrato == 'C':\n",
    "#                 impacto+=0\n",
    "#             elif extrato == 'nan':\n",
    "#                 impacto+=0\n",
    "#         soma_impacto.append(impacto)\n",
    "\n",
    "#     df_impacto_docente['SOMA_IMPACTO'] = soma_impacto\n",
    "#     qte_anos = (final-inicio+1)\n",
    "#     df_impacto_docente['ANOS'] = qte_anos\n",
    "#     df_impacto_docente['IMPACTO_MEDIO_ANUAL'] = np.round(df_impacto_docente['SOMA_IMPACTO']/df_impacto_docente['ANOS'],1)\n",
    "\n",
    "#     return df_impacto_docente, df_impacto_discente\n",
    "\n",
    "\n",
    "\n",
    "# def apurar_pcd_impacto(df_docentes, df_impacto_docente, df_impacto_discente, meta_pcd=50.0, meta_impacto=150.0):\n",
    "#     print(f'Total de nomes de docentes em análise: {len(df_docentes.index)}')\n",
    "#     print(f'Total de nomes de docentes  encontrados nos artigos: {len(df_impacto_docente.index)}')\n",
    "#     print(f'Total de nomes de discentes encontrados nos artigos: {len(df_impacto_discente.index)}')\n",
    "\n",
    "#     df_docentes_pcd_impacto = df_docentes\n",
    "#     ## Montar lista com os índices do dataframe de artigos onde foram achados nomes de discentes na lista de autores\n",
    "#     lista_participacao_discente = []\n",
    "#     for artigos_discentes in df_impacto_discente['INDICES_ARTIGOS']:\n",
    "#         for indice in artigos_discentes:\n",
    "#             lista_participacao_discente.append(indice)\n",
    "\n",
    "#     ## Contar a quantidade de participações de discentes que ocorrem no dataframe de produção docente\n",
    "#     qte_colab_discente=[]\n",
    "#     for docente,artigos_docente in zip(df_impacto_docente['DOCENTE'], df_impacto_docente['INDICES_ARTIGOS']):\n",
    "#         qte=0\n",
    "#         for indice in artigos_docente:\n",
    "#             if indice in lista_participacao_discente:\n",
    "#                 qte+=1\n",
    "            \n",
    "#         qte_colab_discente.append(qte)\n",
    "\n",
    "#     df_docentes_pcd_impacto['PUBLICAÇÕES']  = df_impacto_docente['AUTORIAS']\n",
    "#     df_docentes_pcd_impacto['COM_DISCENTE'] = qte_colab_discente\n",
    "#     df_docentes_pcd_impacto['PCD'] = np.round(100*(df_docentes_pcd_impacto['COM_DISCENTE']/df_impacto_docente['AUTORIAS']),1)\n",
    "#     df_docentes_pcd_impacto['IMPACTO'] = df_impacto_docente['SOMA_IMPACTO']\n",
    "#     df_docentes_pcd_impacto['IMPACTO_MEDIO_ANUAL'] = df_impacto_docente['IMPACTO_MEDIO_ANUAL']\n",
    "\n",
    "#     ## Definir a meta de produção conjunta com discente e apurar o resultado\n",
    "#     # meta_pcd=50.0\n",
    "#     apuracao_pcd     = df_docentes_pcd_impacto.groupby([df_docentes_pcd_impacto.index,'PCD'])\n",
    "#     df_abaixo_pcd    = apuracao_pcd.filter(lambda x: x['PCD'] < meta_pcd)\n",
    "#     df_atingiram_pcd = apuracao_pcd.filter(lambda x: x['PCD'] >= meta_pcd)\n",
    "\n",
    "#     total_docentes         = len(df_docentes_pcd_impacto.index)\n",
    "\n",
    "#     contagem_abaixometa    = len(df_abaixo_pcd.index)\n",
    "#     contagem_atingindometa = len(df_atingiram_pcd.index)\n",
    "#     indicador_pcd = np.round(100*contagem_atingindometa/total_docentes,1)\n",
    "#     print(f'{indicador_pcd}% dos docentes {contagem_atingindometa}/{total_docentes} atingem a meta de {meta_pcd}% publicação com discente')\n",
    "\n",
    "#     ## Definir a meta de impacto por pesquisador e para o grupo\n",
    "#     # meta_impacto=150\n",
    "#     apuracao_impacto     = df_docentes_pcd_impacto.groupby([df_docentes_pcd_impacto.index,'IMPACTO'])\n",
    "#     df_abaixo_impacto    = apuracao_impacto.filter(lambda x: x['IMPACTO_MEDIO_ANUAL'] < meta_impacto)\n",
    "#     df_atingiram_impacto = apuracao_impacto.filter(lambda x: x['IMPACTO_MEDIO_ANUAL'] >= meta_impacto)\n",
    "\n",
    "#     contagem_abaixometa_impacto    = len(df_abaixo_impacto.index)\n",
    "#     contagem_atingindometa_impacto = len(df_atingiram_impacto.index)\n",
    "#     indicador_impacto = np.round(100*contagem_atingindometa_impacto/total_docentes,1)\n",
    "#     print(f'{indicador_impacto}% dos docentes {contagem_atingindometa_impacto}/{total_docentes} atingem a meta de {meta_impacto} pontos de impacto médio por ano das publicações')\n",
    "\n",
    "#     return df_docentes_pcd_impacto, apuracao_pcd, df_abaixo_pcd, df_atingiram_pcd, indicador_pcd, indicador_impacto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cda89d",
   "metadata": {},
   "source": [
    "### Funções para plotagem: \n",
    "    \n",
    "    Plotar gráficos de percentual de participação discente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.offsetbox import (TextArea, DrawingArea, OffsetImage, AnnotationBbox)\n",
    "from matplotlib.cbook import get_sample_data\n",
    "plt.rcParams['font.size']      = 12\n",
    "# plt.rcParams[\"figure.figsize\"] = (15,9)\n",
    "\n",
    "\n",
    "\n",
    "def plotar_pcd(df, grupo=False, inicio=False, final=False):\n",
    "    N    = len(df.index)\n",
    "    percentual = (df['PCD'].values.round(1))\n",
    "\n",
    "    ind   = np.arange(N) # the x locations for the groups\n",
    "    width = 0.75         # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "    # criar figura\n",
    "    fig, ax = plt.subplots(figsize=(25,10))\n",
    "\n",
    "    # plotar barras verticais com cores condicionais se abaixo do valor da variável para aceitação\n",
    "    par = 50 \n",
    "    cor = ['yellow' if (x < par) else 'green' for x in percentual]\n",
    "    p1  = ax.bar(ind, percentual, width, \n",
    "                #  yerr=dsvpad, \n",
    "                 error_kw=dict(lw=0.3, capsize=2, capthick=1),\n",
    "                 label='Percentual de publicação com discente', color=cor)\n",
    "\n",
    "    # plotar os rótulos e título\n",
    "    ax.axhline(par, color='red', linewidth=3, linestyle='dotted')\n",
    "    ax.axhline(70, color='gray', linewidth=3, linestyle='dotted')\n",
    "    if (grupo and inicio and final) != False:\n",
    "        ax.set_title(f'Apuração do percentual de publicação de docentes {grupo.upper()} com discente no período de {inicio} a {final}')\n",
    "    elif grupo == False:\n",
    "        ax.set_title(f'Apuração do percentual de publicação de docentes com discente no período de {inicio} a {final}')\n",
    "    else:\n",
    "        ax.set_title(f'Apuração do percentual de publicação com discente')\n",
    "\n",
    "    ax.set_ylabel('Percentual de artigos publicados com discente')\n",
    "    ax.set_xticks(ind)\n",
    "    \n",
    "    labels_pos=np.arange(1,N+1)\n",
    "    ax.set_xticklabels(labels_pos)\n",
    "\n",
    "    # Label with label_type 'center' instead of the default 'edge'\n",
    "    ax.bar_label(p1, label_type='center')\n",
    "    # ax.bar_label(p1, dsvpad)\n",
    "    # ax.set_yticks(range(0,100))\n",
    "    \n",
    "    # respectivo domínio de cada questão no AGREE II\n",
    "    grupos = ['01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01',\n",
    "              '02','02','02','02','02','02','02','02','02','02','02','02','02','02','02','02',]\n",
    "    \n",
    "    # calcular limites de retângulos dos domínios\n",
    "    lista_dominios   = pd.Series(grupos)\n",
    "    largura_dominios = lista_dominios.value_counts().sort_index().values   \n",
    "    altura = 100\n",
    "    rets=[]   \n",
    "    \n",
    "    for i in range(1,len(largura_dominios)+1):\n",
    "        ret = patches.Rectangle((-0.5,0),\n",
    "                                np.sum(largura_dominios[:i]), altura,\n",
    "#                                 linestyle='dashdot',\n",
    "                                linewidth=2,\n",
    "                                edgecolor='b',\n",
    "                                fill = False)\n",
    "        rets.append(ret)\n",
    "    \n",
    "    # plotar os retângulos das dimensões na área do gráfico\n",
    "    for i in rets:\n",
    "        ax.add_patch(i)\n",
    "        \n",
    "    # plotar legenda, comentar para excluir\n",
    "    # ax.legend(bbox_to_anchor=(0.75,-0.05), ncol=2)\n",
    "    \n",
    "    campo='04'\n",
    "    # savefig_respostas(campo)\n",
    "    \n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "def plotar_medias_impacto(df, grupo=False, inicio=False, final=False):\n",
    "    N      = len(df.index)\n",
    "    pontos = (df['IMPACTO_MEDIO_ANUAL'].values.round(1))\n",
    "\n",
    "    ind   = np.arange(N) # the x locations for the groups\n",
    "    width = 0.75         # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "    # criar figura\n",
    "    fig, ax = plt.subplots(figsize=(25,10))\n",
    "\n",
    "    # plotar barras verticais com cores condicionais se abaixo do valor da variável para aceitação\n",
    "    par = 150 \n",
    "    cor = ['yellow' if (x < par) else 'green' for x in pontos]\n",
    "    p1  = ax.bar(ind, pontos, width, \n",
    "                #  yerr=dsvpad, \n",
    "                 error_kw=dict(lw=0.3, capsize=2, capthick=1),\n",
    "                 label='Pontuação em impacto das publicações de docentes', color=cor)\n",
    "\n",
    "    # plotar os rótulos e título\n",
    "    ax.axhline(par, color='red', linewidth=3, linestyle='dotted')\n",
    "    if (grupo and inicio and final) != False:\n",
    "        ax.set_title(f'Apuração da pontuação de impacto das publicações de docentes {grupo.upper()} no período de {inicio} a {final}')\n",
    "    elif (inicio and final) != False:\n",
    "        ax.set_title(f'Apuração da pontuação de impacto das publicações de docentes no período de {inicio} a {final}')\n",
    "    else:\n",
    "        ax.set_title(f'Apuração da pontuação de impacto médio (total do impacto acumulado / quantidade de anos do período) das publicações de docentes')\n",
    "\n",
    "    ax.set_ylabel('Pontuação ponderada pelo Qualis dos artigos publicados')\n",
    "    ax.set_xticks(ind)\n",
    "    \n",
    "    labels_pos=np.arange(1,N+1)\n",
    "    ax.set_xticklabels(labels_pos)\n",
    "\n",
    "    # Label with label_type 'center' instead of the default 'edge'\n",
    "    ax.bar_label(p1, label_type='center')\n",
    "    # ax.bar_label(p1, dsvpad)\n",
    "    vr_maximo = int(max(pontos)+50)\n",
    "    # ax.set_yticks(range(0,vr_maximo))\n",
    "    \n",
    "    # respectivo domínio de cada questão no AGREE II\n",
    "    grupos = ['01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01',\n",
    "              '02','02','02','02','02','02','02','02','02','02','02','02','02','02','02','02',]\n",
    "    \n",
    "    # calcular limites de retângulos dos domínios\n",
    "    lista_dominios   = pd.Series(grupos)\n",
    "    largura_dominios = lista_dominios.value_counts().sort_index().values   \n",
    "    altura = max(pontos)+50\n",
    "    rets=[]   \n",
    "    \n",
    "    for i in range(1,len(largura_dominios)+1):\n",
    "        ret = patches.Rectangle((-0.5,0),\n",
    "                                np.sum(largura_dominios[:i]), altura,\n",
    "#                                 linestyle='dashdot',\n",
    "                                linewidth=2,\n",
    "                                edgecolor='b',\n",
    "                                fill = False)\n",
    "        rets.append(ret)\n",
    "    \n",
    "    # plotar os retângulos das dimensões na área do gráfico\n",
    "    for i in rets:\n",
    "        ax.add_patch(i)\n",
    "        \n",
    "    # plotar legenda, comentar para excluir\n",
    "    # ax.legend(bbox_to_anchor=(0.75,-0.05), ncol=2)\n",
    "    \n",
    "    campo='04'\n",
    "    # savefig_respostas(campo)\n",
    "    \n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fa03cb",
   "metadata": {},
   "source": [
    "## Apurar participação discente e impacto artigos dos docentes\n",
    "### Todos os períodos e grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(pathcsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea408ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes_docentes_permanentes   = 'lista_docentes_permanentes.csv'\n",
    "lista_nomes_docentes_colaboradores = 'lista_docentes_colaboradores.csv'\n",
    "df_docentes = montardf_docentes(lista_nomes_docentes_permanentes, lista_nomes_docentes_colaboradores)\n",
    "\n",
    "## Escolha dos arquivos que alimentarão a análise da produção\n",
    "lista_csv = ler_artigostodosperiodos()\n",
    "lista_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2eb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c09d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfilename = os.path.join(pathcsv,'lista_docentes.csv')\n",
    "lista_csv = pd.read_csv(pathfilename,header=None)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod   = montardf_producao(lista_csv)\n",
    "\n",
    "## Mostrar quantitativos lidos\n",
    "print(f'\\nCarregado dataframe com {len(df_prod.index)} linhas:')\n",
    "lista_titulos = pd.Series(df_prod['TITULO'].values).unique().tolist()\n",
    "print(f'{len(lista_titulos):4} artigos distintos publicados no período')\n",
    "lista_revistas = pd.Series(df_prod['REVISTA'].values).unique().tolist()\n",
    "print(f'{len(lista_revistas):4} revistas distintas utilizadas no período')\n",
    "\n",
    "## Ler nomes de docentes, discentes e papel de orientador\n",
    "lista_autores_artigos, lista_docentes, lista_orientadores, lista_discentes = montar_listas(lista_csv)\n",
    "qte_docentes=len(lista_docentes)\n",
    "qte_discentes=len(lista_discentes)\n",
    "total_iteracoes=(qte_docentes+qte_discentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e2c31",
   "metadata": {},
   "source": [
    "    Organizar lista de autores e iniciais de nomes\n",
    "    PROBLEMA: não está quebrando no número de artigos 1115, mas sim em apenas 2 e última vazia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f515360",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Montar a lista de autores a partir da lista de strings limpa com nomes de autores\n",
    "def organizar_nomes(str_autores_artigo):\n",
    "    erros_organizar  = []\n",
    "    lista_organizada = []\n",
    "    partes_nomes = str_autores_artigo.split(', ')\n",
    "    n       = len(partes_nomes)\n",
    "    pares   = range(0,n+1,2)\n",
    "    impares = range(1,n+1,2)\n",
    "    try:\n",
    "        for i,j in zip(pares,impares):\n",
    "            nome=[]\n",
    "            try:\n",
    "                nomes_ordenado = str(partes_nomes[j].lower()+' '+partes_nomes[i].lower()).replace('  ',' ').strip()\n",
    "            except:\n",
    "                if len(pares) > len(impares):\n",
    "                    nomes_ordenado = str(partes_nomes[j].lower()).replace('  ',' ').strip()\n",
    "                else:\n",
    "                    nomes_ordenado = str(partes_nomes[i].lower()).replace('  ',' ').strip()\n",
    "            lista_organizada.append(nomes_ordenado)\n",
    "    \n",
    "    except Exception as e1:\n",
    "        print('Erro ao montar listas de nomes de autor:',e1)\n",
    "        erros_organizar.append((i,str_autores_artigo))\n",
    "\n",
    "    return lista_organizada, erros_organizar\n",
    "\n",
    "## Quebrar um nome em seu sobrenome seguido das partes de nome\n",
    "def quebrar_partesnomes(nome):\n",
    "    padrao     = padronizar_nome(nome).lower()\n",
    "    sobrenome  = padrao.split(',')[0].strip()\n",
    "    restonomes = padrao.split(',')[1].strip().split(' ')\n",
    "    try:\n",
    "        partenome1 = restonomes[0].strip()\n",
    "    except:\n",
    "        partenome1 = np.NaN\n",
    "    try:\n",
    "        partenome2 = restonomes[1].strip()\n",
    "    except:\n",
    "        partenome2 = np.NaN\n",
    "    try:\n",
    "        partenome3 = restonomes[2].strip()\n",
    "    except:\n",
    "        partenome3 = np.NaN        \n",
    "    # print(f'{sobrenome:15} | {partenome1:1} | {partenome2:1} | {partenome3}')\n",
    "    \n",
    "    return sobrenome, partenome1, partenome2, partenome3\n",
    "\n",
    "\n",
    "## Quebrar um nome em seu sobrenome seguido as iniciais das partes de nome\n",
    "def quebrar_iniciais(nome):\n",
    "    padrao = iniciais_nome(nome).lower()\n",
    "    sobrenome  = padrao.split(',')[0].strip()\n",
    "    restonomes = padrao.split(',')[1].strip().split(' ')\n",
    "\n",
    "    try:\n",
    "        partenome1 = restonomes[0].strip()\n",
    "    except:\n",
    "        partenome1 = np.NaN\n",
    "    try:\n",
    "        partenome2 = restonomes[1].strip()\n",
    "    except:\n",
    "        partenome2 = np.NaN\n",
    "    try:\n",
    "        partenome3 = restonomes[2].strip()\n",
    "    except:\n",
    "        partenome3 = np.NaN        \n",
    "    # print(f'{sobrenome:15} | {partenome1:1} | {partenome2:1} | {partenome3}')\n",
    "    \n",
    "    return sobrenome, partenome1, partenome2, partenome3\n",
    "\n",
    "\n",
    "## compilar padrão regular expression para buscar ocorência de duas das quatro partes de nome dentro de janela de no máximo 2 palavras de distância\n",
    "def compilar_partes(sobrenome, partenome1, partenome2, partenome3):\n",
    "    return re.compile(r'\\b({0}|{1}|{2}|{3})(?:\\W+\\w+){{0,2}}?\\W+({1}&{2}|{2}&{3}|{0}&{1}|{0}&{3})\\b'.format(sobrenome, partenome1, partenome2, partenome3), flags=re.IGNORECASE)\n",
    "\n",
    "def compilar_iniciais(sobrenome, inicial1, inicial2, inicial3):\n",
    "    return re.compile(r'\\b({0})(?:\\W+\\w+){{0,1}}?\\W+({1}|{2}|{3})\\b'.format(sobrenome, inicial1, inicial2, inicial3), flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ffe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_dicionarios(df_prod, lista_docentes, lista_discentes, inicio = min(df_prod['Ano']), final  = max(df_prod['Ano'])):\n",
    "    qte_docentes     = len(lista_docentes)\n",
    "    qte_discentes    = len(lista_discentes)\n",
    "    total_iteracoes  = (qte_docentes+qte_discentes)\n",
    "    \n",
    "    ## Monta uma lista de strings com nomes dos autores de cada artigo na forma extraída pelo e-lattes\n",
    "    lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "    qte_artigos         = len(lista_nomes_autores)\n",
    "        \n",
    "    ## Define os limites para considerar duas strings com nomes similares entre si\n",
    "    limite_jaro_nome        = 0.88\n",
    "    limite_jaro_iniciais    = 0.75\n",
    "    limite_jaccard_iniciais = 0.32\n",
    "\n",
    "    ## Função para calcular similaridade dos nomes de docentes com cada nome de autor da lista de autores de cada artigo\n",
    "    t1 = time.time()\n",
    "    dic_nomes_docentes  = {}\n",
    "    dic_nomes_discentes = {}    \n",
    "    erros=[]\n",
    "    rot1='Comparando nome do docente'\n",
    "    rot2='Sobren/Iniciais docen'\n",
    "    rot3='Sobrenome/Iniciais autor'\n",
    "    rot4='I.Doc'\n",
    "    rot5='I.Aut'\n",
    "    rot6='Jaro-Winkler'\n",
    "    rot7='Jaccard'\n",
    "    for m,docente in enumerate(lista_docentes):\n",
    "        achados_docentes     = []\n",
    "        lista_indice_docente = []\n",
    "        lista_qualis_docente = []\n",
    "        docentes_naoencontrados = []          \n",
    "        contagem=m+1\n",
    "        # clear_output(wait=True)       \n",
    "        try:\n",
    "            nome_docente_padronizado = padronizar_nome(docente).lower()\n",
    "            iniciais_nome_docente    = iniciais_nome(docente).lower()\n",
    "            string_iniciais_docente  = ' '.join(x.strip() for x in iniciais_nome_docente.split(',')[1:])\n",
    "            set_iniciais_docente     = converter_lista_set([x.strip() for x in iniciais_nome_docente.split(',')[1:]])                \n",
    "            print(f'\\nCálculo das similaridades autores-docentes (nome/iniciais/Jaccard):')\n",
    "            print(f'{rot1:^40} |{rot2:^20}| {rot3:^25}|{rot4:^5}|{rot5:^5}|{rot6:^15}|{rot7:^10}')\n",
    "            ## Monta a lista de autores com a divisão da string organizada padronizada no formato: {sobrenome, iniciais de nomes}\n",
    "            lst_autores_artigo = []\n",
    "            lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "            for n,nomes_autor in enumerate(lista_nomes_autores):\n",
    "                autores,erros = organizar_nomes(nomes_autor)\n",
    "                for o,autor in enumerate(autores):\n",
    "                    qte_autores_artigo = len(autores)\n",
    "                    # print(f'{o+1:2}/{qte_autores_artigo:2} nomes de autor do artigo em análise, restando {qte_autores_artigo-o-1:2}')\n",
    "                    nome_autor_padronizado = padronizar_nome(autor).lower()\n",
    "                    try:    \n",
    "                        iniciais_nome_autor    = iniciais_nome(autor).lower()\n",
    "                        string_iniciais_autor  = ' '.join(x.strip() for x in iniciais_nome_autor.split(',')[1:])\n",
    "                        set_iniciais_autor     = converter_lista_set([x.strip() for x in iniciais_nome_autor.split(',')[1:]])\n",
    "                        # time.sleep(1)\n",
    "                        ## Cálculos de similaridades entre os nomes do autor e do docente\n",
    "                        if iniciais_nome_docente and iniciais_nome_autor != '':\n",
    "                            similaridade_nome     = get_jaro_distance(iniciais_nome_docente, iniciais_nome_autor)\n",
    "                            similaridade_iniciais = get_jaro_distance(string_iniciais_docente, string_iniciais_autor)\n",
    "                            similaridade_jaccard  = np.round(jaccard_similarity(set_iniciais_docente, set_iniciais_autor),2)\n",
    "                            print(f'\\nCálculo das similaridades autores-discentes (nome/iniciais/Jaccard):')\n",
    "                            print(f'{padronizar_nome(docente):^40} | {iniciais_nome_docente:<20}|{iniciais_nome_autor:<20} {similaridade_nome:^5}|{string_iniciais_docente:^5}|{string_iniciais_autor:^5}|{similaridade_iniciais:^15}|{similaridade_jaccard:^10}')\n",
    "                            clear_output(wait=True)\n",
    "                            if similaridade_nome > limite_jaro_nome and similaridade_iniciais > limite_jaro_iniciais and similaridade_jaccard > limite_jaccard_iniciais:\n",
    "                                if n not in lista_indice_docente:\n",
    "                                    print(f'Similaridade encontrada no artigo {n+1}/{qte_artigos}, docente {m+1}/{qte_docentes}')\n",
    "                                    print(f'{rot1:^40} |{rot2:^20}| {rot3:^25}|{rot4:^5}|{rot5:^5}|{rot6:^15}|{rot7:^10}')\n",
    "                                    print(f'{padronizar_nome(docente):^40} | {iniciais_nome_docente:<20}|{iniciais_nome_autor:<20} {similaridade_nome:^5}|{string_iniciais_docente:^5}|{string_iniciais_autor:^5}|{similaridade_iniciais:^15}|{similaridade_jaccard:^10}')\n",
    "                                    achados_docentes.append(docente)\n",
    "                                    lista_indice_docente.append(n)\n",
    "                                    # print(len(lista_indice_docente))\n",
    "                                    extrato = df_prod['Qualis'][n]\n",
    "                                    lista_qualis_docente.append(extrato)\n",
    "                                    clear_output(wait=True)                                    \n",
    "                    except Exception as e1:\n",
    "                        # print(f'Erro na etapa 1 de gerar_dicionarios, ao tratar iniciais do nome de autor/docente da linha  {n}/{o}/{qte_docentes}/{qte_artigos}')\n",
    "                        # print(e1)\n",
    "                        similaridade_iniciais = np.NaN\n",
    "                        similaridade_jaccard  = np.NaN\n",
    "                        erros.append(('e1_similaridadesdocente',m,n,o,e1))                    \n",
    "                lst_autores_artigo.append(iniciais_nome_autor)\n",
    "            # print(f'Lista organizada de nomes de autores: {len(lst_autores_artigo)} listas de autores de artigos publicados no período')\n",
    "\n",
    "            ## Ao final da leitura todos artigos para cada docente, criar o dicionário de docentes quando docente tenha aparecido na linha de autores\n",
    "            if lista_indice_docente != []:\n",
    "                dic_nomes_docentes[m] = (docente, lista_indice_docente, lista_qualis_docente)\n",
    "            else:\n",
    "                docentes_naoencontrados.append(docente)\n",
    "\n",
    "            tdec=time.time()-t1\n",
    "            # tres=tdec/(m+1)*((qte_docentes-m)+qte_discentes)\n",
    "            # print(f'Analisadas{m+1:4}/{total_iteracoes} iterações em {horas(tdec)}, restando {total_iteracoes-m}. Busca{m+1:4}/{qte_docentes:<4}docente: {docente.title():50}')\n",
    "            # print(f'Nome do docente foi encontrado em {len(lista_indice_docente):2} artigos')\n",
    "        except Exception as e2:\n",
    "            # print(f'Erro na etapa 2 de gerar_dicionarios, ao calcular similaridades de autor/docente  da linha {n}/{o}/{qte_docentes}/{qte_artigos}')\n",
    "            # print(e2)\n",
    "            erros.append(('e2_padronizardocentes',m,n,o,e2)) \n",
    "\n",
    "    ## Função para calcular similaridade dos nomes de discentes com cada nome de autor da lista de autores de cada artigo\n",
    "    for p,discente in enumerate(lista_discentes):\n",
    "        achados_discentes     = []\n",
    "        lista_indice_discente = []\n",
    "        lista_qualis_discente = []\n",
    "        discentes_naoencontrados = []\n",
    "        contagem=m+p+1\n",
    "        # clear_output(wait=True)       \n",
    "        try:\n",
    "            nome_discente_padronizado = padronizar_nome(discente).lower()\n",
    "            iniciais_nome_discente    = iniciais_nome(discente).lower()\n",
    "            string_iniciais_discente  = ' '.join(x.strip() for x in iniciais_nome_discente.split(',')[1:])\n",
    "            set_iniciais_discente     = converter_lista_set([x.strip() for x in iniciais_nome_discente.split(',')[1:]])\n",
    "            rot2='Sobren/Iniciais disce'\n",
    "            rot4='I.Dis'            \n",
    "            ## Monta a lista de autores com a divisão da string organizada padronizada no formato: {sobrenome, iniciais de nomes}\n",
    "            lst_autores_artigo = []\n",
    "            lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "            for n,nomes_autor in enumerate(lista_nomes_autores):\n",
    "                # clear_output(wait=True)\n",
    "                # print(f'Procurando {nome_discente_padronizado.title()} em {n+1:2}/{qte_artigos:<2} artigos, restando {qte_artigos-n-1:<2}')\n",
    "                autores,erros = organizar_nomes(nomes_autor)\n",
    "                for q,autor in enumerate(autores):\n",
    "                    qte_autores_artigo = len(autores)\n",
    "                    nome_autor_padronizado = padronizar_nome(autor).lower()\n",
    "                    # print(f'{q+1:2}/{qte_autores_artigo:2} nomes de autor do artigo em análise, restando {qte_autores_artigo-q-1:2}')\n",
    "                    nome_autor_padronizado = padronizar_nome(autor).lower()\n",
    "                    try:    \n",
    "                        iniciais_nome_autor    = iniciais_nome(autor).lower()\n",
    "                        string_iniciais_autor  = ' '.join(x.strip() for x in iniciais_nome_autor.split(',')[1:])\n",
    "                        set_iniciais_autor     = converter_lista_set([x.strip() for x in iniciais_nome_autor.split(',')[1:]])   \n",
    "                        ## Cálculos de similaridades entre os nomes do autor e do discente\n",
    "                        if iniciais_nome_discente and iniciais_nome_autor != '':\n",
    "                            similaridade_nome     = get_jaro_distance(iniciais_nome_discente, iniciais_nome_autor)\n",
    "                            similaridade_iniciais = get_jaro_distance(string_iniciais_discente, string_iniciais_autor)\n",
    "                            similaridade_jaccard  = np.round(jaccard_similarity(set_iniciais_discente, set_iniciais_autor),2)\n",
    "                            print(f'{padronizar_nome(discente):^40} | {iniciais_nome_discente:<20}|{iniciais_nome_autor:<20} {similaridade_nome:^5}|{string_iniciais_docente:^5}|{string_iniciais_autor:^5}|{similaridade_iniciais:^15}|{similaridade_jaccard:^10}')                            \n",
    "                            if similaridade_nome > limite_jaro_nome and similaridade_iniciais > limite_jaro_iniciais and similaridade_jaccard > limite_jaccard_iniciais:\n",
    "                                if n not in lista_indice_discente:\n",
    "                                    print(f'Similaridade encontrada no artigo {n+1}/{qte_artigos}, discente {p+1}/{qte_discentes}')\n",
    "                                    print(f'{rot1:^40} |{rot2:^20}| {rot3:^25}|{rot4:^5}|{rot5:^5}|{rot6:^15}|{rot7:^10}')\n",
    "                                    print(f'{padronizar_nome(discente):^40} | {iniciais_nome_discente:<20}|{iniciais_nome_autor:<20} {similaridade_nome:^5}|{string_iniciais_discente:^5}|{string_iniciais_autor:^5}|{similaridade_iniciais:^15}|{similaridade_jaccard:^10}')\n",
    "                                    achados_discentes.append(discente)\n",
    "                                    lista_indice_discente.append(n)\n",
    "                                    # print(len(lista_indice_discente))\n",
    "                                    extrato = df_prod['Qualis'][n]\n",
    "                                    lista_qualis_discente.append(extrato)\n",
    "                                    clear_output(wait=True)\n",
    "                    except Exception as e3:\n",
    "                        similaridade_iniciais = np.NaN\n",
    "                        similaridade_jaccard  = np.NaN\n",
    "                        # print(f'Erro na etapa 3 de gerar_dicionarios, ao calcular similaridades de nomes de autor/discente da linha {n}/{o}/{qte_discentes}/{qte_artigos}')\n",
    "                        # print(e3)\n",
    "                        erros.append(('e3_buscadiscentes',p,n,q,e3))\n",
    "        \n",
    "            ## Ao final da leitura todos artigos para cada discente, criar o dicionário de discente quando docente tenha aparecido na linha de autores\n",
    "            if lista_indice_discente != []:\n",
    "                dic_nomes_discentes[o] = (discente, lista_indice_discente, lista_qualis_discente)\n",
    "            else:\n",
    "                discentes_naoencontrados.append(discente)            \n",
    "            \n",
    "            tdec=time.time()-t1\n",
    "            # tres=tdec/(o+p+1)*((qte_discentes-p)+qte_discentes)\n",
    "            # print(f'Analisadas{contagem+1:4}/{total_iteracoes} iterações em {horas(tdec)}, restando {horas(tres)} para iterar {total_iteracoes-contagem-1}. Busca{p+1:4}/{qte_discentes:<4}discente: {discente.title():50}')\n",
    "            # print(f'Nome do discente foi encontrado em {len(lista_indice_discente):2} artigos')   \n",
    "        except Exception as e4:\n",
    "            # print('Erro na etapa 4 de gerar_dicionarios, ao finalizar montagem dos dicionários:',e4)\n",
    "            erros.append(('e4_padronizardiscente',m,n,e4))\n",
    "\n",
    "    return dic_nomes_docentes, dic_nomes_discentes, docentes_naoencontrados, discentes_naoencontrados, erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770168bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_nomes_docentes, dic_nomes_discentes, docentes_naoencontrados, discentes_naoencontrados, erros = gerar_dicionarios(df_prod, lista_docentes, lista_discentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_nomes_docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docentes_naoencontrados),'total de nomes de  docentes não encontrados nos artigos')\n",
    "print(len(discentes_naoencontrados),'total de nomes de discentes não encontrados nos artigos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afedd039",
   "metadata": {},
   "outputs": [],
   "source": [
    "discentes_naoencontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(erros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac927dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "erros[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdffe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista_artigos_problemas = []\n",
    "# lista_autores_problemas = []\n",
    "# for etapa,docente,i,discente,artigo in erros:\n",
    "#     if i not in lista_artigos_problemas:\n",
    "#         lista_artigos_problemas.append(i)\n",
    "#         lista_autores_problemas.append(df_prod['AUTORES'][i])\n",
    "\n",
    "# df_artigos_problemas=pd.DataFrame(lista_artigos_problemas).reset_index(drop=True)\n",
    "# df_artigos_problemas['LISTA_AUTORES'] = lista_autores_problemas\n",
    "# df_artigos_problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d13905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Lista ordenada alfabeticamente pelos sobrenomes de docentes\n",
    "# lista_docentes_sobrenome=[]\n",
    "# for i in lista_docentes:\n",
    "#     lista_docentes_sobrenome.append(iniciais_nome(i))\n",
    "    \n",
    "# lista_docentes_sobrenome.sort()\n",
    "# for j in lista_docentes_sobrenome:\n",
    "#     print(f'{j.lower()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a71542",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2017\n",
    "final  = 2022\n",
    "df_impacto_docente, df_impacto_discente = montardf_impacto_docente_discente(df_prod, dic_nomes_docentes, dic_nomes_discentes, inicio, final)\n",
    "df_impacto_docente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d83d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docentes = montardf_docentes(lista_nomes_docentes_permanentes, lista_nomes_docentes_colaboradores)\n",
    "df_docentes_pcd_impacto, apuracao_pcd, df_abaixo_pcd, df_atingiram_pcd, indicador_pcd, indicador_impacto = apurar_pcd_impacto(df_docentes, df_impacto_docente, df_impacto_discente, meta_pcd=50.0, meta_impacto=150.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36af03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotar_pcd(df_docentes_pcd_impacto)\n",
    "plotar_medias_impacto(df_docentes_pcd_impacto, grupo=False, inicio=False, final=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd992d",
   "metadata": {},
   "source": [
    "### Funções avaliação PCD e Impacto Médio Anual: \n",
    "    Avaliar indicadores PCD e Somatório do Fator de Impacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes):\n",
    "    ## Ler arquivos de dados\n",
    "    lista_csv   = ler_csvptg(inicio, final, tipo, grupo)\n",
    "    df_public   = montardf_producao(lista_csv)\n",
    "    df_docentes = montardf_docentes(lista_nomes_docentes)\n",
    "    lista_autores_artigos, lista_docentes, lista_orientadores, lista_discentes = montar_listas(lista_csv, lista_nomes_docentes)\n",
    "\n",
    "    ## Avaliação da Publicação Conjunta com Discentes (PCD) e do Impacto Médio Anual (IMA)\n",
    "    dic_nomes_docentes, dic_nomes_discentes, docentes_naoencontrados, discentes_naoencontrados, erros = gerar_dicionarios(df_public, lista_docentes, lista_discentes, inicio, final)\n",
    "    df_impacto_docente, df_impacto_discente = montardf_impacto_docente_discente(df_public, dic_nomes_docentes, dic_nomes_discentes, inicio, final)\n",
    "\n",
    "    ## Gerar gráfico de apuração de impacto médio anual por docente\n",
    "    df_docentes_pcd_impacto, apuracao_pcd, df_abaixo_pcd, df_atingiram_pcd, indicador_pcd, indicador_impacto = apurar_pcd_impacto(df_docentes, df_impacto_docente, df_impacto_discente)\n",
    "    plotar_pcd(df_docentes_pcd_impacto, grupo, inicio, final)\n",
    "    plotar_medias_impacto(df_docentes_pcd_impacto, grupo, inicio, final)\n",
    "\n",
    "    return df_public, df_impacto_docente, df_impacto_discente, df_docentes_pcd_impacto, indicador_pcd, indicador_impacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85feab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f486c9c2",
   "metadata": {},
   "source": [
    "### Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,b='',''\n",
    "# get_jaro_distance(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbcfc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b='1','0'\n",
    "get_jaro_distance(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4fb0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "print(len(lista_nomes_autores))\n",
    "print(lista_nomes_autores[0])\n",
    "\n",
    "## Verifica se a divisão em nomes de autor é par (sobrenome separado de nomes por vírgula)\n",
    "for i in lista_nomes_autores[:14]:\n",
    "    qte_nomes_autor = len(i.split(','))\n",
    "    if qte_nomes_autor/2 != qte_nomes_autor//2:\n",
    "        print(qte_nomes_autor,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ed58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m,docente in enumerate(lista_docentes):\n",
    "    nome_docente_padronizado = padronizar_nome(docente).lower()\n",
    "    iniciais_nome_docente    = iniciais_nome(docente).lower()\n",
    "    print(iniciais_nome_docente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4278bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ## Monta a lista de autores com a divisão da string de nomes acima por: sobrenome, nomes\n",
    "    # lst_autores_artigo = []\n",
    "    # lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "    # for n,nomes_autor in enumerate(lista_nomes_autores):\n",
    "    #     autores,erros = organizar_nomes(nomes_autor)\n",
    "    #     # print(autores,'\\n')\n",
    "    #     for o,autor in enumerate(autores):\n",
    "    #         # print(autor)\n",
    "    #         # print(f'{o+1:2}/{qte_autores_artigo:2} nomes de autor do artigo em análise, restando {qte_autores_artigo-o-1:2}')\n",
    "    #         sobrenome_iniciais_autor = iniciais_nome(autor).lower()\n",
    "    #         string_iniciais_autor    = ' '.join(x.strip() for x in sobrenome_iniciais_autor.split(',')[1:])\n",
    "    #         set_iniciais_autor       = converter_lista_set([x.strip() for x in sobrenome_iniciais_autor.split(',')[1:]])\n",
    "    #         print(f'{sobrenome_iniciais_autor:20}|{string_iniciais_autor:^9}|{set_iniciais_autor}')\n",
    "    #     lst_autores_artigo.append(sobrenome_iniciais_autor)\n",
    "    # print(f'Lista organizada de nomes de autores: {len(lst_autores_artigo)} listas de autores de artigos publicados no período')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qte_docentes     = len(lista_docentes)\n",
    "qte_discentes    = len(lista_discentes)\n",
    "total_iteracoes  = (qte_docentes+qte_discentes)\n",
    "\n",
    "## Monta uma lista de strings com nomes dos autores de cada artigo\n",
    "lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "qte_artigos         = len(lista_nomes_autores)\n",
    "\n",
    "## Monta a lista de autores com a divisão da string de nomes acima por: sobrenome, nomes\n",
    "lst_autores_artigo = []\n",
    "for cada_lista_autores in lista_nomes_autores:\n",
    "    lista_organizada, erros_organizar = organizar_nomes(cada_lista_autores)\n",
    "    lst_autores_artigo.append(lista_organizada)\n",
    "print(f'{len(lst_autores_artigo)} listas de autores de {qte_artigos} artigos publicados no período')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes_autores[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_autores_artigo[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e752b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a='a b c de oliveira'\n",
    "padronizar_nome(a)\n",
    "iniciais_nome(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078c009e",
   "metadata": {},
   "source": [
    "## Apuração segmentada por períodos e grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ff296",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolucao_pcd=[]\n",
    "evolucao_impacto=[]\n",
    "tipo_analise=[]\n",
    "grupo_analise=[]\n",
    "periodo_analise=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d437b0",
   "metadata": {},
   "source": [
    "## Quadriênio 2017-2020 de Docentes Permanentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes_docentes_permanentes   = 'lista_docentes_permanentes.csv'\n",
    "lista_nomes_docentes_colaboradores = 'lista_docentes_colaboradores.csv'\n",
    "df_docentes = montardf_docentes(lista_nomes_docentes_permanentes, lista_nomes_docentes_colaboradores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621055ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2017\n",
    "final  = 2020\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'permanentes'\n",
    "lista_nomes_docentes = 'lista_docentes_permanentes.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)\n",
    "evolucao_pcd.append(indicador_pcd)\n",
    "evolucao_impacto.append(indicador_impacto)\n",
    "tipo_analise.append(tipo)\n",
    "grupo_analise.append(grupo)\n",
    "periodo_analise.append([inicio,final])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc16d3f",
   "metadata": {},
   "source": [
    "## .\n",
    "## Quadriênio 2017-2020 de Docentes Colaboradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb5d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2017\n",
    "final  = 2020\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'colaboradores'\n",
    "lista_nomes_docentes = 'lista_docentes_colaboradores.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)\n",
    "evolucao_pcd.append(indicador_pcd)\n",
    "evolucao_impacto.append(indicador_impacto)\n",
    "tipo_analise.append(tipo)\n",
    "grupo_analise.append(grupo)\n",
    "periodo_analise.append([inicio,final])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f22aa",
   "metadata": {},
   "source": [
    "## Avaliação de meio termo biênio [2021-2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd6823",
   "metadata": {},
   "source": [
    "## Biênio 2021-2022 de Docentes Permanentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2021\n",
    "final  = 2022\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'permanentes'\n",
    "lista_nomes_docentes = 'lista_docentes_permanentes.csv'\n",
    "# lista_nomes_docentes = 'lista_docentes_colaboradores.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)\n",
    "evolucao_pcd.append(indicador_pcd)\n",
    "evolucao_impacto.append(indicador_impacto)\n",
    "tipo_analise.append(tipo)\n",
    "grupo_analise.append(grupo)\n",
    "periodo_analise.append([inicio,final])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f19cf",
   "metadata": {},
   "source": [
    "## Biênio 2021-2022 de Docentes Colaboradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2021\n",
    "final  = 2022\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'colaboradores'\n",
    "# lista_nomes_docentes = 'lista_docentes_permanentes.csv'\n",
    "lista_nomes_docentes = 'lista_docentes_colaboradores.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)\n",
    "evolucao_pcd.append(indicador_pcd)\n",
    "evolucao_impacto.append(indicador_impacto)\n",
    "tipo_analise.append(tipo)\n",
    "grupo_analise.append(grupo)\n",
    "periodo_analise.append([inicio,final])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c6a47c",
   "metadata": {},
   "source": [
    "## Evolução de indicadores de gestão do programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31656a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicadores = pd.DataFrame({\n",
    "    'TIPO': pd.Series(tipo_analise),\n",
    "    'GRUPO': pd.Series(grupo_analise),\n",
    "    'PERIODOS': pd.Series(periodo_analise),\n",
    "    'META_PCD_50%': pd.Series(evolucao_pcd),\n",
    "    'META_IMPACTO_150ANO': pd.Series(evolucao_impacto),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a687f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicadores.sort_values(by=['GRUPO'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7fd64a",
   "metadata": {},
   "source": [
    "## Conferência em detalhes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2021\n",
    "final  = 2022\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'permanentes'\n",
    "lista_nomes_docentes = 'lista_docentes_permanentes.csv'\n",
    "# lista_nomes_docentes = 'lista_docentes_colaboradores.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f942da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_impacto_docente[:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ccbd6a",
   "metadata": {},
   "source": [
    "## Conferência dos achados de nomes de discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_partes_achadas(lista_discentes, lista_autores, verbose=False):\n",
    "    partes_achadas=[]\n",
    "    discentes_achados=[]\n",
    "    erros=[]\n",
    "    if verbose == True:\n",
    "        print(f'{padronizar_titulo(lista_autores).lower()}')\n",
    "    try:\n",
    "        ## Buscar pelas partes de nomes de autor em cada linha de autores de artigo\n",
    "        for nome in lista_discentes:\n",
    "            sobrenome, partenome1, partenome2, partenome3 = quebrar_partesnomes(nome)\n",
    "            if verbose == True:\n",
    "                print(f'{sobrenome}, {partenome1} {partenome2} {partenome3}')\n",
    "            strbusca_partes = compilar_partes(sobrenome, partenome1, partenome2, partenome3)\n",
    "            try:\n",
    "                achados_partes = re.search(strbusca_partes, padronizar_titulo(lista_autores).lower())\n",
    "                if achados_partes.span() !=None:\n",
    "                    partes_achadas.append(achados_partes.groups())\n",
    "                    discentes_achados.append(nome)\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                pass\n",
    "\n",
    "        ## Buscar pelas iniciais de partes de nomes de autor, que seguem um sobrenome em cada linha de autores de artigo\n",
    "        for nome in lista_discentes:\n",
    "            sobrenome, inicial1, inicial2, inicial3 = quebrar_iniciais(nome)\n",
    "            if verbose == True:\n",
    "                print(f'{sobrenome}, {inicial1} {inicial2} {inicial3}')\n",
    "            strbusca_iniciais = compilar_iniciais(sobrenome, inicial1, inicial2, inicial3)\n",
    "            try:\n",
    "                achados_iniciais = re.search(strbusca_iniciais, padronizar_titulo(lista_autores).lower())\n",
    "                if achados_iniciais.span() !=None and achados_iniciais.groups() not in discentes_achados:\n",
    "                    partes_achadas.append(achados_iniciais.groups())\n",
    "                    discentes_achados.append(nome)\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                pass\n",
    "    except Exception as e:\n",
    "        # print(f'Erro ao buscar partes de nome; {e}')\n",
    "        print(e)\n",
    "    \n",
    "    return partes_achadas, discentes_achados\n",
    "\n",
    "def listar_achados(docente):\n",
    "    lista_csv = ler_artigostodosperiodos()\n",
    "    lista_autores_artigos, lista_docentes, lista_orientadores, lista_discentes = montar_listas(lista_csv)\n",
    "\n",
    "    df_filtrado = df_impacto_docente[(df_impacto_docente.DOCENTE==docente)]\n",
    "\n",
    "    lista_indices = df_filtrado['INDICES_ARTIGOS'].values.tolist()[0]\n",
    "    n=100\n",
    "    print('-'*n)\n",
    "    print(f'\\nDocente: {docente} | {len(lista_indices)} Publicações identificadas para no período [{inicio} a {final}]')\n",
    "    print()\n",
    "    for indice in lista_indices:\n",
    "        print('-'*n)\n",
    "        print(f'Índice da publicação: {indice}')\n",
    "        print(df_public.iloc[indice].values[:3])\n",
    "        lista_autores = padronizar_titulo(df_public.iloc[indice].values[4])\n",
    "        partes_achadas, discentes_achados = mostrar_partes_achadas(lista_discentes, lista_autores, verbose=False)\n",
    "        print()\n",
    "        print(lista_autores)\n",
    "        print('\\nPartes de nomes de alunos encontrados na lista de autores:')\n",
    "        print(partes_achadas)\n",
    "        print('\\nNomes de alunos considerados como encontrados na lista de autores:')\n",
    "        print(discentes_achados)\n",
    "\n",
    "def separar_iniciais(nome):\n",
    "    import re\n",
    "    letras_duasconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2}$')            # Duas Letras consoantes maiúsculas juntas do início ao final da string\n",
    "    letras_tresconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3}$')            # Três Letras consoantes maiúsculas juntas do início ao final da string\n",
    "    letras_duasconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2},$')       # Duas Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "    letras_tresconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3},$')       # Três Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "    partes_nome=[]\n",
    "    for j in nome.split(' '):\n",
    "        div_ltrduasconsnts = letras_duasconsnts.findall(j)\n",
    "        div_ltrtriplicadas = letras_tresconsnts.findall(j)\n",
    "        div_ltrduasconsntsvirg = letras_duasconsntsvirg.findall(j)\n",
    "        div_ltrtresconsntsvirg = letras_tresconsntsvirg.findall(j)\n",
    "        if div_ltrduasconsnts or div_ltrtriplicadas:\n",
    "            iniciais_separadas = ' '.join(x for x in j)\n",
    "            partes_nome.append(iniciais_separadas)\n",
    "        elif div_ltrduasconsntsvirg or div_ltrtresconsntsvirg:\n",
    "            iniciais_separadas = ' '.join(x for x in j[:-1])\n",
    "            partes_nome.append(iniciais_separadas+',')\n",
    "        else:\n",
    "            partes_nome.append(j)\n",
    "    nome_separado = ' '.join(x for x in partes_nome).strip()\n",
    "    return nome_separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1021acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "docente = 'Olindo Assis Martins Filho'\n",
    "listar_achados(docente)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee2749",
   "metadata": {},
   "source": [
    "## Outras funcionalidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374848af",
   "metadata": {},
   "source": [
    "    Formatar tempo (h:min:seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72114631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tempo(start, end):\n",
    "    t=end-start\n",
    "\n",
    "    tempo = timedelta(\n",
    "        weeks   = t//(3600*24*7),\n",
    "        days    = t//(3600*24),\n",
    "        seconds = t,\n",
    "        minutes = t//(60),\n",
    "        hours   = t//(3600),\n",
    "        microseconds=t//1000000,\n",
    "        )\n",
    "    fmt='{H:2}:{M:02}:{S:02}'\n",
    "    return strfdelta(tempo)\n",
    "\n",
    "\n",
    "def horas(segundos): \n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(segundos)) \n",
    "\n",
    "\n",
    "def dias_horas_minutos(td):\n",
    "    x = (td.days, td.seconds//3600, (td.seconds//60)%60, td.seconds)\n",
    "    return x #(days, hrs, mins, seconds)\n",
    "\n",
    "\n",
    "def strfdelta(tdelta, fmt='{H:02}h {M:02}m {S:02}s', inputtype='timedelta'):\n",
    "    \"\"\"Convert a datetime.timedelta object or a regular number to a custom-formatted string, \n",
    "    just like the stftime() method does for datetime.datetime objects.\n",
    "\n",
    "    The fmt argument allows custom formatting to be specified.  Fields can \n",
    "    include seconds, minutes, hours, days, and weeks.  Each field is optional.\n",
    "\n",
    "    Some examples:\n",
    "        '{D:02}d {H:02}h {M:02}m {S:02}s' --> '05d 08h 04m 02s' (default)\n",
    "        '{W}w {D}d {H}:{M:02}:{S:02}'     --> '4w 5d 8:04:02'\n",
    "        '{D:2}d {H:2}:{M:02}:{S:02}'      --> ' 5d  8:04:02'\n",
    "        '{H}h {S}s'                       --> '72h 800s'\n",
    "\n",
    "    The inputtype argument allows tdelta to be a regular number instead of the  \n",
    "    default, which is a datetime.timedelta object.  Valid inputtype strings: \n",
    "        's', 'seconds', \n",
    "        'm', 'minutes', \n",
    "        'h', 'hours', \n",
    "        'd', 'days', \n",
    "        'w', 'weeks'\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert tdelta to integer seconds.\n",
    "    if inputtype == 'timedelta':\n",
    "        remainder = int(tdelta.total_seconds())\n",
    "    elif inputtype in ['s', 'seconds']:\n",
    "        remainder = int(tdelta)\n",
    "    elif inputtype in ['m', 'minutes']:\n",
    "        remainder = int(tdelta)*60\n",
    "    elif inputtype in ['h', 'hours']:\n",
    "        remainder = int(tdelta)*3600\n",
    "    elif inputtype in ['d', 'days']:\n",
    "        remainder = int(tdelta)*86400\n",
    "    elif inputtype in ['w', 'weeks']:\n",
    "        remainder = int(tdelta)*604800\n",
    "\n",
    "    f = Formatter()\n",
    "    desired_fields = [field_tuple[1] for field_tuple in f.parse(fmt)]\n",
    "    possible_fields = ('W', 'D', 'H', 'M', 'S')\n",
    "    constants = {'W': 604800, 'D': 86400, 'H': 3600, 'M': 60, 'S': 1}\n",
    "    values = {}\n",
    "    \n",
    "    for field in possible_fields:\n",
    "        if field in desired_fields and field in constants:\n",
    "            values[field], remainder = divmod(remainder, constants[field])\n",
    "    \n",
    "    return f.format(fmt, **values)\n",
    "\n",
    "\n",
    "# print (timedelta(days=365, hours=8, minutes=15))\n",
    "# print (\"   Hoje é: \" + str(date.today()))\n",
    "# print (\"Agora são: \" + str(datetime.now()))\n",
    "# print (\"Um ano no futuro estaremos em:\" + str(dt.today() + timedelta(days=365)))\n",
    "# hoje = date.today()\n",
    "# print(hoje)\n",
    "# hora = dt.now()\n",
    "# print(hora)\n",
    "# dias_ano = date(hoje.year, 1, 1)\n",
    "# if dias_ano < hoje:\n",
    "#     print (\"Decoridos %d dias do ano\" % ((hoje - dias_ano).days))\n",
    "    \n",
    "# from datetime import datetime\n",
    "# now= datetime.now() #get the current date and time\n",
    "\n",
    "# #%c - local date and time, %x-local's date, %X- local's time\n",
    "# print(now.strftime(\"%c\"))\n",
    "# print(now.strftime(\"%x\"))\n",
    "# print(now.strftime(\"%X\"))\n",
    "\n",
    "# ##### Time Formatting ####\n",
    "# #%I/%H - 12/24 Hour, %M - minute, %S - second, %p - local's AM/PM\n",
    "# print(now.strftime(\"%I:%M:%S %p\")) # 12-Hour:Minute:Second:AM\n",
    "# print(now.strftime(\"%H:%M\")) # 24-Hour:Minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# from neo4j import GraphDatabase\n",
    "# from neo4j.exceptions import Neo4jError\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s', filename='logs/persister.log')\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# class Neo4jPersister:\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._uri = uri\n",
    "#         self._user = user\n",
    "#         self._password = password\n",
    "#         self._driver = GraphDatabase.driver(self._uri, auth=(self._user, self._password))\n",
    "#         self.logger = logger\n",
    "\n",
    "#         # Devem ser persistidos como \n",
    "#         self.tipos = [\n",
    "#             'Identificação',\n",
    "#             'Idiomas',\n",
    "#             'Formação',\n",
    "#             'Atuação Profissional',\n",
    "#             'Linhas de Pesquisa',\n",
    "#             'Áreas',\n",
    "#             'Produções',\n",
    "#             'ProjetosPesquisa',\n",
    "#             'ProjetosExtensão',\n",
    "#             'ProjetosDesenvolvimento',\n",
    "#             'ProjetosOutros',\n",
    "#             'Bancas',\n",
    "#             'Orientações',\n",
    "#             ]\n",
    "\n",
    "#         self.subtipos= [\n",
    "#             'Acadêmica',\n",
    "#             'Pos-Doc',\n",
    "#             'Complementar',\n",
    "#             'Artigos completos publicados em periódicos',\n",
    "#             'Resumos publicados em anais de congressos',\n",
    "#             'Apresentações de Trabalho',\n",
    "#             'Outras produções bibliográficas',\n",
    "#             'Entrevistas, mesas redondas, programas e comentários na mídia',\n",
    "#             'Concurso público',\n",
    "#             'Outras participações',\n",
    "#             'Livros publicados/organizados ou edições',\n",
    "#             'Capítulos de livros publicados',\n",
    "#             'Resumos expandidos publicados em anais de congressos',\n",
    "#             'Resumos publicados em anais de congressos (artigos)',\n",
    "#             'Trabalhos técnicos',\n",
    "#             'Demais trabalhos',\n",
    "#             'Mestrado',\n",
    "#             'Teses de doutorado',\n",
    "#             'Qualificações de Doutorado',\n",
    "#             'Qualificações de Mestrado',\n",
    "#             'Monografias de cursos de aperfeiçoamento/especialização',\n",
    "#             'Trabalhos de conclusão de curso de graduação',\n",
    "#             'Orientações e supervisões concluídas',\n",
    "#             'Citações',\n",
    "#             'Trabalhos completos publicados em anais de congressos',\n",
    "#             'Produtos tecnológicos',\n",
    "#             'Artigos  aceitos para publicação',\n",
    "#             'Assessoria e consultoria',\n",
    "#             'Programas de computador sem registro',\n",
    "#             'Professor titular',\n",
    "#             'Avaliação de cursos',\n",
    "#             'Orientações e supervisões em andamento',\n",
    "#             'Processos ou técnicas',\n",
    "#             'Outras produções artísticas/culturais',\n",
    "#             'Textos em jornais de notícias/revistas',\n",
    "#             'Redes sociais, websites e blogs',\n",
    "#             'Artes Visuais'            \n",
    "#             ]\n",
    "\n",
    "#         self.propriedades = [\n",
    "#             'Nome',\n",
    "#             'ID Lattes',\n",
    "#             'Última atualização',\n",
    "#             ]\n",
    "       \n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "    \n",
    "#     def persistir_revistas_da_planilha(self):\n",
    "#         \"\"\"\n",
    "#         Persiste dados de revistas a partir da planilha 'classificações_publicadas_todas_as_areas_avaliacao1672761192111.xlsx' no Neo4j.\n",
    "\n",
    "#         Args:\n",
    "#             session: Objeto de sessão do Neo4j.\n",
    "#         \"\"\"\n",
    "#         # Leitura da planilha\n",
    "#         dados_qualis = pd.read_excel(os.path.join(LattesScraper.find_repo_root(),'_data','in_xls','classificações_publicadas_todas_as_areas_avaliacao1672761192111.xlsx'))\n",
    "\n",
    "#         # Extração e persistência de dados de revista\n",
    "#         with self._driver.session() as session:\n",
    "#             for index, row in dados_qualis.iterrows():\n",
    "#                 issn = row['ISSN'].replace('-','')\n",
    "#                 nome_revista = row['Título']\n",
    "#                 area_avaliacao = row['Área de Avaliação']\n",
    "#                 estrato = row['Estrato']\n",
    "\n",
    "#                 # Verificação de existência da revista\n",
    "#                 revista_node = session.run(\"\"\"\n",
    "#                     MATCH (j:Revista {issn: $issn})\n",
    "#                     RETURN j\n",
    "#                 \"\"\", issn=issn).single()\n",
    "\n",
    "#                 if not revista_node:\n",
    "#                     # Criação da revista se não existir\n",
    "#                     session.run(\"\"\"\n",
    "#                         CREATE (j:Revista {issn: $issn, nome_revista: $nome_revista, area_avaliacao: $area_avaliacao, estrato: $estrato})\n",
    "#                     \"\"\", nome_revista=nome_revista, issn=issn, area_avaliacao=area_avaliacao,  estrato=estrato)\n",
    "\n",
    "#     # Testes Ok! \n",
    "#     def persist_pessoa_nodes(self, dict_list):\n",
    "#         query_pessoa = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         ON CREATE SET p.nome = $nome, p.ultima_atualizacao = $ultima_atualizacao\n",
    "#         ON MATCH SET p.nome = $nome, p.ultima_atualizacao = $ultima_atualizacao\n",
    "#         \"\"\"\n",
    "#         try:\n",
    "#             with self._driver.session() as session:\n",
    "#                 for item in dict_list:\n",
    "#                     identificacao = item.get('Identificação')\n",
    "#                     nome = identificacao.get('Nome')\n",
    "#                     id_lattes = identificacao.get('ID Lattes')\n",
    "#                     ultima_atualizacao = identificacao.get('Última atualização')\n",
    "#                     if nome:\n",
    "#                         session.run(query_pessoa, id_lattes=id_lattes, nome=nome, ultima_atualizacao=ultima_atualizacao)\n",
    "#         except Exception as e:\n",
    "#             self.logger.error('Erro ao criar node \"Pesquisador\": {}'.format(e))\n",
    "\n",
    "#     # Testes Ok!         \n",
    "#     def persist_pesquisador_grande_area_relationships(self, dict_list):\n",
    "#         query_rel_pessoa_grande_area = \"\"\"\n",
    "#         MATCH (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MATCH (ga:GrandeArea {nome: $grande_area_nome})\n",
    "#         MERGE (p)-[:ATUA_EM]->(ga)\n",
    "#         \"\"\"\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             for item in dict_list:\n",
    "#                 identificacao = item.get('Identificação')\n",
    "#                 id_lattes = identificacao.get('ID Lattes')\n",
    "#                 areas = item.get('Áreas').values()\n",
    "#                 for area_string in areas:\n",
    "#                     grande_area_nome, _, _ = self.extract_area_info(area_string)\n",
    "#                     if grande_area_nome:\n",
    "#                         session.run(query_rel_pessoa_grande_area, id_lattes=id_lattes, grande_area_nome=grande_area_nome)\n",
    "\n",
    "#     # Testes Ok! \n",
    "#     def persist_areas_nodes(self, dict_list):\n",
    "#         query_grande_area = \"\"\"\n",
    "#         MERGE (ga:GrandeArea {nome: $nome})\n",
    "#         \"\"\"\n",
    "#         query_area = \"\"\"\n",
    "#         MATCH (ga:GrandeArea {nome: $grande_area_nome})\n",
    "#         MERGE (a:Area {nome: $nome}) ON CREATE SET a:Area\n",
    "#         MERGE (ga)-[:CONTEM]->(a)\n",
    "#         \"\"\"\n",
    "#         query_subarea = \"\"\"\n",
    "#         MATCH (a:Area {nome: $area_nome})\n",
    "#         MERGE (sa:Subarea {nome: $nome}) ON CREATE SET sa:Subarea\n",
    "#         MERGE (a)-[:CONTEM]->(sa)\n",
    "#         \"\"\"\n",
    "#         query_rel_pessoa_grande_area = \"\"\"\n",
    "#         MATCH (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MATCH (ga:GrandeArea {nome: $grande_area_nome})\n",
    "#         MERGE (p)-[:ATUA_EM]->(ga)    \n",
    "#         \"\"\"\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             for item in dict_list:\n",
    "#                 areas = item.get('Áreas').values()\n",
    "#                 for area_string in areas:\n",
    "#                     grande_area_nome, area_nome, subarea_nome = self.extract_area_info(area_string)\n",
    "                    \n",
    "#                     # Verificar se o nome não está vazio\n",
    "#                     if grande_area_nome:\n",
    "#                         session.run(query_grande_area, nome=grande_area_nome)\n",
    "#                     if area_nome:\n",
    "#                         session.run(query_area, grande_area_nome=grande_area_nome, nome=area_nome)\n",
    "#                     if subarea_nome:\n",
    "#                         session.run(query_subarea, area_nome=area_nome, nome=subarea_nome)\n",
    "                    \n",
    "#                     # Adicionar relacionamento Pesquisador - GrandeÁrea\n",
    "#                     id_lattes = item['Identificação']['ID Lattes']\n",
    "#                     if grande_area_nome:\n",
    "#                         session.run(query_rel_pessoa_grande_area, id_lattes=id_lattes, grande_area_nome=grande_area_nome)\n",
    "\n",
    "#     # Testes Ok! \n",
    "#     @staticmethod\n",
    "#     def extract_area_info(area_string):\n",
    "#         # Extraindo os nomes de GrandeÁrea, Área e Subárea da string\n",
    "#         try:\n",
    "#             grande_area_nome = area_string.split('/')[0].strip().split(': ')[1]\n",
    "#         except:\n",
    "#             grande_area_nome = ''\n",
    "#         try:\n",
    "#             area_nome = area_string.split('/')[1].strip().split(': ')[1]\n",
    "#         except:\n",
    "#             area_nome = ''\n",
    "#         try:\n",
    "#             subarea_nome = area_string.split('/')[2].strip().split(': ')[1]\n",
    "#         except:\n",
    "#             subarea_nome = ''\n",
    "#         return grande_area_nome, area_nome, subarea_nome\n",
    "\n",
    "#     ## PRODUÇÕES\n",
    "#     def persist_producoes_pesquisador(self, dict_list):\n",
    "#         with self._driver.session() as session:\n",
    "#             for pesq in dict_list:\n",
    "#                 identificacao = pesq.get('Identificação')\n",
    "#                 id_lattes = identificacao.get('ID Lattes')\n",
    "#                 producoes = pesq.get('Produções')\n",
    "\n",
    "#                 if not isinstance(producoes, dict):\n",
    "#                     print(f\"Erro!! Dicionário da seção 'Produções' não encontrado para {id_lattes}\")\n",
    "#                     continue\n",
    "\n",
    "#                 for chave_producao, valores_producao in producoes.items():\n",
    "#                     print(f'{chave_producao} | {valores_producao}')\n",
    "#                     if chave_producao == 'Artigos completos publicados em periódicos':\n",
    "#                         # self.persistir_artigos_completos(session, id_lattes, valores_producao)\n",
    "#                         self.persistir_artigos_revistas(session, id_lattes, valores_producao)\n",
    "\n",
    "#     def _get_or_create_node(self, session, label, properties):\n",
    "#         properties = [x.rstrip('.') for x in properties]\n",
    "#         node = session.run(\"MATCH (n: {label}) WHERE {properties} RETURN n\", {\"label\": label, \"properties\": properties}).single()\n",
    "\n",
    "#         if not node:\n",
    "#             node = session.run(\"CREATE (n: {label} {properties}) RETURN n\", {\"label\": label, \"properties\": properties}).single()[\"n\"]\n",
    "#             self._node_created_count += 1\n",
    "\n",
    "#         return node\n",
    "\n",
    "#     def persist_tipo_producao(self, session, id_lattes, tipo_producao):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (t:TipoProducao {nome: $tipo_producao})\n",
    "#         MERGE (p)-[:PRODUZ]->(t)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, tipo_producao=tipo_producao)\n",
    "#         summary = result.consume()\n",
    "#         return summary.counters.nodes_created, summary.counters.nodes_deleted, summary.counters.relationships_created, summary.counters.relationships_deleted\n",
    "\n",
    "#     def persist_subtipo_producao(self, session, id_lattes, tipo_producao, subtipo_producao, dados_producao):\n",
    "#         def checar_e_serializar(dados):\n",
    "#             \"\"\" Verifica e serializa dicionários recursivamente \"\"\"\n",
    "#             if isinstance(dados, dict):\n",
    "#                 for chave, valor in dados.items():\n",
    "#                     if isinstance(valor, dict):\n",
    "#                         dados[chave] = json.dumps(valor)\n",
    "#                     # Checagem adicional para outros tipos inválidos, se necessário\n",
    "#             return dados\n",
    "#         # Serialização recursiva do dicionário\n",
    "#         dados_producao = checar_e_serializar(dados_producao)\n",
    "\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (t:TipoProducao {nome: $tipo_producao})\n",
    "#         MERGE (s:SubtipoProducao {nome: $subtipo_producao})\n",
    "#         MERGE (p)-[PRODUZ:]->(t)-[:DO_TIPO]->(s)\n",
    "#         \"\"\"\n",
    "\n",
    "#         if subtipo_producao in [\"ArtigoCompleto\", \"ResumoCongresso\", \"ApresentacaoTrabalho\", \"OutrasProducoesBibliograficas\"]:\n",
    "#             query_create_node += \"\"\"\n",
    "#             MERGE (o:Ocorrencia {tipo: $subtipo_producao, dados: $dados})\n",
    "#             MERGE (s)-[:OCORRENCIA]->(o)\n",
    "#             \"\"\"\n",
    "\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, tipo_producao=tipo_producao, \n",
    "#                             subtipo_producao=subtipo_producao, dados=dados_producao)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "\n",
    "#         return summary.counters.nodes_created, summary.counters.nodes_deleted, summary.counters.relationships_created, summary.counters.relationships_deleted\n",
    "\n",
    "#     def persistir_artigos_completos(self, session, id_lattes, dados):\n",
    "#         created_nodes = 0\n",
    "#         updated_nodes = 0\n",
    "#         created_relations = 0\n",
    "#         updated_relations = 0\n",
    "        \n",
    "#         for dados_artigo in dados:\n",
    "#             dados_artigo['dados'] = json.dumps(dados_artigo)  # Conversão para JSON da estrutura completa\n",
    "#             query_create_node_artigo = \"\"\"\n",
    "#                 MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#                 CREATE (a:ArtigoPublicado {\n",
    "#                     ano: $ano,\n",
    "#                     fator_impacto_jcr: $fator_impacto_jcr,\n",
    "#                     ISSN: $ISSN,\n",
    "#                     titulo: $titulo,\n",
    "#                     revista: $revista,\n",
    "#                     autores: $autores,\n",
    "#                     Qualis: $Qualis,\n",
    "#                     DOI: $DOI,\n",
    "#                     dados: $dados_artigo\n",
    "#                 })\n",
    "#                 CREATE (p)-[:PRODUZ]->(a)\n",
    "\n",
    "#                 MERGE (j:Revista {nome: $revista, issn: $ISSN})\n",
    "#                 CREATE (a)-[:PUBLICADO_EM]->(j)\n",
    "#             \"\"\"\n",
    "\n",
    "#             result_artigo = session.run(query_create_node_artigo, \n",
    "#                                 id_lattes=id_lattes, \n",
    "#                                 ano=dados_artigo['ano'],\n",
    "#                                 fator_impacto_jcr=dados_artigo['fator_impacto_jcr'],\n",
    "#                                 ISSN=dados_artigo['ISSN'],\n",
    "#                                 titulo=dados_artigo['titulo'],\n",
    "#                                 revista=dados_artigo['revista'],\n",
    "#                                 autores=dados_artigo['autores'],\n",
    "#                                 Qualis=dados_artigo['Qualis'],\n",
    "#                                 DOI=dados_artigo['DOI'],\n",
    "#                                 dados_artigo=dados_artigo\n",
    "#                                 )\n",
    "#             summary_artigo = result_artigo.consume()\n",
    "#             created_nodes += summary_artigo.counters.nodes_created\n",
    "#             updated_nodes += summary_artigo.counters.nodes_deleted\n",
    "#             created_relations += summary_artigo.counters.relationships_created\n",
    "#             updated_relations += summary_artigo.counters.relationships_deleted\n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "\n",
    "#     def persistir_artigos_completos(self, session, id_lattes, dados):\n",
    "#         created_nodes = 0\n",
    "#         updated_nodes = 0\n",
    "#         created_relations = 0\n",
    "#         updated_relations = 0\n",
    "                \n",
    "#         for dados_artigo in dados:\n",
    "#             ano = dados_artigo['ano']\n",
    "#             impact_jcr = dados_artigo['fator_impacto_jcr']\n",
    "#             issn = dados_artigo['ISSN']\n",
    "#             titulo = dados_artigo['titulo']\n",
    "#             revista = dados_artigo['revista']\n",
    "#             autores = dados_artigo['autores']\n",
    "#             qualis = dados_artigo['Qualis']\n",
    "#             doi = dados_artigo['DOI']\n",
    "\n",
    "#             query_create_node_artigo = \"\"\"\n",
    "#                 MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#                 CREATE (a:ArtigoPublicado {ano: $ano, impact_jcr: $impact_jcr, issn: $issn, titulo: $titulo, revista: $revista, autores: $autores, qualis: $qualis, doi: $doi})\n",
    "#                 CREATE (p)-[:PRODUZ]->(a)\n",
    "#                 MERGE (j:Revista {nome: $revista, issn: $issn})\n",
    "#                 CREATE (a)-[:PUBLICADO_EM]->(j)\n",
    "#             \"\"\"\n",
    "#             print(query_create_node_artigo)\n",
    "#             result_artigo = session.run(query_create_node_artigo, \n",
    "#                                 id_lattes=id_lattes, \n",
    "#                                 ano=ano,\n",
    "#                                 impact_jcr=impact_jcr,\n",
    "#                                 issn=issn,\n",
    "#                                 titulo=titulo,\n",
    "#                                 revista=revista,\n",
    "#                                 autores=autores,\n",
    "#                                 qualis=qualis,\n",
    "#                                 doi=doi,\n",
    "#                                 )\n",
    "#             summary_artigo = result_artigo.consume()\n",
    "#             created_nodes += summary_artigo.counters.nodes_created\n",
    "#             updated_nodes += summary_artigo.counters.nodes_deleted\n",
    "#             created_relations += summary_artigo.counters.relationships_created\n",
    "#             updated_relations += summary_artigo.counters.relationships_deleted\n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def buscar_revista_por_issn(self, session, issn):\n",
    "#         query = \"\"\"\n",
    "#             MATCH (revista:Revista {issn: $issn})\n",
    "#             RETURN revista\n",
    "#         \"\"\"\n",
    "\n",
    "#         try:\n",
    "#             result = session.run(query, issn=issn)\n",
    "#             return result.single()\n",
    "#         except Neo4jError as e:\n",
    "#             print(f\"Erro Neo4j ao buscar a revista por ISSN: {e}\")\n",
    "#             return None\n",
    "        \n",
    "#     def persistir_artigos_revistas(self, session, id_lattes, dados):\n",
    "#         \"\"\"\n",
    "#         Função para persistir os dados de artigos completos publicados em periódicos.\n",
    "\n",
    "#         Args:\n",
    "#             session (neo4j.Session): Sessão Neo4j.\n",
    "#             id_lattes (str): ID do Lattes do pesquisador.\n",
    "#             dados (dict): Dicionário contendo os dados dos artigos.\n",
    "\n",
    "#         Returns:\n",
    "#             None\n",
    "#         \"\"\"\n",
    "\n",
    "#         for artigo in dados:\n",
    "#             # Extraindo informações do artigo\n",
    "#             revista_nome  = ''\n",
    "#             created_nodes = ''\n",
    "#             ano = artigo['ano']\n",
    "#             impact_jcr = artigo['fator_impacto_jcr']\n",
    "#             issn = artigo['ISSN']\n",
    "#             titulo = artigo['titulo']\n",
    "#             revista = artigo['revista']\n",
    "#             autores = artigo['autores']\n",
    "#             data_issn = artigo['data_issn']\n",
    "#             doi = artigo['DOI']\n",
    "#             qualis = artigo['Qualis']\n",
    "\n",
    "#             query_create_node_artigo = \"\"\"\n",
    "#                 MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#                 CREATE (a:ArtigoPublicado {ano: $ano, impact_jcr: $impact_jcr, issn: $issn, titulo: $titulo, revista: $revista, autores: $autores, qualis: $qualis, doi: $doi})\n",
    "#                 CREATE (p)-[:PRODUZ]->(a)\n",
    "#                 MERGE (j:Revista {nome: $revista, issn: $issn})\n",
    "#                 CREATE (a)-[:PUBLICADO_EM]->(j)\n",
    "#             \"\"\"\n",
    "            \n",
    "#             # Buscando o nó da revista\n",
    "#             revista_node = self.buscar_revista_por_issn(session, issn)\n",
    "\n",
    "#             # Criando o nó do artigo\n",
    "#             with session.begin_transaction() as tx:\n",
    "#                 tx.run(query_create_node_artigo,\n",
    "#                     id_lattes=id_lattes,\n",
    "#                     ano=ano,\n",
    "#                     impact_jcr=impact_jcr,\n",
    "#                     issn=issn,\n",
    "#                     titulo=titulo,\n",
    "#                     revista=revista,\n",
    "#                     autores=autores,\n",
    "#                     data_issn=data_issn,\n",
    "#                     doi=doi,\n",
    "#                     qualis=qualis\n",
    "#                     )\n",
    "\n",
    "#                 # Criando o relacionamento PUBLICADO_EM\n",
    "#                 if revista_node is not None:\n",
    "#                     node_revista = revista_node[0][1]\n",
    "#                     if node_revista is not None:\n",
    "#                         revista_nome = node_revista['nome_revista']\n",
    "#                         revista_issn = node_revista['issn']\n",
    "#                         revista_area_avaliacao = node_revista['area_avaliacao']\n",
    "#                         revista_estrato = node_revista['estrato']\n",
    "\n",
    "#                     if revista_nome:\n",
    "#                         tx.run(\"\"\"\n",
    "#                             MATCH (a:ArtigoPublicado {doi: $doi}), (j:Revista {nome_revista: $revista_nome, issn: $revista_issn, area_avaliacao: $revista_area_avaliacao, estrato: $revista_estrato})\n",
    "#                             CREATE (a)-[:PUBLICADO_EM]->(j)\n",
    "#                         \"\"\", doi=doi, revista_nome=revista_nome, revista_issn=revista_issn, revista_area_avaliacao=revista_area_avaliacao, revista_estrato=revista_estrato)\n",
    "\n",
    "#                     else:\n",
    "#                         print(\"Erro: O nó da revista não foi encontrado para o ISSN\", issn)\n",
    "#                         # Lógica de tratamento de erro (opcional)\n",
    "#                 else:\n",
    "#                     print(\"Erro: O retorno para a revista com ISSN\", issn, \"é None.\")\n",
    "\n",
    "#                 tx.commit()\n",
    "\n",
    "#         # Atualização dos contadores\n",
    "#         with session.begin_transaction() as tx:\n",
    "#             created_nodes += tx.run(\"MATCH (n) WHERE n:ArtigoPublicado RETURN count(n)\").single()[0]\n",
    "#             updated_nodes += tx.run(\"MATCH (n) WHERE n:ArtigoPublicado SET n.updated_at = datetime() RETURN count(n)\").single()[0]\n",
    "#             created_relations += tx.run(\"MATCH (r) WHERE r:PUBLICADO_EM RETURN count(r)\").single()[0]\n",
    "\n",
    "#     def persistir_resumos_congressos(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (r:ResumoCongresso {titulo: $titulo, ano: $ano, evento: $evento, autores: $autores, data_issn: $data_issn, doi: $doi})\n",
    "#         MERGE (p)-[:PRODUZ]->(r)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, **dados)\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def persistir_apresentacoes_trabalho(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (a:ApresentacaoTrabalho {\n",
    "#             titulo: $titulo,\n",
    "#             ano: $ano,\n",
    "#             evento: $evento,\n",
    "#             autores: $autores\n",
    "#         })\n",
    "#         MERGE (p)-[:PRODUZ]->(a)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, **dados)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def persistir_outras_producoes_bibliograficas(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (o:OutrasProducoesBibliograficas {\n",
    "#             titulo: $titulo,\n",
    "#             ano: $ano,\n",
    "#             autores: $autores,\n",
    "#             doi: $doi\n",
    "#         })\n",
    "#         MERGE (p)-[:PRODUZ]->(o)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, **dados)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def persistir_orientacoes_concluidas(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (o:OrientacaoConcluida {\n",
    "#             tipo: $tipo,\n",
    "#             titulo: $titulo,\n",
    "#             ano: $ano,\n",
    "#             autor: $autor,\n",
    "#             instituicao: $instituicao\n",
    "#         })\n",
    "#         MERGE (p)-[:ORIENTA]->(o)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, **dados)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def persistir_participacoes_bancas(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (b:Banca {\n",
    "#             tipo: $tipo,\n",
    "#             titulo: $titulo,\n",
    "#             ano: $ano,\n",
    "#             instituicao: $instituicao\n",
    "#         })\n",
    "#         MERGE (p)-[:PARTICIPA_BANCA]->(b)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, **dados)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def persistir_projetos_pesquisa(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (pr:ProjetoPesquisa {\n",
    "#             titulo: $titulo,\n",
    "#             ano_inicio: $ano_inicio,\n",
    "#             ano_fim: $ano_fim,\n",
    "#             agencia_financiadora: $agencia_financiadora,\n",
    "#             valor_financiamento: $valor_financiamento\n",
    "#         })\n",
    "#         MERGE (p)-[:COORDENA]->(pr)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, dados=dados)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def persistir_premios_distincoes(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (pd:PremioDistincao {\n",
    "#             titulo: $titulo,\n",
    "#             ano: $ano,\n",
    "#             instituicao: $instituicao,\n",
    "#         })\n",
    "#         MERGE (p)-[:RECEBE]->(pd)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, **dados)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "# uri = \"bolt://localhost:7687\"\n",
    "# user = \"neo4j\"\n",
    "# password = \"password\"\n",
    "# persister = Neo4jPersister(uri, user, password)\n",
    "\n",
    "\n",
    "    # def run(self, query, **parameters):\n",
    "    #     with self.driver.session() as session:\n",
    "    #         return session.run(query, **parameters)\n",
    "\n",
    "    ## Agrupando nós de artigos por revista\n",
    "    # def persistir_artigos_revistas(self, session, id_lattes, dados):\n",
    "    #     created_nodes = 0\n",
    "    #     updated_nodes = 0\n",
    "    #     created_relations = 0\n",
    "    #     updated_relations = 0\n",
    "\n",
    "    #     for dados_artigo in dados:\n",
    "    #         ano = dados_artigo['ano']\n",
    "    #         impact_jcr = dados_artigo['fator_impacto_jcr']\n",
    "    #         issn = dados_artigo['ISSN']\n",
    "    #         titulo = dados_artigo['titulo']\n",
    "    #         revista = dados_artigo['revista']\n",
    "    #         autores = dados_artigo['autores']\n",
    "    #         qualis = dados_artigo['Qualis']\n",
    "    #         doi = dados_artigo['DOI']\n",
    "            \n",
    "    #         query_create_node_artigo = \"\"\"\n",
    "    #             MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "    #             CREATE (a:ArtigoPublicado {ano: $ano, impact_jcr: $impact_jcr, issn: $issn, titulo: $titulo, revista: $revista, autores: $autores, qualis: $qualis, doi: $doi})\n",
    "    #             CREATE (p)-[:PRODUZ]->(a)\n",
    "    #             MERGE (j:Revista {nome: $revista, issn: $issn})\n",
    "    #             CREATE (a)-[:PUBLICADO_EM]->(j)\n",
    "    #         \"\"\"\n",
    "\n",
    "    #         with session.begin_transaction() as tx:\n",
    "    #             print(\"DEBUG: ISSN da revista:\", issn)\n",
    "    #             # Verificação de existência da revista\n",
    "    #             revista_node = tx.run(\"\"\"\n",
    "    #                 MATCH (j:Revista {issn: $issn})\n",
    "    #                 RETURN j\n",
    "    #             \"\"\", issn=issn).single()\n",
    "\n",
    "    #             if not revista_node:\n",
    "    #                 # Revista não encontrada, crie-a\n",
    "    #                 tx.run(\"\"\"\n",
    "    #                     CREATE (j:Revista {nome: $revista, issn: $issn})\n",
    "    #                 \"\"\", revista=revista, issn=issn)\n",
    "\n",
    "    #                 revista_node = tx.run(\"\"\"\n",
    "    #                     MATCH (j:Revista {issn: $issn})\n",
    "    #                     RETURN j\n",
    "    #                 \"\"\", issn=issn).single()\n",
    "\n",
    "    #             if revista_node is not None:\n",
    "    #                 print(\"DEBUG: Propriedades do nó Revista:\", revista_node.items())  \n",
    "    #                 node_revista = revista_node[0]  # Extrair o objeto Node\n",
    "    #                 print(f\"revista_node[0] {node_revista}\")\n",
    "    #                 issn = node_revista['issn']  # Acessar a propriedade 'issn'\n",
    "    #                 print(f\"node_revista['issn'] {issn}\")\n",
    "    #                 revista_nome = node_revista['nome_revista']\n",
    "    #                 revista_area_avaliacao = node_revista['area_avaliacao']\n",
    "    #                 revista_estrato = node_revista['estrato']\n",
    "    #             else:\n",
    "    #                 print(\"Erro: O retorno para a revista com ISSN\", issn, \"é None.\")\n",
    "\n",
    "    #             # Criação do nó do artigo\n",
    "    #             tx.run(query_create_node_artigo, \n",
    "    #                 id_lattes=id_lattes, \n",
    "    #                 ano=ano,\n",
    "    #                 impact_jcr=impact_jcr,\n",
    "    #                 issn=issn,\n",
    "    #                 titulo=titulo,\n",
    "    #                 revista=revista,\n",
    "    #                 autores=autores,\n",
    "    #                 qualis=qualis,\n",
    "    #                 doi=doi)\n",
    "\n",
    "    #             # Criação do relacionamento PUBLICADO_EM\n",
    "    #             tx.run(\"\"\"\n",
    "    #                 MATCH (a:ArtigoPublicado {doi: $doi}), (j:Revista {nome_revista: $revista_nome, issn: $issn, area_avaliacao: $revista_area_avaliacao, estrato: $revista_estrato})\n",
    "    #                 CREATE (a)-[:PUBLICADO_EM]->(j)\n",
    "    #             \"\"\", doi=doi, revista_nome=revista_nome, issn=issn, revista_area_avaliacao=revista_area_avaliacao, revista_estrato=revista_estrato)\n",
    "\n",
    "    #             tx.commit()\n",
    "\n",
    "    #         # Atualização dos contadores\n",
    "    #         created_nodes += tx.run(\"MATCH (n) WHERE n:ArtigoPublicado RETURN count(n)\").single()[0]\n",
    "    #         updated_nodes += tx.run(\"MATCH (n) WHERE n:ArtigoPublicado SET n.updated_at = datetime() RETURN count(n)\").single()[0]\n",
    "    #         created_relations += tx.run(\"MATCH (r) WHERE r:PUBLICADO_EM RETURN count(r)\").single()[0]\n",
    "    #         updated_relations += tx.run(\"MATCH (r) WHERE r:PUBLICADO_EM SET r.updated_at = datetime() RETURN count(r)\").single()[0]\n",
    "\n",
    "    #     return created_nodes, updated_nodes, created_relations, updated_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d90ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import logging\n",
    "\n",
    "# from neo4j import GraphDatabase\n",
    "\n",
    "# class Neo4jDataPersister:\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._uri = uri\n",
    "#         self._user = user\n",
    "#         self._password = password\n",
    "#         self._driver = GraphDatabase.driver(self._uri, auth=(self._user, self._password))\n",
    "#         self.logger = logging.getLogger(__name__)\n",
    "\n",
    "#         self._node_created_count = 0\n",
    "#         self._node_updated_count = 0\n",
    "#         self._node_deleted_count = 0\n",
    "\n",
    "#         self._relationship_created_count = 0\n",
    "#         self._relationship_updated_count = 0\n",
    "#         self._relationship_deleted_count = 0\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "\n",
    "#     def persist_data_from_json(self, json_data):\n",
    "#         with self._driver.session() as session:\n",
    "#             self._persist_data(session, json_data)\n",
    "\n",
    "#         self.logger.info(\"Total nodes created: %d\", self._node_created_count)\n",
    "#         self.logger.info(\"Total nodes updated: %d\", self._node_updated_count)\n",
    "#         self.logger.info(\"Total nodes deleted: %d\", self._node_deleted_count)\n",
    "\n",
    "#         self.logger.info(\"Total relationships created: %d\", self._relationship_created_count)\n",
    "#         self.logger.info(\"Total relationships updated: %d\", self._relationship_updated_count)\n",
    "#         self.logger.info(\"Total relationships deleted: %d\", self._relationship_deleted_count)\n",
    "\n",
    "#     def _persist_data(self, session, data):\n",
    "#         if isinstance(data, dict):  # Check if it's a dictionary\n",
    "#             for key, value in data.items():\n",
    "#                 if key == 'Identificação':\n",
    "#                     self._handle_identificacao(session, value)\n",
    "#                 elif key == 'Atuação Profissional':\n",
    "#                     self._handle_atuacao_profissional(session, value)\n",
    "#                 elif key == 'Atuação Profissional':\n",
    "#                     self._handle_atuacao_profissional(session, value)                    \n",
    "#                 elif key == 'Produções':\n",
    "#                     self._handle_producoes(session, value)\n",
    "#                 elif isinstance(value, list) and not value:\n",
    "#                     # Ignore empty lists\n",
    "#                     pass\n",
    "#                 elif isinstance(value, dict):\n",
    "#                     if 'JCR2' in value:\n",
    "#                         # Ignore the 'JCR2' subdictionary\n",
    "#                         del value['JCR2']\n",
    "\n",
    "#                     self._persist_data(session, value)\n",
    "\n",
    "#         elif isinstance(data, list):  # Check if it's a list\n",
    "#             for item in data:\n",
    "#                 self._persist_data(session, item)  # Recurse on list items\n",
    "\n",
    "#         else:\n",
    "#             # Handle other data types (strings, numbers, etc.) or raise an error\n",
    "#             self.logger.warning(\"Unexpected data type: %s\", type(data))\n",
    "\n",
    "\n",
    "#     def _handle_identificacao(self, session, data):\n",
    "#         for item in data:\n",
    "#             if item['campo'] == 'ID Lattes':\n",
    "#                 node_id = item['valor']\n",
    "#                 node = self._get_or_create_node(session, 'Pesquisador', {'ID Lattes': node_id})\n",
    "#                 self._persist_other_properties(session, node, data)\n",
    "#             else:\n",
    "#                 node = self._get_or_create_node(session, 'Pesquisador', {data.items()})\n",
    "\n",
    "#     def _handle_atuacao_profissional(self, session, data):\n",
    "#         for item in data:\n",
    "#             node = self._create_node(session, 'AtuaçãoProfissional', item)\n",
    "\n",
    "#     def _handle_producoes(self, session, data):\n",
    "#         for production_type, production_data in data.items():\n",
    "#             if production_type == 'Artigos completos publicados em periódicos':\n",
    "#                 for article in production_data:\n",
    "#                     node = self._create_node(session, production_type, article)\n",
    "#             elif production_type.startswith('1.'):\n",
    "#                 for index, article in enumerate(production_data):\n",
    "#                     node = self._create_node(session, production_type, article)\n",
    "#                     node['OrdemCronológica'] = index + 1\n",
    "\n",
    "#     def _get_or_create_node(self, session, label, properties):\n",
    "#         node = session.run(\"MATCH (n: {label}) WHERE {properties} RETURN n\", {\"label\": label, \"properties\": properties}).single()\n",
    "\n",
    "#         if not node:\n",
    "#             node = session.run(\"CREATE (n: {label} {properties}) RETURN n\", {\"label\": label, \"properties\": properties}).single()[\"n\"]\n",
    "#             self._node_created_count += 1\n",
    "\n",
    "#         return node\n",
    "\n",
    "#     def _create_node(self, session, label, properties):\n",
    "#         node = session.run(\"CREATE (n: {label} {properties}) RETURN n\", {\"label\": label, \"properties\": properties}).single()[\"n\"]\n",
    "#         self._node_created_count += 1\n",
    "\n",
    "#         return node\n",
    "\n",
    "#     def _persist_other_properties(self, session, node, data):\n",
    "#         for key, value in data.items():\n",
    "#             if key not in ['campo', 'valor']:\n",
    "#                 node[key] = value  \n",
    "\n",
    "#     def _create_relationship(self, session, start_node, relationship_type, end_node, properties={}):\n",
    "#         session.run(\"MATCH (a), (b) WHERE ID(a) = {start_node_id} AND ID(b) = {end_node_id} CREATE (a)-[r:{type} {props}]->(b) RETURN r\", \n",
    "#                     {\"start_node_id\": id(start_node), \"end_node_id\": id(end_node), \"type\": relationship_type, \"props\": properties})\n",
    "#         self._relationship_created_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tipos=[]\n",
    "# subtipos=[]\n",
    "# for dict_pesq in dict_list:\n",
    "#     # Avaliando elementos da lista de dicionários do arquivo JSON de entrada\n",
    "#     if isinstance(dict_pesq, dict):\n",
    "#         for key1,val1 in dict_pesq.items():\n",
    "#             if key1 not in tipos:\n",
    "#                 tipos.append(key1)            \n",
    "#             print(f'N01: Elementos armazenados em dicionário:')\n",
    "#             print(f'     {key2:25} | Tipo dos valores: {type(val2)}')\n",
    "#             print(f'       Conteúdo disponível nos valores do dicionário de Nível 01:')\n",
    "#             # Avaliando filhos de primeiro nível na hierarquia (Seções)\n",
    "#             if isinstance(val1, list):\n",
    "#                 print(f'N01: Elementos armazenados em lista:')\n",
    "#                 print(f'     Conteúdo disponível nos valores:')\n",
    "#                 print(f'       {[x for x in val1]}')\n",
    "#             elif isinstance(val1, dict):\n",
    "#                 for key2,val2 in val1.items():\n",
    "#                     if key2 not in subtipos:\n",
    "#                         subtipos.append(key2)\n",
    "#                     print(f'       Chave: {key2:25} | Tipo dos valores: {type(val2)}')\n",
    "#                     print(f'         Conteúdo disponível nos valores do dicionário de Nível 02:')\n",
    "#                     # Avaliando filhos de segundo nível na hierarquia (Tipos de Seções)\n",
    "#                     if isinstance(val2, dict):\n",
    "#                         for key3,val3 in val2.items():\n",
    "#                             if key3 not in tipos:\n",
    "#                                 print(f'         Chave: {key3:25} | Tipo dos valores: {type(val3)}')\n",
    "#                                 print(f'          Conteúdo disponível nos valores do dicionário de Nível 03:')\n",
    "#                                 # Avaliando filhos de terceiro nível na hierarquia (Ocorrências de Tipos de Seções)\n",
    "#                                 if isinstance(val3, dict):\n",
    "#                                     print(f'               Chave: {key3:25} | Tipo dos valores: {type(val3)}')\n",
    "#                                     print(f'                 Conteúdo disponível nos valores do dicionário de Nível 04:')\n",
    "#                                     # print(val3)\n",
    "#             else:\n",
    "#                 print(f'N01: Elementos armazenados em {type(val1)}')\n",
    "#     else:\n",
    "#         print('ERRO NA ESTRUTURA DO JSON!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb43cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a Neo4jDataPersister instance\n",
    "# data_persister = Neo4jDataPersister('neo4j://localhost:7687', 'neo4j', 'password')\n",
    "# filename = 'dict_list.json'\n",
    "# json_data, formatted_creation_date, formatted_modification_date, time_count, unit = jfm.load_from_json(os.path.join(folder_data_input,filename))\n",
    "# print(f\"\\n{len(dict_list)} currículos carregados na lista de dicionários '{filename}'\")\n",
    "\n",
    "# # Persist the data to Neo4j\n",
    "# data_persister.persist_data_from_json(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87596beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pesq in json_data:\n",
    "#     print(len(pesq.get('Produções').keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cede6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ProjectsHandler:\n",
    "\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "\n",
    "#     def consult_data_by_property(self, name, property_name):\n",
    "#         with self._driver.session() as session:\n",
    "#             result = session.run(f\"MATCH (p:Person {{name: $name}}) RETURN p.`{property_name}` as data\", name=name)\n",
    "#             record = result.single()\n",
    "#             return record['data'] if record else None\n",
    "\n",
    "#     def create_projects_relations(self, name):\n",
    "#         successful_creations = 0\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             # Process 'Atuação Profissional' data\n",
    "#             professional_data = self.consult_data_by_property(name, 'Atuação Profissional')\n",
    "#             if professional_data:\n",
    "#                 for institution_name, _ in json.loads(professional_data).items():\n",
    "#                     session.run(\"MERGE (i:Instituição {name: $institution_name})\", institution_name=institution_name)\n",
    "#                     print(f\"Institution node created/merged for: {institution_name}\")\n",
    "\n",
    "#                     session.run(\"MATCH (p:Person {name: $name}), (i:Instituição {name: $institution_name}) MERGE (p)-[:TEM]->(i)\", name=name, institution_name=institution_name)\n",
    "#                     print(f\"Relationship established between {name} and {institution_name}.\")\n",
    "\n",
    "#             # Process other dynamic nodes\n",
    "#             key_labels_to_check = ['Linhas de pesquisa', 'Projetos de pesquisa', 'Projetos de extensão', 'Projetos de desenvolvimento']\n",
    "#             for key in key_labels_to_check:\n",
    "#                 formatted_key = f\"`{key}`\"  # Wrap the key with backticks\n",
    "#                 project_data = self.consult_data_by_property(name, key)\n",
    "#                 if project_data:\n",
    "#                     for project_time, project_name in json.loads(project_data).items():\n",
    "#                         if project_name:  # to avoid empty names\n",
    "#                             session.run(f\"MERGE (p:{formatted_key} {{name: $project_name}})\", project_name=project_name)\n",
    "#                             print(f\"{key} node created/merged for: {project_name}\")\n",
    "\n",
    "#                             session.run(f\"MATCH (a:Person {{name: $name}}), (p:{formatted_key} {{name: $project_name}}) MERGE (a)-[:TEM]->(p)\", name=name, project_name=project_name)\n",
    "#                             print(f\"Relationship established between {name} and {project_name} ({key}).\")\n",
    "#                             successful_creations += 1\n",
    "#                 else:\n",
    "#                     print(f\"'{key}' data not found for {name}\")\n",
    "\n",
    "#         print(f\"{successful_creations} projetos atualizados com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef4303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import re\n",
    "# from neo4j import GraphDatabase\n",
    "\n",
    "# class ArticleHandler:\n",
    "\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "\n",
    "#     def fetch_person_productions(self, name):\n",
    "#         with self._driver.session() as session:\n",
    "#             result = session.run(\"MATCH (p:Person {name: $name}) RETURN p.Produções as produções\", name=name)\n",
    "#             record = result.single()\n",
    "#             return record['produções'] if record else None\n",
    "\n",
    "#     def extract_article_info(self, input_str):\n",
    "#         # Encontre todas as abreviaturas de iniciais em maiúsculas e seus índices\n",
    "#         abbreviations = [(match.group(), match.start()) for match in re.finditer(r'\\b[A-Z]\\.', input_str)]\n",
    "\n",
    "#         # Encontre a posição da maior ocorrência de abreviaturas de iniciais, se houver\n",
    "#         if abbreviations:\n",
    "#             max_abbr_position = max(abbreviations, key=lambda x: x[1])\n",
    "\n",
    "#             # Encontre a primeira ocorrência de '. ' ou ' . ' após a maior ocorrência de abreviaturas de iniciais\n",
    "#             first_separator_candidates = [\n",
    "#                 input_str.find('. ', max_abbr_position[1] + 3),\n",
    "#                 input_str.find(' . ', max_abbr_position[1] + 3),\n",
    "#                 input_str.find('.. ')\n",
    "#             ]\n",
    "#             first_separator_candidates = [pos for pos in first_separator_candidates if pos != -1]\n",
    "\n",
    "#             if first_separator_candidates:\n",
    "#                 first_separator = min(first_separator_candidates)\n",
    "\n",
    "#                 # Encontre a primeira ocorrência de '. ' após o primeiro separador\n",
    "#                 second_separator = input_str.find('. ', first_separator + 2)\n",
    "\n",
    "#                 # Encontre a primeira ocorrência de ', ' após o segundo separador\n",
    "#                 third_separator = input_str.find(', ', second_separator + 2)\n",
    "#             else:\n",
    "#                 first_separator = second_separator = third_separator = -1\n",
    "#         else:\n",
    "#             first_separator = second_separator = third_separator = -1\n",
    "\n",
    "#         # Defina o padrão para encontrar \"p.\" e o conteúdo até a próxima vírgula\n",
    "#         pages_match = re.search(r' p\\.\\s*(.*?),', input_str)\n",
    "#         pages = pages_match.group(1) if pages_match else \"\"\n",
    "\n",
    "#         # Defina o padrão para encontrar \"v.\" e o conteúdo até a próxima vírgula\n",
    "#         volume_match = re.search(r' v\\.\\s*(.*?),', input_str)\n",
    "#         volume = volume_match.group(1) if volume_match else \"\"\n",
    "\n",
    "#         # Encontre a primeira ocorrência de um ano de quatro dígitos seguido de ponto final após o terceiro separador\n",
    "#         year_match = re.search(r' \\d{4}\\.', input_str[third_separator + 2:])\n",
    "#         year = year_match.group().strip('.').strip() if year_match else \"\"\n",
    "\n",
    "#         # Extraia os dados com base nas posições dos separadores\n",
    "#         authors = input_str[:first_separator].strip()\n",
    "#         title = input_str[first_separator + 2:second_separator].strip()\n",
    "#         journal = input_str[second_separator + 2:third_separator].strip()\n",
    "\n",
    "#         # Verifique se a lista de autores e o título não estão vazios\n",
    "#         if not authors or not title:\n",
    "#             return None  # Retorna None para indicar falha\n",
    "\n",
    "#         # Crie um dicionário com os dados extraídos\n",
    "#         article_info = {\n",
    "#             \"authors\": authors,\n",
    "#             \"title\": title,\n",
    "#             \"original_title\": journal,\n",
    "#             \"pages\": pages,\n",
    "#             \"volume\": volume,\n",
    "#             \"year\": year\n",
    "#         }\n",
    "\n",
    "#         return article_info\n",
    "    \n",
    "#     def deserialize_and_create_nodes(self, name):\n",
    "#         print(f\"Fetching 'Produções' data for {name}...\")\n",
    "#         productions_data = self.fetch_person_productions(name)\n",
    "        \n",
    "#         if not productions_data:\n",
    "#             print(f\"'Produções' data not found or empty for {name}.\")\n",
    "#             return\n",
    "\n",
    "#         print(f\"Attempting to deserialize 'Produções' data for {name}...\")\n",
    "#         try:\n",
    "#             productions_data = json.loads(productions_data)\n",
    "#         except json.JSONDecodeError as e:\n",
    "#             print(f\"Failed to deserialize 'Produções' data for {name}: {e}\")\n",
    "#             return\n",
    "\n",
    "#         successful_articles = 0\n",
    "#         unsuccessful_articles = []\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             print(f\"Processing 'Produção bibliográfica' for {name}...\")\n",
    "#             bibliographic_production = productions_data.get(\"Produção bibliográfica\", {})\n",
    "            \n",
    "#             if isinstance(bibliographic_production, str):\n",
    "#                 print(f\"Attempting to deserialize 'Produção bibliográfica' for {name}...\")\n",
    "#                 try:\n",
    "#                     bibliographic_production = json.loads(bibliographic_production)\n",
    "#                 except json.JSONDecodeError as e:\n",
    "#                     print(f\"Failed to deserialize 'Produção bibliográfica' for {name}: {e}\")\n",
    "#                     return\n",
    "\n",
    "#             articles = json.loads(bibliographic_production.get(\"Artigos completos publicados em periódicos\", \"{}\"))\n",
    "\n",
    "#             for _, article_str in articles.items():\n",
    "#                 article_details = self.extract_article_info(article_str)\n",
    "\n",
    "#                 # Vamos imprimir os detalhes de cada artigo e verificar se os autores estão presentes.\n",
    "#                 print(f\"Original Article: {article_str}\")\n",
    "#                 print(f\"Extracted Details: {article_details}\")\n",
    "\n",
    "#                 if article_details:\n",
    "#                     article_details[\"title\"] = article_details[\"title\"].strip()\n",
    "#                     article_details[\"original_title\"] = article_details[\"original_title\"].strip()\n",
    "\n",
    "#                     session.run(f\"MERGE (a:Artigo {{title: $title}}) SET a += $details\", title=article_details[\"title\"], details=article_details)\n",
    "#                     session.run(f\"MATCH (p:Person {{name: $name}}), (a:Artigo {{title: $title}}) MERGE (p)-[:PUBLICOU]->(a)\", name=name, title=article_details[\"title\"])\n",
    "#                     successful_articles += 1\n",
    "#                 else:\n",
    "#                     unsuccessful_articles.append(article_str)\n",
    "\n",
    "#         print(f\"Processed {successful_articles} articles successfully for {name}.\")\n",
    "\n",
    "#         if unsuccessful_articles:\n",
    "#             print(\"Failed to process the following articles:\")\n",
    "#             for article in unsuccessful_articles:\n",
    "#                 print(article)\n",
    "\n",
    "#     def process_articles(self, name):\n",
    "#         self.deserialize_and_create_nodes(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395566b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class JcrHandler:\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "\n",
    "#     def _consultar_propriedades_jcr(self, tx, name):\n",
    "#         query = (\n",
    "#             \"MATCH (p:Person {name: $name})\"\n",
    "#             \"RETURN p.JCR AS jcr\"\n",
    "#         )\n",
    "#         result = tx.run(query, name=name)\n",
    "#         return [record[\"jcr\"] for record in result]\n",
    "   \n",
    "#     ## Versão para usar com criação de nós secundários retorna JSON\n",
    "#     def consultar_propriedades_jcr(self, name):\n",
    "#         with self._driver.session() as session:\n",
    "#             query = (\n",
    "#                 \"MATCH (p:Person {name: $name})\"\n",
    "#                 \"RETURN p.JCR AS jcr\"\n",
    "#             )\n",
    "#             result = session.run(query, name=name)\n",
    "#             jcr_data = result.single()[\"jcr\"]\n",
    "#             jcr_properties_list = json.loads(jcr_data)\n",
    "#             return jcr_properties_list\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _convert_list_to_dict(lst):\n",
    "#         \"\"\"\n",
    "#         Converts a list into a dictionary with indices as keys.\n",
    "        \n",
    "#         Parameters:\n",
    "#         - lst: list, input list to be transformed.\n",
    "        \n",
    "#         Returns:\n",
    "#         - dict: Transformed dictionary.\n",
    "#         \"\"\"\n",
    "#         return {str(i): item for i, item in enumerate(lst)}\n",
    "    \n",
    "#     def create_person_with_jcr(self, name, jcr_properties):\n",
    "#         with self._driver.session() as session:\n",
    "#             session.write_transaction(self._create_person_with_jcr, name, jcr_properties)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _create_person_with_jcr(tx, name, jcr_properties):\n",
    "#         # Cria o nó Person\n",
    "#         person_query = (\n",
    "#             \"CREATE (p:Person {name: $name}) \"\n",
    "#             \"RETURN p\"\n",
    "#         )\n",
    "#         person_result = tx.run(person_query, name=name)\n",
    "#         person_node = person_result.single()[0]\n",
    "\n",
    "#         # Cria os nós secundários para cada valor único de data-issn\n",
    "#         data_issn_values = set(prop.get(\"data-issn\") for prop in jcr_properties)\n",
    "#         for data_issn in data_issn_values:\n",
    "#             if data_issn:\n",
    "#                 secondary_node_query = (\n",
    "#                     \"CREATE (s:SecondaryNode {data_issn: $data_issn}) \"\n",
    "#                     \"RETURN s\"\n",
    "#                 )\n",
    "#                 tx.run(secondary_node_query, data_issn=data_issn)\n",
    "\n",
    "#                 # Cria a relação entre o nó Person e o nó secundário\n",
    "#                 relation_query = (\n",
    "#                     \"MATCH (p:Person {name: $name}), (s:SecondaryNode {data_issn: $data_issn}) \"\n",
    "#                     \"CREATE (p)-[:HAS_JCR]->(s)\"\n",
    "#                 )\n",
    "#                 tx.run(relation_query, name=name, data_issn=data_issn)\n",
    "\n",
    "#     def createJournalsNodes(self, name):\n",
    "#         # Get JCR properties\n",
    "#         jcr_properties = self.consultar_propriedades_jcr(name)\n",
    "\n",
    "#         # Convert the serialized JSON strings back into dictionaries\n",
    "#         deserialized_jcr_properties = [json.loads(prop) for prop in jcr_properties.values()]\n",
    "\n",
    "#         # Inform the user about the total number of JCR property entries\n",
    "#         total_entries = len(deserialized_jcr_properties)\n",
    "#         print(f\"Read {total_entries} entries from JCR properties of Person '{name}'.\")\n",
    "\n",
    "#         # Extract relevant journal properties and their count\n",
    "#         journal_counts = Counter(prop.get(\"data-issn\") for prop in deserialized_jcr_properties)\n",
    "        \n",
    "#         # Number of unique ISSNs\n",
    "#         unique_issns = len(journal_counts)\n",
    "#         print(f\"Identified {unique_issns} unique ISSN values.\")\n",
    "\n",
    "#         null_count = journal_counts.pop(None, 0)  # Remove None (null) ISSN and get its count\n",
    "#         null_count += journal_counts.pop(\"NULL\", 0)  # Also account for \"NULL\" as a string\n",
    "\n",
    "#         # Counters for journals\n",
    "#         successful_journal_creations = 0\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             for data_issn, count in journal_counts.items():\n",
    "#                 if data_issn and data_issn != \"NULL\":\n",
    "#                     representative_entry = next(prop for prop in deserialized_jcr_properties if prop.get(\"data-issn\") == data_issn)\n",
    "#                     journal_name = representative_entry.get(\"original_title\")\n",
    "#                     fator_impacto = representative_entry.get(\"impact-factor\")\n",
    "#                     jcr_year = representative_entry.get(\"jcr-year\")\n",
    "\n",
    "#                     # Create or merge the Journal node\n",
    "#                     journal_node_query = (\n",
    "#                         \"MERGE (j:Revistas {ISSN: $data_issn}) \"\n",
    "#                         \"ON CREATE SET j.name = $journal_name, j.FatorImpacto = $impact_factor, j.JCRYear = $jcr_year \"  # Corrected this line\n",
    "#                         \"RETURN j\"\n",
    "#                     )\n",
    "#                     session.run(journal_node_query, data_issn=data_issn, journal_name=journal_name, impact_factor=fator_impacto, jcr_year=jcr_year)  # And this line\n",
    "\n",
    "#                     # Create or update the \"PUBLICOU_EM\" relationship\n",
    "#                     relation_query = (\n",
    "#                         \"MATCH (p:Person {name: $name}), (j:Revistas {ISSN: $data_issn}) \"  # corrected this line\n",
    "#                         \"MERGE (p)-[r:PUBLICOU_EM]->(j) \"\n",
    "#                         \"ON CREATE SET r.QuantidadePublicações = $count \"\n",
    "#                         \"ON MATCH SET r.QuantidadePublicações = r.QuantidadePublicações + $count\"\n",
    "#                     )\n",
    "#                     session.run(relation_query, name=name, data_issn=data_issn, count=count)\n",
    "                    \n",
    "#                     successful_journal_creations += 1\n",
    "                \n",
    "#                 if null_count:\n",
    "#                     # For example, to print the count:\n",
    "#                     pass\n",
    "        \n",
    "#         # Inform the user about journals\n",
    "#         print(f\"{successful_journal_creations} Revistas adicionadas com sucesso.\")\n",
    "#         print(f\"{null_count} Revistas não foram criadas por terem valor NULL de ISSN.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4fe327",
   "metadata": {},
   "source": [
    "## Teste extrair homônimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Teste de extração para homônimos\n",
    "# t1 = time.time()\n",
    "# lista_homonimos = [\n",
    "#     'Tania Maria Alves de Almeida',\n",
    "#     'Rodrigo Corrêa de Oliveira',\n",
    "# ]\n",
    "\n",
    "# scraper = LattesScraper(termos_busca, 'bolt://localhost:7687', 'neo4j', 'password', only_doctors=True)\n",
    "# dom_dict_homonimos = scraper.scrape(lista_homonimos, termos_busca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.spacy3': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "197d8f220c237ea2269a397bcc5571d13b6ee9614ab9ae87aa2d290b25dc373b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
