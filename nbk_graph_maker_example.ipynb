{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Graph from a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este caderno demonstra como extrair grafo de qualquer texto usando o criador de grafos\n",
    "\n",
    "Passos:\n",
    "- Definir uma ontologia\n",
    "- Carregar uma lista de exemplos de blocos de texto. Usaremos o resumo do Senhor dos Anéis desta página da Wikipedia.\n",
    "- Criar gráfico usando um modelo de código aberto usando APIs Groq.\n",
    "- Salve o gráfico no banco de dados Neo4j\n",
    "- Visualizar\n",
    "\n",
    "\n",
    "\n",
    "Carregar as funções do criador de grafos ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\anaconda3\\Lib\\site-packages\\certifi\\cacert.pem\n"
     ]
    }
   ],
   "source": [
    "## no Linux no terminal rodar:\n",
    "# export GROQ_API_KEY='secret'\n",
    "\n",
    "## no Windows no Powershell rodar:\n",
    "# $env:GROQ_API_KEY = \"secret\"\n",
    "\n",
    "# %pip install --upgrade httpx\n",
    "# %pip install --upgrade groq\n",
    "# %pip install python-certifi-win32\n",
    "# %pip install --upgrade certifi\n",
    "\n",
    "import certifi\n",
    "print(certifi.where())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: httpx\n",
      "Version: 0.27.0\n",
      "Summary: The next generation HTTP client.\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Tom Christie <tom@tomchristie.com>\n",
      "License: \n",
      "Location: c:\\Users\\marco\\anaconda3\\Lib\\site-packages\n",
      "Requires: anyio, certifi, httpcore, idna, sniffio\n",
      "Required-by: fastapi, googletrans, gradio, gradio_client, groq, qdrant-client\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: httpx\n",
      "Version: 0.13.3\n",
      "Summary: The next generation HTTP client.\n",
      "Home-page: https://github.com/encode/httpx\n",
      "Author: Tom Christie\n",
      "Author-email: tom@tomchristie.com\n",
      "License: BSD\n",
      "Location: c:\\Users\\marco\\anaconda3\\Lib\\site-packages\n",
      "Requires: certifi, chardet, hstspreload, httpcore, idna, rfc3986, sniffio\n",
      "Required-by: fastapi, googletrans, gradio, gradio_client, groq, qdrant-client\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As principais questões científicas de interesse na área de imunologia e imunopatologia incluem:\n",
      "\n",
      "1. **Como o sistema imune distingue entre o eu e o não-eu?**: Este é um desafio fundamental na imunologia, pois o sistema imune precisa distinguir entre as células do próprio corpo e as células estranhas, como bactérias e vírus, para evitar respostas imunes autoimunes.\n",
      "\n",
      "2. **Como a imunidade celular e humoral se coordinam para controlar infecções?**: A resposta imune é mediada por células imunes, como linfócitos T e B, que trabalham juntas para eliminar patógenos. Entender como essas células se comunicam e se coordenam é fundamental para desenvolver estratégias de prevenção e tratamento de doenças.\n",
      "\n",
      "3. **Quais são os mecanismos moleculares que regulam a resposta imune?**: A sinalização molecular é crucial para a ativação e regulação da resposta imune. Entender como as moléculas sinalizadoras, como citocinas e quimiocinas, regulam a resposta imune pode levar a terapias mais eficazes.\n",
      "\n",
      "4. **Como as respostas imunes contribuem para doenças autoimunes e inflamatórias?**: As doenças autoimunes, como o lúpus e a artrite reumatoide, são causadas por respostas imunes desreguladas. Entender como essas respostas se desenvolvem pode levar a terapias mais eficazes.\n",
      "\n",
      "5. **Como podemos desenvolver vacinas mais eficazes?**: As vacinas são fundamentais para prevenir doenças infecciosas. Entender como as respostas imunes são geradas em resposta a vacinas pode levar ao desenvolvimento de vacinas mais eficazes.\n",
      "\n",
      "6. **Como as respostas imunes afetam o câncer?**: O sistema imune pode tanto prevenir quanto promover o crescimento tumoral. Entender como as respostas imunes afetam o câncer pode levar a terapias mais eficazes.\n",
      "\n",
      "7. **Como as doenças crônicas, como diabetes e doenças cardíacas, afetam o sistema imune?**: As doenças crônicas podem afetar a resposta imune e levar a complicações. Entender como essas doenças afetam o sistema imune pode levar a terapias mais eficazes.\n",
      "\n",
      "8. **Como as respostas imunes são afetadas pela microbiota?**: A microbiota (microrganismos que habitam o corpo humano) desempenha um papel importante na regulação do sistema imune. Entender como a microbiota afeta a resposta imune pode levar a terapias mais eficazes.\n",
      "\n",
      "Essas são apenas algumas das principais questões científicas de interesse na área de imunologia e imunopatologia. O estudo dessas questões pode levar a avanços significativos no tratamento e prevenção de doenças.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import platform\n",
    "import httpx\n",
    "import ssl\n",
    "from groq import Groq\n",
    "\n",
    "if platform.system() == 'Linux':\n",
    "    folder = '../'\n",
    "elif platform.system() == 'Windows':\n",
    "    try:\n",
    "        folder = '../'\n",
    "        pathfilename = os.path.join(folder, 'secrets.json')\n",
    "        with open(pathfilename) as file:\n",
    "            data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        folder = '../../../'\n",
    "        pathfilename = os.path.join(folder, 'secrets.json')\n",
    "        with open(pathfilename) as file:\n",
    "            data = json.load(file)\n",
    "else:\n",
    "    raise SystemError('Sistema operacional não suportado')\n",
    "\n",
    "try:\n",
    "    httpx_client = httpx.Client(\n",
    "        verify=False,  \n",
    "        limits=httpx.Limits(max_keepalive_connections=None, max_connections=None),\n",
    "        transport=httpx.HTTPTransport(retries=3)\n",
    "    )\n",
    "\n",
    "    client = Groq(api_key=data.get('groq'), http_client=httpx_client)\n",
    "\n",
    "    if not client.api_key:  # Verifica se a chave de API foi obtida corretamente\n",
    "        raise ValueError(\"Chave de API Groq não encontrada ou inválida.\")\n",
    "\n",
    "    immunology_questions = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What are the main scientific questions of interest in the area of immunology and immunopathology? Escreva a resposta em português do Brasil\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-70b-8192\",\n",
    "    )\n",
    "\n",
    "    print(immunology_questions.choices[0].message.content)\n",
    "\n",
    "except (httpx.ConnectError, httpx.ReadTimeout) as e:\n",
    "    if isinstance(e.reason, ssl.SSLError):\n",
    "        print(f\"Erro de certificado SSL: {e.reason} ({e})\")  # Mensagem de erro mais detalhada\n",
    "    else:\n",
    "        print(f\"Erro de conexão: {e}\")\n",
    "except ValueError as e:  # Captura erro de chave de API inválida\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, json, platform\n",
    "# import httpx, ssl\n",
    "# from groq import Groq\n",
    "\n",
    "# if platform.system() == 'Linux':\n",
    "#     folder = '../'\n",
    "# elif platform.system() =='Windows':\n",
    "#     try:\n",
    "#         folder = '../'\n",
    "#         pathfilename = os.path.join(folder,'secrets.json')\n",
    "#         with open(pathfilename) as file:\n",
    "#             # Carregar seu conteúdo e torná-lo um novo dicionário\n",
    "#             data = json.load(file)        \n",
    "#     except:\n",
    "#         folder = '../../../'\n",
    "#         pathfilename = os.path.join(folder,'secrets.json')\n",
    "#         with open(pathfilename) as file:\n",
    "#             # Carregar seu conteúdo e torná-lo um novo dicionário\n",
    "#             data = json.load(file)        \n",
    "# else:\n",
    "#     print('Sistema operacional não suportado')\n",
    "\n",
    "# try:\n",
    "#     # Criar um cliente HTTPx com verificação SSL desativada e limites customizados\n",
    "#     httpx_client = httpx.Client(\n",
    "#         verify=False,\n",
    "#         limits=httpx.Limits(max_keepalive_connections=None, max_connections=None),\n",
    "#         transport=httpx.HTTPTransport(retries=3)\n",
    "#     )\n",
    "\n",
    "#     client = Groq(\n",
    "#         # api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "#         api_key=data.get('groq'),\n",
    "#         http_client=httpx_client\n",
    "#     )\n",
    "\n",
    "\n",
    "#     immunology_questions = client.chat.completions.create(\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": \"What are the main scientific questions of interest in the area of immunology and immunopathology? Escreva a resposta em português do Brasil\",\n",
    "#             }\n",
    "#         ],\n",
    "#         # model=\"llama3-8b-8192\",\n",
    "#         model = \"llama3-70b-8192\",\n",
    "#     )\n",
    "\n",
    "#     print(immunology_questions.choices[0].message.content)\n",
    "\n",
    "# except httpx.ConnectError as e:\n",
    "#     if isinstance(e.reason, ssl.SSLError):\n",
    "#         print(\"Erro de certificado SSL:\", e.reason)\n",
    "#         # ... (investigar o certificado SSL da Groq e corrigi-lo) ...\n",
    "#     else:\n",
    "#         print(\"Erro de conexão:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há várias plataformas científicas importantes para realização de pesquisas em imunologia e imunopatologia. Aqui estão algumas das principais:\n",
      "\n",
      "1. Nature Immunology: É uma revista de alto impacto que publica artigos originais sobre imunologia humana e animal.\n",
      "2. Journal of Experimental Medicine: É uma revista líder em imunologia e biologia celular, que publica artigos originais sobre imunopatologia, imunobiologia e biologia do câncer.\n",
      "3. Immunity: É uma revista que concentra-se em imunologia clínica, experimentação e temas relacionados à patalogia imune.\n",
      "4. Blood: É uma revista que publica artigos sobre hematologia, Hemostasia e imunologia sanguínea.\n",
      "5. European Journal of Immunology: É uma revista que publica artigos originais sobre imunologia humana e animal, incluindo imunologia clínica e experimental.\n",
      "6. Journal of Immunology: É uma revista que publica artigos originais sobre imunologia humana e animal, incluindo imunopatologia e imunobiologia.\n",
      "7. Journal of Allergy and Clinical Immunology: É uma revista que concentra-se em doenças alérgicas e imunopatias, incluindo ascerasos e anafilaxia.\n",
      "8. Science Immunology: É uma revista que publica artigos originais sobre imunologia, incluindo imunopatologia e imunobiologia.\n",
      "9. Immune Reviews: É uma revista que publica revisões críticas sobre assuntos atuais em imunologia.\n",
      "10. Advances in Immunology: É uma série de livros que concentracam-se em assuntos atuais em imunologia.\n",
      "\n",
      "Além disso, existem também algumas plataformas de publicação online que reunem artigos de autoridade em imunologia e imunopatologia, como:\n",
      "\n",
      "1. F1000Prime: É um portal de publicação de artigos científicos que fornece revisões críticas das publicações recentes em imunologia e outras disciplinas.\n",
      "2. DOAJ (Directory of Open Access Journals): É um diretório de periódicos de acesso aberto que incluem várias revistas de imunologia e imunopatologia.\n",
      "3. arXiv: É um repositório de artigos pré-publicados em imunologia e outras disciplinas.\n",
      "4. bioRxiv: É um repositório de artigos pré-publicados em biologia e saúde.\n",
      "\n",
      "Essas são apenas algumas das principais plataformas científicas para realizar pesquisas em imunologia e imunopatologia.\n"
     ]
    }
   ],
   "source": [
    "immunology_platform_communication = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are the main scientific platforms for carrying out research in immunology and immunopathology? Escreva a resposta em português do Brasil\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(immunology_platform_communication.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excelente pergunta!\n",
      "\n",
      "As principais plataformas científicas e tecnológicas utilizadas para realizar pesquisas científicas em imunologia e imunopatologia são:\n",
      "\n",
      "1. Microscopia de Fluorescência - Utilizada para visualizar e analisar a expressão de moléculas de sinalização e de adesão nas células do sistema imunológico.\n",
      "2. Cytometry by Fluorescence - Uso de feitores de fluorescência para medir a expressão de moléculas de sinalização e de adesão nas células do sistema imunológico.\n",
      "3. Flow Cytometry - Utilizado para analisar a expressão de moléculas de sinalização e de adesão nas células do sistema imunológico.\n",
      "4. ELISA (Enzyme-Linked Immunosorbent Assay) - Utilizado para medir a concentração de anticorpos e outras proteínas presentes no sangue e nos tecidos.\n",
      "5. PCR (Polymerase Chain Reaction) - Uma técnica de amplificação de DNA utilizada para detectar e quantificar genes associados a doenças imunológicas.\n",
      "6. qPCR (Quantitative PCR) - Uma variante da PCR que fornece informações quantitativas sobre a presença de genes associados a doenças imunológicas.\n",
      "7. Array CGH (Comparative Genomic Hybridization) - Uma técnica utilizada para detectar anormalidades cromossômicas em células normais ou cancerígenas.\n",
      "8. Immunofluorescence microscopy - Utilizado para visualizar e analisar a expressão de moléculas de sinalização e de adesão nas células do sistema imunológico.\n",
      "9. High-Throughput Sequencing - Utilizado para analyse genômica e proteômica em células do sistema imunológico.\n",
      "10. Single-cell RNA Sequencing - Utilizado para analisar a expressão genômica em níveis celulares isolados.\n",
      "11. Bioinformática - Utilizada para análise de dados em grande escala e inferência de conhecimento biológico a partir de dados de alta dimensionalidade.\n",
      "\n",
      "Essas plataformas permitem à comunidade científica investigar e elucidar processos imunológicos e patológicos, bem como desenvolver terapias e tratamentos eficazes para doenças relacionadas ao sistema imunológico.\n"
     ]
    }
   ],
   "source": [
    "immunology_tech_platforms = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are the main scientific technology platforms for carrying out scientific research questions in immunology and immunopathology? Escreva a resposta em português do Brasil\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(immunology_tech_platforms.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Um desafio interessante!\n",
      "\n",
      "As principais ontologias que abordam conceitos semânticos em plataformas de tecnologia científica relacionadas à imunologia e patologia imunológica são:\n",
      "\n",
      "1. **Biologie de Immunologie** (Immune System Ontology): desenvolvida pelo Universidade de Oxford, essa ontologia descreve conceitos e relações importantes na imunologia, como células imunes, citocinas, antígenos e respostas imunológicas.\n",
      "2. **MGI Mouse Gene Functional Ontology** (MGI): embora não exclusivamente centrada em imunologia, a MGI é uma ontologia ampla que aborda genes, proteínas e fenótipos, incluindo conceitos relacionados à imunologia e patologia.\n",
      "3. **The Gene Ontology (GO)**: enquanto não especializada em imunologia, a GO é amplamente utilizada em muitos campos da biologia e saúde, incluindo a imunologia, para descrever e relacionar genes e seu comportamento.\n",
      "4. **The Immunological Database and Analysis Portal (ImmPort)**: embora não uma ontologia propriamente dita, o ImmPort é uma ferramenta que agrega e organiza dados de imunologia, incluindo informações sobre moléculas, células e respostas imunológicas.\n",
      "5. **The PANTHER Pathway Ontology**: desenvolvida pelo PhD2, a PANTHER é uma ontologia mais ampla que aborda vários campos biológicos, incluindo a imunologia, para descrever caminhos moleculares e interações celulares.\n",
      "6. **The Cell Ontology (CL)**: embora não exclusivamente centrada em imunologia, a CL é uma ontologia que descreve e relaciona células, incluindo células imunes e outras células envolvidas na imunologia.\n",
      "\n",
      "Essas ontologias podem ser utilizadas para melhorar a interoperabilidade e a reutilização de dados em plataformas de tecnologia científica em imunologia e patologia imunológica.\n"
     ]
    }
   ],
   "source": [
    "immunology_ontologies = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are the main ontologies to encompass the semantics concepts in scientific technology platforms in immunology and immunopathology? Escreva a resposta em português do Brasil\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(immunology_ontologies.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Excelente pergunta!\n",
    "\n",
    "As ontologias que abarcam conceitos semânticos em plataformas tecnológicas para a imunologia e imunopatologia incluem:\n",
    "\n",
    "1. **Human Phenotype Ontology (HPO)**: Desenvolvido pelo Institute for Systems Biology, o HPO é uma ontologia que descreve os fenótipos humanos, incluindo doenças e condições clínicas, incluindo as relacionadas à imunologia.\n",
    "2. **Gene Ontology (GO)**: Desenvolvido pelo Gene Ontology Consortium, o GO é uma ontologia que descreve as funcionalidades biológicas de genes e proteínas, incluindo processos celulares e moleculares importantes na imunologia.\n",
    "3. **ImmPort**: Desenvolvido pela National Institute of Allergy and Infectious Diseases (NIAID), o ImmPort é uma ontologia que descreve os conceitos e termos relacionados à imunologia, incluindo a patogenia, a resposta imune e a diagnostico.\n",
    "4. **MIRIAM (Minimal Information Requested in the Annotation of Biological and Integrated Datasets)**: Desenvolvido pela Bioinformatics Working Group da International AIDS Society, o MIRIAM é uma ontologia que fornece diretrizes para a aquisição e compartilhamento de dados biológicos e de saúde, incluindo dados imunológicos.\n",
    "5. **iCER (Immunology Cellular Expression and Response)**: Desenvolvido pela Institute for Systems Biology, o iCER é uma ontologia que descreve a expressão de células e moléculas envolvidas na resposta imune, incluindo a imunidade adaptativa e inata.\n",
    "6. **Immunology Ontology (IO)**: Desenvolvido pela University of Victoria, o IO é uma ontologia que descreve os conceitos e termos relacionados à imunologia, incluindo a imunogene, a citotóxica e a imunopatia.\n",
    "\n",
    "Essas ontologias podem ser integradas para criar um quadro comum que abarca a complexidade da imunologia e imunopatologia, tornando mais fácil a comunicação e o compartilhamento de dados entre pesquisadores e clínicos."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "A área da imunologia e imunopatologia é caracterizada por uma ampla gama de plataformas científicas que permitem ao pesquisador desbloquear os segredos da comunicação entre as células do sistema imune e compreender as patogenias das doenças imunopatológicas. \n",
    "\n",
    "Dentre as questões científicas de interesse na área de imunologia e imunopatologia estão incluídas:\n",
    "Essas questões científicas de interesse permitem que os pesquisadores e científicos na área de imunologia e imunopatologia continuem a avançar em nosso entendimento da resposta imune e desenvolvam novas estratégias para prevenir e tratar doenças.\n",
    "\"Como o sistema imune diferencia entre um patógeno e o próprio corpo\": \"Compreender como o sistema imune reconhece e responde a agentes patogênicos, enquanto mantém a tolerância ao próprio tecido é fundamental para entender a imunologia.\",\n",
    "\"Entendimento da resposta imune adaptativa\": \"Como as células imunes, como os linfócitos, reconhecem e respondem a patógenos específicos?\",\n",
    "\"Regulação da resposta imune\": \"Como a resposta imune é regulada para evitar reações exageradas ou inadequadas que podem levar a doenças autoimunes ou infecções crônicas?\",\n",
    "\"Quais são os mecanismos que regulam a resposta imune?\": \"Entender como as células imunes se comunicam entre si e como são reguladas as respostas imunes é crucial para o desenvolvimento de terapias eficazes.\",\n",
    "\"Como as células imunes são educadas e diferenciadas?\": \"A compreensão de como as células imunes se desenvolvem e se diferenciam pode levar a novas estratégias para o tratamento de doenças imunes.\"\n",
    "\"Como as respostas imunes são influenciadas pelo sistema nervoso central?\": \"A interação entre o sistema imune e o sistema nervoso central é complexa e não é ainda completamente compreendida.\"\n",
    "\"Imunologia do câncer\": \"Como as células imunes interagem com células tumorais e como podemos desenvolver terapias imune-orientadas para o tratamento do câncer?\",\n",
    "\"Imunologia das doenças autoimunes\": \"A compreensão dos mecanismos que levam ao desenvolvimento de doenças autoimunes, como o lúpus e a artrite reumatoide, pode levar a tratamentos mais eficazes. Qual é a origem das doenças autoimunes e como podemos desenvolver terapias para prevenir ou tratar essas doenças?. A interação entre fatores genéticos e ambientais pode influenciar a suscetibilidade a doenças imunes, então, como as doenças imunes são influenciadas pelo ambiente e pela genética?\"\n",
    "\"Imunologia das doenças infecciosas\": \"Infecções crônicas, como a infecção por HIV, podem levar a uma debilitação do sistema imune, tornando os indivíduos mais suscetíveis a outras doenças. Como as células imunes respondem a patógenos específicos e como podemos desenvolver terapias para prevenir ou tratar infecções?\",\n",
    "\"Imunologia da tolerância\": \"Como as células imunes aprendem a tolerar substâncias estranhas, como alimentos ou transplantes, evitando reações imunes indesejadas?\",\n",
    "\"Imunologia do microbioma\": \"O microbioma, conjunto de microrganismos que habitam o corpo humano, pode influenciar a resposta imune e a saúde em geral. Como as células imunes interagem com o microbioma humano e como essa interação afeta a saúde e a doença?\",\n",
    "\"Imunosenescência e imunorejuvenescimento\": \"Como o sistema imune envelhece e como podemos desenvolver estratégias para manter ou restaurar a função imune saudável com o envelhecimento?\"\n",
    "\"Quais são os mecanismos que regulam a imunossenescência?\": \"A imunossenescência, ou o declínio da função imune com a idade, é um processo complexo que não é ainda completamente compreendido.\",\n",
    "\"Desenvolvimento de vacinas eficazes\": Como desenvolver vacinas que sejam capazes de induzir respostas imunes protetoras contra doenças infecciosas e cancerígenas?\",\n",
    "\"Desenvolvimento de terapias celulares\": \"Como desenvolver terapias que utilizam células imunes, como células T, para tratar doenças, como o câncer e doenças autoimunes?\",\n",
    "\n",
    "Algumas das principais plataformas científicas para a realização de pesquisas em imunologia e imunopatologia incluem:\n",
    "Essas plataformas científicas permitem que os pesquisadores aprofundem o entendimento da imunologia e imunopatologia, desenvolvendo novas estratégias terapêuticas para tratarem doenças imunopatológicas e melhorar a compreensão da interação entre o sistema imune e o microbioma. \n",
    "\"Bioinformática\": \"a interpretação de dados genômicos e transcriptômicos é fundamental para entender as respostas imunológicas e identificar os principais mediadores da resposta imune.\"\n",
    "\"Cultura de Células isoladas\": \"a cultura de células imunológicas, como linfócitos e macrófagos, permite estudar a função e a regulação dessas células em condições in vitro.\"\n",
    "\"Modelos animais\": \"os modelos animais, como camundongos e ratos, permitem a investigação da resposta imune em modelos de doenças específicas, como a doença de Alzheimer e a Tireoplasticidade.\"\n",
    "\"Imagem médica\": \"técnicas de imagem como a ressonância magnética (RM) e a tomografia por estimulação para a função de positron (PET) permitem a avaliação in vivo da Actividade das células imunológicas e doenças imunopatológicas.\"\n",
    "\"Microbioma\": \"a análise do microbioma, que é a comunidade microbiana do tecido humano, é fundamental para entender a relação entre a microbiota e a resposta imune.\"\n",
    "\"Dados públicos\": \"a disponibilização de dados públicos a partir de fontes como o GenBank e o ArrayExpress, possibilitam a comparação e a integração de resultados de pesquisa em imunologia.\"\n",
    "\"Análise de fluxo celular\": \"a técnica de fluorecência de marcação e análise de fluxo permitem a avaliação do movimento e da morfologia de células imunológicas em condições variáveis.\"\n",
    "\"Microscopia\": \"a microscopia confocal e super-resolucione permite a visualização direta das interações entre as células imunológicas e a avaliação da expressão de moléculas adesivas.\"\n",
    "\"Células dendríticas\": \"a preparação e a cultura de células dendríticas é fundamental para entender a apresentação de antígenos e a resposta imune.\"\n",
    "\"Proteômica\": \"a análise proteômica permite a avaliação da expressão proteica e a identificação de novos biomarcadores para a monitorização de doenças imunopatológicas.\"\n",
    "\n",
    "Já quanto as principais plataformas tecnológicas para realizar pesquisas científicas em imunologia e imunopatologia são:\n",
    "\"Flow cytometry\": \"A citometria de fluxo é uma técnica instrumental para análise de células sanguíneas que permite uma grande variedade de aplicações em imunologia, incluindo a detecção de células imunes específicas, a quantificação de marcadores de superfície e a avaliação da funcionalidade das células imunes.\"\n",
    "\"Microscópio de força atômica (AFM)\": \"O microscópio de força atômica é uma ferramenta que permite a observação de estruturas celulares com precisão nanométrica, permitindo a análise de interações moleculares importantes para a imunologia.\"\n",
    "\"Assaio de proteínas (Western blot)\": \"O Western blot é uma técnica de laboratório que permite a separação, detecção e quantificação de proteínas específicas em amostras biológicas, fundamental para entender as reações imunes e a patogenese de doenças.\"\n",
    "\"Sequenciamento de mRNA (RNA-seq)\": \"O sequenciamento de mRNA é uma tecnologia que permite a análise global da expressão gênica em diferentes condições, ajudando a entender como as células imunes respondem a estímulos e patógenos.\n",
    "\"Análise de dados de pluripotência (Single-cell RNA-seq)\": \"A análise de dados de pluripotência com base em RNA-seq permite a investigação de grupos celulares singulares e a detecção de subpopulações celulares específicas, o que é fundamental para entender a imunologia e a patogenese de doenças.\"\n",
    "\"Técnicas de PCR (Polimerase Chain Reaction) e qPCR (quantitative PCR)\": \"A PCR é uma técnica que permite amplificar DNA específico e a qPCR é uma versão quantitativa da técnica, fundamental para a detecção e quantificação de genes específicos.\n",
    "\"Imunofluorescência\": \"A imunofluorescência é uma técnica que utiliza anticorpos conjugados a corantes para avaliar a expressão de proteínas específicas em células e tecidos, fundamental para entender a expressão de marcadores de superfície e a migração de células imunes.\"\n",
    "\"Células características\": \"As células características são células que expressam um marcador específico, permitindo a separação de subpopulações celulares específicas e a análise de suas propriedades funcionais.\"\n",
    "\"Técnicas de microscopia confocal\": \"Microscopia confocal é uma técnica que permite obter imagens tridimensionais de estruturas celulares, fundamental para entender a localização de proteínas e a interação entre células.\"\n",
    "\"Biótica e bioinformática\": \"A biotecnologia e a bioinformática são ferramentas essenciais para o armazenamento, análise e interpretação de grandes quantidades de dados gerados em estudos de imunologia.\"\n",
    "\n",
    "Em termos sobre pesquisas científicas em imunologia e imunopatologia, há várias ontologias importantes que abordam conceitos semânticos relevantes para a área, tais como:\n",
    "https://help.iedb.org/hc/en-us/articles/4402872882189-Immune-Epitope-Database-Query-API-IQ-API\n",
    "\"Human Phenotype Ontology (HPO)\": Desenvolvido pelo Institute for Systems Biology, o HPO é uma ontologia que descreve os fenótipos humanos, incluindo doenças e condições clínicas, incluindo as relacionadas à imunologia.\",\n",
    "\"Gene Ontology (GO)\": Desenvolvido pelo Gene Ontology Consortium, o GO é uma ontologia que descreve as funcionalidades biológicas de genes e proteínas, incluindo processos celulares e moleculares importantes na imunologia.\",\n",
    "\"ImmPort\": Desenvolvido pela National Institute of Allergy and Infectious Diseases (NIAID), o ImmPort é uma ontologia que descreve os conceitos e termos relacionados à imunologia, incluindo a patogenia, a resposta imune e a diagnostico.\",\n",
    "\"MIRIAM (Minimal Information Requested in the Annotation of Biological and Integrated Datasets)\": Desenvolvido pela Bioinformatics Working Group da International AIDS Society, o MIRIAM é uma ontologia que fornece diretrizes para a aquisição e compartilhamento de dados biológicos e de saúde, incluindo dados imunológicos.\",\n",
    "\"iCER (Immunology Cellular Expression and Response)\": \"Desenvolvido pela Institute for Systems Biology, o iCER é uma ontologia que descreve a expressão de células e moléculas envolvidas na resposta imune, incluindo a imunidade adaptativa e inata.\",\n",
    "\"Immunology Ontology (IO)\": \"Desenvolvido pela University of Victoria, o IO é uma ontologia que descreve os conceitos e termos relacionados à imunologia, incluindo a imunogene, a citotóxica e a imunopatia.\"\n",
    "\n",
    "Outras muitas ontologias dizem respeito a áreas correlatas como:\n",
    "\"Biological Process Ontology (BPO)\": \"Descreve processos biológicos, como a resposta imune, e é fundamental para a definição de amostras e experimentos em estudos de imunologia.\"\n",
    "\"Immune Epitope Database and Analysis Resource (IEDB)\": \"Descreve o reconhecimento de epitopes por células imunes, o que é crucial para a compreensão da resposta imune.\"\n",
    "\"Pathway Ontology (PAO)\": \"Descreve caminhos metabólicos relacionados às vias de sinalização e resposta imune.\"\n",
    "\"Cell Ontology (CO)\": \"Descreve diferentes tipos de células, incluindo as células sanguíneas, linfócitos e macrófagos, entre outras.\"\n",
    "\"Sequence Ontology (SO)\": \"Descreve a estrutura e função de sequências de nucleótidos e proteínas, o que é importante para a análise de sequências genômicas e transcriptômicas em estudos de imunologia.\"\n",
    "\"Diseasome Ontology (DO)\": \"Descreve a formação de complexos de proteínas envolvidas na patogenese de doenças, incluindo doenças imunopatológicas.\"\n",
    "\"ICD (International Classification of Diseases)\": \"Uma classificação internacialemente aceita para doenças, incluindo doenças imunopatológicas, como doenças autoimunes e alérgicas.\"\n",
    "\"MeSH (Medical Subject Headings)\": \"Indicadores de saúde e doenças, que incluem títulos e descrições para doenças, incluindo doenças imunológicas.\"\n",
    "\"UMLS (Unified Medical Language System)\": \"Conjunto de vocabulários e ontologias para a representação e classificação de conceitos em saúde, incluindo doenças e processos biológicos.\"\n",
    "\n",
    "Essas ontologias são fundamentais para a representação e análise de dados em estudos de imunologia e imunopatologia, permitindo a integração de dados de diferentes fontes e a compreensão de Mecanismos moleculares envolvidos na resposta imune. Integrar ontologias na área de imunologia e imunopatologia pode seem uma tarefa complexa, mas, com a ajuda da ontologia e de ferramentas de knowledge graphs, é possível criar uma estrutura que comporte os conceitos semânticos essenciais para a realização de pesquisas científicas em imunologia e imunopatologia.\n",
    "\n",
    "A seguir, vamos apresentar uma abordagem geral para integrar as principais ontologias na área de imunologia e imunopatologia:\n",
    "\n",
    "\"Seleçionar Ontologias\": \"Primeiramente, é necessário selecionar as ontologias mais relevantes para a área de imunologia e imunopatologia. Algumas das ontologias mais importantes incluem BIO, MED e IMM\"\n",
    "\t\"Ontologia de Biologia (BIO)\": \"para descrever conceitos biológicos e biotecnológicos.\"\n",
    "\t\"Ontologia de Medicina (MED)\": \"para descrever conceitos médicos e relacionados à saúde.\"\n",
    "\t\"Ontologia de Imunologia (IMM)\": \"para descrever conceitos específicos da imunologia.\"\n",
    "\n",
    "\"Identificar Conceitos\": \"Em seguida, é necessário identificar os conceitos semânticos mais importantes para a área de imunologia e imunopatologia. Algumas das áreas mais relevantes incluem\"\n",
    "\t\"Células imunócelulas (linfócitos, macrófagos, etc.)\"\n",
    "\t\"Proteínas imunológicas (antígenos, antigênicos, etc.)\"\n",
    "\t\"Mecanismos de respostas imunológicas (resposta inflamatória crônica, etc.)\"\n",
    "\t\"Doenças imunopatológias (artrite reumatoide, doença de Lyme, etc.)\"\n",
    "\n",
    "\"Elaborar Estrutura de Ontologia\": \"A estrutura de ontologia deve ser projetada para representar a relação entre os conceitos identificados. Isso pode ser feito utilizando um modelo de ontologia como o OWL (Web Ontology Language). Algumas das principais características da estrutura de ontologia incluem\"\n",
    "\t\"Classes\": \"representam os conceitos mais abrangentes (por exemplo, Imunócito ou Proteína Imunológica).\"\n",
    "\t\"Propriedades\" :\"representam as relações entre as classes (por exemplo, 'é um tipo de Imunócito' ou 'é relacionado à doença de Lyme').\n",
    "\t\"Instâncias\": \"representam os objetos específicos (por exemplo, 'CD4' é um tipo de Imunócito).\"\n",
    "\n",
    "\"Integrar Plataformas de Ciência\": \"Para integrar as ontologias nas plataformas de ciência, é necessário utilizar ferramentas e linguagens de programação que suportem a ontologia, como o Python com bibliotecas como GraphDB ou Apache Jena. Além disso, é possível desenvolver aplicativos que integrem as ontologias com outras fontes de dados, como base de dados de projetos de Pesquisa e Bancos de dados de Imunologia.\"\n",
    "\n",
    "\"Manuter, Atualizar e Evoluir\": \"É fundamental manter e atualizar a ontologia ao longo do tempo para refletir mudanças nas diretrizes de nomenclatura, novas descobertas científicas e mudanças na denominação de doenças e tratamentos.\"\n",
    "\n",
    "Integrar ontologias para representar os conceitos semânticos essenciais da imunologia e imunopatologia é um passo fundamental para a realização de pesquisas científicas em áreas específicas. Através da seleção de ontologias relevantes, identificação de conceitos, elaboração de estruturas de ontologia e integração nas plataformas de ciência, é possível criar uma ferramenta poderosa para a comunidade científica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install jupyter_contrib_nbextensions\n",
    "# %jupyter contrib nbextension install --user\n",
    "# %jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "# %jupyter nbextension enable mermaid --py --sys-prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Síntese da arquitetura\n",
    "\n",
    "    Integração de ontologias em Grafo de Conhecimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR\n",
    "    subgraph Camada de Domínio\n",
    "        Ontology[Ontology]\n",
    "        Article[Article]\n",
    "        Route[Route]\n",
    "    end\n",
    "\n",
    "    subgraph Camada de Aplicação\n",
    "        NLP[NLP]\n",
    "        GraphKnowledge[Graph Knowledge]\n",
    "        MachineLearning[Machine Learning]\n",
    "        Recommendation[Recommendation]\n",
    "    end\n",
    "\n",
    "    subgraph Camada de Infraestrutura\n",
    "        Persistence[Persistence]\n",
    "        UI[UI]\n",
    "    end\n",
    "\n",
    "    Ontology --> GraphKnowledge\n",
    "    Article --> NLP\n",
    "    Article --> GraphKnowledge\n",
    "    NLP --> GraphKnowledge\n",
    "    GraphKnowledge --> MachineLearning\n",
    "    MachineLearning --> Recommendation\n",
    "    Recommendation --> Route\n",
    "    Persistence --> GraphKnowledge\n",
    "    Persistence --> MachineLearning\n",
    "    UI --> NLP\n",
    "    Route --> UI    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "classDiagram\n",
    "    class Ontology {\n",
    "        -ontologies: List<OntologyConcept>\n",
    "        +addOntologyConcept(concept: OntologyConcept): void\n",
    "        +getOntologyConcepts(): List<OntologyConcept>\n",
    "        +getOntologyConceptByName(name: string): OntologyConcept\n",
    "    }\n",
    "\n",
    "    class OntologyConcept {\n",
    "        -name: string\n",
    "        -description: string\n",
    "        -relationships: List<OntologyRelationship>\n",
    "        +getName(): string\n",
    "        +getDescription(): string\n",
    "        +getRelationships(): List<OntologyRelationship>\n",
    "    }\n",
    "\n",
    "    class OntologyRelationship {\n",
    "        -source: OntologyConcept\n",
    "        -target: OntologyConcept\n",
    "        -type: string\n",
    "        +getSource(): OntologyConcept\n",
    "        +getTarget(): OntologyConcept\n",
    "        +getType(): string\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "classDiagram\n",
    "    class Article {\n",
    "        -title: string\n",
    "        -abstract: string\n",
    "        -authors: List<string>\n",
    "        -publicationDate: Date\n",
    "        -entities: List<Entity>\n",
    "        -relationships: List<Relationship>\n",
    "        +getTitle(): string\n",
    "        +getAbstract(): string\n",
    "        +getAuthors(): List<string>\n",
    "        +getPublicationDate(): Date\n",
    "        +getEntities(): List<Entity>\n",
    "        +getRelationships(): List<Relationship>\n",
    "    }\n",
    "\n",
    "    class Entity {\n",
    "        -name: string\n",
    "        -type: string\n",
    "        +getName(): string\n",
    "        +getType(): string\n",
    "    }\n",
    "\n",
    "    class Relationship {\n",
    "        -source: Entity\n",
    "        -target: Entity\n",
    "        -type: string\n",
    "        +getSource(): Entity\n",
    "        +getTarget(): Entity\n",
    "        +getType(): string\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "classDiagram\n",
    "    class Route {\n",
    "        -steps: List<Step>\n",
    "        -technologies: List<Technology>\n",
    "        -applications: List<string>\n",
    "        +getSteps(): List<Step>\n",
    "        +getTechnologies(): List<Technology>\n",
    "        +getApplications(): List<string>\n",
    "    }\n",
    "\n",
    "    class Step {\n",
    "        -description: string\n",
    "        -entities: List<Entity>\n",
    "        +getDescription(): string\n",
    "        +getEntities(): List<Entity>\n",
    "    }\n",
    "\n",
    "    class Technology {\n",
    "        -name: string\n",
    "        -description: string\n",
    "        +getName(): string\n",
    "        +getDescription(): string\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01_nosCNPq.png',\n",
       " 'aplications_cml_diagram',\n",
       " 'aplications_cml_diagram.png',\n",
       " 'aplications_gml_diagram',\n",
       " 'aplications_gml_diagram.png',\n",
       " 'azure_architecture_diagram.png',\n",
       " 'bpmn',\n",
       " 'cadeia_valor_processos_n00.png',\n",
       " 'cadeia_valor_processos_n01.png',\n",
       " 'detailed_ml_pipeline_architecture_diagram.png',\n",
       " 'diagram5x5',\n",
       " 'diagram5x5.png',\n",
       " 'diagram_procurement.gv',\n",
       " 'diagram_procurement.gv.pdf',\n",
       " 'gml_architecture.png',\n",
       " 'gml_simplified_architecture_diagram.png',\n",
       " 'gml_simplified_architecture_diagram_azure.png',\n",
       " 'PRISMA_01.gv',\n",
       " 'PRISMA_01.pdf',\n",
       " 'prisma_flowchart.png',\n",
       " 'prisma_simple_flowchart.png',\n",
       " 'recomendar_rotas_tecnológicas.png',\n",
       " 'simple_prisma_diagram.png',\n",
       " 'simple_prisma_flowchart.png']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "filepath = os.path.join('source','adapters','input','jupyter_notebooks','diagrams')\n",
    "os.chmod(filepath, 0o755)  # Set permissions to rwxr-xr-x\n",
    "os.listdir(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'source\\\\adapters\\\\input\\\\jupyter_notebooks\\\\diagrams'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# https://diagrams.mingrammer.com/docs/nodes/programming\u001b[39;00m\n\u001b[0;32m     26\u001b[0m filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madapters\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjupyter_notebooks\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiagrams\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Diagram(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecomendar Rotas Tecnológicas\u001b[39m\u001b[38;5;124m\"\u001b[39m, show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTB\u001b[39m\u001b[38;5;124m\"\u001b[39m, node_attr\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplaintext\u001b[39m\u001b[38;5;124m\"\u001b[39m}, filename\u001b[38;5;241m=\u001b[39mfilepath) \u001b[38;5;28;01mas\u001b[39;00m diag:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Cluster(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAMADA DE DOMÍNIO\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     29\u001b[0m         article \u001b[38;5;241m=\u001b[39m Dcat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArticle\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n",
      "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\Lib\\site-packages\\diagrams\\__init__.py:164\u001b[0m, in \u001b[0;36mDiagram.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# Remove the graphviz file leaving only the image.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename)\n",
      "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\Lib\\site-packages\\diagrams\\__init__.py:198\u001b[0m, in \u001b[0;36mDiagram.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdot\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mone_format, view\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow, quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdot\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutformat, view\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow, quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\Lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\Lib\\site-packages\\graphviz\\rendering.py:118\u001b[0m, in \u001b[0;36mRender.render\u001b[1;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outfile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_filepath(outfile)\n\u001b[1;32m--> 118\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(filename, directory\u001b[38;5;241m=\u001b[39mdirectory, skip_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    120\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(filepath)\n\u001b[0;32m    122\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\Lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\marco\\anaconda3\\Lib\\site-packages\\graphviz\\saving.py:79\u001b[0m, in \u001b[0;36mSave.save\u001b[1;34m(self, filename, directory, skip_existing)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mkdirs(filepath)\n\u001b[0;32m     78\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite lines to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, filepath)\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding) \u001b[38;5;28;01mas\u001b[39;00m fd:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m uline \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m     81\u001b[0m         fd\u001b[38;5;241m.\u001b[39mwrite(uline)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'source\\\\adapters\\\\input\\\\jupyter_notebooks\\\\diagrams'"
     ]
    }
   ],
   "source": [
    "from diagrams import Cluster, Diagram\n",
    "from diagrams.custom import Custom\n",
    "from diagrams.oci.compute import OKE\n",
    "from diagrams.oci.storage import DataTransfer\n",
    "from diagrams.oci.governance import Compartments, Audit\n",
    "from diagrams.oci.connectivity import CustomerDatacenter, NATGateway\n",
    "from diagrams.oci.database import BigdataService, DatabaseService, Dcat\n",
    "from diagrams.oci.monitoring import HealthCheck, Queue, Workflow, Search\n",
    "from diagrams.onprem.inmemory import Redis\n",
    "from diagrams.generic.os import Windows\n",
    "from diagrams.generic.storage import Storage\n",
    "from diagrams.generic.compute import Rack\n",
    "from diagrams.generic.place import Datacenter\n",
    "from diagrams.generic.device import Mobile, Tablet\n",
    "from diagrams.aws.general import User, Toolkit\n",
    "from diagrams.aws.compute import ECS, EKS, Lambda\n",
    "from diagrams.aws.cost import CostExplorer\n",
    "from diagrams.aws.ml import SagemakerModel, DeepLearningAmis\n",
    "from diagrams.aws.storage import ElasticFileSystemEFSFileSystem\n",
    "from diagrams.aws.database import RedshiftDenseComputeNode as KnowledgeGraph, DynamodbAttributes as Ontology\n",
    "from diagrams.programming.language import Python, NodeJS\n",
    "from diagrams.programming.framework import React, Flask, GraphQL\n",
    "from diagrams.programming.flowchart import MultipleDocuments\n",
    "# https://diagrams.mingrammer.com/docs/nodes/programming\n",
    "\n",
    "filepath = os.path.join('source','adapters','input','jupyter_notebooks','diagrams')\n",
    "with Diagram(\"Recomendar Rotas Tecnológicas\", show=False, direction=\"TB\", node_attr={\"shape\": \"plaintext\"}, filename=filepath) as diag:\n",
    "    with Cluster(\"CAMADA DE DOMÍNIO\"):\n",
    "        article = Dcat(\"Article\")  \n",
    "        entity = Storage(\"Entity\")\n",
    "        \n",
    "        with Cluster(\"Módulo Semântico\"):\n",
    "            ontology = Search(\"Ontology\")\n",
    "            concept = BigdataService(\"Concept\")\n",
    "            relationship = DatabaseService(\"Relationship\")\n",
    "\n",
    "        with Cluster(\"Módulo Rota Tecnológica\"):\n",
    "            route = Workflow(\"Route\")\n",
    "            step = Queue(\"Step\")\n",
    "            technology = Toolkit(\"Technology\")\n",
    "        with Cluster(\"Módulo CEIS\"):\n",
    "            ceis = Datacenter(\"CEIS\")\n",
    "            competence = CustomerDatacenter(\"Competence\")\n",
    "            objective = HealthCheck(\"Objective\")\n",
    "            platform = OKE(\"Platform\")\n",
    "            product = Compartments(\"Product\")\n",
    "\n",
    "    with Cluster(\"CAMADA DE APLICAÇÃO\"):\n",
    "        nlp = Python(\"NLP\")\n",
    "        with Cluster(\"Módulo GML\"):\n",
    "            graph_knowledge = DeepLearningAmis(\"Graph Knowledge\", width=\"1.5\") \n",
    "            machine_learning = SagemakerModel(\"Machine Learning\", width=\"1.5\")\n",
    "        recommendation = Audit(\"Recommendation\")\n",
    "        integration = CostExplorer(\"Integration\")\n",
    "\n",
    "    with Cluster(\"CAMADA DE INFRAESTRUTURA\"):\n",
    "        persistence = Python(\"Persistence\")\n",
    "        ui = NodeJS(\"UI\")\n",
    "\n",
    "    user = User(\"Usuários\")\n",
    "\n",
    "    ontology >> graph_knowledge\n",
    "    ontology >> concept\n",
    "    ontology >> relationship\n",
    "    concept >> graph_knowledge\n",
    "    relationship >> graph_knowledge\n",
    "    article >> nlp\n",
    "    article >> entity\n",
    "    article >> graph_knowledge\n",
    "    entity >> graph_knowledge\n",
    "    nlp >> graph_knowledge\n",
    "    nlp >> entity\n",
    "    nlp >> relationship\n",
    "    graph_knowledge >> machine_learning\n",
    "    machine_learning >> recommendation\n",
    "    machine_learning >> competence\n",
    "    machine_learning >> objective\n",
    "    machine_learning >> platform\n",
    "    machine_learning >> product\n",
    "    recommendation >> ui\n",
    "    recommendation >> machine_learning\n",
    "    integration >> graph_knowledge\n",
    "    integration >> ontology\n",
    "    integration >> article\n",
    "    integration >> ceis\n",
    "    persistence >> graph_knowledge\n",
    "    persistence >> machine_learning\n",
    "    ui >> nlp\n",
    "    ceis >> competence\n",
    "    ceis >> objective\n",
    "    ceis >> platform\n",
    "    ceis >> product\n",
    "    competence >> recommendation\n",
    "    objective >> recommendation\n",
    "    platform >> recommendation\n",
    "    product >> recommendation\n",
    "\n",
    "    route >> step\n",
    "    route >> technology\n",
    "    step >> entity\n",
    "    technology >> graph_knowledge\n",
    "\n",
    "    ui >> user\n",
    "    user >> ui\n",
    "\n",
    "diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip show diagrams\n",
    "# %pip install --upgrade diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detalhamento da interação entre módulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR\n",
    "    subgraph Camada de Domínio\n",
    "        Ontology[Ontology]\n",
    "        Concept[Concept]\n",
    "        Relationship[Relationship]\n",
    "        Article[Article]\n",
    "        Entity[Entity]\n",
    "        Route[Route]\n",
    "        Step[Step]\n",
    "        Technology[Technology]\n",
    "        CEIS[CEIS]\n",
    "        Competence[Competence]\n",
    "        Objective[Objective]\n",
    "        Platform[Platform]\n",
    "        Product[Product]\n",
    "    end\n",
    "\n",
    "    subgraph Camada de Aplicação\n",
    "        NLP[NLP]\n",
    "        GraphKnowledge[Graph Knowledge]\n",
    "        MachineLearning[Machine Learning]\n",
    "        Recommendation[Recommendation]\n",
    "        Integration[Integration]\n",
    "    end\n",
    "\n",
    "    subgraph Camada de Infraestrutura\n",
    "        Persistence[Persistence]\n",
    "        UI[UI]\n",
    "    end\n",
    "\n",
    "    Ontology --> GraphKnowledge\n",
    "    Ontology --> Concept\n",
    "    Ontology --> Relationship\n",
    "    Concept --> GraphKnowledge\n",
    "    Relationship --> GraphKnowledge\n",
    "    Article --> NLP\n",
    "    Article --> Entity\n",
    "    Article --> GraphKnowledge\n",
    "    Entity --> GraphKnowledge\n",
    "    NLP --> GraphKnowledge\n",
    "    NLP --> Entity\n",
    "    NLP --> Relationship\n",
    "    GraphKnowledge --> MachineLearning\n",
    "    MachineLearning --> Recommendation\n",
    "    MachineLearning --> Competence\n",
    "    MachineLearning --> Objective\n",
    "    MachineLearning --> Platform\n",
    "    MachineLearning --> Product\n",
    "    Recommendation --> UI\n",
    "    Integration --> GraphKnowledge\n",
    "    Integration --> Ontology\n",
    "    Integration --> Article\n",
    "    Integration --> CEIS\n",
    "    Persistence --> GraphKnowledge\n",
    "    Persistence --> MachineLearning\n",
    "    UI --> NLP\n",
    "    CEIS --> Competence\n",
    "    CEIS --> Objective\n",
    "    CEIS --> Platform\n",
    "    CEIS --> Product\n",
    "    Competence --> Recommendation\n",
    "    Objective --> Recommendation\n",
    "    Platform --> Recommendation\n",
    "    Product --> Recommendation\n",
    "\n",
    "    Route --> Step\n",
    "    Route --> Technology\n",
    "    Step --> Entity\n",
    "    Technology --> GraphKnowledge \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "classDiagram\n",
    "    Ontology <|-- Concept\n",
    "    Ontology <|-- Relationship\n",
    "\n",
    "    class Ontology {\n",
    "        -ontologies: List<OntologyConcept>\n",
    "        +addOntologyConcept(concept: OntologyConcept): void\n",
    "        +getOntologyConcepts(): List<OntologyConcept>\n",
    "        +getOntologyConceptByName(name: string): OntologyConcept\n",
    "        +getRelationships(): List<OntologyRelationship>\n",
    "        +getRelationshipsByType(type: string): List<OntologyRelationship>\n",
    "        +findRelatedConcepts(concept: OntologyConcept): List<OntologyConcept>\n",
    "    }\n",
    "\n",
    "    class OntologyConcept {\n",
    "        -id: string\n",
    "        -name: string\n",
    "        -description: string\n",
    "        -synonyms: List<string>\n",
    "        -relationships: List<OntologyRelationship>\n",
    "        +getId(): string\n",
    "        +getName(): string\n",
    "        +getDescription(): string\n",
    "        +getSynonyms(): List<string>\n",
    "        +getRelationships(): List<OntologyRelationship>\n",
    "        +getRelationshipsByType(type: string): List<OntologyRelationship>\n",
    "    }\n",
    "\n",
    "    class OntologyRelationship {\n",
    "        -id: string\n",
    "        -source: OntologyConcept\n",
    "        -target: OntologyConcept\n",
    "        -type: string\n",
    "        +getId(): string\n",
    "        +getSource(): OntologyConcept\n",
    "        +getTarget(): OntologyConcept\n",
    "        +getType(): string\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "classDiagram\n",
    "    Article <|-- Entity\n",
    "\n",
    "    class Article {\n",
    "        -id: string\n",
    "        -title: string\n",
    "        -abstract: string\n",
    "        -authors: List<string>\n",
    "        -publicationDate: Date\n",
    "        -entities: List<Entity>\n",
    "        -relationships: List<Relationship>\n",
    "        +getId(): string\n",
    "        +getTitle(): string\n",
    "        +getAbstract(): string\n",
    "        +getAuthors(): List<string>\n",
    "        +getPublicationDate(): Date\n",
    "        +getEntities(): List<Entity>\n",
    "        +getRelationships(): List<Relationship>\n",
    "        +addEntity(entity: Entity): void\n",
    "        +addRelationship(relationship: Relationship): void\n",
    "    }\n",
    "\n",
    "    class Entity {\n",
    "        -id: string\n",
    "        -name: string\n",
    "        -type: string\n",
    "        -ontologyConcept: OntologyConcept\n",
    "        +getId(): string\n",
    "        +getName(): string\n",
    "        +getType(): string\n",
    "        +getOntologyConcept(): OntologyConcept\n",
    "    }\n",
    "\n",
    "    class Relationship {\n",
    "        -id: string\n",
    "        -source: Entity\n",
    "        -target: Entity\n",
    "        -type: string\n",
    "        -ontologyRelationship: OntologyRelationship\n",
    "        +getId(): string\n",
    "        +getSource(): Entity\n",
    "        +getTarget(): Entity\n",
    "        +getType(): string\n",
    "        +getOntologyRelationship(): OntologyRelationship\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "classDiagram\n",
    "\n",
    "    CEIS <|-- Competence\n",
    "    CEIS <|-- Objective\n",
    "    CEIS <|-- Platform\n",
    "    CEIS <|-- Product\n",
    "\n",
    "    class CEIS {\n",
    "        -competences: List<Competence>\n",
    "        -objectives: List<Objective>\n",
    "        -platforms: List<Platform>\n",
    "        -products: List<Product>\n",
    "        +addCompetence(competence: Competence): void\n",
    "        +getCompetences(): List<Competence>\n",
    "        +addObjective(objective: Objective): void\n",
    "        +getObjectives(): List<Objective>\n",
    "        +addPlatform(platform: Platform): void\n",
    "        +getPlatforms(): List<Platform>\n",
    "        +addProduct(product: Product): void\n",
    "        +getProducts(): List<Product>\n",
    "    }\n",
    "\n",
    "    class Competence {\n",
    "        -id: string\n",
    "        -name: string\n",
    "        -description: string\n",
    "        +getId(): string\n",
    "        +getName(): string\n",
    "        +getDescription(): string\n",
    "    }\n",
    "\n",
    "    class Objective {\n",
    "        -id: string\n",
    "        -name: string\n",
    "        -description: string\n",
    "        +getId(): string\n",
    "        +getName(): string\n",
    "        +getDescription(): string\n",
    "    }\n",
    "\n",
    "    class Platform {\n",
    "        -id: string\n",
    "        -name: string\n",
    "        -description: string\n",
    "        +getId(): string\n",
    "        +getName(): string\n",
    "        +getDescription(): string\n",
    "    }\n",
    "\n",
    "    class Product {\n",
    "        -id: string\n",
    "        -name: string\n",
    "        -description: string\n",
    "        +getId(): string\n",
    "        +getName(): string\n",
    "        +getDescription(): string\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "classDiagram\n",
    "    Route <|-- Step\n",
    "    Route <|-- Technology\n",
    "\n",
    "    class Route {\n",
    "        -id: string\n",
    "        -steps: List<Step>\n",
    "        -technologies: List<Technology>\n",
    "        -applications: List<string>\n",
    "        +getId(): string\n",
    "        +getSteps(): List<Step>\n",
    "        +getTechnologies(): List<Technology>\n",
    "        +getApplications(): List<string>\n",
    "        +addStep(step: Step): void\n",
    "        +addTechnology(technology: Technology): void\n",
    "    }\n",
    "\n",
    "    class Step {\n",
    "        -id: string\n",
    "        -description: string\n",
    "        -entities: List<Entity>\n",
    "        +getId(): string\n",
    "        +getDescription(): string\n",
    "        +getEntities(): List<Entity>\n",
    "        +addEntity(entity: Entity): void\n",
    "    }\n",
    "\n",
    "    class Technology {\n",
    "        -id: string\n",
    "        -name: string\n",
    "        -description: string\n",
    "        -ontologyConcept: OntologyConcept\n",
    "        +getId(): string\n",
    "        +getName(): string\n",
    "        +getDescription(): string\n",
    "        +getOntologyConcept(): OntologyConcept\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O diagrama apresenta a arquitetura proposta, onde algumas relações podem ser destacadas para maior clareza e precisão:\n",
    "\n",
    "### Módulo de Integração:\n",
    "A seta de Integration para Graph Knowledge indica que a integração alimenta o grafo com dados externos, bem como conecta a Ontology, Article, e CEIS, já que extrai informações desses domínios para integrá-las ao grafo.\n",
    "NLP (Processamento de Linguagem Natural). Já as setas de Article e UI para NLP indicam que o NLP processa dados de artigos e interage com a interface do usuário, e NLP também, se conecta a Entity e Relationship, por extrair essas informações dos artigos.\n",
    "\n",
    "### Módulo de Graph Knowledge:\n",
    "As setas de Ontology, Concept, Relationship, Article, Entity, Technology e Integration para Graph Knowledge estão corretas, mostrando que o grafo armazena informações de todas essas fontes.\n",
    "\n",
    "### Módulo de Machine Learning:\n",
    "As setas de Graph Knowledge e Persistence para Machine Learning indicam que o aprendizado de máquina utiliza dados do grafo e do armazenamento persistente, e se conectar a Competence, Objective, Platform e Product do domínio CEIS, pois o aprendizado de máquina usa essas informações para modelar as recomendações.\n",
    "\n",
    "### Módulo de Recommendation:\n",
    "As setas de Machine Learning, Competence, Objective, Platform e Product para Recommendation estão corretas, mostrando que a recomendação é baseada em aprendizado de máquina e nas informações do CEIS.\n",
    "\n",
    "### UI (Interface do Usuário): \n",
    "A seta de Recommendation para UI está correta, indicando que a interface exibe as recomendações.\n",
    "A seta de UI para NLP também está correta, representando a interação do usuário com o sistema através de linguagem natural.\n",
    "\n",
    "### Persistência: \n",
    "A seta de Persistence para Graph Knowledge está correta, mas também poderia haver uma seta para Machine Learning, já que alguns modelos podem precisar armazenar dados persistentes (como checkpoints de treinamento).\n",
    "\n",
    "### Domínio CEIS: \n",
    "As setas dentro do domínio CEIS estão corretas, representando as relações entre competências, objetivos, plataformas e produtos.\n",
    "\n",
    "### Obs.: \n",
    "Bidirecionalidade: Algumas setas poderiam ser bidirecionais, como entre Graph Knowledge e Machine Learning, para indicar que o aprendizado de máquina não apenas utiliza dados do grafo, mas também pode atualizar o grafo com novos conhecimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_graph_maker import GraphMaker, Ontology, GroqClient, OpenAIClient\n",
    "from knowledge_graph_maker import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrating main REAL ontologies in a knowledge graph to encompass the semantics concepts in scientific technology platforms for carrying out scientific research questions in immunology and immunopathology is a complex task that requires a clear understanding of the real-world domain, the ontologies, and the knowledge graph architecture. Here's a suggested approach:\n",
      "\n",
      "**Choose the relevant ontologies:**\n",
      "\n",
      "1. **SNOMED-CT** (Systematized Nomenclature of Medicine – Clinical Terms): a comprehensive ontology for biomedical concepts, including immunology and immunopathology.\n",
      "2. **MeSH** (Medical Subject Headings): a thesaurus for medical topics, including immunology and immunopathology.\n",
      "3. **NCI Thesaurus** (National Cancer Institute Thesaurus): a controlled vocabulary for cancer research, including immunology and immunopathology.\n",
      "4. **HO** (Human Ontology): a comprehensive ontology for human biology, including immunology and immunopathology.\n",
      "\n",
      "**Integrate the ontologies:**\n",
      "\n",
      "1. **Merge the ontologies**: Combine the ontologies by mapping their concepts, relationships, and semantics. Use tools like Semantic Web technologies (e.g., OWL, RDF, SPARQL) to integrate the ontologies.\n",
      "2. **Resolve conflicts and ambiguities**: Address conflicting concepts, synonyms, and ambiguous labels between the ontologies. Use manual curation, automated algorithms, or a combination of both to resolve these issues.\n",
      "3. **Create a unified vocabulary**: Establish a unified vocabulary by reconciling the different termologies and concepts across the ontologies. This will facilitate seamless communication and querying across the integrated ontology.\n",
      "\n",
      "**Create the knowledge graph:**\n",
      "\n",
      "1. **Define the entities and relationships**: Identify the key entities and relationships in immunology and immunopathology, such as diseases, cells, genes, proteins, pathways, and interactions.\n",
      "2. **Map the concepts to the integrated ontology**: Associate the entities and relationships with the integrated ontology, using properties like \"part of,\" \"has part,\" \"is a,\" and \"has property.\"\n",
      "3. **Incorporate evidence and data sources**: Integrate relevant data sources, such as publishing databases, clinical trials, and literature, to support the knowledge graph.\n",
      "4. **Incorporate computational models and simulations**: Incorporate computational models and simulations to represent complex biological processes, such as disease progression and immune response.\n",
      "\n",
      "**Query and analyze the knowledge graph:**\n",
      "\n",
      "1. **Develop querying and analysis tools**: Design querying and analysis tools to facilitate exploration of the knowledge graph, such as SPARQL queries, graph algorithms, and visualization tools.\n",
      "2. **Use the knowledge graph for scientific research**: Apply the integrated ontologies and knowledge graph to answer scientific research questions in immunology and immunopathology, such as identifying genetic associations with diseases or predicting treatment outcomes.\n",
      "\n",
      "**Challenges and future directions:**\n",
      "\n",
      "1. **Interoperability and standardization**: Standardize terminology and formats to ensure seamless integration and querying across the knowledge graph.\n",
      "2. **Scalability and performance**: Ensure the knowledge graph can efficiently handle large amounts of data and queries.\n",
      "3. **Update and maintenance**: Continuously update and maintain the knowledge graph to reflect new research findings, disease understanding, and methodological advancements.\n",
      "\n",
      "By following these steps, you can integrate main REAL ontologies to create a comprehensive knowledge graph for carrying out scientific research questions in immunology and immunopathology.\n"
     ]
    }
   ],
   "source": [
    "immunology_graph_ontologies = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How integrate in a knowledge graph the main REAL ontologies to encompass the semantics concepts in scientific technology platforms for carrying out scientific research questions in immunology and immunopathology? Escreva a resposta em português do Brasil\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(immunology_graph_ontologies.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para integrar as principais ontologias reais em um grafo de conhecimento para abranger os conceitos semânticos em plataformas de tecnologia científica para realizar perguntas de pesquisa científica em imunologia e imunopatologia, é necessário seguir os seguintes passos:\n",
      "\n",
      "1. **Identificar as ontologias relevantes**: É importante identificar as principais ontologias reais em imunologia e imunopatologia, como:\n",
      "\t* Ontologia de Doenças (Disease Ontology, DOID)\n",
      "\t* Ontologia de Genômica e Proteômica (Gene Ontology, GO)\n",
      "\t* Ontologia de Anatomia (Anatomy Ontology, Uberon)\n",
      "\t* Ontologia de Patologia (Pathology Ontology, PATO)\n",
      "\t* Ontologia de Imunologia (Immunology Ontology, IEDB)\n",
      "2. **Selecionar as ontologias mais relevantes**: Selecionar as ontologias mais relevantes para o domínio de imunologia e imunopatologia, considerando a sua abrangência, precisão e importância.\n",
      "3. **Criar um grafo de conhecimento**: Criar um grafo de conhecimento que integre as ontologias selecionadas, utilizando tecnologias como RDF (Resource Description Framework) e OWL (Web Ontology Language).\n",
      "4. **Mapear as ontologias**: Mapear as ontologias selecionadas para o grafo de conhecimento, garantindo que os conceitos semânticos sejam correlacionados corretamente.\n",
      "5. **Adicionar recursos adicionais**: Adicionar recursos adicionais, como artigos científicos, dados de experimentos e outros dados relevantes, para enriquecer o grafo de conhecimento.\n",
      "6. **Definir regras de inferência**: Definir regras de inferência para permitir que o grafo de conhecimento faça deduções e relacione conceitos semânticos de forma eficaz.\n",
      "7. **Testar e refinar o grafo de conhecimento**: Testar o grafo de conhecimento com perguntas de pesquisa científica em imunologia e imunopatologia e refinar o modelo à medida que necessário.\n",
      "\n",
      "Alguns exemplos de plataformas que podem ser utilizadas para criar e gerenciar o grafo de conhecimento incluem:\n",
      "\n",
      "* Apache Jena\n",
      "* GraphDB\n",
      "* Stardog\n",
      "* Amazon Neptune\n",
      "\n",
      "Alguns recursos online que podem ser úteis para integrar ontologias incluem:\n",
      "\n",
      "* Ontology Lookup Service (OLS)\n",
      "* Open Biomedical Ontologies (OBO)\n",
      "* BioPortal\n",
      "\n",
      "É importante mencionar que a integração de ontologias em um grafo de conhecimento é um processo complexo que requer conhecimentos em ontologia, inteligência artificial, ciência de dados e conhecimento do domínio. É recomendável trabalhar com uma equipe interdisciplinar para garantir a qualidade e a consistência do grafo de conhecimento.\n"
     ]
    }
   ],
   "source": [
    "immunology_graph_ontologies = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How integrate in a knowledge graph the main REAL ontologies to encompass the semantics concepts in scientific technology platforms for carrying out scientific research questions in immunology and immunopathology? Escreva a resposta em português do Brasil\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\",\n",
    ")\n",
    "\n",
    "print(immunology_graph_ontologies.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir a ontologia.\n",
    "\n",
    "A ontologia é um modelo formatado com o seguinte esquema.\n",
    "\n",
    "```python\n",
    "class Ontology(BaseModel):\n",
    "    label: List[Union[str, Dict]]\n",
    "    relationships: List[str]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por exemplo, vamos usar resumos dos livros LOTR da página da Wikipedia. Copiei-o para um arquivo para facilitar a importação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lotr_wikipedia_summary import lord_of_the_rings_wikipedia_summary as example_text_list\n",
    "# len(example_text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui está a ontologia que usaremos para os resumos do LOTR ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llama3-70b-8192'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str() argument 2 must be str, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Union, Dict\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOntology\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama3-70b-8192\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      3\u001b[0m     label: List[Union[\u001b[38;5;28mstr\u001b[39m, Dict]]\n\u001b[0;32m      4\u001b[0m     relationships: List[\u001b[38;5;28mstr\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: str() argument 2 must be str, not tuple"
     ]
    }
   ],
   "source": [
    "from typing import List, Union, Dict\n",
    "BaseModel='llama3-70b-8192'\n",
    "class Ontology(BaseModel):\n",
    "    label: List[Union[str, Dict]]\n",
    "    relationships: List[str]\n",
    "\n",
    "ontology = Ontology(\n",
    "    labels=[\n",
    "        {\"Person\": \"Person name without any adjectives, Remember a person may be referenced by their name or using a pronoun\"},\n",
    "        {\"Object\": \"Do not add the definite article 'the' in the object name\"},\n",
    "        {\"Event\": \"Event event involving multiple people. Do not include qualifiers or verbs like gives, leaves, works etc.\"},\n",
    "        \"Place\",\n",
    "        \"Document\",\n",
    "        \"Organisation\",\n",
    "        \"Action\",\n",
    "        {\"Miscellaneous\": \"Any important concept can not be categorised with any other given label\"},\n",
    "    ],\n",
    "    relationships=[\n",
    "        \"Relation between any pair of Entities\"\n",
    "        ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a Model\n",
    "\n",
    "Groq support the following models at present. \n",
    "\n",
    "*LLaMA3 8b*\n",
    "Model ID: llama3-8b-8192\n",
    "\n",
    "*LLaMA3 70b*\n",
    "Model ID: llama3-70b-8192\n",
    "\n",
    "*Mixtral 8x7b*\n",
    "Model ID: mixtral-8x7b-32768\n",
    "\n",
    "*Gemma 7b*\n",
    "Model ID: gemma-7b-it\n",
    "\n",
    "\n",
    "Selecting a model for this example ->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAIClient' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m## Use Groq\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# llm = GroqClient(model=model, temperature=0.1, top_p=0.5)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m## OR Use OpenAI\u001b[39;00m\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3-70b-8192\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 15\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIClient\u001b[49m(model\u001b[38;5;241m=\u001b[39moai_model, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OpenAIClient' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "## Groq models\n",
    "# model = \"mixtral-8x7b-32768\"\n",
    "# model =\"llama3-8b-8192\"\n",
    "model = \"llama3-70b-8192\"\n",
    "# model=\"gemma-7b-it\"\n",
    "\n",
    "## Open AI models\n",
    "oai_model=\"gpt-3.5-turbo\"\n",
    "\n",
    "## Use Groq\n",
    "# llm = GroqClient(model=model, temperature=0.1, top_p=0.5)\n",
    "\n",
    "## OR Use OpenAI\n",
    "model = \"llama3-70b-8192\"\n",
    "llm = OpenAIClient(model=oai_model, temperature=0.1, top_p=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar documentos a partir de blocos de texto.\n",
    "Documents é um modelo com o seguinte esquema\n",
    "\n",
    "```python\n",
    "class Document(BaseModel):\n",
    "    text: str\n",
    "    metadata: dict\n",
    "```\n",
    "\n",
    "Os metadados que adicionamos ao documento aqui são copiados para cada relação extraída do documento. Na maioria das vezes, os pares de nós têm múltiplas relações entre si. Os metadados ajudam a adicionar mais contexto a essas relações\n",
    "\n",
    "Neste exemplo, estou gerando um resumo do bloco de texto e o carimbo de data/hora da execução para ser usado como metadados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str() argument 'encoding' must be str, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m      2\u001b[0m current_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDocument\u001b[39;00m(BaseModel):\n\u001b[0;32m      5\u001b[0m     text: \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m      6\u001b[0m     metadata: \u001b[38;5;28mdict\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: str() argument 'encoding' must be str, not tuple"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_time = str(datetime.datetime.now())\n",
    "\n",
    "class Document(BaseModel):\n",
    "    text: str\n",
    "    metadata: dict\n",
    "\n",
    "graph_maker = GraphMaker(ontology=ontology, llm_client=llm, verbose=False)\n",
    "\n",
    "def generate_summary(text):\n",
    "    SYS_PROMPT = (\n",
    "        \"Succintly summarise the text provided by the user. \"\n",
    "        \"Respond only with the summary and no other comments\"\n",
    "    )\n",
    "    try:\n",
    "        summary = llm.generate(user_message=text, system_message=SYS_PROMPT)\n",
    "    except:\n",
    "        summary = \"\"\n",
    "    finally:\n",
    "        return summary\n",
    "\n",
    "docs = map(\n",
    "    lambda t: Document(text=t, metadata={\"summary\": generate_summary(t), 'generated_at': current_time}),\n",
    "    example_text_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example_text_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m     summary \u001b[38;5;241m=\u001b[39m generate_summary(text)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m: summary, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_at\u001b[39m\u001b[38;5;124m\"\u001b[39m: current_time}\n\u001b[0;32m      6\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m t: Document(text\u001b[38;5;241m=\u001b[39mt, metadata\u001b[38;5;241m=\u001b[39mgenerate_metadata(t)),\n\u001b[1;32m----> 8\u001b[0m     example_text_list,\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'example_text_list' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_metadata(text):\n",
    "    current_time = str(datetime.datetime.now())\n",
    "    summary = generate_summary(text)\n",
    "    return {\"summary\": summary, \"generated_at\": current_time}\n",
    "\n",
    "docs = map(\n",
    "    lambda t: Document(text=t, metadata=generate_metadata(t)),\n",
    "    example_text_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph\n",
    "Finally run the Graph Maker to generate graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_maker.from_documents(\n",
    "    list(docs), \n",
    "    delay_s_between=0 ## delay_s_between because otherwise groq api maxes out pretty fast. \n",
    "    ) \n",
    "print(\"Total number of Edges\", len(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in graph:\n",
    "    print(edge.model_dump(exclude=['metadata']), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Graph to Neo4j "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n",
      "aenter called\n",
      "aexit called\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from knowledge_graph_maker import Neo4jGraphModel\n",
    "\n",
    "create_indices = False\n",
    "neo4j_graph = Neo4jGraphModel(edges=graph, create_indices=create_indices)\n",
    "\n",
    "neo4j_graph.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
