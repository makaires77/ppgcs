{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3510628",
   "metadata": {},
   "source": [
    "# Pasta de origem dos arquivos\n",
    "\n",
    "Salvar o arquivo geral zipado do e-lattes na pasta _data/in_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9b3aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tkinter as tk\n",
    "# from tkinter import filedialog\n",
    "# from file_manipulation import FileManipulation\n",
    "\n",
    "# root = tk.Tk()\n",
    "\n",
    "# # Pergunta ao usuário se ele deseja criar uma nova pasta ou escolher uma já existente\n",
    "# selection = input(\"Digite (N) para criar uma nova pasta ou tecle enter para escolher uma existente\")\n",
    "\n",
    "# # Define a pasta onde serão salvas as análises\n",
    "# if selection.lower() == \"n\":\n",
    "#     folder_path = filedialog.askdirectory(initialdir=\"./\", title=\"Selecione uma pasta\")\n",
    "# else:\n",
    "#     folder_path = \"./analises\"\n",
    "\n",
    "#     # Caso a pasta já exista, avisa o usuário que os arquivos antigos serão substituídos\n",
    "#     if len(os.listdir(folder_path)) > 0:\n",
    "#         confirmation = input(\"\\nAtenção: a pasta selecionada já contém arquivos. Eles serão substituídos. Deseja continuar (S/N)? \")\n",
    "#         if confirmation.lower() != \"s\":\n",
    "#             root.destroy()\n",
    "#             exit()\n",
    "\n",
    "# fm = FileManipulation(master=root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b5e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "class PreparadorDePublicacoes:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.colunas = ['idLattes', 'nome', 'tipo', 'titulo_do_capitulo', 'idioma', 'titulo_do_livro', 'ano', 'doi', 'pais_de_publicacao', 'isbn', 'nome_da_editora', 'numero_da_edicao_revisao', 'organizadores', 'paginas', 'autores', 'autores-endogeno', 'autores-endogeno-nome', 'tags', 'Hash', 'tipo_producao', 'natureza', 'titulo', 'nome_do_evento', 'ano_do_trabalho', 'pais_do_evento', 'cidade_do_evento', 'classificacao', 'periodico', 'volume', 'issn', 'estrato_qualis', 'editora', 'numero_de_paginas', 'numero_de_volumes']\n",
    "\n",
    "    def extrair_dados(self, registro, tipo_producao):\n",
    "        linha = {coluna: None for coluna in self.colunas}\n",
    "        linha['tipo'] = tipo_producao  # Define o tipo de produção com base na chave do dicionário\n",
    "        \n",
    "        # Mapear diretamente os campos do registro para a linha, assegurando que todos os campos desejados sejam extraídos\n",
    "        for campo in ['titulo', 'idioma', 'periodico', 'ano', 'volume', 'issn', 'estrato_qualis', 'pais_de_publicacao', 'paginas', 'doi']:\n",
    "            linha[campo] = registro.get(campo, '')\n",
    "\n",
    "        # Tratar os autores como uma string concatenada se eles existirem\n",
    "        linha['autores'] = '; '.join(registro.get('autores', []))\n",
    "\n",
    "        # Tratar os campos 'autores-endogeno' e 'autores-endogeno-nome'\n",
    "        if 'autores-endogeno' in registro and registro['autores-endogeno']:\n",
    "            id_endogeno = registro['autores-endogeno'][0]\n",
    "            linha['idLattes'] = id_endogeno\n",
    "            linha['nome'] = registro['autores-endogeno-nome'][0].get(id_endogeno, None)\n",
    "        \n",
    "        # Adicionar os outros campos conforme necessário aqui\n",
    "        # Por exemplo, tratamento de 'tags', 'Hash', etc., quando necessário\n",
    "\n",
    "        return linha\n",
    "\n",
    "    def processar_publicacoes(self):\n",
    "        linhas = []\n",
    "        # Itera diretamente sobre cada registro em self.data\n",
    "        for registro in self.data:\n",
    "            linha = self.extrair_dados(registro, registro.get('tipo_producao', 'Desconhecido'))\n",
    "            linhas.append(linha)\n",
    "        return linhas\n",
    "\n",
    "    def exportar_para_csv(self, nome_arquivo='dados_achatados.csv'):\n",
    "        linhas = self.processar_publicacoes()\n",
    "        print(f\"{len(linhas)} linhas processadas...\")\n",
    "        df = pd.DataFrame(linhas, columns=self.colunas)\n",
    "        df.to_csv(nome_arquivo, index=False)\n",
    "        print(f'Arquivo {nome_arquivo} criado com sucesso.')\n",
    "    \n",
    "    def extract_zips(self, pathzip):\n",
    "        destination = os.path.join(os.getcwd(), '_data', 'in_json')\n",
    "        if not os.path.exists(destination):\n",
    "            os.makedirs(destination)\n",
    "            print(f\"Criada pasta para armazenar dados descompactados: {destination}\")\n",
    "        else:\n",
    "            print(f\"Descompactando arquivos para: {destination}\")\n",
    "\n",
    "        with zipfile.ZipFile(pathzip, 'r') as zip_ref:\n",
    "            zip_ref.extractall(destination)\n",
    "        \n",
    "        print(\"Descompactação concluída...\")\n",
    "        return destination  # Retorna o caminho onde os arquivos foram descompactados\n",
    "\n",
    "    def find_and_merge_publication_json_files(self, pathjson):\n",
    "        all_data = []\n",
    "        for filename in os.listdir(pathjson):\n",
    "            if 'publication.json' in filename:\n",
    "                print(f\"Extraindo dados do arquivo '{filename}'...\")\n",
    "                with open(os.path.join(pathjson, filename), 'r', encoding='utf-8') as file:\n",
    "                    file_data = json.load(file)\n",
    "                    for tipo_producao in file_data:  # Para cada tipo de produção no arquivo\n",
    "                        for ano in file_data[tipo_producao]:  # Para cada ano dentro de um tipo de produção\n",
    "                            all_data.extend(file_data[tipo_producao][ano])  # Une os registros\n",
    "\n",
    "        # Salva a lista unificada em um novo arquivo JSON\n",
    "        unified_json_path = os.path.join(pathjson, 'unified_pub.json')\n",
    "        with open(unified_json_path, 'w', encoding='utf-8') as unified_file:\n",
    "            json.dump(all_data, unified_file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        print(f\"Arquivo unificado criado em: {unified_json_path}\")\n",
    "\n",
    "        # Atualiza self.data com os dados unidos\n",
    "        self.data = all_data\n",
    "\n",
    "    def merge_publication_json_files(self, pathjson):\n",
    "        \"\"\"\n",
    "        This function receives a path to a JSON folder, accesses the folder's contents, searches for files\n",
    "        containing 'publication.json' in their filename, merges their contents and saves the resulting\n",
    "        data as a CSV file in destination folder.\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        # Looping through the files in the given path\n",
    "        for filename in os.listdir(pathjson):\n",
    "            if 'publication.json' in filename:\n",
    "                print(f\"Extraindo dados do arquivo {filename}...\")\n",
    "                # Opening the file and appending its data to the list\n",
    "                with open(os.path.join(pathjson, filename), 'r', encoding='utf-8') as file:\n",
    "                    data.append(json.load(file))\n",
    "\n",
    "        # Creating the output directory if it doesn't exist\n",
    "        destination = os.path.join(os.getcwd(), '_data','powerbi')\n",
    "        if not os.path.exists(destination):\n",
    "            os.mkdir(destination)\n",
    "\n",
    "        # Writing the merged data to a CSV file\n",
    "        print(f\"Criando arquivo CSV...\")\n",
    "        with open(os.path.join(destination, 'publication.csv'), 'w', encoding='utf-8', newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            # Writing the header based on the keys of the first item in the list\n",
    "            writer.writerow(data[0].keys())\n",
    "            # Looping through the items in the list and writing them as rows in the CSV file\n",
    "            for item in data:\n",
    "                writer.writerow(item.values())\n",
    "\n",
    "    def exportar_para_csv(self, nome_arquivo='publicacoes.csv'):\n",
    "        linhas = self.processar_publicacoes()\n",
    "        df = pd.DataFrame(linhas, columns=self.colunas)\n",
    "        filepathcsv = os.path.join(\"./\",\"_data\",\"powerbi\",nome_arquivo)\n",
    "        df.to_csv(filepathcsv, index=False)\n",
    "        print(f'Arquivo criado com sucesso em {filepathcsv}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e9d3321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pasta corrente: ./\n",
      "Pasta arquivos JSON: ./_data\\in_json\n",
      " Pasta de dados CSV: ./_data\\powerbi\n",
      "\n",
      "Conteúdo da pasta JSON:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['642.files', '644.files', '863.files.zip']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./\"\n",
    "print(f\"     Pasta corrente: {path}\")\n",
    "pathjson = os.path.join(path,'_data','in_json')\n",
    "print(f\"Pasta arquivos JSON: {pathjson}\")\n",
    "try:\n",
    "    pathdata = os.path.join(path,'_data','powerbi')\n",
    "    print(f\" Pasta de dados CSV: {pathdata}\")\n",
    "except:\n",
    "    print('Pasta de dados ainda não existe.')\n",
    "\n",
    "print(\"\\nConteúdo da pasta JSON:\")\n",
    "list(os.listdir(pathjson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3840c0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descompactando arquivos para: c:\\Users\\marco\\ppgcs\\_data\\in_json\n",
      "Descompactação concluída...\n",
      "Extraindo dados do arquivo '863.publication.json'...\n",
      "Arquivo unificado criado em: ./_data\\in_json\\unified_pub.json\n",
      "Arquivo criado com sucesso em ./_data\\powerbi\\publicacoes.csv.\n"
     ]
    }
   ],
   "source": [
    "## Descompactar arquivo zipado na pasta JSON:\n",
    "preparador = PreparadorDePublicacoes()\n",
    "arquivo_zip = '863.files.zip'\n",
    "pathfilezip = os.path.join(pathjson,arquivo_zip)\n",
    "destination = preparador.extract_zips(pathfilezip)\n",
    "\n",
    "## Unir aquivos de publicações caso haja mais de um:\n",
    "preparador.find_and_merge_publication_json_files(pathjson)\n",
    "\n",
    "## Mapear arquivo de dados para PowerBI a partir do JSON unificado\n",
    "linhas = preparador.processar_publicacoes()\n",
    "preparador.exportar_para_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5d20c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020_Madhumangal-Ghorai_modern-trends-in-fuzzy-graph-theory-1st-ed.odt',\n",
       " 'classificacoes_publicadas_todas_as_areas_avaliacao1672761192111.csv',\n",
       " 'classificações_publicadas_todas_as_areas_avaliacao1672761192111.xlsx',\n",
       " 'colaboracao_discente.csv',\n",
       " 'dashboard_ppggs_v3.pbix',\n",
       " 'dashboard_ppggs_v4.pbix',\n",
       " 'dashboard_ppggs_v5.pbix',\n",
       " 'DAX_ApuraMetas.txt',\n",
       " 'df_dadosartigos.csv',\n",
       " 'lista_docentes.csv',\n",
       " 'lista_docentes_colaboradores.csv',\n",
       " 'lista_docentes_permanentes.csv',\n",
       " 'lista_orientadores-discentes.csv',\n",
       " 'orientacoes.csv',\n",
       " 'patentes.csv',\n",
       " 'publicacoes.csv',\n",
       " 'publicacoes_old.csv',\n",
       " 'publication_test.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(pathdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090dde8d-29f4-4736-b400-beb9627220af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Funções tratar nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b90dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padronizar_titulo(titulo_bruto):\n",
    "    '''Retira acentos, expressão (Org.) e espaços vazios do título da publicação\n",
    "    Autor: Marcos Aires (Fev.2022)\n",
    "    '''\n",
    "    import unicodedata\n",
    "    import re\n",
    "    string = ''.join(ch for ch in unicodedata.normalize('NFKD', titulo_bruto) if not unicodedata.combining(ch))\n",
    "    string = string.replace('(Org)','').replace('(Org.)','').replace('(Org).','').replace('.','')\n",
    "    \n",
    "    titulo_padronizado = string.strip().strip('\"')\n",
    "    \n",
    "    return titulo_padronizado\n",
    "\n",
    "\n",
    "\n",
    "def padronizar_nome(linha_texto):\n",
    "    '''Procura sobrenomes e abreviaturas e monta nome completo\n",
    "     Recebe: String com todos os sobrenomes e nomes, abreviados ou não\n",
    "    Retorna: Nome completo no formato padronizado em SOBRENOME AGNOME, Prenomes\n",
    "      Autor: Marcos Aires (Mar.2022)\n",
    "    '''\n",
    "    import unicodedata\n",
    "    import re\n",
    "    # print('               Analisando:',linha_texto)\n",
    "    string = ''.join(ch for ch in unicodedata.normalize('NFKD', linha_texto) if not unicodedata.combining(ch))\n",
    "    string = string.replace('(Org)','').replace('(Org.)','').replace('(Org).','').replace('.','').replace('\\'','')\n",
    "    string = string.replace(',,,',',').replace(',,',',')\n",
    "    string = re.sub(r'[0-9]+', '', string)\n",
    "    string = ''.join(ch for ch in unicodedata.normalize('NFKD', string) if not unicodedata.combining(ch))\n",
    "    \n",
    "    # Expressões regulares para encontrar padrões de divisão de nomes de autores\n",
    "    sobrenome_inicio   = re.compile(r'^[A-ZÀ-ú-a-z]+,')                  # Sequência de letras maiúsculas no início da string\n",
    "    sobrenome_composto = re.compile(r'^[A-ZÀ-ú-a-z]+[ ][A-ZÀ-ú-a-z]+,')  # Duas sequências de letras no início da string, separadas por espaço, seguidas por vírgula\n",
    "    letra_abrevponto   = re.compile(r'^[A-Z][.]')                        # Uma letra maiúscula no início da string, seguida por ponto\n",
    "    letra_abrevespaco  = re.compile(r'^[A-Z][ ]')                        # Uma letra maiúscula no início da string, seguida por espaço\n",
    "    letras_dobradas    = re.compile(r'[A-Z]{2}')                         # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "    letras_dobradasini = re.compile(r'[A-Z]{2}[ ]')                      # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "    letras_dobradasfim = re.compile(r'[ ][A-Z]{2}')                      # Duas letras maiúsculas juntas no final da string, precedida por espaço\n",
    "    letras_duasconsnts = re.compile(r'[B-DF-HJ-NP-TV-XZ]{2}')            # Duas Letras maiúsculas e consoantes juntas\n",
    "    letras_tresconsnts = re.compile(r'[B-DF-HJ-NP-TV-XZ]{3}')            # Três Letras maiúsculas e consoantes juntas\n",
    "    \n",
    "    # Agnomes e preprosições a tratar, agnomes vão maiúsculas para sobrenome e preposições vão para minúsculas nos nomes\n",
    "    nomes=[]\n",
    "    agnomes       = ['NETO','JUNIOR','FILHO','SEGUNDO','TERCEIRO','SOBRINHO']\n",
    "    preposicoes   = ['de','da','do','das','dos', ' e ']\n",
    "    nome_completo = ''\n",
    "    \n",
    "    # Ajustar lista de termos, identificar sobrenomes compostos e ajustar sobrenome com ou sem presença de vírgula\n",
    "    div_sobrenome   = sobrenome_inicio.findall(string)\n",
    "    div_sbrcomposto = sobrenome_composto.findall(string)\n",
    "    \n",
    "    # print('-'*100)\n",
    "    # print('                 Recebido:',string)\n",
    "    \n",
    "    # Caso haja vírgulas na string, tratar sobrenomes e sobrenomes compostos\n",
    "    if div_sobrenome != [] or div_sbrcomposto != []:\n",
    "        # print('CASO_01: Há víruglas na string')\n",
    "        div = string.split(', ')\n",
    "        sobrenome     = div[0].strip().upper()\n",
    "        try:\n",
    "            div_espaco    = div[1].split(' ')\n",
    "        except:\n",
    "            div_espaco    = ['']\n",
    "        primeiro      = div_espaco[0].strip('.').strip()\n",
    "        \n",
    "        # print('     Dividir por vírgulas:',div)\n",
    "        # print('      Primeira DivVirgula:',sobrenome)\n",
    "        # print('Segunda DivVrg/DivEspaços:',div_espaco)\n",
    "        # print('      Primeira DivEspaços:',primeiro)\n",
    "               \n",
    "        # Caso primeiro nome seja somente duas letras maiúsculas juntas, trata-se de duas iniciais\n",
    "        if len(primeiro)==2 or letras_tresconsnts.findall(primeiro):\n",
    "            # print('CASO_01.a: Há duas letras ou três letras consoantes juntas, são iniciais')\n",
    "            primeiro_nome=primeiro[0].strip()\n",
    "            # print('          C01.a1_PrimNome:',primeiro_nome)\n",
    "            nomes.append(primeiro[1].strip().upper())\n",
    "            try:\n",
    "                nomes.append(primeiro[2].strip().upper())\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            # print('CASO_01.b: Primeiro nome maior que 2 caracteres')\n",
    "            primeiro_nome = div_espaco[0].strip().title()\n",
    "            # print('          C01.a2_PrimNome:',primeiro_nome)\n",
    "        \n",
    "        # Montagem da lista de nomes do meio\n",
    "        for nome in div_espaco:\n",
    "            # print('CASO_01.c: Para cada nome da divisão por espaços após divisão por vírgula')\n",
    "            if nome not in nomes and nome.lower()!=primeiro_nome.lower() and nome.lower() not in primeiro_nome.lower() and nome!=sobrenome:   \n",
    "                # print('CASO_01.c1: Se o nome não está nem como primeiro nome, nem sobrenomes')\n",
    "                # print(nome, len(nome))\n",
    "                \n",
    "                # Avaliar se é abreviatura seguida de ponto e remover o ponto\n",
    "                if len(nome)<=2 and nome.lower() not in preposicoes:\n",
    "                    # print('    C01.c1.1_Nome<=02:',nome)\n",
    "                    for inicial in nome:\n",
    "                        # print(inicial)\n",
    "                        if inicial not in nomes and inicial not in primeiro_nome:\n",
    "                            nomes.append(inicial.replace('.','').strip().title())\n",
    "                elif len(nome)==3 and nome.lower() not in preposicoes:\n",
    "                        # print('    C01.c1.2_Nome==03:',nome)\n",
    "                        for inicial in nome:\n",
    "                            if inicial not in nomes and inicial not in primeiro_nome:\n",
    "                                nomes.append(inicial.replace('.','').strip().title())\n",
    "                else:\n",
    "                    if nome not in nomes and nome!=primeiro_nome and nome!=sobrenome and nome!='':\n",
    "                        if nome.lower() in preposicoes:\n",
    "                            nomes.append(nome.replace('.','').strip().lower())\n",
    "                        else:\n",
    "                            nomes.append(nome.replace('.','').strip().title())\n",
    "                        # print(nome,'|',primeiro_nome)\n",
    "                        \n",
    "        #caso haja sobrenome composto que não esteja nos agnomes considerar somente primeiro como sobrenome\n",
    "        if div_sbrcomposto !=[] and sobrenome.split(' ')[1] not in agnomes and sobrenome.split(' ')[0].lower() not in preposicoes:\n",
    "            # print('CASO_01.d: Sobrenome composto sem agnomes')\n",
    "            # print(div_sbrcomposto)\n",
    "            # print('Sobrenome composto:',sobrenome)\n",
    "            \n",
    "            nomes.append(sobrenome.split(' ')[1].title())\n",
    "            sobrenome = sobrenome.split(' ')[0].upper().strip()\n",
    "            # print('Sobrenome:',sobrenome)\n",
    "            \n",
    "            for i in nomes:\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('    Nomes:',nomes)\n",
    "        \n",
    "        #caso haja preposição como agnome desconsiderar e passar para final dos nomes\n",
    "        if div_sbrcomposto !=[] and sobrenome.split(' ')[0].lower() in preposicoes:\n",
    "            # print('CASO_01.e: Preposição no Sobrenome passar para o final dos nomes')\n",
    "            # print('   div_sbrcomposto:', div_sbrcomposto)\n",
    "            # print('Sobrenome composto:',div_sbrcomposto)\n",
    "            \n",
    "            nomes.append(div_sbrcomposto[0].split(' ')[0].lower())\n",
    "            # print('    Nomes:',nomes)\n",
    "            sobrenome = div_sbrcomposto[0].split(' ')[1].upper().strip(',').strip()\n",
    "            # print('Sobrenome:',sobrenome)\n",
    "            \n",
    "            for i in nomes:\n",
    "                # print('CASO_01.e1: Para cada nome avaliar se o sobrenome está na lista')\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('  Nomes:',nomes)\n",
    "        \n",
    "        # print('Ao final do Caso 01')\n",
    "        # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('           Lista de nomes:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "    # Caso não haja vírgulas na string considera sobrenome o último nome da string dividida com espaço vazio\n",
    "    else:\n",
    "        # print('CASO_02: Não há víruglas na string')\n",
    "        try:\n",
    "            div = string.split(' ')\n",
    "            # print('      Divisões por espaço:',div)\n",
    "            \n",
    "            if div[-1] in agnomes: # nome final é um agnome\n",
    "                sobrenome     = div[-2].upper().strip()+' '+div[-1].upper().strip()\n",
    "                for i in div[1:-2]:\n",
    "                    if i not in sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.title().strip())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.lower().strip())\n",
    "            else:\n",
    "                if len(div[-1]) > 2:\n",
    "                    sobrenome     = div[-1].upper().strip()\n",
    "                    primeiro_nome = div[1].title().strip()\n",
    "                    for i in div[1:-1]:\n",
    "                        if i != sobrenome and i not in preposicoes:\n",
    "                            nomes.append(i.title().strip())\n",
    "                        if i in preposicoes:\n",
    "                            nomes.append(i.lower().strip())\n",
    "                else:\n",
    "                    sobrenome     = div[-2].upper().strip()\n",
    "                    for i in div[-1]:\n",
    "                        nomes.append(i.title())\n",
    "                    primeiro_nome = nomes[0].title().strip()\n",
    "                    for i in div[1:-1]:\n",
    "                        if i != sobrenome and i not in preposicoes:\n",
    "                            nomes.append(i.title().strip())\n",
    "                        if i in preposicoes:\n",
    "                            nomes.append(i.lower().strip())\n",
    "        except:\n",
    "            sobrenome = div[-1].upper().strip()\n",
    "            for i in div[1:-1]:\n",
    "                    if i != sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.title().strip())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.lower().strip())\n",
    "            \n",
    "        if sobrenome.lower() != div[0].lower().strip():\n",
    "            primeiro_nome=div[0].title().strip()\n",
    "        else:\n",
    "            primeiro_nome=''\n",
    "        \n",
    "        # print('Ao final do Caso 02')\n",
    "        # print('    Sobrenome sem vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome sem vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('Nomes do meio sem vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "    # Encontrar e tratar como abreviaturas termos com apenas uma ou duas letras iniciais juntas, com ou sem ponto\n",
    "    for j in nomes:\n",
    "        # print('CASO_03: Avaliar cada nome armazenado na variável nomes')\n",
    "        # Procura padrões com expressões regulares na string\n",
    "        div_sobrenome      = sobrenome_inicio.findall(j)\n",
    "        div_sbrcomposto    = sobrenome_composto.findall(j)\n",
    "        div_abrevponto     = letra_abrevponto.findall(j)\n",
    "        div_abrevespaco    = letra_abrevespaco.findall(j)\n",
    "        div_ltrdobradasini = letras_dobradasini.findall(j)\n",
    "        div_ltrdobradasfim = letras_dobradasfim.findall(j)\n",
    "        div_ltrdobradas    = letras_dobradas.findall(j)\n",
    "        tamanho=len(j)\n",
    "        # print('\\n', div_ltrdobradasini, div_ltrdobradasfim, tamanho, 'em:',j,len(j))\n",
    "        \n",
    "        #caso houver abreviatura com uma letra em maiúscula nos nomes\n",
    "        if div_abrevponto !=[] or tamanho==1:\n",
    "            # print('CASO_03.1: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "            nome = j.replace('.','').strip()\n",
    "            if nome not in nomes and nome != sobrenome and nome != primeiro_nome:\n",
    "                # print('CASO_03.1a: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "                nomes.append(nome.upper())\n",
    "        \n",
    "        #caso houver duas inicias juntas em maiúsculas\n",
    "        elif div_ltrdobradasini !=[] or div_ltrdobradasfim !=[] or div_ltrdobradas !=[] :\n",
    "            # print('CASO_03.2: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "            for letra in j:\n",
    "                # print('CASO_03.2a: Avaliar cada inicial do nome')\n",
    "                if letra not in nomes and letra != sobrenome and letra != primeiro_nome:\n",
    "                    # print('CASO_03.2a.1: Se não estiver adicionar inicial aos nomes')\n",
    "                    nomes.append(letra.upper())\n",
    "        \n",
    "        #caso haja agnomes ao sobrenome\n",
    "        elif sobrenome in agnomes:\n",
    "            # print('CASO_03.3: Há agnomes nos sobrenomes')\n",
    "            sobrenome = nomes[-1].upper()+' '+sobrenome\n",
    "            # print(sobrenome.split(' '))\n",
    "            # print('Sobrenome composto:',sobrenome)\n",
    "            for i in nomes:\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('Nomes do meio:',nomes)\n",
    "            \n",
    "        else:\n",
    "            # print('CASO_03.4: Não há agnomes nos sobrenomes')\n",
    "            if j not in nomes and j not in sobrenome and j != primeiro_nome:\n",
    "                if len(nomes) == 1:\n",
    "                    nomes.append(j.upper())\n",
    "                elif 1 < len(nomes) <= 3:\n",
    "                    nomes.append(j.lower())\n",
    "                else:\n",
    "                    nomes.append(j.title())\n",
    "         \n",
    "        # print('Ao final do Caso 03')\n",
    "        # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "    nomes_meio=' '.join([str for str in nomes]).strip()\n",
    "    # print('        Qte nomes do meio:',nomes,len(nomes))\n",
    "    \n",
    "    if primeiro_nome.lower() == sobrenome.lower():\n",
    "        # print('CASO_04: Primeiro nome é igual ao sobrenome')\n",
    "        try:\n",
    "            primeiro_nome=nomes_meio.split(' ')[0]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            nomes_meio.remove(sobrenome)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        # print('Ao final do caso 04')\n",
    "        # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "    # Caso sobrenome seja só de 1 letra passá-lo para nomes e considerar o próximo nome como sobrenome\n",
    "    for i in range(len(div)):\n",
    "        if len(sobrenome)==1 or sobrenome.lower() in preposicoes:\n",
    "            # print('CASO_05: Mudar sobrenomes até o adequado')\n",
    "            div    = string.split(', ')\n",
    "            # print('Divisão por vírgulas:',div)\n",
    "            avaliar0       = div[0].split(' ')[0].strip()\n",
    "            if 1< len(avaliar0) < 3:\n",
    "                # print('CASO_05.1: 1 < Sobrenome < 3 fica em minúsculas')\n",
    "                sbrn0          = avaliar0.lower()\n",
    "            else:\n",
    "                # print('CASO_05.2: Sobrenome de tamanho 1 ou maior que 3 fica em maiúsculas')\n",
    "                sbrn0          = avaliar0.title()\n",
    "            # print('sbrn0:',sbrn0, len(sbrn0))\n",
    "            \n",
    "            try:\n",
    "                avaliar1=div[0].split(' ')[1].strip()\n",
    "                # print('avaliar0',avaliar0)\n",
    "                # print('avaliar1',avaliar1)\n",
    "                if 1 < len(avaliar1) <=3:\n",
    "                    sbrn1     = avaliar1.lower()\n",
    "                else:\n",
    "                    sbrn1     = avaliar1.title()\n",
    "                # print('sbrn1:',sbrn1, len(sbrn1))\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if div != []:\n",
    "                # print('CASO_05.3: Caso haja divisão por vírgulas na string')\n",
    "                try:\n",
    "                    div_espaco     = div[1].split(' ')\n",
    "                except:\n",
    "                    div_espaco     = div[0].split(' ')\n",
    "                sobrenome      = div_espaco[0].strip().upper()\n",
    "                try:\n",
    "                    primeiro_nome  = div_espaco[1].title().strip()\n",
    "                except:\n",
    "                    primeiro_nome  = div_espaco[0].title().strip()\n",
    "                if len(sbrn0) == 1:\n",
    "                    # print('CASO_05.3a: Avalia primeiro sobrenome de tamanho 1')\n",
    "                    # print('Vai pros nomes:',str(sbrn0).title())\n",
    "                    nomes_meio = nomes_meio+str(' '+sbrn0.title())\n",
    "                    # print('   NomesMeio:',nomes_meio)\n",
    "\n",
    "                elif 1 < len(sbrn0) <= 3:\n",
    "                    # print('CASO_05.3b: Avalia primeiro sobrenome 1< tamanho <=3')\n",
    "                    # print('Vão pros nomes sbrn0:',sbrn0, 'e sbrn1:',sbrn1)\n",
    "\n",
    "                    div_tresconsoantes = letras_tresconsnts.findall(sobrenome)\n",
    "                    if div_tresconsoantes != []:\n",
    "                        # print('CASO_05.4: Três consoantes como sobrenome')\n",
    "                        for letra in sobrenome:\n",
    "                            nomes.append(letra)\n",
    "\n",
    "                        if len(sobrenome) >2:\n",
    "                            sobrenome=nomes[0]\n",
    "                        else:\n",
    "                            sobrenome=nomes[1]\n",
    "                        nomes.remove(sobrenome)\n",
    "                        primeiro_nome=nomes[0]\n",
    "                        nomes_meio=' '.join([str for str in nomes[1:]]).strip()\n",
    "                        nome_completo=sobrenome.upper()+', '+nomes_meio                \n",
    "                    \n",
    "                    try:                       \n",
    "                        # print(' 05.3b    Lista de Nomes:',nomes_meio)\n",
    "                        nomes_meio=nomes_meio.replace(sbrn0,'')\n",
    "                        # print(' 05.3b ReplaceSobrenome0:',nomes_meio)\n",
    "                        nomes_meio=nomes_meio.replace(sbrn1,'')\n",
    "                        # print(' 05.3b ReplaceSobrenome1:',nomes_meio)\n",
    "                    except Exception as e:\n",
    "                        # print('   Erro ReplaceSobrenome:',e)\n",
    "                        pass\n",
    "                    try:\n",
    "                        nomes_meio.replace(primeiro_nome.title(),'')\n",
    "                        nomes_meio.replace(primeiro_nome.lower(),'')\n",
    "                        nomes_meio.replace(primeiro_nome,'')\n",
    "                        # print(' 05.3b Replace PrimNome:',nomes_meio)\n",
    "                    except Exception as e:\n",
    "                        print('Erro no try PrimeiroNome:',e)\n",
    "                        pass\n",
    "                    nomes_meio = nomes_meio.replace(sobrenome,'')\n",
    "                    try:\n",
    "                        for n,i in enumerate(avaliar1):\n",
    "                            nomes.append(i.upper())\n",
    "                            sbrn1     = avaliar1[0]\n",
    "                        else:\n",
    "                            sbrn1     = avaliar1.title()\n",
    "                        # print('sbrn1:',sbrn1, len(sbrn1))\n",
    "                        nomes_meio = nomes_meio+str(' '+sbrn0)+str(' '+sbrn1)\n",
    "                    except:\n",
    "                        nomes_meio = nomes_meio+str(' '+sbrn0)\n",
    "                    nomes      = nomes_meio.strip().strip(',').split(' ')\n",
    "                    # print(' 05.3b NomesMeio:',nomes_meio)\n",
    "                    # print(' 05.3b     Nomes:',nome)\n",
    "\n",
    "                else:\n",
    "                    # print('CASO_05.3c: Avalia primeiro sobrenome >3')\n",
    "                    nomes_meio = nomes_meio+str(' '+div[0].strip().title())\n",
    "                    nomes      = nomes_meio.strip().split(' ')\n",
    "                    # print(' 05.3c NomesMeio:',nomes_meio)\n",
    "                    # print(' 05.3c     Nomes:',nomes)\n",
    "\n",
    "                nomes_meio=nomes_meio.replace(sobrenome,'').replace(',','').strip()\n",
    "                nomes_meio=nomes_meio.replace(primeiro_nome,'').strip()\n",
    "\n",
    "            # print('Ao final do caso 05')\n",
    "            # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "            # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "            # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "    if sobrenome != '' and primeiro_nome !='':\n",
    "        nome_completo=sobrenome.upper().replace(',','')+', '+primeiro_nome.replace(',','')+' '+nomes_meio.replace(sobrenome,'').replace(',','')\n",
    "    elif sobrenome != '':\n",
    "        nome_completo=sobrenome.upper().replace(',','')+', '+nomes_meio.replace(sobrenome,'').replace(',','')\n",
    "    else:\n",
    "        nome_completo=sobrenome.upper()\n",
    "    \n",
    "#     print('Após ajustes finais')\n",
    "#     print('     Sobrenome:',sobrenome)\n",
    "#     print(' Primeiro Nome:',primeiro_nome)\n",
    "#     print('         Nomes:',nomes)\n",
    "#     print('     NomesMeio:',nomes_meio)        \n",
    "        \n",
    "#     print('                Resultado:',nome_completo)\n",
    "    \n",
    "    return nome_completo.strip()\n",
    "\n",
    "\n",
    "def iniciais_nome(linha_texto):\n",
    "    '''Função para retornar sobrenome+iniciais dos nomes, na forma: SOBRENOME, X Y Z\n",
    "     Recebe: String com nome\n",
    "    Retorna: Tupla com nome e sua versão padronizada em sobrenome+agnomes em maiúsculas, seguida de vírgula e iniciais dos nomes \n",
    "      Autor: Marcos Aires (Mar.2022)\n",
    "    '''\n",
    "    import unicodedata\n",
    "    import re\n",
    "    # print('               Analisando:',linha_texto)\n",
    "    string = ''.join(ch for ch in unicodedata.normalize('NFKD', linha_texto) if not unicodedata.combining(ch))\n",
    "    string = string.replace('(Org)','').replace('(Org.)','').replace('(Org).','').replace('.','')\n",
    "        \n",
    "    # Expressões regulares para encontrar padrões de divisão de nomes de autores\n",
    "    sobrenome_inicio   = re.compile(r'^[A-ZÀ-ú-a-z]+,')                 # Sequência de letras maiúsculas no início da string\n",
    "    sobrenome_composto = re.compile(r'^[A-ZÀ-ú-a-z]+[ ][A-ZÀ-ú-a-z]+,') # Duas sequências de letras no início da string, separadas por espaço, seguidas por vírgula\n",
    "    letra_abrevponto   = re.compile(r'^[A-Z][.]')                       # Uma letra maiúscula no início da string, seguida por ponto\n",
    "    letra_abrevespaco  = re.compile(r'^[A-Z][ ]')                       # Uma letra maiúscula no início da string, seguida por espaço\n",
    "    letras_dobradas    = re.compile(r'[A-Z]{2}')                        # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "    letras_dobradasini = re.compile(r'[A-Z]{2}[ ]')                     # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "    letras_dobradasfim = re.compile(r'[ ][A-Z]{2}')                     # Duas letras maiúsculas juntas no final da string, precedida por espaço\n",
    "        \n",
    "    nomes=[]\n",
    "    agnomes       = ['NETO','JUNIOR','FILHO','SEGUNDO','TERCEIRO', 'SOBRINHO']\n",
    "    preposicoes   = ['da','de','do','das','dos','DA','DE','DOS','DAS','DOS','De']\n",
    "    nome_completo = ''\n",
    "    \n",
    "    # Ajustar lista de termos, identificar sobrenomes compostos e ajustar sobrenome com ou sem presença de vírgula\n",
    "    div_sobrenome      = sobrenome_inicio.findall(string)\n",
    "    div_sbrcomposto    = sobrenome_composto.findall(string)\n",
    "    \n",
    "    # Caso haja vírgulas na string, tratar sobrenomes e sobrenomes compostos\n",
    "    if div_sobrenome != [] or div_sbrcomposto != []:\n",
    "        div   = string.split(', ')\n",
    "        sobrenome     = div[0].strip().upper()\n",
    "        try:\n",
    "            div_espaco    = div[1].split(' ')\n",
    "        except:\n",
    "            div_espaco  = ['']\n",
    "        primeiro      = div_espaco[0].strip('.')\n",
    "        \n",
    "        # Caso primeiro nome sejam somente duas letras maiúsculas juntas, trata-se de duas iniciais\n",
    "        if len(primeiro)==2:\n",
    "            primeiro_nome=primeiro[0].strip()\n",
    "            nomes.append(primeiro[1].strip())\n",
    "        else:\n",
    "            primeiro_nome = div_espaco[0].strip().title()\n",
    "        \n",
    "        # Montagem da lista de nomes do meio\n",
    "        for nome in div_espaco:\n",
    "            if nome not in nomes and nome.lower()!=primeiro_nome.lower() and nome.lower() not in primeiro_nome.lower() and nome!=sobrenome:   \n",
    "                # print(nome, len(nome))\n",
    "                \n",
    "                # Avaliar se é abreviatura seguida de ponto e remover o ponto\n",
    "                if len(nome)<=2 and nome.lower() not in preposicoes:\n",
    "                    for inicial in nome:\n",
    "                        # print(inicial)\n",
    "                        if inicial not in nomes and inicial not in primeiro_nome:\n",
    "                            nomes.append(inicial.replace('.','').strip().title())\n",
    "                else:\n",
    "                    if nome not in nomes and nome!=primeiro_nome and nome!=sobrenome and nome!='':\n",
    "                        if nome.lower() in preposicoes:\n",
    "                            nomes.append(nome.replace('.','').strip().lower())\n",
    "                        else:\n",
    "                            nomes.append(nome.replace('.','').strip().title())\n",
    "                        # print(nome,'|',primeiro_nome)\n",
    "                        \n",
    "        #caso haja sobrenome composto que não esteja nos agnomes considerar somente primeiro como sobrenome\n",
    "        if div_sbrcomposto !=[] and sobrenome.split(' ')[1] not in agnomes:\n",
    "            # print(div_sbrcomposto)\n",
    "            # print('Sobrenome composto:',sobrenome)\n",
    "            nomes.append(sobrenome.split(' ')[1].title())\n",
    "            sobrenome = sobrenome.split(' ')[0].upper()\n",
    "            # print('Sobrenome:',sobrenome.split(' '))\n",
    "            for i in nomes:\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('Nomes do meio:',nomes)\n",
    "        \n",
    "        # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "    # Caso não haja vírgulas na string considera sobrenome o último nome da string dividida com espaço vazio\n",
    "    else:\n",
    "        try:\n",
    "            div       = string.split(' ')\n",
    "            if div[-2] in agnomes:\n",
    "                sobrenome = div[-2].upper()+' '+div[-1].strip().upper()\n",
    "                for i in nomes[1:-2]:\n",
    "                    if i not in sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.strip().title())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.strip().lower())\n",
    "            else:\n",
    "                sobrenome = div[-1].strip().upper()\n",
    "                for i in div[1:-1]:\n",
    "                    if i not in sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.strip().title())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.strip().lower())\n",
    "        except:\n",
    "            sobrenome = div[-1].strip().upper()\n",
    "            for i in div[1:-1]:\n",
    "                    if i not in sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.strip().title())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.strip().lower())\n",
    "            \n",
    "        if sobrenome.lower() != div[0].strip().lower():\n",
    "            primeiro_nome=div[0].strip().title()\n",
    "        else:\n",
    "            primeiro_nome=''\n",
    "        \n",
    "        # print('    Sobrenome sem vírgula:',sobrenome)\n",
    "        # print('Primeiro nome sem vírgula:',primeiro_nome)\n",
    "        # print('Nomes do meio sem vírgula:',nomes)\n",
    "    \n",
    "    # Encontrar e tratar como abreviaturas termos com apenas uma ou duas letras iniciais juntas, com ou sem ponto\n",
    "    for j in nomes:\n",
    "        # Procura padrões com expressões regulares na string\n",
    "        div_sobrenome      = sobrenome_inicio.findall(j)\n",
    "        div_sbrcomposto    = sobrenome_composto.findall(j)\n",
    "        div_abrevponto     = letra_abrevponto.findall(j)\n",
    "        div_abrevespaco    = letra_abrevespaco.findall(j)\n",
    "        div_ltrdobradasini = letras_dobradasini.findall(j)\n",
    "        div_ltrdobradasfim = letras_dobradasfim.findall(j)\n",
    "        div_ltrdobradas    = letras_dobradas.findall(j)\n",
    "        tamanho=len(j)\n",
    "        # print('\\n', div_ltrdobradasini, div_ltrdobradasfim, tamanho, 'em:',j,len(j))\n",
    "        \n",
    "        #caso houver abreviatura com uma letra em maiúscula nos nomes\n",
    "        if div_abrevponto !=[] or tamanho==1:\n",
    "            cada_nome = j.replace('.','').strip()\n",
    "            if cada_nome not in nomes and cada_nome != sobrenome and nome != primeiro_nome:\n",
    "                nomes.append(cada_nome)\n",
    "        \n",
    "        #caso houver duas inicias juntas em maiúsculas\n",
    "        elif div_ltrdobradasini !=[] or div_ltrdobradasfim !=[] or div_ltrdobradas !=[] :\n",
    "            for letra in j:\n",
    "                if letra not in nomes and letra != sobrenome and letra != primeiro_nome:\n",
    "                    nomes.append(letra)\n",
    "        \n",
    "        #caso haja agnomes ao sobrenome\n",
    "        elif sobrenome in agnomes:\n",
    "            sobrenome = nomes[-1].upper()+' '+sobrenome\n",
    "            # print(sobrenome.split(' '))\n",
    "            # print('Sobrenome composto:',sobrenome)\n",
    "            for i in nomes:\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('Nomes do meio:',nomes)\n",
    "            \n",
    "        else:\n",
    "            if j not in nomes and j not in sobrenome and j != primeiro_nome:\n",
    "                nomes.append(j)\n",
    "    \n",
    "    nomes_meio=' '.join([str[0] for str in nomes]).strip()\n",
    "    # print('Qte nomes do meio',len(nomes),nomes)\n",
    "    if sobrenome != '' and primeiro_nome !='':\n",
    "        sobrenome_iniciais = sobrenome+', '+primeiro_nome[0]+' '+nomes_meio\n",
    "    elif sobrenome != '':\n",
    "        sobrenome_iniciais = sobrenome\n",
    "    \n",
    "    return sobrenome_iniciais.strip()\n",
    "\n",
    "\n",
    "## Agregar aprendizado supervisionado humano à medida que forem sendo identificados erros na situação atual\n",
    "lista_extra = [\n",
    "                # ('ALBUQUERQUE, Adriano B', 'ALBUQUERQUE, Adriano Bessa'),\n",
    "                # ('ALBUQUERQUE, Adriano', 'ALBUQUERQUE, Adriano Bessa'),\n",
    "                # ('COELHO, Andre L V', 'COELHO, Andre Luis Vasconcelos'),\n",
    "                # ('DUARTE, Joao B F', 'DUARTE, Joao Batista Furlan'),\n",
    "                # ('FILHO, Raimir H','HOLANDA FILHO, Raimir'),\n",
    "                # ('FILHO, Raimir','HOLANDA FILHO, Raimir'),\n",
    "                # ('FORMIGO, A','FORMICO, Maria Andreia Rodrigues'),\n",
    "                # ('FORMICO, A','FORMICO, Maria Andreia Rodrigues'),\n",
    "                # ('FURLAN, J B D', 'FURLAN, Joao Batista Duarte'),\n",
    "                # ('FURTADO, Elizabeth', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "                # ('FURTADO, Elizabeth S', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "                # ('FURTADO, Elizabeth Sucupira','FURTADO, Maria Elizabeth Sucupira'),\n",
    "                # ('FURTADO, M E S', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "                # ('FURTADO, Vasco', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "                # ('FURTADO, J P', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "                # ('FURTADO, J V P', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "                # ('FURTADO, Vasco', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "                # ('FURTADO, Elizabeth','FURTADO, Maria Elizabeth Sucupira'),\n",
    "                # ('HOLANDA, Raimir', 'HOLANDA FILHO, Raimir'),\n",
    "                # ('LEITE, G S', 'LEITE, Gleidson Sobreira'),\n",
    "                # ('PEQUENO, T H C', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                # ('PEQUENO, Tarcisio','PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                # ('PEQUENO, Tarcisio Cavalcante', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                # ('PINHEIRO, Placido R', 'PINHEIRO, Placido Rogerio'),\n",
    "                # ('PINHEIRO, Vladia', 'PINHEIRO, Vladia Celia Monteiro'),\n",
    "                # ('RODRIGUES, M A F', 'RODRIGUES, Maria Andreia Formico'),\n",
    "                # ('RODRIGUES, Andreia', 'RODRIGUES, Maria Andreia Formico'),\n",
    "                # ('JOAO, Batista F Duarte,', 'FURLAN, Joao Batista Duarte'),\n",
    "                # ('MACEDO, Antonio Roberto M de', 'MACEDO, Antonio Roberto Menescal de'),\n",
    "                # ('MACEDO, D V', 'MACEDO, Daniel Valente'),\n",
    "                # ('MENDONCA, Nabor C', 'MENDONCA, Nabor das Chagas'),\n",
    "                # ('PEQUENO, Tarcisio', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                # ('PEQUENO, Tarcisio H', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                # ('PINHEIRO, Mirian C D', 'PINHEIRO, Miriam Caliope Dantas'),\n",
    "                # ('PINHEIRO, Mirian Caliope Dantas', 'PINHEIRO, Miriam Caliope Dantas'),\n",
    "                # ('PINHEIRO, P G C D', 'PINHEIRO, Pedro Gabriel Caliope Dantas'),\n",
    "                # ('PINHEIRO, Pedro G C', 'PINHEIRO, Pedro Gabriel Caliope Dantas'),\n",
    "                # ('PINHEIRO, Placido R', 'PINHEIRO, Placido Rogerio'),\n",
    "                # ('PINHEIRO, Vladia', 'PINHEIRO, Vladia Celia Monteiro'),\n",
    "                # ('ROGERIO, Placido Pinheiro', 'PINHEIRO, Placido Rogerio'),\n",
    "                # ('REBOUCRAS FILHO, Pedro', 'REBOUCAS FILHO, Pedro Pedrosa'),\n",
    "                # ('SAMPAIO, A', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "                # ('SAMPAIO, Americo', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "                # ('SAMPAIO, Americo Falcone', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "                # ('SUCUPIRA, Elizabeth Furtado','FURTADO, Maria Elizabeth Sucupira'),\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688df2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quebrar_partesnomes(nome):\n",
    "    padrao = padronizar_nome(nome).lower()\n",
    "    sobrenome  = padrao.split(',')[0].strip()\n",
    "    restonomes = padrao.split(',')[1].strip().split(' ')\n",
    "    try:\n",
    "        partenome1 = restonomes[0].strip()\n",
    "    except:\n",
    "        partenome1 = ''\n",
    "    try:\n",
    "        partenome2 = restonomes[1].strip()\n",
    "    except:\n",
    "        partenome2 = ''\n",
    "    try:\n",
    "        partenome3 = restonomes[2].strip()\n",
    "    except:\n",
    "        partenome3 = ''        \n",
    "    # print(f'{sobrenome:15} | {partenome1:1} | {partenome2:1} | {partenome3}')\n",
    "    \n",
    "    return sobrenome, partenome1, partenome2, partenome3\n",
    "\n",
    "\n",
    "\n",
    "def quebrar_iniciais(nome):\n",
    "    padrao = iniciais_nome(nome).lower()\n",
    "    sobrenome  = padrao.split(',')[0].strip()\n",
    "    restonomes = padrao.split(',')[1].strip().split(' ')\n",
    "    try:\n",
    "        partenome1 = restonomes[0].strip()\n",
    "    except:\n",
    "        partenome1 = ''\n",
    "    try:\n",
    "        partenome2 = restonomes[1].strip()\n",
    "    except:\n",
    "        partenome2 = ''\n",
    "    try:\n",
    "        partenome3 = restonomes[2].strip()\n",
    "    except:\n",
    "        partenome3 = ''        \n",
    "    # print(f'{sobrenome:15} | {partenome1:1} | {partenome2:1} | {partenome3}')\n",
    "    \n",
    "    return sobrenome, partenome1, partenome2, partenome3\n",
    "\n",
    "\n",
    "## compilar padrão regular expression para buscar dois termos dentro de janela de no máximo 3 palavras de distância\n",
    "## em caso de dúvidas ver a fonte https://regex101.com/r/yL6dE4/1\n",
    "def pesquisar_partes(sobrenome, partenome1, partenome2, partenome3):\n",
    "    return re.compile(r'\\b{0}(?:\\W+\\w+){{0,3}}\\W+{1}\\b|\\b{0}(?:\\W+\\w+){{0,3}}\\W+{2}\\b|\\b{0}(?:\\W+\\w+){{0,3}}\\W+{3}\\b'.format(sobrenome, partenome1, partenome2, partenome3), flags=re.IGNORECASE)\n",
    "    # return re.compile(r'\\b{0}(?:\\W+\\w+){{0,3}}\\W+{1}\\b|\\b{0}(?:\\W+\\w+){{0,3}}\\W+{2}\\b|\\b{0}(?:\\W+\\w+){{0,3}}\\W+{3}\\b|\\b{3}(?:\\W+\\w+){{0,3}}\\W+{0}\\b|\\b{2}(?:\\W+\\w+){{0,3}}\\W+{0}\\b|'.format(sobrenome, partenome1, partenome2, partenome3), flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "def buscar_padrao(sobrenome, partenome1, partenome2, partenome3):\n",
    "    indices_achados=[]\n",
    "    qte_achados_artigo=0\n",
    "    for n,i in enumerate(df_prod['AUTORES'].tolist()):\n",
    "        lista_autores  = i.replace('Autores: ','').lower()\n",
    "        \n",
    "        ## Buscar pelos nomes de autor em cada linha de autores de artigo\n",
    "        busca_autor = pesquisar_partes(sobrenome, partenome1, partenome2, partenome3)\n",
    "        try:\n",
    "            achar = re.search(busca_autor, lista_autores)\n",
    "            if achar.span() !=None:\n",
    "                print(achar.group(1))\n",
    "                indices_achados.append(n)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return indices_achados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_pastacsv():    \n",
    "    print(pathcsv)\n",
    "    import os, sys\n",
    "\n",
    "    lista_csv=[]\n",
    "    dirs = os.listdir(pathcsv)\n",
    "    for file in dirs:\n",
    "        if 'Artigos' in file:\n",
    "            lista_csv.append(file)\n",
    "    lista_csv.sort()\n",
    "    \n",
    "    for i in lista_csv:\n",
    "        print(i)\n",
    "\n",
    "    return lista_csv\n",
    "\n",
    "def ler_lista_docentes():\n",
    "    try:\n",
    "        l1='lista_docentes_colaboradores.csv'\n",
    "        l2='lista_docentes_permanentes.csv'\n",
    "        df_docclbr = pd.read_csv(pathcsv+l1, header=None)\n",
    "        df_docperm = pd.read_csv(pathcsv+l2, header=None)\n",
    "        lista_docentes = pd.concat([df_docperm, df_docclbr], ignore_index=True)[0].values\n",
    "        print(f'{len(lista_docentes)} docentes permanentes e colaboradores encontrados')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return lista_docentes\n",
    "\n",
    "\n",
    "\n",
    "def ler_lista_orientacoes():\n",
    "    try:\n",
    "        l1='lista_orientadores-discentes.csv'\n",
    "        df_orientacoes = pd.read_csv(pathcsv+l1, delimiter=';', header=None)\n",
    "        \n",
    "        lista_orientadores = df_orientacoes.iloc[:,0].unique()\n",
    "        lista_discentes    = df_orientacoes.iloc[:,1].unique()\n",
    "        print(f'{len(lista_orientadores)} orientadores, com {len(lista_discentes)} discentes encontrados')\n",
    "    except Exception as e:\n",
    "        print('Erro ao gerar lista de orientações:')\n",
    "        print(e)\n",
    "        return df_orientacoes\n",
    "        \n",
    "    return lista_orientadores, lista_discentes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77b96a-fa95-446f-afe9-ae32fb936fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções montagem de dataframes\n",
    "def montardf_orientacoes():\n",
    "    try:\n",
    "        l1='lista_orientadores-discentes.csv'\n",
    "        df_orientacoes = pd.read_csv(pathcsv+l1, delimiter=';', header=None)\n",
    "        df_orientacoes.columns=['ORIENTADOR','DISCENTE']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Erro ao dividir dataframe de orientações:')\n",
    "        print(e)\n",
    "        return\n",
    "        \n",
    "    return df_orientacoes\n",
    "\n",
    "\n",
    "\n",
    "def montardf_docentes_permanentes_colaboradores():\n",
    "    try:\n",
    "        l1='lista_docentes_colaboradores.csv'\n",
    "        l2='lista_docentes_permanentes.csv'\n",
    "        df_docclbr = pd.read_csv(pathcsv+l1, header=None)\n",
    "        df_docperm = pd.read_csv(pathcsv+l2, header=None)\n",
    "        df_docentes = pd.concat([df_docperm, df_docclbr], ignore_index=True)\n",
    "        print(f'{len(df_docentes.index)} docentes permanentes e colaboradores encontrados')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return df_docentes\n",
    "\n",
    "\n",
    "def montardf_producao(lista_csv):\n",
    "    df_public=pd.DataFrame()\n",
    "    for nome_csv in lista_csv:\n",
    "        if 'colaboradores' in nome_csv.lower():\n",
    "            tipo='colaboradores'\n",
    "        else:\n",
    "            tipo='permanentes'\n",
    "        \n",
    "        df_pub = pd.read_csv(pathcsv+nome_csv)\n",
    "\n",
    "        pat='\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'\n",
    "        df_temp1 = df_pub.Data.str.split(pat=pat,expand=True)\n",
    "        df_temp1.columns = (['TITULO','RevAut'])\n",
    "\n",
    "        pat1='\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'\n",
    "        df_temp2 = df_temp1.RevAut.str.split(pat=pat1,expand=True)\n",
    "        df_temp2.columns = (['REVISTA','AUTORES'])\n",
    "\n",
    "        df_temp0 = df_pub.drop(['Data'], axis=1)\n",
    "        df_pub=df_temp0.merge(df_temp1['TITULO'],left_index=True,right_index=True)\n",
    "        df_pub=df_pub.merge(df_temp2,left_index=True,right_index=True)\n",
    "        try:\n",
    "            df_pub.drop(['Issn','Natureza'], axis=1, inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            df_pub.drop(['Tipo','Idioma'], axis=1, inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        df_public = pd.concat([df_public, df_pub], ignore_index=True)\n",
    "        # print(len(df_public.index))\n",
    "        \n",
    "    ## Extrai o período com base nos dados\n",
    "    inicio = min(df_public['Ano'])\n",
    "    final  = max(df_public['Ano'])\n",
    "    \n",
    "    total_artigos=len(df_public.index)\n",
    "    print(f'Carregadas {total_artigos} publicações de artigos de docentes do programa no período de {inicio} a {final}...') \n",
    "    \n",
    "    return df_public\n",
    "\n",
    "\n",
    "def similares(lista_autores, lista_grupo, limite_jarowinkler, distancia_levenshtein, lista_extra):\n",
    "    \"\"\"Função para aplicar padronização no nome de autor da lista de pesquisadores e buscar similaridade na lista de coautores\n",
    "     Recebe: Lista de pesquisadores do grupo em análise gerada pela lista de nomes dos coautores das publicações em análise\n",
    "    Utiliza: get_jaro_distance(), editdistance()\n",
    "    Retorna: Lista de autores com fusão de nomes cuja similaridade esteja dentro dos limites definidos nesta função\n",
    "      Autor: Marcos Aires (Fev.2022)\n",
    "      \n",
    "    Refazer: Inserir crítica de, mantendo sequência ordem alfabética, retornar no final nome mais extenso em caso de similaridade;\n",
    "    \"\"\"\n",
    "    from pyjarowinkler.distance import get_jaro_distance\n",
    "    from IPython.display import clear_output\n",
    "    import editdistance\n",
    "    import numpy as np\n",
    "    import time\n",
    "    \n",
    "    t0=time.time()\n",
    "    \n",
    "    # limite_jarowinkler=0.85\n",
    "    # distancia_levenshtein=6\n",
    "    similares_jwl=[]\n",
    "    similares_regras=[]\n",
    "    similares=[]\n",
    "    tempos=[]\n",
    "    \n",
    "    count=0\n",
    "    t1=time.time()\n",
    "    for i in lista_autores:\n",
    "        count+=1\n",
    "        if count > 0:\n",
    "            tp=time.time()-t1\n",
    "            tmed=tp/count*2\n",
    "            tempos.append(tp)\n",
    "        # print(\"Analisar similaridades com: \", nome_padronizado)\n",
    "        \n",
    "        count1=0\n",
    "        for nome in lista_autores:\n",
    "            if count1 > 0:\n",
    "                resta=len(lista_autores)-count\n",
    "                print(f'Analisando {count1:3}/{len(lista_autores)} resta analisar {resta:3} nomes. Previsão de término em {np.round(tmed*resta/60,1)} minutos')\n",
    "            else:\n",
    "                print(f'Analisando {count1:3}/{len(lista_autores)} resta analisar {len(lista_autores)-count1} nomes.')\n",
    "            \n",
    "            t2=time.time()\n",
    "            count1+=1            \n",
    "\n",
    "            try:\n",
    "                similaridade_jarowinkler = get_jaro_distance(i, nome)\n",
    "                print(f'{i:40} | {nome:40} | Jaro-Winkler: {np.round(similaridade_jarowinkler,2):4} Levenshtein: {editdistance.eval(i, nome)}')\n",
    "                similaridade_levenshtein = editdistance.eval(i, nome)\n",
    "\n",
    "                # inferir similaridade para nomes que estejam acima do limite ponderado definido, mas não idênticos e não muito distantes em edição\n",
    "                if  similaridade_jarowinkler > limite_jarowinkler and similaridade_jarowinkler!=1 and similaridade_levenshtein < distancia_levenshtein:\n",
    "                    # Crítica no nome mais extenso como destino no par (origem, destino)\n",
    "                    \n",
    "                    similares_jwl.append((i,nome))\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            clear_output(wait=True)\n",
    "    \n",
    "    # Conjunto de regras de validação de similaridade\n",
    "    # Monta uma lista de nomes a serem retirados antes de montar a lista de troca\n",
    "    trocar=[]\n",
    "    retirar=[]\n",
    "    for i in similares_jwl:\n",
    "        sobrenome_i = i[0].split(',')[0]\n",
    "        sobrenome_j = i[1].split(',')[0]\n",
    "\n",
    "        try:\n",
    "            iniciais_i  = iniciais_nome(i[0]).split(',')[1].strip()\n",
    "        except:\n",
    "            iniciais_i  = ''\n",
    "\n",
    "        try:\n",
    "            iniciais_j  = iniciais_nome(i[1]).split(',')[1].strip()\n",
    "        except:\n",
    "            iniciais_j  = ''\n",
    "\n",
    "        try:\n",
    "            primnome_i = i[0].split(',')[1].strip().split(' ')[0].strip()\n",
    "        except:\n",
    "            primnome_i = ''\n",
    "\n",
    "        try:\n",
    "            primnome_j = i[1].split(',')[1].strip().split(' ')[0].strip()\n",
    "        except:\n",
    "            primnome_j = ''    \n",
    "\n",
    "        try:\n",
    "            inicial_i = i[0].split(',')[1].strip()[0]\n",
    "        except:\n",
    "            inicial_i = ''\n",
    "\n",
    "        try:\n",
    "            resto_i   = i[0].split(',')[1].strip().split(' ')[0][1:]\n",
    "        except:\n",
    "            resto_i   = ''\n",
    "\n",
    "        try:\n",
    "            inicial_j = i[1].split(',')[1].strip()[0]\n",
    "        except:\n",
    "            inicial_j = ''\n",
    "\n",
    "        try:\n",
    "            resto_j   = i[1].split(',')[1].strip().split(' ')[0][1:]\n",
    "        except:\n",
    "            resto_j = ''\n",
    "\n",
    "        # Se a distância de edição entre os sobrenomes\n",
    "        if editdistance.eval(sobrenome_i, sobrenome_j) > 2 or inicial_i!=inicial_j:\n",
    "            retirar.append(i)\n",
    "        else:\n",
    "            if primnome_i!=primnome_j and len(primnome_i)>1:\n",
    "                retirar.append(i)\n",
    "            if primnome_i!=primnome_j and len(primnome_i)>1 and len(primnome_j)>1:\n",
    "                retirar.append(i)\n",
    "            if resto_i!=resto_j and resto_i!='':\n",
    "                retirar.append(i)\n",
    "            if len(i[1]) < len(i[0]):\n",
    "                retirar.append(i)\n",
    "            if len(iniciais_i) != len(iniciais_j):\n",
    "                retirar.append(i)\n",
    "\n",
    "    for i in similares_jwl:\n",
    "        if i not in retirar:\n",
    "            trocar.append(i)\n",
    "\n",
    "        if iniciais_nome(i[0]) in iniciais_nome(i[1]) and len(i[0]) < len(i[1]):\n",
    "            trocar.append(i)\n",
    "\n",
    "        if iniciais_nome(i[0]) == iniciais_nome(i[1]) and len(i[0]) < len(i[1]):\n",
    "             trocar.append(i)\n",
    "    \n",
    "    trocar=trocar+lista_extra\n",
    "    trocar.sort()\n",
    "    \n",
    "    return trocar\n",
    "\n",
    "\n",
    "\n",
    "def extrair_variantes(df_dadosgrupo):\n",
    "    ''' Utiliza campo de Nome em Citações do currículo como filtro para obter variantes do nome de cada membro\n",
    "     Recebe: Dataframe com os dados brutos do grupo de pesquisa agrupados; lista de nomes de pesquisadores de interesse\n",
    "    Retorna: Lista de tuplas com pares a serem trocados da variante pelo nome padronizado na forma (origem, destino)\n",
    "    '''\n",
    "    filtro1   = 'Nome'\n",
    "    lista_nomes = df_dadosgrupo[(df_dadosgrupo.ROTULOS == filtro1)]['CONTEUDOS'].values\n",
    "\n",
    "    variantes=[]\n",
    "    filtro='Nome em citações bibliográficas'\n",
    "    variantes=df_dadosgrupo[(df_dadosgrupo.ROTULOS == filtro)]['CONTEUDOS'].to_list()\n",
    "\n",
    "    trocar=[]\n",
    "    for j in range(len(variantes)):\n",
    "        padrao_destino = padronizar_nome(lista_nomes[j])\n",
    "        trocar.append((lista_nomes[j], padrao_destino))\n",
    "        for k in variantes[j]:\n",
    "            padrao_origem = padronizar_nome(k)\n",
    "            trocar.append((k, padrao_destino))\n",
    "            trocar.append((padrao_origem, padrao_destino))\n",
    "    \n",
    "    return trocar\n",
    "\n",
    "def tempo(start, end):\n",
    "    t=end-start\n",
    "\n",
    "    tempo = timedelta(\n",
    "        weeks   = t//(3600*24*7),\n",
    "        days    = t//(3600*24),\n",
    "        seconds = t,\n",
    "        minutes = t//(60),\n",
    "        hours   = t//(3600),\n",
    "        microseconds=t//1000000,\n",
    "        )\n",
    "    fmt='{H:2}:{M:02}:{S:02}'\n",
    "    return strfdelta(tempo)\n",
    "\n",
    "\n",
    "def horas(segundos): \n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(segundos)) \n",
    "\n",
    "\n",
    "def dias_horas_minutos(td):\n",
    "    x = (td.days, td.seconds//3600, (td.seconds//60)%60, td.seconds)\n",
    "    return x #(days, hrs, mins, seconds)\n",
    "\n",
    "\n",
    "def strfdelta(tdelta, fmt='{H:02}h {M:02}m {S:02}s', inputtype='timedelta'):\n",
    "    \"\"\"Convert a datetime.timedelta object or a regular number to a custom-formatted string, \n",
    "    just like the stftime() method does for datetime.datetime objects.\n",
    "\n",
    "    The fmt argument allows custom formatting to be specified.  Fields can \n",
    "    include seconds, minutes, hours, days, and weeks.  Each field is optional.\n",
    "\n",
    "    Some examples:\n",
    "        '{D:02}d {H:02}h {M:02}m {S:02}s' --> '05d 08h 04m 02s' (default)\n",
    "        '{W}w {D}d {H}:{M:02}:{S:02}'     --> '4w 5d 8:04:02'\n",
    "        '{D:2}d {H:2}:{M:02}:{S:02}'      --> ' 5d  8:04:02'\n",
    "        '{H}h {S}s'                       --> '72h 800s'\n",
    "\n",
    "    The inputtype argument allows tdelta to be a regular number instead of the  \n",
    "    default, which is a datetime.timedelta object.  Valid inputtype strings: \n",
    "        's', 'seconds', \n",
    "        'm', 'minutes', \n",
    "        'h', 'hours', \n",
    "        'd', 'days', \n",
    "        'w', 'weeks'\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert tdelta to integer seconds.\n",
    "    if inputtype == 'timedelta':\n",
    "        remainder = int(tdelta.total_seconds())\n",
    "    elif inputtype in ['s', 'seconds']:\n",
    "        remainder = int(tdelta)\n",
    "    elif inputtype in ['m', 'minutes']:\n",
    "        remainder = int(tdelta)*60\n",
    "    elif inputtype in ['h', 'hours']:\n",
    "        remainder = int(tdelta)*3600\n",
    "    elif inputtype in ['d', 'days']:\n",
    "        remainder = int(tdelta)*86400\n",
    "    elif inputtype in ['w', 'weeks']:\n",
    "        remainder = int(tdelta)*604800\n",
    "\n",
    "    f = Formatter()\n",
    "    desired_fields = [field_tuple[1] for field_tuple in f.parse(fmt)]\n",
    "    possible_fields = ('W', 'D', 'H', 'M', 'S')\n",
    "    constants = {'W': 604800, 'D': 86400, 'H': 3600, 'M': 60, 'S': 1}\n",
    "    values = {}\n",
    "    \n",
    "    for field in possible_fields:\n",
    "        if field in desired_fields and field in constants:\n",
    "            values[field], remainder = divmod(remainder, constants[field])\n",
    "    \n",
    "    return f.format(fmt, **values)\n",
    "\n",
    "\n",
    "# print (timedelta(days=365, hours=8, minutes=15))\n",
    "# print (\"   Hoje é: \" + str(date.today()))\n",
    "# print (\"Agora são: \" + str(datetime.now()))\n",
    "# print (\"Um ano no futuro estaremos em:\" + str(dt.today() + timedelta(days=365)))\n",
    "# hoje = date.today()\n",
    "# print(hoje)\n",
    "# hora = dt.now()\n",
    "# print(hora)\n",
    "# dias_ano = date(hoje.year, 1, 1)\n",
    "# if dias_ano < hoje:\n",
    "#     print (\"Decoridos %d dias do ano\" % ((hoje - dias_ano).days))\n",
    "    \n",
    "# from datetime import datetime\n",
    "# now= datetime.now() #get the current date and time\n",
    "\n",
    "# #%c - local date and time, %x-local's date, %X- local's time\n",
    "# print(now.strftime(\"%c\"))\n",
    "# print(now.strftime(\"%x\"))\n",
    "# print(now.strftime(\"%X\"))\n",
    "\n",
    "# ##### Time Formatting ####\n",
    "# #%I/%H - 12/24 Hour, %M - minute, %S - second, %p - local's AM/PM\n",
    "# print(now.strftime(\"%I:%M:%S %p\")) # 12-Hour:Minute:Second:AM\n",
    "# print(now.strftime(\"%H:%M\")) # 24-Hour:Minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71708b35-097d-4d8b-8a5a-f21b840d06b8",
   "metadata": {},
   "source": [
    "### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe7237",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_csv = ler_pastacsv()\n",
    "df_prod = montardf_producao(lista_csv)\n",
    "df_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999d3ee-c13d-481d-a4e5-07a4aec413a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Sendo:')\n",
    "lista_titulos = pd.Series(df_prod['TITULO'].values).unique().tolist()\n",
    "print(f'{len(lista_titulos)} artigos distintos publicados no período')\n",
    "lista_revistas = pd.Series(df_prod['REVISTA'].values).unique().tolist()\n",
    "print(f'{len(lista_revistas)} revistas distintas utilizadas no período')\n",
    "lista_docentes = ler_lista_docentes()\n",
    "lista_orientadores, lista_discentes = ler_lista_orientacoes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd74b72-00e9-4d73-93ed-73ec9417ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c1abb-0d85-4266-888b-579d424f6877",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobrenome, partenome1, partenome2, partenome3 = quebrar_partesnomes('FARIA, N. R')\n",
    "indices_achados=[]\n",
    "qte_achados_artigo=0\n",
    "for n,i in enumerate(df_prod['AUTORES'].tolist()):\n",
    "    lista_autores  = i.replace('Autores: ','').lower()\n",
    "\n",
    "    ## Buscar pelos nomes de autor em cada linha de autores de artigo\n",
    "    busca_autor = pesquisar_partes(sobrenome, partenome1, partenome2, partenome3)\n",
    "    achar = re.search(busca_autor, lista_autores)\n",
    "    print(achar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a91b9b-f5f3-4d27-b6fc-4f18bcc91f12",
   "metadata": {},
   "source": [
    "### Busca por discentes dentre os autores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417bf4a0-01ff-43b6-b51d-4dea21328a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "\n",
    "indices_discente=[]\n",
    "indices_docente=[]\n",
    "nomes_discentes={}\n",
    "nomes_docentes={}\n",
    "for m,discente in enumerate(lista_discentes):\n",
    "    qte_discentes=len(lista_discentes)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    ## Buscar por sobrenome seguido de partes de nomes abreviados em suas iniciais\n",
    "    sobrenome, partenome1, partenome2, partenome3 = quebrar_iniciais(discente)\n",
    "    lista_indice_discente = buscar_padrao(sobrenome, partenome1, partenome2, partenome3)\n",
    "    if lista_indice_discente != []:\n",
    "        nomes_discentes[m] = (discente, lista_indice_discente)\n",
    "    \n",
    "    ## Buscar por sobrenome seguido partes de nomes sem abreviaturas por iniciais\n",
    "    sobrenome, partenome1, partenome2, partenome3 = quebrar_partesnomes(discente)\n",
    "    lista_indice_discente = buscar_padrao(sobrenome, partenome1, partenome2, partenome3)\n",
    "    if lista_indice_discente != [] and lista_indice_discente not in indices_discente:\n",
    "        nomes_discentes[m] = (discente, lista_indice_discente)\n",
    "    \n",
    "    tdec=time.time()-t1\n",
    "    tres=tdec/(m+1)*(qte_discentes-m)\n",
    "    print(f'Buscado discente: {discente.title():40} registro {m+1:4}/{qte_discentes:4}, buscados {m+1:4} em {horas(tdec)}, resta {qte_discentes-m}')\n",
    "    \n",
    "    \n",
    "\n",
    "for m,docente in enumerate(lista_docentes):\n",
    "    qte_docentes=len(lista_docentes)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    ## Buscar por sobrenome seguido de partes de nomes abreviados em suas iniciais\n",
    "    sobrenome, partenome1, partenome2, partenome3 = quebrar_iniciais(docente)\n",
    "    lista_indice_docente = buscar_padrao(sobrenome, partenome1, partenome2, partenome3)\n",
    "    if lista_indice_docente != []:\n",
    "        nomes_docentes[m] = (docente, lista_indice_docente)\n",
    "    \n",
    "    ## Buscar por sobrenome seguido partes de nomes sem abreviaturas por iniciais\n",
    "    sobrenome, partenome1, partenome2, partenome3 = quebrar_partesnomes(docente)\n",
    "    lista_indice_docente = buscar_padrao(sobrenome, partenome1, partenome2, partenome3)\n",
    "    if lista_indice_docente != [] and lista_indice_docente not in indices_docente:\n",
    "        nomes_docentes[m] = (docente, lista_indice_docente)\n",
    "\n",
    "    tdec=time.time()-t1\n",
    "    tres=tdec/(m+1)*(qte_docentes-m)\n",
    "    print(f'Buscado  docente: {docente.title():40} registro {m+1:4}/{qte_docentes:4}, buscados {m+1:4} em {horas(tdec)}, resta {qte_docentes-m}')\n",
    "    \n",
    "t2=time.time()\n",
    "tempo(t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f425ca6-c585-41ec-976b-7b3823baef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_participacao_discente = pd.DataFrame(nomes_discentes).T\n",
    "df_participacao_discente.columns = ['DISCENTE','INDICES_ARTIGOS']\n",
    "df_participacao_discente['CONTAGEM_COAUTORIAS'] = [len(x) for x in df_participacao_discente['INDICES_ARTIGOS']]\n",
    "\n",
    "df_participacao_docente = pd.DataFrame(nomes_docentes).T\n",
    "df_participacao_docente.columns = ['DOCENTE','INDICES_ARTIGOS']\n",
    "df_participacao_docente['CONTAGEM_COAUTORIAS'] = [len(x) for x in df_participacao_docente['INDICES_ARTIGOS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8337b-c9d3-4b5d-af1a-7b26af63f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,d in zip(df_participacao_docente['INDICES_ARTIGOS'],df_participacao_docente['DOCENTE']):\n",
    "#     for n in i:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31680677-e01d-406f-8168-5348ca34bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_participacao_docente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867ac7a-5d43-42a6-b6ed-289e75cc0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_participacao_discente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb5007-3e7c-405a-af00-66145ffc8471",
   "metadata": {},
   "outputs": [],
   "source": [
    "artigos_com_docentes=[]\n",
    "for m in df_participacao_docente['INDICES_ARTIGOS']:\n",
    "    for n in m:\n",
    "        if n not in artigos_com_docentes:\n",
    "            artigos_com_docentes.append(n)\n",
    "print(len(artigos_com_docentes))    \n",
    "artigos_com_docentes.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61d455-3fcc-4f99-b705-054e577b7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "artigos_com_discentes=[]\n",
    "for m in df_participacao_discente['INDICES_ARTIGOS']:\n",
    "    for n in m:\n",
    "        if n not in artigos_com_discentes:\n",
    "            artigos_com_discentes.append(n)\n",
    "    \n",
    "artigos_com_discentes.sort()\n",
    "print(len(artigos_com_discentes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd66d9-51f7-4600-9340-e03505b9a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_semparticipacaodiscente=[]\n",
    "for i in range(len(df_prod.index)):\n",
    "    if i not in lista_participacaodiscente:\n",
    "        lista_semparticipacaodiscente.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45233b-9cdd-4e78-a195-260cf8649524",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lista_semparticipacaodiscente)/len(df_prod.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae5837-fc3e-42a9-b65d-47b3f135e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lista_participacaodocente)/len(df_prod.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8318ef-8b52-4993-a23c-2b8c9d218441",
   "metadata": {},
   "outputs": [],
   "source": [
    "docentes_unificada=[]\n",
    "indices_docentes_unificados=[]\n",
    "for i,j in zip(nomes_discentes,indices_discente):\n",
    "    print(f'{i:25} | {j}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb44e129-b7de-465b-b15f-bd1025e4d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices_discente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce90ddb3-211b-4ccc-966f-a3c97ef2abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices_docente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e1e4c5-7e9d-4a06-8c12-4a8494003039",
   "metadata": {},
   "outputs": [],
   "source": [
    "docentes_autores = pd.Series(nomes_docentes).unique()\n",
    "docentes_autores.sort()\n",
    "indices_com_docente = pd.Series(indices_docente).unique()\n",
    "indices_com_docente.sort()\n",
    "print(f'{len(docentes_autores)} docentes aparecem como autores em {len(indices_com_docente)} artigos distintos')\n",
    "\n",
    "discente_autores = pd.Series(nomes_discentes).unique()\n",
    "discente_autores.sort()\n",
    "indices_com_discente = pd.Series(indices_discente).unique()\n",
    "indices_com_discente.sort()\n",
    "print(f'{len(discente_autores)} discentes aparecem como autores em {len(indices_com_discente)} artigos distintos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62623ad3-6563-4b2a-bb68-4763efd6b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices_com_discente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d92d9-4050-4761-b724-98f1873679ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices_com_docente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f4823-b543-4ab7-a22e-bc8e4acff660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discente_achados = pd.DataFrame({\n",
    "    'di': pd.Series(indices_discente),\n",
    "    'DISCENTE': pd.Series(nomes_discentes),\n",
    "})\n",
    "df_discente_achados = df_discente_achados.sort_values('di')\n",
    "df_discente_achados.reset_index(inplace=True, drop=True)\n",
    "df_artigos_discentes = df_discente_achados.groupby(['di'], as_index=False, sort=False).agg('; '.join)\n",
    "\n",
    "df_docente_achados = pd.DataFrame({\n",
    "    'do': pd.Series(indices_docente),\n",
    "    'DOCENTE': pd.Series(nomes_docentes),\n",
    "})\n",
    "df_docente_achados = df_docente_achados.sort_values('do')\n",
    "df_docente_achados.reset_index(inplace=True, drop=True)\n",
    "df_artigos_docentes = df_docente_achados.groupby(['do'], as_index=False, sort=False).agg('; '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884cf383-866b-4b11-add7-b86fe94c77ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1e510-c246-4fb3-a64b-b611789f1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producao_docentes = pd.merge(df_prod, df_artigos_docentes,  left_index=True, right_on='do')\n",
    "df_producao_docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28134041-9faa-41ee-97e1-56ddf97f07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_artigos_docentes = []\n",
    "coautorias_docentes=[]\n",
    "for i,j in zip(indices_docente, nomes_docentes):\n",
    "    # print(f'{i:3} {j}')\n",
    "    if i not in lista_artigos_docentes:\n",
    "        lista_artigos_docentes.append(j)\n",
    "    else:\n",
    "        pass\n",
    "        # lista_artigos_docentes.extend(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182eb3eb-0036-4774-9298-df30291fb57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas library\n",
    "import pandas as pd\n",
    "  \n",
    "# dictionary with dictionary object in values i.e. nested dictionary\n",
    "details = { \n",
    "    0 : {\n",
    "        'Name' : 'Ankit',\n",
    "        'Age' : 22,\n",
    "        'University' : 'BHU'\n",
    "        },\n",
    "    1 : {\n",
    "        'Name' : 'Aishwarya',\n",
    "        'Age' : 21,\n",
    "        'University' : 'JNU'\n",
    "        },\n",
    "    2 : {\n",
    "        'Name' : 'Shaurya',\n",
    "        'Age' : 23,\n",
    "        'University' : 'DU'\n",
    "        }\n",
    "}\n",
    "  \n",
    "# creating a Dataframe object from nested dictionary\n",
    "# in which inside dictionary key is act as index value\n",
    "# and column value is 0, 1, 2...\n",
    "df = pd.DataFrame(details)\n",
    "  \n",
    "# swap the columns with indexes\n",
    "df = df.transpose()\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a8ead4-b863-4ea4-88d3-0eea549bc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_docentes = montardf_docentes_permanentes_colaboradores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae2e7d-db5f-415f-a238-f9143f3ca4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_orientacoes = montardf_orientacoes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7034be-2032-44c1-8127-5e3374951036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
