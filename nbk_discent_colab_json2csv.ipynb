{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b48e5c3",
   "metadata": {},
   "source": [
    "## <center>Avaliação regular do perfil do corpo docente do PPCS IRR/Fiocruz <br /> Programa de Pós-graduação em Ciências da Saúde <br /> Instituto René Rachou – Fiocruz Minas</center>\n",
    "\n",
    "    Rubens Lima do Monte Neto – Instituto René Rachou\n",
    "    Antonio Marcos Aires Barbosa – Fiocruz Ceará\n",
    "    Equipe do PPGCS\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "    Reavaliação de meio termo do corpo docente do programa, a fim de acompanhar a manutenção dos parâmetros exigidos pela CAPES – Área de Medicina II e readequar a composição do grupo. São considerados os docentes permanentes (DP) e docentes colaboradores (DC), com base nos mesmos parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c3005",
   "metadata": {},
   "source": [
    "# Apuração do Indicadores de Gestão do PPGCS\n",
    "### 1. Índice de Produção Conjunta dos docentes com discentes (IPC >= 50%):\n",
    "    Indicador: Índice de publicações com discentes por orientador (IPC)\n",
    "     Objetivo: Em, pelo menos, 50 % dos artigos publicados deve constar discentes do programa\n",
    "         Meta: IPC >= 50,00\n",
    "      \n",
    "      Cálculo:\n",
    "\n",
    "$$\\sum_{k=1}^{n}\\, 100 * \\frac{QPCD}{QPAT}$$\n",
    "\n",
    "        onde:\n",
    "               n = Artigos completos publicado em periódicos indexados\n",
    "            QPCD = Qte. Publicação de Artigos com discentes do Programa na lista de autores\n",
    "            QPAT = Qte. Publicação de Artigos Total no período avaliado\n",
    "\n",
    "### 2. Pontuação segundo Fator de Impacto (PFI >= 600 em pelo menos 70% dos docentes):\n",
    "\n",
    "    Indicador: Total de pontos conforme periódicos das publicações no período\n",
    "     Objetivo: Publicar trabalhos em periódicos de elevado impacto\n",
    "               \n",
    "         Meta: 70% dos docentes permanentes com PFI >= 600 pontos no quadriênio\n",
    "               (150/ano e ao menos 03 artigos A, no mínimo 02 em A1, ou 04 artigos A2);\n",
    " \n",
    "      Cálculo: Soma ponderada pela estratificação Qualis de acordo com o que segue:\n",
    "        A1 = 100 pontos\n",
    "        A2 = 80 pontos\n",
    "        B1 = 60 pontos\n",
    "        B2 = 40 pontos\n",
    "        B3 = 20 pontos\n",
    "        B4 = 10 pontos\n",
    "        B5 = 2 pontos.\n",
    "\n",
    "\n",
    "Parâmetro para classificaçao do periódico:\n",
    "\n",
    "        A1: Periódicos com FI ou CPD >= 4,300\n",
    "        A2: Periódicos com FI ou CPD entre 2,950 e 4,299\n",
    "        B1: Periódicos com FI ou CPD entre 1,800 e 2,949\n",
    "        B2: Periódicos com FI ou CPD entre 1,100 e 1,799\n",
    "        B3: Periódicos com FI ou CPD entre 0,300 e 1,099\n",
    "        B4: Periódicos com FI ou CPD entre 0,001 e 0,299, (ou Scielo, Scimago, PubMed ou Web of Science)\n",
    "        B5: Periódicos sem FI ou CPD e indexado nas lases Lilacs ou Latindex    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090dde8d-29f4-4736-b400-beb9627220af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Grupos de Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0082ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install levenshtein\n",
    "# !pip3 install editdistance\n",
    "# !pip3 install seaborn\n",
    "# !pip3 install pyjarowinkler\n",
    "\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time # from datetime import time\n",
    "from unidecode import unidecode\n",
    "from datetime import timedelta\n",
    "from datetime import datetime as dt\n",
    "from string import Formatter\n",
    "from datetime import date\n",
    "from pyjarowinkler.distance import get_jaro_distance\n",
    "from IPython.display import clear_output, display, HTML\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('colheader_justify', 'left')\n",
    "\n",
    "def agrupar_orientacoes(filename):\n",
    "    # Caminho para o arquivo JSON\n",
    "    pathjson = '.\\_data\\in_json' \n",
    "    pathfilename = os.path.join(pathjson,filename)\n",
    "\n",
    "    # dict_orientacoes = pd.read_json(pathfilename)\n",
    "\n",
    "    # Carregar o JSON e aplicar a função\n",
    "    with open(pathfilename, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    linhas_achatadas = extrair_orientacoes(data)\n",
    "    df = pd.DataFrame(linhas_achatadas)\n",
    "\n",
    "    # Salvar os dados achatados em um CSV\n",
    "    df.to_csv('orientacoes_achatadas.csv', index=False)\n",
    "\n",
    "    # Use .loc para modificar o DataFrame diretamente e evitar o aviso\n",
    "    df.loc[:, 'sigla_natureza'] = df['natureza'].apply(lambda x: sigla_natureza(x))\n",
    "    df_orientacoes = df[['id_lattes_orientadores','ano','sigla_natureza']]\n",
    "\n",
    "    # Agrupar por 'ano', 'natureza' e orientador e contar as ocorrências\n",
    "    contagem_orientacoes = df_orientacoes.groupby(['ano','sigla_natureza','id_lattes_orientadores']).size().reset_index(name='contagem')\n",
    "\n",
    "    # Retornar a contagem de orientações por tipo e por ano\n",
    "    return contagem_orientacoes\n",
    "\n",
    "# Prosseguir com a definição e uso da função para extrair as orientações\n",
    "def extrair_orientacoes(json_data):\n",
    "    colunas = ['id_lattes_orientadores', 'tipo_orientacao', 'natureza', 'titulo', 'idioma', 'ano', 'id_lattes_aluno', 'nome_aluno', 'instituicao', 'pais', 'curso', 'codigo_do_curso', 'bolsa', 'agencia_financiadora', 'codigo_agencia_financiadora', 'nome_orientadores', 'tags', 'Hash']\n",
    "    linhas = []\n",
    "\n",
    "    # Iterar sobre cada tipo de orientação e ano\n",
    "    for tipo_orientacao, anos in json_data.items():\n",
    "        for ano, orientacoes in anos.items():\n",
    "            for orientacao in orientacoes:\n",
    "                # Preparar um dicionário para cada linha de acordo com as colunas definidas\n",
    "                linha = {}\n",
    "                # Adicionar dados específicos da orientação\n",
    "                for campo in orientacao:\n",
    "                    if campo in colunas:\n",
    "                        linha[campo] = orientacao[campo]\n",
    "                # Tratar 'id_lattes_orientadores' como uma lista, juntar os IDs com vírgula se houver mais de um\n",
    "                linha['id_lattes_orientadores'] = ', '.join(orientacao.get('id_lattes_orientadores', []))\n",
    "                # Adicionar o tipo de orientação como uma coluna\n",
    "                linha['tipo_orientacao'] = tipo_orientacao\n",
    "                # Adicionar o ano, garantindo que sobreponha qualquer valor de 'ano' nos dados individuais\n",
    "                linha['ano'] = ano\n",
    "                linhas.append(linha)\n",
    "\n",
    "    return linhas\n",
    "\n",
    "def sigla_natureza(natureza, separador=\"\"):\n",
    "    \"\"\"\n",
    "    Função para converter os valores da coluna 'natureza' em siglas, desconsiderando preposições,\n",
    "    fazendo split de 'natureza' em palavras também pelo caractere \"_\".\n",
    "    \n",
    "    Parâmetros:\n",
    "    - natureza: O valor da coluna 'natureza'.\n",
    "    - separador: O caractere para separar as iniciais. Padrão é \"_\".\n",
    "    \n",
    "    Retorna:\n",
    "    - Uma string que é a sigla formada pelas iniciais das palavras em 'natureza', desconsiderando preposições.\n",
    "    \"\"\"\n",
    "    # Lista de preposições para serem ignoradas\n",
    "    preposicoes = ['e', 'de', 'do', 'da', 'dos', 'das', 'em', 'na', 'no', 'nas', 'nos', 'por', 'para', 'com']\n",
    "\n",
    "    # Mapeamento de exemplo conforme as siglas fornecidas\n",
    "    mapeamento_siglas = {\n",
    "        \"OON\": 1,\n",
    "        \"IC\": 2,\n",
    "        \"MCCAE\": 3,\n",
    "        \"SPD\": 4,\n",
    "        \"TCCG\": 5,\n",
    "        \"DM\": 6,\n",
    "        \"TD\": 7,\n",
    "    }\n",
    "\n",
    "    # Fazendo split por espaço e por underscore\n",
    "    palavras = natureza.replace('_', ' ').replace('-', ' ').split()\n",
    "\n",
    "    # Inicializar a lista de iniciais\n",
    "    iniciais = []\n",
    "\n",
    "    for palavra in palavras:\n",
    "        # Verificar se a palavra não é uma preposição e não está vazia\n",
    "        if palavra.lower() not in preposicoes and palavra:\n",
    "            # Adicionar a inicial em maiúsculo à lista de iniciais\n",
    "            iniciais.append(palavra[0].upper())\n",
    "\n",
    "    # Juntar as iniciais para formar a sigla\n",
    "    sigla = \"\".join(iniciais)\n",
    "\n",
    "    # Aplicar o mapeamento para encontrar o número correspondente à sigla\n",
    "    numero = mapeamento_siglas.get(sigla, \"Desconhecido\")\n",
    "\n",
    "    # Retornar a string formatada com o número e a sigla\n",
    "    return f\"{numero}-{sigla}\"\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plotar_orientacoes_barras_agrupadas(contagem_orientacoes):\n",
    "    # Supondo que 'contagem_orientacoes' seja o DataFrame com dados organizados por tipo e ano\n",
    "\n",
    "    # Criar uma figura com subplots\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "    # Encontrar anos e naturezas únicos para as orientações\n",
    "    anos = sorted(contagem_orientacoes['ano'].unique())\n",
    "\n",
    "    # Mapeamento de exemplo conforme as siglas fornecidas\n",
    "    mapeamento_siglas = {\n",
    "        \"OON\": 1,\n",
    "        \"IC\": 2,\n",
    "        \"MCCAE\": 3,\n",
    "        \"SPD\": 4,\n",
    "        \"TCCG\": 5,\n",
    "        \"DM\": 6,\n",
    "        \"TD\": 7,\n",
    "    }\n",
    "\n",
    "    # Ordenar as naturezas com base nos números associados em mapeamento_siglas\n",
    "    mapeamento_siglas_para_numeros = {sigla: int(sigla.split('-')[0]) for sigla in contagem_orientacoes['sigla_natureza'].unique()}\n",
    "    naturezas_ordenadas = sorted(contagem_orientacoes['sigla_natureza'].unique(), key=lambda x: mapeamento_siglas_para_numeros.get(x, 999))\n",
    "\n",
    "    # Criar uma barra para cada tipo de orientação em cada ano\n",
    "    for natureza in naturezas_ordenadas:\n",
    "        contagem_por_ano = []\n",
    "        for ano in anos:\n",
    "            # Somar as contagens para cada ano e natureza\n",
    "            contagem = contagem_orientacoes[(contagem_orientacoes['ano'] == ano) & (contagem_orientacoes['sigla_natureza'] == natureza)]['contagem'].sum()\n",
    "            contagem_por_ano.append(contagem)\n",
    "        \n",
    "        # Adicionar a barra ao gráfico\n",
    "        fig.add_trace(go.Bar(x=anos, y=contagem_por_ano, name=natureza))\n",
    "\n",
    "    # Atualizar o layout para permitir barras agrupadas\n",
    "    fig.update_layout(barmode='group', title_text='Contagem de Orientações no Programa por Tipo e Ano', xaxis_title=\"Ano\", yaxis_title=\"Quantidade de Orientações\")\n",
    "\n",
    "    # Mostrar o gráfico\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plotar_orientacoes_barras_empilhadas(contagem_orientacoes):\n",
    "    # 'contagem_orientacoes' DataFrame com a contagem por tipos por ano\n",
    "    \n",
    "    # Criar uma figura com subplots\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "    # Encontrar anos únicos para as orientações\n",
    "    anos = sorted(contagem_orientacoes['ano'].unique())\n",
    "\n",
    "    # Mapeamento de exemplo conforme as siglas fornecidas\n",
    "    mapeamento_siglas = {\n",
    "        \"OON\": 1,\n",
    "        \"IC\": 2,\n",
    "        \"MCCAE\": 3,\n",
    "        \"SPD\": 4,\n",
    "        \"TCCG\": 5,\n",
    "        \"DM\": 6,\n",
    "        \"TD\": 7,\n",
    "    }\n",
    "\n",
    "    # Mapeamento de exemplo conforme as siglas fornecidas\n",
    "    mapeamento_siglas_para_numeros = {\n",
    "        \"1-OON\": 1,\n",
    "        \"2-IC\": 2,\n",
    "        \"3-MCCAE\": 3,\n",
    "        \"4-SPD\": 4,\n",
    "        \"5-TCCG\": 5,\n",
    "        \"6-DM\": 6,\n",
    "        \"7-TD\": 7,\n",
    "    }\n",
    "\n",
    "    # Ordenar as naturezas baseando-se no número extraído\n",
    "    naturezas_ordenadas = sorted(contagem_orientacoes['sigla_natureza'].unique(), key=lambda x: mapeamento_siglas_para_numeros.get(x, 999))\n",
    "\n",
    "    # Criar uma barra para cada tipo de orientação em cada ano, seguindo a ordem definida\n",
    "    for natureza in naturezas_ordenadas:\n",
    "        contagem_por_ano = []\n",
    "        for ano in anos:\n",
    "            # Somar as contagens para cada ano e natureza\n",
    "            contagem = contagem_orientacoes[(contagem_orientacoes['ano'] == ano) & (contagem_orientacoes['sigla_natureza'] == natureza)]['contagem'].sum()\n",
    "            # Se a sigla estiver associada ao número 1 ou 2, tornar a contagem negativa\n",
    "            if mapeamento_siglas_para_numeros.get(natureza, 999) in [1, 2, 3, 4]:\n",
    "                contagem = -contagem\n",
    "            contagem_por_ano.append(contagem)\n",
    "        \n",
    "        # Adicionar a barra ao gráfico\n",
    "        fig.add_trace(go.Bar(x=anos, y=contagem_por_ano, name=natureza))\n",
    "\n",
    "    # Atualizar o layout para permitir barras empilhadas e ajustar o eixo Y para mostrar valores negativos\n",
    "    fig.update_layout(\n",
    "        barmode='relative',  # Usar 'relative' para empilhar incluindo valores negativos\n",
    "        title_text='Contagem de Orientações por Tipo e Ano (curta duração abaixo do eixo X)',\n",
    "        xaxis_title=\"Ano\",\n",
    "        yaxis_title=\"Quantidade de Orientações\",\n",
    "        yaxis=dict(zeroline=True, zerolinewidth=2, zerolinecolor='black'),  # Destacar a linha zero\n",
    "    )\n",
    "\n",
    "    # Mostrar o gráfico\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc9e34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['642.files',\n",
       " '644.files',\n",
       " '863.advise.json',\n",
       " '863.files.zip',\n",
       " '863.graph.json',\n",
       " '863.list.json',\n",
       " '863.profile.json',\n",
       " '863.publication.json',\n",
       " '863patents.json',\n",
       " '863researchers_by_area.json',\n",
       " '863vosviewer.json',\n",
       " 'unified_pub.json']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathjson = '.\\_data\\in_json' \n",
    "os.listdir(pathjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aac29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '863.advise.json'\n",
    "contagem_orientacoes = agrupar_orientacoes(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c61df53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "1-OON",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          0,
          6,
          4,
          14,
          12,
          12,
          9,
          9,
          2,
          16,
          17,
          11,
          5,
          4,
          4,
          12,
          13,
          18,
          9,
          3,
          3,
          6,
          4,
          3,
          0
         ]
        },
        {
         "name": "2-IC",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          4,
          8,
          7,
          21,
          15,
          14,
          28,
          35,
          28,
          34,
          55,
          59,
          63,
          57,
          72,
          49,
          62,
          36,
          53,
          43,
          17,
          33,
          42,
          33,
          0
         ]
        },
        {
         "name": "3-MCCAE",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          0,
          0,
          0,
          3,
          5,
          2,
          2,
          3,
          9,
          3,
          2,
          2,
          2,
          2,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0
         ]
        },
        {
         "name": "4-SPD",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          0,
          4,
          2,
          1,
          2,
          3,
          6,
          6,
          15,
          8,
          10,
          20,
          18,
          18,
          15,
          13,
          15,
          22,
          21,
          19,
          33,
          21,
          13,
          22,
          0
         ]
        },
        {
         "name": "5-TCCG",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          1,
          1,
          3,
          1,
          4,
          17,
          7,
          8,
          17,
          5,
          11,
          17,
          4,
          7,
          6,
          6,
          4,
          5,
          7,
          1,
          0,
          2,
          2,
          1,
          0
         ]
        },
        {
         "name": "6-DM",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          6,
          8,
          3,
          6,
          8,
          18,
          21,
          28,
          28,
          18,
          20,
          17,
          34,
          43,
          30,
          29,
          32,
          46,
          34,
          37,
          46,
          26,
          42,
          37,
          0
         ]
        },
        {
         "name": "7-TD",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          7,
          4,
          12,
          14,
          10,
          15,
          8,
          18,
          19,
          17,
          15,
          29,
          23,
          24,
          33,
          32,
          23,
          42,
          37,
          49,
          50,
          43,
          27,
          26,
          1
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Contagem de Orientações no Programa por Tipo e Ano"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Ano"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Quantidade de Orientações"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "1-OON",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          0,
          -6,
          -4,
          -14,
          -12,
          -12,
          -9,
          -9,
          -2,
          -16,
          -17,
          -11,
          -5,
          -4,
          -4,
          -12,
          -13,
          -18,
          -9,
          -3,
          -3,
          -6,
          -4,
          -3,
          0
         ]
        },
        {
         "name": "2-IC",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          -4,
          -8,
          -7,
          -21,
          -15,
          -14,
          -28,
          -35,
          -28,
          -34,
          -55,
          -59,
          -63,
          -57,
          -72,
          -49,
          -62,
          -36,
          -53,
          -43,
          -17,
          -33,
          -42,
          -33,
          0
         ]
        },
        {
         "name": "3-MCCAE",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          0,
          0,
          0,
          -3,
          -5,
          -2,
          -2,
          -3,
          -9,
          -3,
          -2,
          -2,
          -2,
          -2,
          -1,
          -1,
          -1,
          0,
          0,
          0,
          0,
          -1,
          0,
          0,
          0
         ]
        },
        {
         "name": "4-SPD",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          0,
          -4,
          -2,
          -1,
          -2,
          -3,
          -6,
          -6,
          -15,
          -8,
          -10,
          -20,
          -18,
          -18,
          -15,
          -13,
          -15,
          -22,
          -21,
          -19,
          -33,
          -21,
          -13,
          -22,
          0
         ]
        },
        {
         "name": "5-TCCG",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          1,
          1,
          3,
          1,
          4,
          17,
          7,
          8,
          17,
          5,
          11,
          17,
          4,
          7,
          6,
          6,
          4,
          5,
          7,
          1,
          0,
          2,
          2,
          1,
          0
         ]
        },
        {
         "name": "6-DM",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          6,
          8,
          3,
          6,
          8,
          18,
          21,
          28,
          28,
          18,
          20,
          17,
          34,
          43,
          30,
          29,
          32,
          46,
          34,
          37,
          46,
          26,
          42,
          37,
          0
         ]
        },
        {
         "name": "7-TD",
         "type": "bar",
         "x": [
          "2000",
          "2001",
          "2002",
          "2003",
          "2004",
          "2005",
          "2006",
          "2007",
          "2008",
          "2009",
          "2010",
          "2011",
          "2012",
          "2013",
          "2014",
          "2015",
          "2016",
          "2017",
          "2018",
          "2019",
          "2020",
          "2021",
          "2022",
          "2023",
          "2024"
         ],
         "y": [
          7,
          4,
          12,
          14,
          10,
          15,
          8,
          18,
          19,
          17,
          15,
          29,
          23,
          24,
          33,
          32,
          23,
          42,
          37,
          49,
          50,
          43,
          27,
          26,
          1
         ]
        }
       ],
       "layout": {
        "barmode": "relative",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Contagem de Orientações por Tipo e Ano (curta duração abaixo do eixo X)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Ano"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Quantidade de Orientações"
         },
         "zeroline": true,
         "zerolinecolor": "black",
         "zerolinewidth": 2
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotar_orientacoes_barras_agrupadas(contagem_orientacoes)\n",
    "plotar_orientacoes_barras_empilhadas(contagem_orientacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_orientador=[]\n",
    "for i, j in list(df['nome_orientadores'].items()):\n",
    "    list_orientador.append(j[0])\n",
    "\n",
    "ds_orientacoes = pd.Series(list_orientador)\n",
    "ds_orientacoes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ce032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathcsv = '.\\_data\\powerbi' \n",
    "os.listdir(pathcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be258ab8",
   "metadata": {},
   "source": [
    "# Demais passos\n",
    "\n",
    "Calcular índice de publicação em conjunto com alunos do programa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1574aac1",
   "metadata": {},
   "source": [
    "- Levantar nome dos discentes do programa\n",
    "- Levantar os nomes de autores nas publicações de docentes\n",
    "- Identificar por similadidade as publicações onde constam nome de alunos do programa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fbfc46",
   "metadata": {},
   "source": [
    "    Apurar colaborações docente/discente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d78c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter_lista_set(lista):\n",
    "    set1 = set(lista)\n",
    "    return set1\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    '''\n",
    "    Recebe dois conjuntos (sets) como entradas e retorna a similaridade Jaccard entre eles e avalia: \n",
    "    1. calcula a interseção dos dois conjuntos usando a função de interseção \n",
    "    2. calcula a união dos dois conjuntos usando a função de união \n",
    "    3. retorna a razão entre o comprimento da interseção e o comprimento da união, que é a similaridade de Jaccard.\n",
    "    '''\n",
    "    intersection = set1.intersection(set2)\n",
    "    union        = set1.union(set2)\n",
    "    return len(intersection) / len(union)\n",
    "    \n",
    "def montardf_docentes(lista_nomes1=False, lista_nomes2=False):\n",
    "    # print(lista_nomes1)\n",
    "    # print(lista_nomes2)\n",
    "\n",
    "    ## Montagem do dataframe de participação docente\n",
    "    if (lista_nomes1 and lista_nomes2) != False:\n",
    "        ## Criar dataframe com os nomes do grupo de docentes permanentes\n",
    "        file_path = os.path.join(pathcsv,'lista_docentes_permanentes.csv')\n",
    "        df_docentes_permanentes   = pd.read_csv(file_path, header=None)\n",
    "        # df_docentes_permanentes['GRUPO']='Permanente'\n",
    "        # try:\n",
    "        #     df_docentes_permanentes.drop(columns=([1,2]), inplace=True)\n",
    "        # except:\n",
    "        #     pass\n",
    "        # df_docentes_permanentes.columns = ['DOCENTE','GRUPO']\n",
    "        df_docentes_permanentes.columns = ['DOCENTE','IDLATES','PROGRAMA','GRUPO']\n",
    "\n",
    "        ## Criar dataframe com os nomes do grupo de docentes colaboradores\n",
    "        file_path = os.path.join(pathcsv,'lista_docentes_colaboradores.csv')\n",
    "        df_docentes_colaboradores = pd.read_csv(file_path, header=None)\n",
    "        # df_docentes_colaboradores['GRUPO']='Colaborador'\n",
    "        # try:\n",
    "        #     df_docentes_colaboradores.drop(columns=([1,2]), inplace=True)\n",
    "        # except:\n",
    "        #     pass\n",
    "        df_docentes_colaboradores.columns = ['DOCENTE','IDLATES','PROGRAMA','GRUPO']\n",
    "\n",
    "        ## Criar um dataframe único com todos grupos de docentes juntos\n",
    "        df_docentes = pd.concat([df_docentes_permanentes, df_docentes_colaboradores]).reset_index(drop=True)\n",
    "        return df_docentes\n",
    "\n",
    "    elif 'permanentes' in lista_nomes1.lower():\n",
    "        ## Criar dataframe com os nomes do grupo de docentes permanentes\n",
    "        file_path = os.path.join(pathcsv,lista_nomes1)       \n",
    "        df_docentes_permanentes   = pd.read_csv(file_path, header=None)\n",
    "        # df_docentes_permanentes['GRUPO']='Permanente'\n",
    "        # try:\n",
    "        #     df_docentes_permanentes.drop(columns=([1,2]), inplace=True)\n",
    "        # except:\n",
    "        #     pass\n",
    "        df_docentes_permanentes.columns = ['DOCENTE','IDLATES','PROGRAMA','GRUPO']\n",
    "        return df_docentes_permanentes\n",
    "\n",
    "    elif 'colaboradores' in lista_nomes1.lower():\n",
    "        ## Criar dataframe com os nomes do grupo de docentes colaboradores\n",
    "        file_path = os.path.join(pathcsv,lista_nomes1)\n",
    "        df_docentes_colaboradores = pd.read_csv(file_path, header=None)\n",
    "        # df_docentes_colaboradores['GRUPO']='Colaborador'\n",
    "        # try:\n",
    "        #     df_docentes_colaboradores.drop(columns=([1,2]), inplace=True)\n",
    "        # except:\n",
    "        #     pass\n",
    "        df_docentes_colaboradores.columns = ['DOCENTE','IDLATES','PROGRAMA','GRUPO']\n",
    "        return df_docentes_colaboradores\n",
    "    else:\n",
    "        print('Erro ao montar dataframe de docentes, verifique os nomes de arquivo.')\n",
    "        return\n",
    "        \n",
    "def montar_listas(lista_csv, csv_permanentes=None, csv_colaboradores=None):\n",
    "    if csv_permanentes == None and csv_colaboradores == None:\n",
    "        csv_permanentes   = 'lista_docentes_permanentes.csv'\n",
    "        csv_colaboradores = 'lista_docentes_colaboradores.csv'\n",
    "        print(f'\\nNomes de docentes não informados, utilizando caminho e nomes padrão:')\n",
    "        print(f'     Docentes   permanentes de {pathcsv}{csv_permanentes}')\n",
    "        print(f'     Docentes colaboradores de {pathcsv}{csv_colaboradores}')\n",
    "        try:\n",
    "            file_path = os.path.join(pathcsv,csv_permanentes)\n",
    "            df_docperm = pd.read_csv(file_path, header=None)\n",
    "            file_path = os.path.join(pathcsv,csv_colaboradores)\n",
    "            df_docclbr = pd.read_csv(file_path, header=None)\n",
    "            lista_docentes = pd.concat([df_docperm, df_docclbr], ignore_index=True)[0].values\n",
    "            print(f'{len(lista_docentes):4} docentes permanentes e colaboradores encontrados')\n",
    "        except Exception as e:\n",
    "            print(f'Erro ao ler listas de docentes, verificar se os arquivos CSV estão na pasta {pathcsv}')\n",
    "            print(e)\n",
    "    elif 'permanentes' in csv_permanentes.lower():\n",
    "        print(f'\\nArquivo docentes   permanentes informado: {csv_permanentes}')\n",
    "        try:\n",
    "            file_path = os.path.join(pathcsv,csv_permanentes)\n",
    "            lista_docentes = pd.read_csv(file_path, header=None)[0].values\n",
    "            print(f'{len(lista_docentes)} docentes permanentes encontrados')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    elif 'colaboradores' in csv_permanentes.lower():\n",
    "        print(f'\\nArquivo docentes colaboradores informado: {csv_colaboradores}')\n",
    "        try:\n",
    "            file_path = os.path.join(pathcsv,csv_permanentes)\n",
    "            lista_docentes = pd.read_csv(file_path, header=None)[0].values\n",
    "            print(f'{len(lista_docentes)} docentes colaboradores encontrados')\n",
    "        except Exception as e:\n",
    "            print(e)    \n",
    "    else:\n",
    "        print('Erro ao ler listas de docentes, verificar listas')\n",
    "\n",
    "    df_prod   = montardf_producao(lista_csv)\n",
    "    \n",
    "    ## Montar a lista de autores com limpar_nomes remove caracteres, preposições e separa iniciais com espaço\n",
    "    lista_listas = df_prod['AUTORES'].tolist()\n",
    "    lista_autores_artigos = []\n",
    "    for i in lista_listas:\n",
    "        lista_autores_artigos.append(limpar_nomes(i))\n",
    "    \n",
    "    ## Ler nomes de discentes e orientadores\n",
    "    lista_orientadores, lista_discentes = ler_lista_orientacoes()\n",
    "    \n",
    "    return lista_autores_artigos, lista_docentes, lista_orientadores, lista_discentes\n",
    "\n",
    "def montardf_participacao_docente_discente(df_prod, dic_nomes_docentes, dic_nomes_discentes):\n",
    "    ## Montar dataframe de participação docente\n",
    "    df_participacao_docente = pd.DataFrame(dic_nomes_docentes).T\n",
    "    df_participacao_docente.columns = ['DOCENTE','INDICES_ARTIGOS']\n",
    "    df_participacao_docente['AUTORIAS'] = [len(x) for x in df_participacao_docente['INDICES_ARTIGOS']]\n",
    "\n",
    "    ## Montar dataframe de participação discente\n",
    "    df_participacao_discente = pd.DataFrame(dic_nomes_discentes).T\n",
    "    df_participacao_discente.columns = ['DISCENTE','INDICES_ARTIGOS']\n",
    "    df_participacao_discente['AUTORIAS'] = [len(x) for x in df_participacao_discente['INDICES_ARTIGOS']]\n",
    "\n",
    "    ## Criar lista com os artigos onde foi encontado nome de algum docente\n",
    "    artigos_com_docentes=[]\n",
    "    for m in df_participacao_docente['INDICES_ARTIGOS']:\n",
    "        for n in m:\n",
    "            if n not in artigos_com_docentes:\n",
    "                artigos_com_docentes.append(n)\n",
    "    artigos_com_docentes.sort()\n",
    "                \n",
    "    ## Criar lista com os artigos onde foi encontado nome de algum discente\n",
    "    artigos_com_discentes=[]\n",
    "    for m in df_participacao_discente['INDICES_ARTIGOS']:\n",
    "        for n in m:\n",
    "            if n not in artigos_com_discentes:\n",
    "                artigos_com_discentes.append(n)\n",
    "    artigos_com_discentes.sort()\n",
    "                \n",
    "        \n",
    "    ## Criar lista com os artigos onde NÃO foi encontado nome de discente\n",
    "    lista_semparticipacaodiscente=[]\n",
    "    for i in range(len(df_prod.index)):\n",
    "        if i not in artigos_com_discentes and i not in lista_semparticipacaodiscente:\n",
    "            lista_semparticipacaodiscente.append(i)\n",
    "            \n",
    "    ## Criar lista com os artigos onde NÃO foi encontado nome de docente\n",
    "    lista_semparticipacaodocente=[]\n",
    "    for i in range(len(df_prod.index)):\n",
    "        if i not in artigos_com_docentes and i not in lista_semparticipacaodocente:\n",
    "            lista_semparticipacaodocente.append(i)\n",
    "\n",
    "    ## Apresentar resultados das buscas por nomes de autores docentes e discentes\n",
    "    lista_titulos = pd.Series(df_prod['TITULO'].values).unique().tolist()\n",
    "    print(len(lista_titulos),'títulos únicos de artigo encontrados')\n",
    "    pdoc = np.round(100*len(artigos_com_docentes)/len(df_prod.index),2)\n",
    "    spdoc = np.round(100*len(lista_semparticipacaodocente)/len(df_prod.index),2)\n",
    "    print(f'{len(artigos_com_docentes):4} ({pdoc:6}%) artigos com nome de  docente encontrado, faltando {len(lista_semparticipacaodocente):3} ({spdoc:5}%)')\n",
    "\n",
    "    pdis = np.round(100*len(artigos_com_discentes)/len(df_prod.index),2)\n",
    "    spdis = np.round(100*len(lista_semparticipacaodiscente)/len(df_prod.index),2)\n",
    "    print(f'{len(artigos_com_discentes):4} ({pdis:6}%) artigos com nome de discente encontrado, faltando {len(lista_semparticipacaodiscente):3} ({spdis:5}%)')\n",
    "\n",
    "    return df_participacao_docente, df_participacao_discente, lista_semparticipacaodocente, lista_semparticipacaodiscente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616ca80e",
   "metadata": {},
   "source": [
    "    Ler arquivos de dados do disco local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea93d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ler arquivos de publicação de artigos na pasta de arquivos CSV\n",
    "def ler_artigostodosperiodos():    \n",
    "    print(pathcsv)\n",
    "    import os, sys\n",
    "\n",
    "    lista_csv=[]\n",
    "    dirs = os.listdir(pathcsv)\n",
    "    for file in dirs:\n",
    "        if 'Artigos' in file:\n",
    "            lista_csv.append(file)\n",
    "    lista_csv.sort()\n",
    "    \n",
    "    for i in lista_csv:\n",
    "        print(i)\n",
    "\n",
    "    return lista_csv\n",
    "\n",
    "\n",
    "\n",
    "## ler arquivos de publicação de de período determinado\n",
    "def ler_csvptg(inicio=False, final=False, tipo=False, grupo=False):    \n",
    "    import os, sys\n",
    "\n",
    "    print(pathcsv)\n",
    "    lista_csv=[]\n",
    "    dirs = os.listdir(pathcsv)\n",
    "    for file in dirs:\n",
    "        if (str(inicio) or str(final)) == False:\n",
    "            if tipo.lower() == False:\n",
    "                if grupo.lower() == False:\n",
    "                    lista_csv.append(file)\n",
    "\n",
    "        elif (str(inicio) and str(final)) in file.lower():\n",
    "            if unidecode(tipo).lower() in unidecode(file).lower():\n",
    "                if unidecode(grupo).lower() in unidecode(file).lower():\n",
    "                    lista_csv.append(file)\n",
    "    lista_csv.sort()\n",
    "    \n",
    "    for i in lista_csv:\n",
    "        print(i)\n",
    "\n",
    "    return lista_csv\n",
    "\n",
    "\n",
    "\n",
    "def ler_nomesdocentes():    \n",
    "    print(pathcsv)\n",
    "    import os, sys\n",
    "\n",
    "    lista_csv=[]\n",
    "    dirs = os.listdir(pathcsv)\n",
    "    for file in dirs:\n",
    "        if 'nomes_docentes' in file:\n",
    "            lista_csv.append(file)\n",
    "    lista_csv.sort()\n",
    "    \n",
    "    for i in lista_csv:\n",
    "        print(i)\n",
    "\n",
    "    return lista_csv\n",
    "\n",
    "\n",
    "## ler arquivo com as orientações para gerar a lista de discentes\n",
    "def ler_lista_orientacoes():\n",
    "    try:\n",
    "        l1='lista_orientadores-discentes.csv'\n",
    "        df_orientacoes = pd.read_csv(pathcsv+l1, delimiter=';', header=None)\n",
    "        \n",
    "        lista_orientadores = df_orientacoes.iloc[:,0].unique()\n",
    "        lista_discentes    = df_orientacoes.iloc[:,1].unique()\n",
    "        print(f'{len(lista_orientadores):4} orientadores, com {len(lista_discentes)} discentes encontrados')\n",
    "    except Exception as e:\n",
    "        print('Erro ao gerar lista de orientações:')\n",
    "        print(e)\n",
    "        return df_orientacoes\n",
    "        \n",
    "    return lista_orientadores, lista_discentes \n",
    "\n",
    "\n",
    "## montar um dataframe com nome dos discentes de cada orientador\n",
    "def montardf_orientacoes():\n",
    "    try:\n",
    "        l1='lista_orientadores-discentes.csv'\n",
    "        df_orientacoes = pd.read_csv(pathcsv+l1, delimiter=';', header=None)\n",
    "        df_orientacoes.columns=['ORIENTADOR','DISCENTE']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Erro ao dividir dataframe de orientações:')\n",
    "        print(e)\n",
    "        return\n",
    "        \n",
    "    return df_orientacoes\n",
    "\n",
    "\n",
    "\n",
    "def montardf_docentes_permanentes_colaboradores():\n",
    "    try:\n",
    "        l1='lista_docentes_colaboradores.csv'\n",
    "        l2='lista_docentes_permanentes.csv'\n",
    "        df_docclbr = pd.read_csv(os.path.join(pathcsv,l1), header=None)\n",
    "        df_docperm = pd.read_csv(os.path.join(pathcsv,l2), header=None)\n",
    "        df_docentes = pd.concat([df_docperm, df_docclbr], ignore_index=True)\n",
    "        print(f'{len(df_docentes.index):4} docentes permanentes e colaboradores encontrados')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return df_docentes\n",
    "\n",
    "\n",
    "\n",
    "def montardf_producao(lista_csv):\n",
    "    df_public=pd.DataFrame()\n",
    "    for nome_csv in lista_csv:\n",
    "        if 'colaboradores' in nome_csv.lower():\n",
    "            tipo='colaboradores'\n",
    "        else:\n",
    "            tipo='permanentes'\n",
    "        \n",
    "        df_pub = pd.read_csv(pathcsv+nome_csv)\n",
    "\n",
    "        pat='\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'\n",
    "        df_temp1 = df_pub.Data.str.split(pat=pat,expand=True)\n",
    "        df_temp1.columns = (['TITULO','RevAut'])\n",
    "\n",
    "        pat1='\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'\n",
    "        df_temp2 = df_temp1.RevAut.str.split(pat=pat1,expand=True)\n",
    "        df_temp2.columns = (['REVISTA','AUTORES'])\n",
    "\n",
    "        df_temp0 = df_pub.drop(['Data'], axis=1)\n",
    "        df_pub=df_temp0.merge(df_temp1['TITULO'],left_index=True,right_index=True)\n",
    "        df_pub=df_pub.merge(df_temp2,left_index=True,right_index=True)\n",
    "        try:\n",
    "            df_pub.drop(['Issn','Natureza'], axis=1, inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            df_pub.drop(['Tipo','Idioma'], axis=1, inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        df_public = pd.concat([df_public, df_pub], ignore_index=True)\n",
    "        # print(len(df_public.index))\n",
    "        \n",
    "    ## Extrai o período com base nos dados\n",
    "    inicio = min(df_public['Ano'])\n",
    "    final  = max(df_public['Ano'])\n",
    "    \n",
    "    total_artigos=len(df_public.index)\n",
    "    # print(f'{total_artigos:4} publicações de artigos de docentes do programa no período de {inicio} a {final} carregadas...') \n",
    "    \n",
    "    return df_public"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f505b4",
   "metadata": {},
   "source": [
    "### Funções para avaliar a PCD e Pontuação de Impacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eef1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def montardf_impacto_docente_discente(df_prod, dic_nomes_docentes, dic_nomes_discentes, inicio, final):\n",
    "    artigos_com_discentes=[]\n",
    "    artigos_com_docentes=[]\n",
    "    lista_semparticipacaodiscente=[]\n",
    "    lista_semparticipacaodocente=[]\n",
    "\n",
    "    try:\n",
    "        ## Montar dataframe de participação docente\n",
    "        df_impacto_docente = pd.DataFrame(dic_nomes_docentes).T\n",
    "        df_impacto_docente.columns = ['DOCENTE','INDICES_ARTIGOS','EXTRATOS_QUALIS']\n",
    "        df_impacto_docente['AUTORIAS'] = [len(x) for x in df_impacto_docente['INDICES_ARTIGOS']]\n",
    "\n",
    "        ## Criar lista com os artigos onde foi encontado nome de algum docente\n",
    "        for m in df_impacto_docente['INDICES_ARTIGOS']:\n",
    "            for n in m:\n",
    "                if n not in artigos_com_docentes:\n",
    "                    artigos_com_docentes.append(n)\n",
    "        artigos_com_docentes.sort()\n",
    "\n",
    "        ## Criar lista com os artigos onde NÃO foi encontado nome de docente\n",
    "        for i in range(len(df_prod.index)):\n",
    "            if i not in artigos_com_docentes and i not in lista_semparticipacaodocente:\n",
    "                lista_semparticipacaodocente.append(i)\n",
    "    except:\n",
    "        df_impacto_docente = pd.DataFrame()\n",
    "        print('Não foi possível encontrar nenhuma ocorrência dos nomes dos docentes com este conjunto de dados')\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        ## Montar dataframe de participação discente\n",
    "        df_impacto_discente = pd.DataFrame(dic_nomes_discentes).T\n",
    "        df_impacto_discente.columns = ['DISCENTE','INDICES_ARTIGOS','EXTRATOS_QUALIS']\n",
    "        df_impacto_discente['AUTORIAS'] = [len(x) for x in df_impacto_discente['INDICES_ARTIGOS']]\n",
    "\n",
    "        ## Criar lista com os artigos onde foi encontado nome de algum discente\n",
    "        for m in df_impacto_discente['INDICES_ARTIGOS']:\n",
    "            for n in m:\n",
    "                if n not in artigos_com_discentes:\n",
    "                    artigos_com_discentes.append(n)\n",
    "        artigos_com_discentes.sort()\n",
    "    except:\n",
    "        df_impacto_discente = pd.DataFrame()\n",
    "        print('Não foi possível encontrar nenhuma ocorrência dos nomes dos discentes com este conjunto de dados')\n",
    "        pass\n",
    "                \n",
    "    ## Criar lista com os artigos onde NÃO foi encontado nome de discente\n",
    "    for i in range(len(df_prod.index)):\n",
    "        if i not in artigos_com_discentes and i not in lista_semparticipacaodiscente:\n",
    "            lista_semparticipacaodiscente.append(i)\n",
    "\n",
    "    ## Apresentar resultados das buscas por nomes de autores docentes e discentes\n",
    "    lista_titulos = pd.Series(df_prod['TITULO'].values).unique().tolist()\n",
    "    print(len(lista_titulos),'títulos únicos de artigo encontrados')\n",
    "    pdoc  = np.round(100*len(artigos_com_docentes)/len(df_prod.index),2)\n",
    "    spdoc = np.round(100*len(lista_semparticipacaodocente)/len(df_prod.index),2)\n",
    "    print(f'{len(artigos_com_docentes):4} ({pdoc:6}%) artigos com nome de  docente encontrado, faltando {len(lista_semparticipacaodocente):3} ({spdoc:5}%)')\n",
    "\n",
    "    pdis = np.round(100*len(artigos_com_discentes)/len(df_prod.index),2)\n",
    "    spdis = np.round(100*len(lista_semparticipacaodiscente)/len(df_prod.index),2)\n",
    "    print(f'{len(artigos_com_discentes):4} ({pdis:6}%) artigos com nome de discente encontrado, faltando {len(lista_semparticipacaodiscente):3} ({spdis:5}%)')\n",
    "\n",
    "    ## A1=100, A2=80, B1=60, B2=40, B3=20, B4=10, B5=2\n",
    "    soma_impacto=[]\n",
    "    for linha in df_impacto_docente['EXTRATOS_QUALIS']:\n",
    "        impacto=0\n",
    "        for extrato in linha:\n",
    "            if extrato == 'A1':\n",
    "                impacto+=100\n",
    "            elif extrato == 'A2':\n",
    "                impacto+=80\n",
    "            elif extrato == 'B1':\n",
    "                impacto+=60\n",
    "            elif extrato == 'B2':\n",
    "                impacto+=40\n",
    "            elif extrato == 'B3':\n",
    "                impacto+=20\n",
    "            elif extrato == 'B4':\n",
    "                impacto+=10\n",
    "            elif extrato == 'B5':\n",
    "                impacto+=2\n",
    "            elif extrato == 'C':\n",
    "                impacto+=0\n",
    "            elif extrato == 'nan':\n",
    "                impacto+=0\n",
    "        soma_impacto.append(impacto)\n",
    "\n",
    "    df_impacto_docente['SOMA_IMPACTO'] = soma_impacto\n",
    "    qte_anos = (final-inicio+1)\n",
    "    df_impacto_docente['ANOS'] = qte_anos\n",
    "    df_impacto_docente['IMPACTO_MEDIO_ANUAL'] = np.round(df_impacto_docente['SOMA_IMPACTO']/df_impacto_docente['ANOS'],1)\n",
    "\n",
    "    return df_impacto_docente, df_impacto_discente\n",
    "\n",
    "\n",
    "\n",
    "def apurar_pcd_impacto(df_docentes, df_impacto_docente, df_impacto_discente, meta_pcd=50.0, meta_impacto=150.0):\n",
    "    print(f'Total de nomes de docentes em análise: {len(df_docentes.index)}')\n",
    "    print(f'Total de nomes de docentes  encontrados nos artigos: {len(df_impacto_docente.index)}')\n",
    "    print(f'Total de nomes de discentes encontrados nos artigos: {len(df_impacto_discente.index)}')\n",
    "\n",
    "    df_docentes_pcd_impacto = df_docentes\n",
    "    ## Montar lista com os índices do dataframe de artigos onde foram achados nomes de discentes na lista de autores\n",
    "    lista_participacao_discente = []\n",
    "    for artigos_discentes in df_impacto_discente['INDICES_ARTIGOS']:\n",
    "        for indice in artigos_discentes:\n",
    "            lista_participacao_discente.append(indice)\n",
    "\n",
    "    ## Contar a quantidade de participações de discentes que ocorrem no dataframe de produção docente\n",
    "    qte_colab_discente=[]\n",
    "    for docente,artigos_docente in zip(df_impacto_docente['DOCENTE'], df_impacto_docente['INDICES_ARTIGOS']):\n",
    "        qte=0\n",
    "        for indice in artigos_docente:\n",
    "            if indice in lista_participacao_discente:\n",
    "                qte+=1\n",
    "            \n",
    "        qte_colab_discente.append(qte)\n",
    "\n",
    "    df_docentes_pcd_impacto['PUBLICAÇÕES']  = df_impacto_docente['AUTORIAS']\n",
    "    df_docentes_pcd_impacto['COM_DISCENTE'] = qte_colab_discente\n",
    "    df_docentes_pcd_impacto['PCD'] = np.round(100*(df_docentes_pcd_impacto['COM_DISCENTE']/df_impacto_docente['AUTORIAS']),1)\n",
    "    df_docentes_pcd_impacto['IMPACTO'] = df_impacto_docente['SOMA_IMPACTO']\n",
    "    df_docentes_pcd_impacto['IMPACTO_MEDIO_ANUAL'] = df_impacto_docente['IMPACTO_MEDIO_ANUAL']\n",
    "\n",
    "    ## Definir a meta de produção conjunta com discente e apurar o resultado\n",
    "    # meta_pcd=50.0\n",
    "    apuracao_pcd     = df_docentes_pcd_impacto.groupby([df_docentes_pcd_impacto.index,'PCD'])\n",
    "    df_abaixo_pcd    = apuracao_pcd.filter(lambda x: x['PCD'] < meta_pcd)\n",
    "    df_atingiram_pcd = apuracao_pcd.filter(lambda x: x['PCD'] >= meta_pcd)\n",
    "\n",
    "    total_docentes         = len(df_docentes_pcd_impacto.index)\n",
    "\n",
    "    contagem_abaixometa    = len(df_abaixo_pcd.index)\n",
    "    contagem_atingindometa = len(df_atingiram_pcd.index)\n",
    "    indicador_pcd = np.round(100*contagem_atingindometa/total_docentes,1)\n",
    "    print(f'{indicador_pcd}% dos docentes {contagem_atingindometa}/{total_docentes} atingem a meta de {meta_pcd}% publicação com discente')\n",
    "\n",
    "    ## Definir a meta de impacto por pesquisador e para o grupo\n",
    "    # meta_impacto=150\n",
    "    apuracao_impacto     = df_docentes_pcd_impacto.groupby([df_docentes_pcd_impacto.index,'IMPACTO'])\n",
    "    df_abaixo_impacto    = apuracao_impacto.filter(lambda x: x['IMPACTO_MEDIO_ANUAL'] < meta_impacto)\n",
    "    df_atingiram_impacto = apuracao_impacto.filter(lambda x: x['IMPACTO_MEDIO_ANUAL'] >= meta_impacto)\n",
    "\n",
    "    contagem_abaixometa_impacto    = len(df_abaixo_impacto.index)\n",
    "    contagem_atingindometa_impacto = len(df_atingiram_impacto.index)\n",
    "    indicador_impacto = np.round(100*contagem_atingindometa_impacto/total_docentes,1)\n",
    "    print(f'{indicador_impacto}% dos docentes {contagem_atingindometa_impacto}/{total_docentes} atingem a meta de {meta_impacto} pontos de impacto médio por ano das publicações')\n",
    "\n",
    "    return df_docentes_pcd_impacto, apuracao_pcd, df_abaixo_pcd, df_atingiram_pcd, indicador_pcd, indicador_impacto\n",
    "\n",
    "    \n",
    "   \n",
    "def mostrar_partes_achadas(lista_discentes, lista_autores, verbose=False):\n",
    "    partes_achadas=[]\n",
    "    discentes_achados=[]\n",
    "    erros=[]\n",
    "    if verbose == True:\n",
    "        print(f'{padronizar_titulo(lista_autores).lower()}')\n",
    "    try:\n",
    "        ## Buscar pelas partes de nomes de autor em cada linha de autores de artigo\n",
    "        for nome in lista_discentes:\n",
    "            sobrenome, partenome1, partenome2, partenome3 = quebrar_partesnomes(nome)\n",
    "            if verbose == True:\n",
    "                print(f'{sobrenome}, {partenome1} {partenome2} {partenome3}')\n",
    "            strbusca_partes = compilar_partes(sobrenome, partenome1, partenome2, partenome3)\n",
    "            try:\n",
    "                achados_partes = re.search(strbusca_partes, padronizar_titulo(lista_autores).lower())\n",
    "                if achados_partes.span() !=None:\n",
    "                    partes_achadas.append(achados_partes.groups())\n",
    "                    discentes_achados.append(nome)\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                pass\n",
    "\n",
    "        ## Buscar pelas iniciais de partes de nomes de autor, que seguem um sobrenome em cada linha de autores de artigo\n",
    "        for nome in lista_discentes:\n",
    "            sobrenome, inicial1, inicial2, inicial3 = quebrar_iniciais(nome)\n",
    "            if verbose == True:\n",
    "                print(f'{sobrenome}, {inicial1} {inicial2} {inicial3}')\n",
    "            strbusca_iniciais = compilar_iniciais(sobrenome, inicial1, inicial2, inicial3)\n",
    "            try:\n",
    "                achados_iniciais = re.search(strbusca_iniciais, padronizar_titulo(lista_autores).lower())\n",
    "                if achados_iniciais.span() !=None and achados_iniciais.groups() not in discentes_achados:\n",
    "                    partes_achadas.append(achados_iniciais.groups())\n",
    "                    discentes_achados.append(nome)\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                pass\n",
    "    except Exception as e:\n",
    "        # print(f'Erro ao buscar partes de nome; {e}')\n",
    "        print(e)\n",
    "    \n",
    "    return partes_achadas, discentes_achados\n",
    "\n",
    "\n",
    "\n",
    "def listar_achados(docente):\n",
    "    lista_csv = ler_artigostodosperiodos()\n",
    "    lista_autores_artigos, lista_docentes, lista_orientadores, lista_discentes = montar_listas(lista_csv)\n",
    "\n",
    "    df_filtrado = df_impacto_docente[(df_impacto_docente.DOCENTE==docente)]\n",
    "\n",
    "    lista_indices = df_filtrado['INDICES_ARTIGOS'].values.tolist()[0]\n",
    "    n=100\n",
    "    print('-'*n)\n",
    "    print(f'\\nDocente: {docente} | {len(lista_indices)} Publicações identificadas para no período [{inicio} a {final}]')\n",
    "    print()\n",
    "    for indice in lista_indices:\n",
    "        print('-'*n)\n",
    "        print(f'Índice da publicação: {indice}')\n",
    "        print(df_public.iloc[indice].values[:3])\n",
    "        lista_autores = padronizar_titulo(df_public.iloc[indice].values[4])\n",
    "        partes_achadas, discentes_achados = mostrar_partes_achadas(lista_discentes, lista_autores, verbose=False)\n",
    "        print()\n",
    "        print(lista_autores)\n",
    "        print('\\nPartes de nomes de alunos encontrados na lista de autores:')\n",
    "        print(partes_achadas)\n",
    "        print('\\nNomes de alunos considerados como encontrados na lista de autores:')\n",
    "        print(discentes_achados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cda89d",
   "metadata": {},
   "source": [
    "### Funções para plotagem: \n",
    "    \n",
    "    Plotar gráficos de percentual de participação discente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.offsetbox import (TextArea, DrawingArea, OffsetImage, AnnotationBbox)\n",
    "from matplotlib.cbook import get_sample_data\n",
    "plt.rcParams['font.size']      = 12\n",
    "# plt.rcParams[\"figure.figsize\"] = (15,9)\n",
    "\n",
    "\n",
    "\n",
    "def plotar_pcd(df, grupo=False, inicio=False, final=False):\n",
    "    N    = len(df.index)\n",
    "    percentual = (df['PCD'].values.round(1))\n",
    "\n",
    "    ind   = np.arange(N) # the x locations for the groups\n",
    "    width = 0.75         # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "    # criar figura\n",
    "    fig, ax = plt.subplots(figsize=(25,10))\n",
    "\n",
    "    # plotar barras verticais com cores condicionais se abaixo do valor da variável para aceitação\n",
    "    par = 50 \n",
    "    cor = ['yellow' if (x < par) else 'green' for x in percentual]\n",
    "    p1  = ax.bar(ind, percentual, width, \n",
    "                #  yerr=dsvpad, \n",
    "                 error_kw=dict(lw=0.3, capsize=2, capthick=1),\n",
    "                 label='Percentual de publicação com discente', color=cor)\n",
    "\n",
    "    # plotar os rótulos e título\n",
    "    ax.axhline(par, color='red', linewidth=3, linestyle='dotted')\n",
    "    ax.axhline(70, color='gray', linewidth=3, linestyle='dotted')\n",
    "    if (grupo and inicio and final) != False:\n",
    "        ax.set_title(f'Apuração do percentual de publicação de docentes {grupo.upper()} com discente no período de {inicio} a {final}')\n",
    "    elif grupo == False:\n",
    "        ax.set_title(f'Apuração do percentual de publicação de docentes com discente no período de {inicio} a {final}')\n",
    "    else:\n",
    "        ax.set_title(f'Apuração do percentual de publicação com discente')\n",
    "\n",
    "    ax.set_ylabel('Percentual de artigos publicados com discente')\n",
    "    ax.set_xticks(ind)\n",
    "    \n",
    "    labels_pos=np.arange(1,N+1)\n",
    "    ax.set_xticklabels(labels_pos)\n",
    "\n",
    "    # Label with label_type 'center' instead of the default 'edge'\n",
    "    ax.bar_label(p1, label_type='center')\n",
    "    # ax.bar_label(p1, dsvpad)\n",
    "    # ax.set_yticks(range(0,100))\n",
    "    \n",
    "    # respectivo domínio de cada questão no AGREE II\n",
    "    grupos = ['01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01',\n",
    "              '02','02','02','02','02','02','02','02','02','02','02','02','02','02','02','02',]\n",
    "    \n",
    "    # calcular limites de retângulos dos domínios\n",
    "    lista_dominios   = pd.Series(grupos)\n",
    "    largura_dominios = lista_dominios.value_counts().sort_index().values   \n",
    "    altura = 100\n",
    "    rets=[]   \n",
    "    \n",
    "    for i in range(1,len(largura_dominios)+1):\n",
    "        ret = patches.Rectangle((-0.5,0),\n",
    "                                np.sum(largura_dominios[:i]), altura,\n",
    "#                                 linestyle='dashdot',\n",
    "                                linewidth=2,\n",
    "                                edgecolor='b',\n",
    "                                fill = False)\n",
    "        rets.append(ret)\n",
    "    \n",
    "    # plotar os retângulos das dimensões na área do gráfico\n",
    "    for i in rets:\n",
    "        ax.add_patch(i)\n",
    "        \n",
    "    # plotar legenda, comentar para excluir\n",
    "    # ax.legend(bbox_to_anchor=(0.75,-0.05), ncol=2)\n",
    "    \n",
    "    campo='04'\n",
    "    # savefig_respostas(campo)\n",
    "    \n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "def plotar_medias_impacto(df, grupo=False, inicio=False, final=False):\n",
    "    N      = len(df.index)\n",
    "    pontos = (df['IMPACTO_MEDIO_ANUAL'].values.round(1))\n",
    "\n",
    "    ind   = np.arange(N) # the x locations for the groups\n",
    "    width = 0.75         # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "    # criar figura\n",
    "    fig, ax = plt.subplots(figsize=(25,10))\n",
    "\n",
    "    # plotar barras verticais com cores condicionais se abaixo do valor da variável para aceitação\n",
    "    par = 150 \n",
    "    cor = ['yellow' if (x < par) else 'green' for x in pontos]\n",
    "    p1  = ax.bar(ind, pontos, width, \n",
    "                #  yerr=dsvpad, \n",
    "                 error_kw=dict(lw=0.3, capsize=2, capthick=1),\n",
    "                 label='Pontuação em impacto das publicações de docentes', color=cor)\n",
    "\n",
    "    # plotar os rótulos e título\n",
    "    ax.axhline(par, color='red', linewidth=3, linestyle='dotted')\n",
    "    if (grupo and inicio and final) != False:\n",
    "        ax.set_title(f'Apuração da pontuação de impacto das publicações de docentes {grupo.upper()} no período de {inicio} a {final}')\n",
    "    elif (inicio and final) != False:\n",
    "        ax.set_title(f'Apuração da pontuação de impacto das publicações de docentes no período de {inicio} a {final}')\n",
    "    else:\n",
    "        ax.set_title(f'Apuração da pontuação de impacto médio (total do impacto acumulado / quantidade de anos do período) das publicações de docentes')\n",
    "\n",
    "    ax.set_ylabel('Pontuação ponderada pelo Qualis dos artigos publicados')\n",
    "    ax.set_xticks(ind)\n",
    "    \n",
    "    labels_pos=np.arange(1,N+1)\n",
    "    ax.set_xticklabels(labels_pos)\n",
    "\n",
    "    # Label with label_type 'center' instead of the default 'edge'\n",
    "    ax.bar_label(p1, label_type='center')\n",
    "    # ax.bar_label(p1, dsvpad)\n",
    "    vr_maximo = int(max(pontos)+50)\n",
    "    # ax.set_yticks(range(0,vr_maximo))\n",
    "    \n",
    "    # respectivo domínio de cada questão no AGREE II\n",
    "    grupos = ['01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01',\n",
    "              '02','02','02','02','02','02','02','02','02','02','02','02','02','02','02','02',]\n",
    "    \n",
    "    # calcular limites de retângulos dos domínios\n",
    "    lista_dominios   = pd.Series(grupos)\n",
    "    largura_dominios = lista_dominios.value_counts().sort_index().values   \n",
    "    altura = max(pontos)+50\n",
    "    rets=[]   \n",
    "    \n",
    "    for i in range(1,len(largura_dominios)+1):\n",
    "        ret = patches.Rectangle((-0.5,0),\n",
    "                                np.sum(largura_dominios[:i]), altura,\n",
    "#                                 linestyle='dashdot',\n",
    "                                linewidth=2,\n",
    "                                edgecolor='b',\n",
    "                                fill = False)\n",
    "        rets.append(ret)\n",
    "    \n",
    "    # plotar os retângulos das dimensões na área do gráfico\n",
    "    for i in rets:\n",
    "        ax.add_patch(i)\n",
    "        \n",
    "    # plotar legenda, comentar para excluir\n",
    "    # ax.legend(bbox_to_anchor=(0.75,-0.05), ncol=2)\n",
    "    \n",
    "    campo='04'\n",
    "    # savefig_respostas(campo)\n",
    "    \n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd992d",
   "metadata": {},
   "source": [
    "### Funções avaliação PCD e Impacto Médio Anual: \n",
    "    Avaliar indicadores PCD e Somatório do Fator de Impacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes):\n",
    "    ## Ler arquivos de dados\n",
    "    lista_csv   = ler_csvptg(inicio, final, tipo, grupo)\n",
    "    df_public   = montardf_producao(lista_csv)\n",
    "    df_docentes = montardf_docentes(lista_nomes_docentes)\n",
    "    lista_autores_artigos, lista_docentes, lista_orientadores, lista_discentes = montar_listas(lista_csv, lista_nomes_docentes)\n",
    "\n",
    "    ## Avaliação da Publicação Conjunta com Discentes (PCD) e do Impacto Médio Anual (IMA)\n",
    "    dic_nomes_docentes, dic_nomes_discentes, docentes_naoencontrados, discentes_naoencontrados, erros = gerar_dicionarios(df_public, lista_docentes, lista_discentes, inicio, final)\n",
    "    df_impacto_docente, df_impacto_discente = montardf_impacto_docente_discente(df_public, dic_nomes_docentes, dic_nomes_discentes, inicio, final)\n",
    "\n",
    "    ## Gerar gráfico de apuração de impacto médio anual por docente\n",
    "    df_docentes_pcd_impacto, apuracao_pcd, df_abaixo_pcd, df_atingiram_pcd, indicador_pcd, indicador_impacto = apurar_pcd_impacto(df_docentes, df_impacto_docente, df_impacto_discente)\n",
    "    plotar_pcd(df_docentes_pcd_impacto, grupo, inicio, final)\n",
    "    plotar_medias_impacto(df_docentes_pcd_impacto, grupo, inicio, final)\n",
    "\n",
    "    return df_public, df_impacto_docente, df_impacto_discente, df_docentes_pcd_impacto, indicador_pcd, indicador_impacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85feab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ace99be1",
   "metadata": {},
   "source": [
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "# .\n",
    "## Apurar participação discente e impacto artigos dos docentes\n",
    "### Todos os períodos e grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b41aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(pathcsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes_docentes_permanentes   = 'lista_docentes_permanentes.csv'\n",
    "lista_nomes_docentes_colaboradores = 'lista_docentes_colaboradores.csv'\n",
    "df_docentes = montardf_docentes(lista_nomes_docentes_permanentes, lista_nomes_docentes_colaboradores)\n",
    "\n",
    "## Escolha dos arquivos que alimentarão a análise da produção\n",
    "lista_csv = ler_artigostodosperiodos()\n",
    "lista_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff4e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41efa852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod   = montardf_producao(lista_csv)\n",
    "\n",
    "## Mostrar quantitativos lidos\n",
    "print(f'\\nCarregado dataframe com {len(df_prod.index)} linhas:')\n",
    "lista_titulos = pd.Series(df_prod['TITULO'].values).unique().tolist()\n",
    "print(f'{len(lista_titulos):4} artigos distintos publicados no período')\n",
    "lista_revistas = pd.Series(df_prod['REVISTA'].values).unique().tolist()\n",
    "print(f'{len(lista_revistas):4} revistas distintas utilizadas no período')\n",
    "\n",
    "## Ler nomes de docentes, discentes e papel de orientador\n",
    "lista_autores_artigos, lista_docentes, lista_orientadores, lista_discentes = montar_listas(lista_csv)\n",
    "qte_docentes=len(lista_docentes)\n",
    "qte_discentes=len(lista_discentes)\n",
    "total_iteracoes=(qte_docentes+qte_discentes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f486c9c2",
   "metadata": {},
   "source": [
    "### Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,b='',''\n",
    "# get_jaro_distance(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbcfc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b='1','0'\n",
    "get_jaro_distance(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4fb0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "print(len(lista_nomes_autores))\n",
    "print(lista_nomes_autores[0])\n",
    "\n",
    "## Verifica se a divisão em nomes de autor é par (sobrenome separado de nomes por vírgula)\n",
    "for i in lista_nomes_autores[:14]:\n",
    "    qte_nomes_autor = len(i.split(','))\n",
    "    if qte_nomes_autor/2 != qte_nomes_autor//2:\n",
    "        print(qte_nomes_autor,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ed58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m,docente in enumerate(lista_docentes):\n",
    "    nome_docente_padronizado = padronizar_nome(docente).lower()\n",
    "    iniciais_nome_docente    = iniciais_nome(docente).lower()\n",
    "    print(iniciais_nome_docente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4278bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ## Monta a lista de autores com a divisão da string de nomes acima por: sobrenome, nomes\n",
    "    # lst_autores_artigo = []\n",
    "    # lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "    # for n,nomes_autor in enumerate(lista_nomes_autores):\n",
    "    #     autores,erros = organizar_nomes(nomes_autor)\n",
    "    #     # print(autores,'\\n')\n",
    "    #     for o,autor in enumerate(autores):\n",
    "    #         # print(autor)\n",
    "    #         # print(f'{o+1:2}/{qte_autores_artigo:2} nomes de autor do artigo em análise, restando {qte_autores_artigo-o-1:2}')\n",
    "    #         sobrenome_iniciais_autor = iniciais_nome(autor).lower()\n",
    "    #         string_iniciais_autor    = ' '.join(x.strip() for x in sobrenome_iniciais_autor.split(',')[1:])\n",
    "    #         set_iniciais_autor       = converter_lista_set([x.strip() for x in sobrenome_iniciais_autor.split(',')[1:]])\n",
    "    #         print(f'{sobrenome_iniciais_autor:20}|{string_iniciais_autor:^9}|{set_iniciais_autor}')\n",
    "    #     lst_autores_artigo.append(sobrenome_iniciais_autor)\n",
    "    # print(f'Lista organizada de nomes de autores: {len(lst_autores_artigo)} listas de autores de artigos publicados no período')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    qte_docentes     = len(lista_docentes)\n",
    "    qte_discentes    = len(lista_discentes)\n",
    "    total_iteracoes  = (qte_docentes+qte_discentes)\n",
    "    \n",
    "    ## Monta uma lista de strings com nomes dos autores de cada artigo\n",
    "    lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "    qte_artigos         = len(lista_nomes_autores)\n",
    "\n",
    "    ## Monta a lista de autores com a divisão da string de nomes acima por: sobrenome, nomes\n",
    "    lst_autores_artigo = []\n",
    "    for cada_lista_autores in lista_nomes_autores:\n",
    "        lista_organizada, erros_organizar = organizar_nomes(cada_lista_autores)\n",
    "        lst_autores_artigo.append(lista_organizada)\n",
    "    print(f'{len(lst_autores_artigo)} listas de autores de {qte_artigos} artigos publicados no período')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes_autores[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_autores_artigo[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e752b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a='a b c de oliveira'\n",
    "padronizar_nome(a)\n",
    "iniciais_nome(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1c671",
   "metadata": {},
   "source": [
    "### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_dicionarios(df_prod, lista_docentes, lista_discentes, inicio = min(df_prod['Ano']), final  = max(df_prod['Ano'])):\n",
    "    qte_docentes     = len(lista_docentes)\n",
    "    qte_discentes    = len(lista_discentes)\n",
    "    total_iteracoes  = (qte_docentes+qte_discentes)\n",
    "    \n",
    "    ## Monta uma lista de strings com nomes dos autores de cada artigo na forma extraída pelo e-lattes\n",
    "    lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "    qte_artigos         = len(lista_nomes_autores)\n",
    "        \n",
    "    ## Define os limites para considerar duas strings com nomes similares entre si\n",
    "    limite_jaro_nome        = 0.88\n",
    "    limite_jaro_iniciais    = 0.75\n",
    "    limite_jaccard_iniciais = 0.32\n",
    "\n",
    "    ## Função para calcular similaridade dos nomes de docentes com cada nome de autor da lista de autores de cada artigo\n",
    "    t1 = time.time()\n",
    "    dic_nomes_docentes  = {}\n",
    "    dic_nomes_discentes = {}    \n",
    "    erros=[]\n",
    "    rot1='Comparando nome do docente'\n",
    "    rot2='Sobren/Iniciais docen'\n",
    "    rot3='Sobrenome/Iniciais autor'\n",
    "    rot4='I.Doc'\n",
    "    rot5='I.Aut'\n",
    "    rot6='Jaro-Winkler'\n",
    "    rot7='Jaccard'\n",
    "    for m,docente in enumerate(lista_docentes):\n",
    "        achados_docentes     = []\n",
    "        lista_indice_docente = []\n",
    "        lista_qualis_docente = []\n",
    "        docentes_naoencontrados = []          \n",
    "        contagem=m+1\n",
    "        # clear_output(wait=True)       \n",
    "        try:\n",
    "            nome_docente_padronizado = padronizar_nome(docente).lower()\n",
    "            iniciais_nome_docente    = iniciais_nome(docente).lower()\n",
    "            string_iniciais_docente  = ' '.join(x.strip() for x in iniciais_nome_docente.split(',')[1:])\n",
    "            set_iniciais_docente     = converter_lista_set([x.strip() for x in iniciais_nome_docente.split(',')[1:]])                \n",
    "            print(f'\\nCálculo das similaridades autores-docentes (nome/iniciais/Jaccard):')\n",
    "            print(f'{rot1:^40} |{rot2:^20}| {rot3:^25}|{rot4:^5}|{rot5:^5}|{rot6:^15}|{rot7:^10}')\n",
    "            ## Monta a lista de autores com a divisão da string organizada padronizada no formato: {sobrenome, iniciais de nomes}\n",
    "            lst_autores_artigo = []\n",
    "            lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "            for n,nomes_autor in enumerate(lista_nomes_autores):\n",
    "                autores,erros = organizar_nomes(nomes_autor)\n",
    "                for o,autor in enumerate(autores):\n",
    "                    qte_autores_artigo = len(autores)\n",
    "                    # print(f'{o+1:2}/{qte_autores_artigo:2} nomes de autor do artigo em análise, restando {qte_autores_artigo-o-1:2}')\n",
    "                    nome_autor_padronizado = padronizar_nome(autor).lower()\n",
    "                    try:    \n",
    "                        iniciais_nome_autor    = iniciais_nome(autor).lower()\n",
    "                        string_iniciais_autor  = ' '.join(x.strip() for x in iniciais_nome_autor.split(',')[1:])\n",
    "                        set_iniciais_autor     = converter_lista_set([x.strip() for x in iniciais_nome_autor.split(',')[1:]])\n",
    "                        # time.sleep(1)\n",
    "                        ## Cálculos de similaridades entre os nomes do autor e do docente\n",
    "                        if iniciais_nome_docente and iniciais_nome_autor != '':\n",
    "                            similaridade_nome     = get_jaro_distance(iniciais_nome_docente, iniciais_nome_autor)\n",
    "                            similaridade_iniciais = get_jaro_distance(string_iniciais_docente, string_iniciais_autor)\n",
    "                            similaridade_jaccard  = np.round(jaccard_similarity(set_iniciais_docente, set_iniciais_autor),2)\n",
    "                            print(f'\\nCálculo das similaridades autores-discentes (nome/iniciais/Jaccard):')\n",
    "                            print(f'{padronizar_nome(docente):^40} | {iniciais_nome_docente:<20}|{iniciais_nome_autor:<20} {similaridade_nome:^5}|{string_iniciais_docente:^5}|{string_iniciais_autor:^5}|{similaridade_iniciais:^15}|{similaridade_jaccard:^10}')\n",
    "                            clear_output(wait=True)\n",
    "                            if similaridade_nome > limite_jaro_nome and similaridade_iniciais > limite_jaro_iniciais and similaridade_jaccard > limite_jaccard_iniciais:\n",
    "                                if n not in lista_indice_docente:\n",
    "                                    print(f'Similaridade encontrada no artigo {n+1}/{qte_artigos}, docente {m+1}/{qte_docentes}')\n",
    "                                    print(f'{rot1:^40} |{rot2:^20}| {rot3:^25}|{rot4:^5}|{rot5:^5}|{rot6:^15}|{rot7:^10}')\n",
    "                                    print(f'{padronizar_nome(docente):^40} | {iniciais_nome_docente:<20}|{iniciais_nome_autor:<20} {similaridade_nome:^5}|{string_iniciais_docente:^5}|{string_iniciais_autor:^5}|{similaridade_iniciais:^15}|{similaridade_jaccard:^10}')\n",
    "                                    achados_docentes.append(docente)\n",
    "                                    lista_indice_docente.append(n)\n",
    "                                    # print(len(lista_indice_docente))\n",
    "                                    extrato = df_prod['Qualis'][n]\n",
    "                                    lista_qualis_docente.append(extrato)\n",
    "                                    clear_output(wait=True)                                    \n",
    "                    except Exception as e1:\n",
    "                        # print(f'Erro na etapa 1 de gerar_dicionarios, ao tratar iniciais do nome de autor/docente da linha  {n}/{o}/{qte_docentes}/{qte_artigos}')\n",
    "                        # print(e1)\n",
    "                        similaridade_iniciais = np.NaN\n",
    "                        similaridade_jaccard  = np.NaN\n",
    "                        erros.append(('e1_similaridadesdocente',m,n,o,e1))                    \n",
    "                lst_autores_artigo.append(iniciais_nome_autor)\n",
    "            # print(f'Lista organizada de nomes de autores: {len(lst_autores_artigo)} listas de autores de artigos publicados no período')\n",
    "\n",
    "            ## Ao final da leitura todos artigos para cada docente, criar o dicionário de docentes quando docente tenha aparecido na linha de autores\n",
    "            if lista_indice_docente != []:\n",
    "                dic_nomes_docentes[m] = (docente, lista_indice_docente, lista_qualis_docente)\n",
    "            else:\n",
    "                docentes_naoencontrados.append(docente)\n",
    "\n",
    "            tdec=time.time()-t1\n",
    "            # tres=tdec/(m+1)*((qte_docentes-m)+qte_discentes)\n",
    "            # print(f'Analisadas{m+1:4}/{total_iteracoes} iterações em {horas(tdec)}, restando {total_iteracoes-m}. Busca{m+1:4}/{qte_docentes:<4}docente: {docente.title():50}')\n",
    "            # print(f'Nome do docente foi encontrado em {len(lista_indice_docente):2} artigos')\n",
    "        except Exception as e2:\n",
    "            # print(f'Erro na etapa 2 de gerar_dicionarios, ao calcular similaridades de autor/docente  da linha {n}/{o}/{qte_docentes}/{qte_artigos}')\n",
    "            # print(e2)\n",
    "            erros.append(('e2_padronizardocentes',m,n,o,e2)) \n",
    "\n",
    "    ## Função para calcular similaridade dos nomes de discentes com cada nome de autor da lista de autores de cada artigo\n",
    "    for p,discente in enumerate(lista_discentes):\n",
    "        achados_discentes     = []\n",
    "        lista_indice_discente = []\n",
    "        lista_qualis_discente = []\n",
    "        discentes_naoencontrados = []\n",
    "        contagem=m+p+1\n",
    "        # clear_output(wait=True)       \n",
    "        try:\n",
    "            nome_discente_padronizado = padronizar_nome(discente).lower()\n",
    "            iniciais_nome_discente    = iniciais_nome(discente).lower()\n",
    "            string_iniciais_discente  = ' '.join(x.strip() for x in iniciais_nome_discente.split(',')[1:])\n",
    "            set_iniciais_discente     = converter_lista_set([x.strip() for x in iniciais_nome_discente.split(',')[1:]])\n",
    "            rot2='Sobren/Iniciais disce'\n",
    "            rot4='I.Dis'            \n",
    "            ## Monta a lista de autores com a divisão da string organizada padronizada no formato: {sobrenome, iniciais de nomes}\n",
    "            lst_autores_artigo = []\n",
    "            lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "            for n,nomes_autor in enumerate(lista_nomes_autores):\n",
    "                # clear_output(wait=True)\n",
    "                # print(f'Procurando {nome_discente_padronizado.title()} em {n+1:2}/{qte_artigos:<2} artigos, restando {qte_artigos-n-1:<2}')\n",
    "                autores,erros = organizar_nomes(nomes_autor)\n",
    "                for q,autor in enumerate(autores):\n",
    "                    qte_autores_artigo = len(autores)\n",
    "                    nome_autor_padronizado = padronizar_nome(autor).lower()\n",
    "                    # print(f'{q+1:2}/{qte_autores_artigo:2} nomes de autor do artigo em análise, restando {qte_autores_artigo-q-1:2}')\n",
    "                    nome_autor_padronizado = padronizar_nome(autor).lower()\n",
    "                    try:    \n",
    "                        iniciais_nome_autor    = iniciais_nome(autor).lower()\n",
    "                        string_iniciais_autor  = ' '.join(x.strip() for x in iniciais_nome_autor.split(',')[1:])\n",
    "                        set_iniciais_autor     = converter_lista_set([x.strip() for x in iniciais_nome_autor.split(',')[1:]])   \n",
    "                        ## Cálculos de similaridades entre os nomes do autor e do discente\n",
    "                        if iniciais_nome_discente and iniciais_nome_autor != '':\n",
    "                            similaridade_nome     = get_jaro_distance(iniciais_nome_discente, iniciais_nome_autor)\n",
    "                            similaridade_iniciais = get_jaro_distance(string_iniciais_discente, string_iniciais_autor)\n",
    "                            similaridade_jaccard  = np.round(jaccard_similarity(set_iniciais_discente, set_iniciais_autor),2)\n",
    "                            print(f'{padronizar_nome(discente):^40} | {iniciais_nome_discente:<20}|{iniciais_nome_autor:<20} {similaridade_nome:^5}|{string_iniciais_docente:^5}|{string_iniciais_autor:^5}|{similaridade_iniciais:^15}|{similaridade_jaccard:^10}')                            \n",
    "                            if similaridade_nome > limite_jaro_nome and similaridade_iniciais > limite_jaro_iniciais and similaridade_jaccard > limite_jaccard_iniciais:\n",
    "                                if n not in lista_indice_discente:\n",
    "                                    print(f'Similaridade encontrada no artigo {n+1}/{qte_artigos}, discente {p+1}/{qte_discentes}')\n",
    "                                    print(f'{rot1:^40} |{rot2:^20}| {rot3:^25}|{rot4:^5}|{rot5:^5}|{rot6:^15}|{rot7:^10}')\n",
    "                                    print(f'{padronizar_nome(discente):^40} | {iniciais_nome_discente:<20}|{iniciais_nome_autor:<20} {similaridade_nome:^5}|{string_iniciais_discente:^5}|{string_iniciais_autor:^5}|{similaridade_iniciais:^15}|{similaridade_jaccard:^10}')\n",
    "                                    achados_discentes.append(discente)\n",
    "                                    lista_indice_discente.append(n)\n",
    "                                    # print(len(lista_indice_discente))\n",
    "                                    extrato = df_prod['Qualis'][n]\n",
    "                                    lista_qualis_discente.append(extrato)\n",
    "                                    clear_output(wait=True)\n",
    "                    except Exception as e3:\n",
    "                        similaridade_iniciais = np.NaN\n",
    "                        similaridade_jaccard  = np.NaN\n",
    "                        # print(f'Erro na etapa 3 de gerar_dicionarios, ao calcular similaridades de nomes de autor/discente da linha {n}/{o}/{qte_discentes}/{qte_artigos}')\n",
    "                        # print(e3)\n",
    "                        erros.append(('e3_buscadiscentes',p,n,q,e3))\n",
    "        \n",
    "            ## Ao final da leitura todos artigos para cada discente, criar o dicionário de discente quando docente tenha aparecido na linha de autores\n",
    "            if lista_indice_discente != []:\n",
    "                dic_nomes_discentes[o] = (discente, lista_indice_discente, lista_qualis_discente)\n",
    "            else:\n",
    "                discentes_naoencontrados.append(discente)            \n",
    "            \n",
    "            tdec=time.time()-t1\n",
    "            # tres=tdec/(o+p+1)*((qte_discentes-p)+qte_discentes)\n",
    "            # print(f'Analisadas{contagem+1:4}/{total_iteracoes} iterações em {horas(tdec)}, restando {horas(tres)} para iterar {total_iteracoes-contagem-1}. Busca{p+1:4}/{qte_discentes:<4}discente: {discente.title():50}')\n",
    "            # print(f'Nome do discente foi encontrado em {len(lista_indice_discente):2} artigos')   \n",
    "        except Exception as e4:\n",
    "            # print('Erro na etapa 4 de gerar_dicionarios, ao finalizar montagem dos dicionários:',e4)\n",
    "            erros.append(('e4_padronizardiscente',m,n,e4))\n",
    "\n",
    "    return dic_nomes_docentes, dic_nomes_discentes, docentes_naoencontrados, discentes_naoencontrados, erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_nomes_docentes, dic_nomes_discentes, docentes_naoencontrados, discentes_naoencontrados, erros = gerar_dicionarios(df_prod, lista_docentes, lista_discentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d54d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_nomes_docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e47697",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docentes_naoencontrados),'total de nomes de  docentes não encontrados nos artigos')\n",
    "print(len(discentes_naoencontrados),'total de nomes de discentes não encontrados nos artigos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25574691",
   "metadata": {},
   "outputs": [],
   "source": [
    "discentes_naoencontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3084177",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(erros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db856f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "erros[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e31bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista_artigos_problemas = []\n",
    "# lista_autores_problemas = []\n",
    "# for etapa,docente,i,discente,artigo in erros:\n",
    "#     if i not in lista_artigos_problemas:\n",
    "#         lista_artigos_problemas.append(i)\n",
    "#         lista_autores_problemas.append(df_prod['AUTORES'][i])\n",
    "\n",
    "# df_artigos_problemas=pd.DataFrame(lista_artigos_problemas).reset_index(drop=True)\n",
    "# df_artigos_problemas['LISTA_AUTORES'] = lista_autores_problemas\n",
    "# df_artigos_problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11420072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Lista ordenada alfabeticamente pelos sobrenomes de docentes\n",
    "# lista_docentes_sobrenome=[]\n",
    "# for i in lista_docentes:\n",
    "#     lista_docentes_sobrenome.append(iniciais_nome(i))\n",
    "    \n",
    "# lista_docentes_sobrenome.sort()\n",
    "# for j in lista_docentes_sobrenome:\n",
    "#     print(f'{j.lower()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c744196",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2017\n",
    "final  = 2022\n",
    "df_impacto_docente, df_impacto_discente = montardf_impacto_docente_discente(df_prod, dic_nomes_docentes, dic_nomes_discentes, inicio, final)\n",
    "df_impacto_docente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9c51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docentes = montardf_docentes(lista_nomes_docentes_permanentes, lista_nomes_docentes_colaboradores)\n",
    "df_docentes_pcd_impacto, apuracao_pcd, df_abaixo_pcd, df_atingiram_pcd, indicador_pcd, indicador_impacto = apurar_pcd_impacto(df_docentes, df_impacto_docente, df_impacto_discente, meta_pcd=50.0, meta_impacto=150.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d72a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotar_pcd(df_docentes_pcd_impacto)\n",
    "plotar_medias_impacto(df_docentes_pcd_impacto, grupo=False, inicio=False, final=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078c009e",
   "metadata": {},
   "source": [
    "# Apuração segmentada por períodos e grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ff296",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolucao_pcd=[]\n",
    "evolucao_impacto=[]\n",
    "tipo_analise=[]\n",
    "grupo_analise=[]\n",
    "periodo_analise=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d437b0",
   "metadata": {},
   "source": [
    "## Quadriênio 2017-2020 de Docentes Permanentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes_docentes_permanentes   = 'lista_docentes_permanentes.csv'\n",
    "lista_nomes_docentes_colaboradores = 'lista_docentes_colaboradores.csv'\n",
    "df_docentes = montardf_docentes(lista_nomes_docentes_permanentes, lista_nomes_docentes_colaboradores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621055ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2017\n",
    "final  = 2020\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'permanentes'\n",
    "lista_nomes_docentes = 'lista_docentes_permanentes.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)\n",
    "evolucao_pcd.append(indicador_pcd)\n",
    "evolucao_impacto.append(indicador_impacto)\n",
    "tipo_analise.append(tipo)\n",
    "grupo_analise.append(grupo)\n",
    "periodo_analise.append([inicio,final])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc16d3f",
   "metadata": {},
   "source": [
    "## .\n",
    "## Quadriênio 2017-2020 de Docentes Colaboradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb5d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2017\n",
    "final  = 2020\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'colaboradores'\n",
    "lista_nomes_docentes = 'lista_docentes_colaboradores.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)\n",
    "evolucao_pcd.append(indicador_pcd)\n",
    "evolucao_impacto.append(indicador_impacto)\n",
    "tipo_analise.append(tipo)\n",
    "grupo_analise.append(grupo)\n",
    "periodo_analise.append([inicio,final])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f22aa",
   "metadata": {},
   "source": [
    "# .\n",
    "# .\n",
    "# .\n",
    "# Avaliação de meio termo biênio [2021-2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd6823",
   "metadata": {},
   "source": [
    "## Biênio 2021-2022 de Docentes Permanentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2021\n",
    "final  = 2022\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'permanentes'\n",
    "lista_nomes_docentes = 'lista_docentes_permanentes.csv'\n",
    "# lista_nomes_docentes = 'lista_docentes_colaboradores.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)\n",
    "evolucao_pcd.append(indicador_pcd)\n",
    "evolucao_impacto.append(indicador_impacto)\n",
    "tipo_analise.append(tipo)\n",
    "grupo_analise.append(grupo)\n",
    "periodo_analise.append([inicio,final])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f19cf",
   "metadata": {},
   "source": [
    "## .\n",
    "## .\n",
    "## Biênio 2021-2022 de Docentes Colaboradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2021\n",
    "final  = 2022\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'colaboradores'\n",
    "# lista_nomes_docentes = 'lista_docentes_permanentes.csv'\n",
    "lista_nomes_docentes = 'lista_docentes_colaboradores.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)\n",
    "evolucao_pcd.append(indicador_pcd)\n",
    "evolucao_impacto.append(indicador_impacto)\n",
    "tipo_analise.append(tipo)\n",
    "grupo_analise.append(grupo)\n",
    "periodo_analise.append([inicio,final])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c6a47c",
   "metadata": {},
   "source": [
    "# Evolução de indicadores de gestão do programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31656a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicadores = pd.DataFrame({\n",
    "    'TIPO': pd.Series(tipo_analise),\n",
    "    'GRUPO': pd.Series(grupo_analise),\n",
    "    'PERIODOS': pd.Series(periodo_analise),\n",
    "    'META_PCD_50%': pd.Series(evolucao_pcd),\n",
    "    'META_IMPACTO_150ANO': pd.Series(evolucao_impacto),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a687f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicadores.sort_values(by=['GRUPO'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7fd64a",
   "metadata": {},
   "source": [
    "# Conferência em detalhes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2021\n",
    "final  = 2022\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'permanentes'\n",
    "lista_nomes_docentes = 'lista_docentes_permanentes.csv'\n",
    "# lista_nomes_docentes = 'lista_docentes_colaboradores.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f942da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_impacto_docente[:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ccbd6a",
   "metadata": {},
   "source": [
    "## Conferência dos achados de nomes de discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "docente = 'Olindo Assis Martins Filho'\n",
    "listar_achados(docente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1021acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def separar_iniciais(nome):\n",
    "#     import re\n",
    "#     letras_duasconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2}$')            # Duas Letras consoantes maiúsculas juntas do início ao final da string\n",
    "#     letras_tresconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3}$')            # Três Letras consoantes maiúsculas juntas do início ao final da string\n",
    "#     letras_duasconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2},$')       # Duas Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "#     letras_tresconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3},$')       # Três Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "#     partes_nome=[]\n",
    "#     for j in nome.split(' '):\n",
    "#         div_ltrduasconsnts = letras_duasconsnts.findall(j)\n",
    "#         div_ltrtriplicadas = letras_tresconsnts.findall(j)\n",
    "#         div_ltrduasconsntsvirg = letras_duasconsntsvirg.findall(j)\n",
    "#         div_ltrtresconsntsvirg = letras_tresconsntsvirg.findall(j)\n",
    "#         if div_ltrduasconsnts or div_ltrtriplicadas:\n",
    "#             iniciais_separadas = ' '.join(x for x in j)\n",
    "#             partes_nome.append(iniciais_separadas)\n",
    "#         elif div_ltrduasconsntsvirg or div_ltrtresconsntsvirg:\n",
    "#             iniciais_separadas = ' '.join(x for x in j[:-1])\n",
    "#             partes_nome.append(iniciais_separadas+',')\n",
    "#         else:\n",
    "#             partes_nome.append(j)\n",
    "#     nome_separado = ' '.join(x for x in partes_nome).strip()\n",
    "#     return nome_separado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee2749",
   "metadata": {},
   "source": [
    "# Outras funcionalidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374848af",
   "metadata": {},
   "source": [
    "    Formatar tempo (h:min:seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72114631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tempo(start, end):\n",
    "    t=end-start\n",
    "\n",
    "    tempo = timedelta(\n",
    "        weeks   = t//(3600*24*7),\n",
    "        days    = t//(3600*24),\n",
    "        seconds = t,\n",
    "        minutes = t//(60),\n",
    "        hours   = t//(3600),\n",
    "        microseconds=t//1000000,\n",
    "        )\n",
    "    fmt='{H:2}:{M:02}:{S:02}'\n",
    "    return strfdelta(tempo)\n",
    "\n",
    "\n",
    "def horas(segundos): \n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(segundos)) \n",
    "\n",
    "\n",
    "def dias_horas_minutos(td):\n",
    "    x = (td.days, td.seconds//3600, (td.seconds//60)%60, td.seconds)\n",
    "    return x #(days, hrs, mins, seconds)\n",
    "\n",
    "\n",
    "def strfdelta(tdelta, fmt='{H:02}h {M:02}m {S:02}s', inputtype='timedelta'):\n",
    "    \"\"\"Convert a datetime.timedelta object or a regular number to a custom-formatted string, \n",
    "    just like the stftime() method does for datetime.datetime objects.\n",
    "\n",
    "    The fmt argument allows custom formatting to be specified.  Fields can \n",
    "    include seconds, minutes, hours, days, and weeks.  Each field is optional.\n",
    "\n",
    "    Some examples:\n",
    "        '{D:02}d {H:02}h {M:02}m {S:02}s' --> '05d 08h 04m 02s' (default)\n",
    "        '{W}w {D}d {H}:{M:02}:{S:02}'     --> '4w 5d 8:04:02'\n",
    "        '{D:2}d {H:2}:{M:02}:{S:02}'      --> ' 5d  8:04:02'\n",
    "        '{H}h {S}s'                       --> '72h 800s'\n",
    "\n",
    "    The inputtype argument allows tdelta to be a regular number instead of the  \n",
    "    default, which is a datetime.timedelta object.  Valid inputtype strings: \n",
    "        's', 'seconds', \n",
    "        'm', 'minutes', \n",
    "        'h', 'hours', \n",
    "        'd', 'days', \n",
    "        'w', 'weeks'\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert tdelta to integer seconds.\n",
    "    if inputtype == 'timedelta':\n",
    "        remainder = int(tdelta.total_seconds())\n",
    "    elif inputtype in ['s', 'seconds']:\n",
    "        remainder = int(tdelta)\n",
    "    elif inputtype in ['m', 'minutes']:\n",
    "        remainder = int(tdelta)*60\n",
    "    elif inputtype in ['h', 'hours']:\n",
    "        remainder = int(tdelta)*3600\n",
    "    elif inputtype in ['d', 'days']:\n",
    "        remainder = int(tdelta)*86400\n",
    "    elif inputtype in ['w', 'weeks']:\n",
    "        remainder = int(tdelta)*604800\n",
    "\n",
    "    f = Formatter()\n",
    "    desired_fields = [field_tuple[1] for field_tuple in f.parse(fmt)]\n",
    "    possible_fields = ('W', 'D', 'H', 'M', 'S')\n",
    "    constants = {'W': 604800, 'D': 86400, 'H': 3600, 'M': 60, 'S': 1}\n",
    "    values = {}\n",
    "    \n",
    "    for field in possible_fields:\n",
    "        if field in desired_fields and field in constants:\n",
    "            values[field], remainder = divmod(remainder, constants[field])\n",
    "    \n",
    "    return f.format(fmt, **values)\n",
    "\n",
    "\n",
    "# print (timedelta(days=365, hours=8, minutes=15))\n",
    "# print (\"   Hoje é: \" + str(date.today()))\n",
    "# print (\"Agora são: \" + str(datetime.now()))\n",
    "# print (\"Um ano no futuro estaremos em:\" + str(dt.today() + timedelta(days=365)))\n",
    "# hoje = date.today()\n",
    "# print(hoje)\n",
    "# hora = dt.now()\n",
    "# print(hora)\n",
    "# dias_ano = date(hoje.year, 1, 1)\n",
    "# if dias_ano < hoje:\n",
    "#     print (\"Decoridos %d dias do ano\" % ((hoje - dias_ano).days))\n",
    "    \n",
    "# from datetime import datetime\n",
    "# now= datetime.now() #get the current date and time\n",
    "\n",
    "# #%c - local date and time, %x-local's date, %X- local's time\n",
    "# print(now.strftime(\"%c\"))\n",
    "# print(now.strftime(\"%x\"))\n",
    "# print(now.strftime(\"%X\"))\n",
    "\n",
    "# ##### Time Formatting ####\n",
    "# #%I/%H - 12/24 Hour, %M - minute, %S - second, %p - local's AM/PM\n",
    "# print(now.strftime(\"%I:%M:%S %p\")) # 12-Hour:Minute:Second:AM\n",
    "# print(now.strftime(\"%H:%M\")) # 24-Hour:Minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c4e2a6",
   "metadata": {},
   "source": [
    "    Padronizar nomes de autores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69c93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_nomes(linha_texto):\n",
    "    '''\n",
    "    Retira erros e sujeira da string formada pela lista de nomes de autor dos artigos retirada do Lattes\n",
    "     Recebe: Uma string com os nomes de autor\n",
    "    Retorna: Uma string com os nomes de autor, removidas preposições, acentos, e demais erros pontuais\n",
    "    '''\n",
    "    import unicodedata\n",
    "    import re\n",
    "    # print('               Analisando:',linha_texto)\n",
    "    string = linha_texto.replace('Network for Genomic Surveillance in South Africa;Network for Genomic Surveillance in South Africa (NGS-SA);10.1002/jmv.27190;','')\n",
    "    string = string.replace('Autores: ','').replace('(Org)','').replace('(Org.)','').replace('et. al.','').replace('et al','').replace('(Org).','').replace('.','').replace('\\'','')\n",
    "    string = string.replace(',,,',',').replace(',,',',').replace(';',', ').replace('-',' ').replace('S?', 'SA').replace('S?', 'SA').replace('ARA?JO', 'ARAUJO').replace('FL?VIO','FLAVIO').replace('F?BIO','FABIO').replace('VIT?RIO','VITORIO')\n",
    "    string = re.sub(r'[0-9]+', '', string)\n",
    "    partes_string = string.split(' ')\n",
    "\n",
    "    ## Retirar partes de nomes caso sejam preposições\n",
    "    preposicoes = ['da', 'de', 'do', 'das', 'dos', ' e ']\n",
    "    string = ' '.join(x for x in partes_string if x.lower() not in preposicoes)\n",
    "\n",
    "    ## Retirar símbolos não unicode, como acentuação gráfica e cedilha\n",
    "    string = ''.join(ch for ch in unicodedata.normalize('NFKD', string) if not unicodedata.combining(ch))\n",
    "    \n",
    "    ## Retirar iniciais juntas, separando-as com espaço em branco\n",
    "    letras_duasconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2}$')            # Duas Letras consoantes maiúsculas juntas do início ao final da string\n",
    "    letras_tresconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3}$')            # Três Letras consoantes maiúsculas juntas do início ao final da string\n",
    "    letras_duasconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2},$')       # Duas Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "    letras_tresconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3},$')       # Três Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "    \n",
    "    partes_nome=[]\n",
    "    for j in string.split(' '):\n",
    "        div_ltrduasconsnts = letras_duasconsnts.findall(j)\n",
    "        div_ltrtriplicadas = letras_tresconsnts.findall(j)\n",
    "        div_ltrduasconsntsvirg = letras_duasconsntsvirg.findall(j)\n",
    "        div_ltrtresconsntsvirg = letras_tresconsntsvirg.findall(j)\n",
    "        if div_ltrduasconsnts or div_ltrtriplicadas:\n",
    "            iniciais_separadas = ' '.join(x for x in j)\n",
    "            partes_nome.append(iniciais_separadas)\n",
    "        elif div_ltrduasconsntsvirg or div_ltrtresconsntsvirg:\n",
    "            iniciais_separadas = ' '.join(x for x in j[:-1])\n",
    "            partes_nome.append(iniciais_separadas+',')\n",
    "        else:\n",
    "            partes_nome.append(j)\n",
    "    string = ' '.join(x for x in partes_nome).strip()\n",
    "    return string\n",
    "\n",
    "\n",
    "\n",
    "def padronizar_nome(linha_texto):\n",
    "    '''\n",
    "    Procura sobrenomes e abreviaturas e monta nome completo\n",
    "     Recebe: String com todos os sobrenomes e nomes, abreviados ou não\n",
    "    Retorna: Nome completo no formato padronizado em SOBRENOME AGNOME, Partes de nomes\n",
    "      Autor: Marcos Aires (Mar.2022)\n",
    "    '''\n",
    "    import unicodedata\n",
    "    import re\n",
    "    # print('               Analisando:',linha_texto)\n",
    "    partes_string = linha_texto.split(' ')\n",
    "\n",
    "    ## Retirar partes de nomes caso sejam preposições\n",
    "    preposicoes = ['da', 'de', 'do', 'das', 'dos', ' e ']\n",
    "    string = ' '.join(x for x in partes_string if x.lower() not in preposicoes)\n",
    "\n",
    "    ## Retirar símbolos não unicode, como acentuação gráfica e cedilha\n",
    "    string = ''.join(ch for ch in unicodedata.normalize('NFKD', string) if not unicodedata.combining(ch))\n",
    "    \n",
    "    ## Expressões regulares para encontrar padrões de divisão de nomes de autores\n",
    "    sobrenome_inicio   = re.compile(r'^[A-ZÀ-ú-a-z]+,')                  # Sequência de letras maiúsculas no início da string\n",
    "    sobrenome_composto = re.compile(r'^[A-ZÀ-ú-a-z]+[ ][A-ZÀ-ú-a-z]+,')  # Duas sequências de letras no início da string, separadas por espaço, seguidas por vírgula\n",
    "    letra_abrevponto   = re.compile(r'^[A-Z][.]')                        # Uma letra maiúscula no início da string, seguida por ponto\n",
    "    letra_abrevespaco  = re.compile(r'^[A-Z][ ]')                        # Uma letra maiúscula no início da string, seguida por espaço\n",
    "    letras_dobradas    = re.compile(r'[A-Z]{2}')                         # Duas letras maiúsculas juntas\n",
    "    letras_dobradasini = re.compile(r'[A-Z]{2}[ ]')                      # Duas letras maiúsculas juntas, seguidas por espaço\n",
    "    letras_dobradasfim = re.compile(r'[ ][A-Z]{2}')                      # Duas letras maiúsculas juntas, precedidas por espaço\n",
    "\n",
    "    ## Expressões regulares para encontrar iniciais juntas, separando-as com espaço em branco\n",
    "    letras_duasconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2}$')            # Duas Letras consoantes maiúsculas juntas do início ao final da string\n",
    "    letras_tresconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3}$')            # Três Letras consoantes maiúsculas juntas do início ao final da string\n",
    "    letras_duasconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2},$')       # Duas Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "    letras_tresconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3},$')       # Três Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "\n",
    "    ## Agnomes e preprosições a tratar, agnomes vão em maiúsculas para sobrenome e preposições vão em minúsculas para restante das partes de nomes\n",
    "    nomes=[]\n",
    "    agnomes       = ['NETO','JUNIOR','FILHO','SEGUNDO','TERCEIRO','SOBRINHO']\n",
    "    preposicoes   = ['de','da','do','das','dos', ' e ']\n",
    "    nome_completo = ''\n",
    "    \n",
    "    ## Ajustar lista de termos, identificar sobrenomes compostos e ajustar sobrenome com ou sem presença de vírgula\n",
    "    div_sobrenome   = sobrenome_inicio.findall(string)\n",
    "    div_sbrcomposto = sobrenome_composto.findall(string)\n",
    "    \n",
    "    # print('-'*100)\n",
    "    # print('                 Recebido:',string)\n",
    "    \n",
    "    ## Caso haja vírgulas na string, tratar sobrenomes e sobrenomes compostos\n",
    "    if div_sobrenome != [] or div_sbrcomposto != []:\n",
    "        # print('CASO_01: Há víruglas na string')\n",
    "        div = string.split(', ')\n",
    "        sobrenome     = div[0].strip().upper()\n",
    "        try:\n",
    "            div_espaco    = div[1].split(' ')\n",
    "        except:\n",
    "            div_espaco    = ['']\n",
    "        primeiro      = div_espaco[0].strip('.').strip()\n",
    "        \n",
    "        # print('     Dividir por vírgulas:',div)\n",
    "        # print('      Primeira DivVirgula:',sobrenome)\n",
    "        # print('Segunda DivVrg/DivEspaços:',div_espaco)\n",
    "        # print('      Primeira DivEspaços:',primeiro)\n",
    "               \n",
    "        # Caso primeiro nome seja somente duas letras maiúsculas juntas, trata-se de duas iniciais\n",
    "        if len(primeiro)==2 or letras_tresconsnts.findall(primeiro) or letras_duasconsnts.findall(primeiro):\n",
    "            # print('CASO_01.a: Há duas letras ou três letras consoantes juntas, são iniciais')\n",
    "            primeiro_nome=primeiro[0].strip()\n",
    "            # print('          C01.a1_PrimNome:',primeiro_nome)\n",
    "            nomes.append(primeiro[1].strip().upper())\n",
    "            try:\n",
    "                nomes.append(primeiro[2].strip().upper())\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                nomes.append(primeiro[3].strip().upper())\n",
    "            except:\n",
    "                pass            \n",
    "        else:\n",
    "            # print('CASO_01.b: Primeiro nome maior que 2 caracteres')\n",
    "            primeiro_nome = div_espaco[0].strip().title()\n",
    "            # print('          C01.a2_PrimNome:',primeiro_nome)\n",
    "        \n",
    "        ## Montagem da lista de partes de nomes do meio\n",
    "        for nome in div_espaco:\n",
    "            # print('CASO_01.c: Para cada parte de nome da divisão por espaços após divisão por vírgula')\n",
    "            if nome not in nomes and nome.lower()!=primeiro_nome.lower() and nome.lower() not in primeiro_nome.lower() and nome!=sobrenome:   \n",
    "                # print('CASO_01.c1: Se o nome não está nem como primeiro nome, nem sobrenomes')\n",
    "                # print(nome, len(nome))\n",
    "                \n",
    "                ## Avaliar se é abreviatura seguida de ponto e remover o ponto\n",
    "                if len(nome)<=2 and nome.lower() not in preposicoes:\n",
    "                    # print('    C01.c1.1_Nome<=02:',nome)\n",
    "                    for inicial in nome:\n",
    "                        # print(inicial)\n",
    "                        if inicial not in nomes and inicial not in primeiro_nome:\n",
    "                            nomes.append(inicial.replace('.','').strip().title())\n",
    "                elif len(nome)==3 and nome.lower() not in preposicoes:\n",
    "                        # print('    C01.c1.2_Nome==03:',nome)\n",
    "                        for inicial in nome:\n",
    "                            if inicial not in nomes and inicial not in primeiro_nome:\n",
    "                                nomes.append(inicial.replace('.','').strip().title())\n",
    "                else:\n",
    "                    if nome not in nomes and nome!=primeiro_nome and nome!=sobrenome and nome!='':\n",
    "                        if nome.lower() in preposicoes:\n",
    "                            nomes.append(nome.replace('.','').strip().lower())\n",
    "                        else:\n",
    "                            nomes.append(nome.replace('.','').strip().title())\n",
    "                        # print(nome,'|',primeiro_nome)\n",
    "                        \n",
    "        ## Caso haja sobrenome composto que não esteja nos agnomes considerar somente primeira parte como sobrenome\n",
    "        if div_sbrcomposto !=[] and sobrenome.split(' ')[1] not in agnomes and sobrenome.split(' ')[0].lower() not in preposicoes:\n",
    "            # print('CASO_01.d: Sobrenome composto sem agnomes')\n",
    "            # print(div_sbrcomposto)\n",
    "            # print('Sobrenome composto:',sobrenome)\n",
    "            \n",
    "            nomes.append(sobrenome.split(' ')[1].title())\n",
    "            sobrenome = sobrenome.split(' ')[0].upper().strip()\n",
    "            # print('Sobrenome:',sobrenome)\n",
    "            \n",
    "            for i in nomes:\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('    Nomes:',nomes)\n",
    "        \n",
    "        ## Caso haja preposição como agnome desconsiderar e passar para final dos nomes\n",
    "        if div_sbrcomposto !=[] and sobrenome.split(' ')[0].lower() in preposicoes:\n",
    "            # print('CASO_01.e: Preposição no Sobrenome passar para o final dos nomes')\n",
    "            # print('   div_sbrcomposto:', div_sbrcomposto)\n",
    "            # print('Sobrenome composto:',div_sbrcomposto)\n",
    "            \n",
    "            nomes.append(div_sbrcomposto[0].split(' ')[0].lower())\n",
    "            # print('    Nomes:',nomes)\n",
    "            sobrenome = div_sbrcomposto[0].split(' ')[1].upper().strip(',').strip()\n",
    "            # print('Sobrenome:',sobrenome)\n",
    "            \n",
    "            for i in nomes:\n",
    "                # print('CASO_01.e1: Para cada nome avaliar se o sobrenome está na lista')\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('  Nomes:',nomes)\n",
    "        \n",
    "        # print('Ao final do Caso 01')\n",
    "        # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('           Lista de nomes:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "    ## Caso não haja vírgulas na string considera sobrenome o último nome da string dividida com espaço vazio\n",
    "    else:\n",
    "        # print('CASO_02: Não há víruglas na string')\n",
    "        try:\n",
    "            div = string.split(' ')\n",
    "            # print('      Divisões por espaço:',div)\n",
    "            \n",
    "            if div[-1] in agnomes: # nome final é um agnome\n",
    "                sobrenome     = div[-2].upper().strip()+' '+div[-1].upper().strip()\n",
    "                for i in div[1:-2]:\n",
    "                    if i not in sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.title().strip())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.lower().strip())\n",
    "            else:\n",
    "                if len(div[-1]) > 2:\n",
    "                    sobrenome     = div[-1].upper().strip()\n",
    "                    primeiro_nome = div[1].title().strip()\n",
    "                    for i in div[1:-1]:\n",
    "                        if i != sobrenome and i not in preposicoes:\n",
    "                            nomes.append(i.title().strip())\n",
    "                        if i in preposicoes:\n",
    "                            nomes.append(i.lower().strip())\n",
    "                else:\n",
    "                    sobrenome     = div[-2].upper().strip()\n",
    "                    for i in div[-1]:\n",
    "                        nomes.append(i.title())\n",
    "                    primeiro_nome = nomes[0].title().strip()\n",
    "                    for i in div[1:-1]:\n",
    "                        if i != sobrenome and i not in preposicoes:\n",
    "                            nomes.append(i.title().strip())\n",
    "                        if i in preposicoes:\n",
    "                            nomes.append(i.lower().strip())\n",
    "        except:\n",
    "            sobrenome = div[-1].upper().strip()\n",
    "            for i in div[1:-1]:\n",
    "                    if i != sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.title().strip())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.lower().strip())\n",
    "            \n",
    "        if sobrenome.lower() != div[0].lower().strip():\n",
    "            primeiro_nome=div[0].title().strip()\n",
    "        else:\n",
    "            primeiro_nome=''\n",
    "        \n",
    "        # print('Ao final do Caso 02')\n",
    "        # print('    Sobrenome sem vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome sem vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('Nomes do meio sem vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "    ## Encontrar e tratar como abreviaturas termos com apenas uma ou duas letras iniciais juntas, com ou sem ponto\n",
    "    for j in nomes:\n",
    "        # print('CASO_03: Avaliar cada nome armazenado na variável nomes')\n",
    "        # Procura padrões com expressões regulares na string\n",
    "        div_sobrenome      = sobrenome_inicio.findall(j)\n",
    "        div_sbrcomposto    = sobrenome_composto.findall(j)\n",
    "        div_abrevponto     = letra_abrevponto.findall(j)\n",
    "        div_abrevespaco    = letra_abrevespaco.findall(j)\n",
    "        div_ltrdobradasini = letras_dobradasini.findall(j)\n",
    "        div_ltrdobradasfim = letras_dobradasfim.findall(j)\n",
    "        div_ltrdobradas    = letras_dobradas.findall(j)\n",
    "        div_ltrduasconsnts = letras_duasconsnts.findall(j)\n",
    "        div_ltrtriplicadas = letras_tresconsnts.findall(j)\n",
    "        tamanho=len(j)\n",
    "        # print('\\n', div_ltrdobradasini, div_ltrdobradasfim, tamanho, 'em:',j,len(j))\n",
    "        \n",
    "        ## Caso houver abreviatura com uma letra em maiúscula nos nomes\n",
    "        if div_abrevponto !=[] or tamanho==1:\n",
    "            # print('CASO_03.1: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "            nome = j.replace('.','').strip()\n",
    "            if nome not in nomes and nome != sobrenome and nome != primeiro_nome:\n",
    "                # print('CASO_03.1a: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "                nomes.append(nome.upper())\n",
    "        \n",
    "        ## Caso houver duas inicias juntas em maiúsculas\n",
    "        elif div_ltrdobradasini !=[] or div_ltrdobradasfim !=[] or div_ltrdobradas !=[] :\n",
    "            # print('CASO_03.2: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "            for letra in j:\n",
    "                # print('CASO_03.2a: Avaliar cada inicial do nome')\n",
    "                if letra not in nomes and letra != sobrenome and letra != primeiro_nome:\n",
    "                    # print('CASO_03.2a.1: Se não estiver adicionar inicial aos nomes')\n",
    "                    nomes.append(letra.upper())\n",
    "        \n",
    "        # Caso haja agnomes ao sobrenome\n",
    "        elif sobrenome in agnomes:\n",
    "            # print('CASO_03.3: Há agnomes nos sobrenomes')\n",
    "            sobrenome = nomes[-1].upper()+' '+sobrenome\n",
    "            # print(sobrenome.split(' '))\n",
    "            # print('Sobrenome composto:',sobrenome)\n",
    "            for i in nomes:\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('Nomes do meio:',nomes)\n",
    "            \n",
    "        else:\n",
    "            # print('CASO_03.4: Não há agnomes nos sobrenomes')\n",
    "            if j not in nomes and j not in sobrenome and j != primeiro_nome:\n",
    "                if len(nomes) == 1:\n",
    "                    nomes.append(j.upper())\n",
    "                elif 1 < len(nomes) <= 3:\n",
    "                    nomes.append(j.lower())\n",
    "                else:\n",
    "                    nomes.append(j.title())\n",
    "         \n",
    "        # print('Ao final do Caso 03')\n",
    "        # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "    nomes_meio=' '.join([str for str in nomes]).strip()\n",
    "    # print('        Qte nomes do meio:',nomes,len(nomes))\n",
    "    \n",
    "    if primeiro_nome.lower() == sobrenome.lower():\n",
    "        # print('CASO_04: Primeiro nome é igual ao sobrenome')\n",
    "        try:\n",
    "            primeiro_nome=nomes_meio.split(' ')[0]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            nomes_meio.remove(sobrenome)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        # print('Ao final do caso 04')\n",
    "        # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "    ## Caso sobrenome seja só de 1 letra passá-lo para nomes e considerar o próximo nome como sobrenome\n",
    "    for i in range(len(div)):\n",
    "        if len(sobrenome)==1 or sobrenome.lower() in preposicoes:\n",
    "            # print('CASO_05: Mudar sobrenomes até o adequado')\n",
    "            div    = string.split(', ')\n",
    "            # print('Divisão por vírgulas:',div)\n",
    "            avaliar0       = div[0].split(' ')[0].strip()\n",
    "            if 1< len(avaliar0) < 3:\n",
    "                # print('CASO_05.1: 1 < Sobrenome < 3 fica em minúsculas')\n",
    "                sbrn0          = avaliar0.lower()\n",
    "            else:\n",
    "                # print('CASO_05.2: Sobrenome de tamanho 1 ou maior que 3 fica em maiúsculas')\n",
    "                sbrn0          = avaliar0.title()\n",
    "            # print('sbrn0:',sbrn0, len(sbrn0))\n",
    "            \n",
    "            try:\n",
    "                avaliar1=div[0].split(' ')[1].strip()\n",
    "                # print('avaliar0',avaliar0)\n",
    "                # print('avaliar1',avaliar1)\n",
    "                if 1 < len(avaliar1) <=3:\n",
    "                    sbrn1     = avaliar1.lower()\n",
    "                else:\n",
    "                    sbrn1     = avaliar1.title()\n",
    "                # print('sbrn1:',sbrn1, len(sbrn1))\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if div != []:\n",
    "                # print('CASO_05.3: Caso haja divisão por vírgulas na string')\n",
    "                try:\n",
    "                    div_espaco     = div[1].split(' ')\n",
    "                except:\n",
    "                    div_espaco     = div[0].split(' ')\n",
    "                sobrenome      = div_espaco[0].strip().upper()\n",
    "                try:\n",
    "                    primeiro_nome  = div_espaco[1].title().strip()\n",
    "                except:\n",
    "                    primeiro_nome  = div_espaco[0].title().strip()\n",
    "                if len(sbrn0) == 1:\n",
    "                    # print('CASO_05.3a: Avalia primeiro sobrenome de tamanho 1')\n",
    "                    # print('Vai pros nomes:',str(sbrn0).title())\n",
    "                    nomes_meio = nomes_meio+str(' '+sbrn0.title())\n",
    "                    # print('   NomesMeio:',nomes_meio)\n",
    "\n",
    "                elif 1 < len(sbrn0) <= 3:\n",
    "                    # print('CASO_05.3b: Avalia primeiro sobrenome 1< tamanho <=3')\n",
    "                    # print('Vão pros nomes sbrn0:',sbrn0, 'e sbrn1:',sbrn1)\n",
    "\n",
    "                    div_tresconsoantes = letras_tresconsnts.findall(sobrenome)\n",
    "                    if div_tresconsoantes != []:\n",
    "                        # print('CASO_05.4: Três consoantes como sobrenome')\n",
    "                        for letra in sobrenome:\n",
    "                            nomes.append(letra)\n",
    "\n",
    "                        if len(sobrenome) >2:\n",
    "                            sobrenome=nomes[0]\n",
    "                        else:\n",
    "                            sobrenome=nomes[1]\n",
    "                        nomes.remove(sobrenome)\n",
    "                        primeiro_nome=nomes[0]\n",
    "                        nomes_meio=' '.join([str for str in nomes[1:]]).strip()\n",
    "                        nome_completo=sobrenome.upper()+', '+nomes_meio                \n",
    "                    \n",
    "                    try:                       \n",
    "                        # print(' 05.3b    Lista de Nomes:',nomes_meio)\n",
    "                        nomes_meio=nomes_meio.replace(sbrn0,'')\n",
    "                        # print(' 05.3b ReplaceSobrenome0:',nomes_meio)\n",
    "                        nomes_meio=nomes_meio.replace(sbrn1,'')\n",
    "                        # print(' 05.3b ReplaceSobrenome1:',nomes_meio)\n",
    "                    except Exception as e:\n",
    "                        # print('   Erro ReplaceSobrenome:',e)\n",
    "                        pass\n",
    "                    try:\n",
    "                        nomes_meio.replace(primeiro_nome.title(),'')\n",
    "                        nomes_meio.replace(primeiro_nome.lower(),'')\n",
    "                        nomes_meio.replace(primeiro_nome,'')\n",
    "                        # print(' 05.3b Replace PrimNome:',nomes_meio)\n",
    "                    except Exception as e:\n",
    "                        print('Erro no try PrimeiroNome:',e)\n",
    "                        pass\n",
    "                    nomes_meio = nomes_meio.replace(sobrenome,'')\n",
    "                    try:\n",
    "                        for n,i in enumerate(avaliar1):\n",
    "                            nomes.append(i.upper())\n",
    "                            sbrn1     = avaliar1[0]\n",
    "                        else:\n",
    "                            sbrn1     = avaliar1.title()\n",
    "                        # print('sbrn1:',sbrn1, len(sbrn1))\n",
    "                        nomes_meio = nomes_meio+str(' '+sbrn0)+str(' '+sbrn1)\n",
    "                    except:\n",
    "                        nomes_meio = nomes_meio+str(' '+sbrn0)\n",
    "                    nomes      = nomes_meio.strip().strip(',').split(' ')\n",
    "                    # print(' 05.3b NomesMeio:',nomes_meio)\n",
    "                    # print(' 05.3b     Nomes:',nome)\n",
    "\n",
    "                else:\n",
    "                    # print('CASO_05.3c: Avalia primeiro sobrenome >3')\n",
    "                    nomes_meio = nomes_meio+str(' '+div[0].strip().title())\n",
    "                    nomes      = nomes_meio.strip().split(' ')\n",
    "                    # print(' 05.3c NomesMeio:',nomes_meio)\n",
    "                    # print(' 05.3c     Nomes:',nomes)\n",
    "\n",
    "                nomes_meio=nomes_meio.replace(sobrenome,'').replace(',','').strip()\n",
    "                nomes_meio=nomes_meio.replace(primeiro_nome,'').strip()\n",
    "\n",
    "            # print('Ao final do caso 05')\n",
    "            # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "            # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "            # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "    if sobrenome != '' and primeiro_nome !='':\n",
    "        nome_completo=sobrenome.upper().replace(',','')+', '+primeiro_nome.replace(',','')+' '+nomes_meio.replace(sobrenome,'').replace(',','')\n",
    "    elif sobrenome != '':\n",
    "        nome_completo=sobrenome.upper().replace(',','')+', '+nomes_meio.replace(sobrenome,'').replace(',','')\n",
    "    else:\n",
    "        nome_completo=sobrenome.upper()\n",
    "    \n",
    "#     print('Após ajustes finais')\n",
    "#     print('     Sobrenome:',sobrenome)\n",
    "#     print(' Primeiro Nome:',primeiro_nome)\n",
    "#     print('         Nomes:',nomes)\n",
    "#     print('     NomesMeio:',nomes_meio)        \n",
    "        \n",
    "#     print('                Resultado:',nome_completo)\n",
    "    \n",
    "    return nome_completo.strip()\n",
    "\n",
    "\n",
    "\n",
    "def padronizar_titulo(titulo_bruto):\n",
    "    '''\n",
    "    Retira acentos, expressão (Org.) e espaços vazios do título da publicação\n",
    "    Autor: Marcos Aires (Fev.2022)\n",
    "    '''\n",
    "    import re\n",
    "    import unicodedata\n",
    "    \n",
    "    ## Retirar caracteres não unicode\n",
    "    string = ''.join(ch for ch in unicodedata.normalize('NFKD', titulo_bruto) if not unicodedata.combining(ch))\n",
    "    string = string.replace('(Org)','').replace('(Org.)','').replace('(Org).','').replace('.',' ').replace('-',' ').replace('\\'',' ').lower()\n",
    "    \n",
    "    substitui_iniciais=[('rl,', 'r l,'), ('hs,', 'h s,'), ('gc,', 'g c,'), ('sf,', 's f,'), ('fo,', 'f o,'), (' oa,', ' o a,'), ('mss,', 'm s s,'), \n",
    "                        ('lagares, ma', 'lagares, m a'), ('cota, gf', 'cota, g f'), ('cota gf,', 'cota, g f,'), ('diotaiut,', 'diotaiuti,'), ('grenfell, r f q','queiroz, rafaella fortini grenfell')]\n",
    "    for i in substitui_iniciais:\n",
    "        string = string.replace(i[0], i[1])\n",
    "    \n",
    "    ## Retirar preposições\n",
    "    preposicoes = ['da', 'de', 'do', 'das', 'dos']\n",
    "    partes_string = string.split(' ')\n",
    "    string = ' '.join(x for x in partes_string if x.lower() not in preposicoes)\n",
    "    \n",
    "    titulo_padronizado = string.strip().strip('\"')\n",
    "    \n",
    "    return titulo_padronizado\n",
    "\n",
    "\n",
    "\n",
    "def iniciais_nome(linha_texto):\n",
    "    '''\n",
    "    Função para retornar sobrenome+iniciais das partes de nome, na forma: SOBRENOME, X Y Z\n",
    "     Recebe: String com nome\n",
    "    Retorna: Tupla com nome e sua versão padronizada em sobrenome+agnome em maiúsculas, seguida de vírgula e das iniciais das demais partes de nome\n",
    "      Autor: Marcos Aires (Mar.2022)\n",
    "    '''\n",
    "    import unicodedata\n",
    "    import re\n",
    "    # print('               Analisando:',linha_texto)\n",
    "    \n",
    "    ## Retirar caracteres não unicode\n",
    "    string = ''.join(ch for ch in unicodedata.normalize('NFKD', linha_texto) if not unicodedata.combining(ch))\n",
    "    string = string.replace('(Org)','').replace('(Org.)','').replace('(Org).','').replace('.','')\n",
    "    \n",
    "    ## Retirar preposições\n",
    "    preposicoes   = ['da','de','do','das','dos']\n",
    "    partes_string = string.split(' ')\n",
    "    string = ' '.join(x for x in partes_string if x.lower() not in preposicoes)\n",
    "        \n",
    "    ## Expressões regulares para encontrar padrões de divisão de nomes de autores\n",
    "    sobrenome_inicio   = re.compile(r'^[A-ZÀ-ú-a-z]+,')                 # Sequência de letras maiúsculas no início da string\n",
    "    sobrenome_composto = re.compile(r'^[A-ZÀ-ú-a-z]+[ ][A-ZÀ-ú-a-z]+,') # Duas sequências de letras no início da string, separadas por espaço, seguidas por vírgula\n",
    "    letra_abrevponto   = re.compile(r'^[A-Z][.]')                       # Uma letra maiúscula no início da string, seguida por ponto\n",
    "    letra_abrevespaco  = re.compile(r'^[A-Z][ ]')                       # Uma letra maiúscula no início da string, seguida por espaço\n",
    "    letras_dobradas    = re.compile(r'[A-Z]{2}')                        # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "    letras_dobradasini = re.compile(r'[A-Z]{2}[ ]')                     # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "    letras_dobradasfim = re.compile(r'[ ][A-Z]{2}')                     # Duas letras maiúsculas juntas no final da string, precedida por espaço\n",
    "        \n",
    "    nomes=[]\n",
    "    agnomes       = ['NETO','JUNIOR','FILHO','SEGUNDO','TERCEIRO', 'SOBRINHO']\n",
    "    nome_completo = ''\n",
    "    \n",
    "    ## Ajustar lista de termos, identificar sobrenomes compostos e ajustar sobrenome com ou sem presença de vírgula\n",
    "    div_sobrenome      = sobrenome_inicio.findall(string)\n",
    "    div_sbrcomposto    = sobrenome_composto.findall(string)\n",
    "    \n",
    "    ## Caso haja vírgulas na string, tratar sobrenomes e sobrenomes compostos\n",
    "    if div_sobrenome != [] or div_sbrcomposto != []:\n",
    "        div   = string.split(', ')\n",
    "        sobrenome     = div[0].strip().upper()\n",
    "        try:\n",
    "            div_espaco    = div[1].split(' ')\n",
    "        except:\n",
    "            div_espaco  = ['']\n",
    "        primeiro      = div_espaco[0].strip('.')\n",
    "        \n",
    "        ## Caso primeiro nome sejam somente duas letras maiúsculas juntas, trata-se de duas iniciais\n",
    "        if len(primeiro)==2:\n",
    "            primeiro_nome=primeiro[0].strip()\n",
    "            nomes.append(primeiro[1].strip())\n",
    "        else:\n",
    "            primeiro_nome = div_espaco[0].strip().title()\n",
    "        \n",
    "        ## Montagem da lista de nomes do meio\n",
    "        for nome in div_espaco:\n",
    "            if nome not in nomes and nome.lower()!=primeiro_nome.lower() and nome.lower() not in primeiro_nome.lower() and nome!=sobrenome:   \n",
    "                # print(nome, len(nome))\n",
    "                \n",
    "                ## Avaliar se é abreviatura seguida de ponto e remover o ponto\n",
    "                if len(nome)<=2 and nome.lower() not in preposicoes:\n",
    "                    for inicial in nome:\n",
    "                        # print(inicial)\n",
    "                        if inicial not in nomes and inicial not in primeiro_nome:\n",
    "                            nomes.append(inicial.replace('.','').strip().title())\n",
    "                else:\n",
    "                    if nome not in nomes and nome!=primeiro_nome and nome!=sobrenome and nome!='':\n",
    "                        if nome.lower() in preposicoes:\n",
    "                            nomes.append(nome.replace('.','').strip().lower())\n",
    "                        else:\n",
    "                            nomes.append(nome.replace('.','').strip().title())\n",
    "                        # print(nome,'|',primeiro_nome)\n",
    "                        \n",
    "        ## Caso haja sobrenome composto que não esteja nos agnomes considerar somente primeira parte como sobrenome\n",
    "        if div_sbrcomposto !=[] and sobrenome.split(' ')[1] not in agnomes:\n",
    "            # print(div_sbrcomposto)\n",
    "            # print('Sobrenome composto:',sobrenome)\n",
    "            nomes.append(sobrenome.split(' ')[1].title())\n",
    "            sobrenome = sobrenome.split(' ')[0].upper()\n",
    "            # print('Sobrenome:',sobrenome.split(' '))\n",
    "            for i in nomes:\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('Nomes do meio:',nomes)\n",
    "        \n",
    "        # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "    ## Caso não haja vírgulas na string considera sobrenome o último nome da string dividida com espaço vazio\n",
    "    else:\n",
    "        try:\n",
    "            div       = string.split(' ')\n",
    "            if div[-2] in agnomes:\n",
    "                sobrenome = div[-2].upper()+' '+div[-1].strip().upper()\n",
    "                for i in nomes[1:-2]:\n",
    "                    if i not in sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.strip().title())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.strip().lower())\n",
    "            else:\n",
    "                sobrenome = div[-1].strip().upper()\n",
    "                for i in div[1:-1]:\n",
    "                    if i not in sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.strip().title())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.strip().lower())\n",
    "        except:\n",
    "            sobrenome = div[-1].strip().upper()\n",
    "            for i in div[1:-1]:\n",
    "                    if i not in sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.strip().title())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.strip().lower())\n",
    "            \n",
    "        if sobrenome.lower() != div[0].strip().lower():\n",
    "            primeiro_nome=div[0].strip().title()\n",
    "        else:\n",
    "            primeiro_nome=''\n",
    "        \n",
    "        # print('    Sobrenome sem vírgula:',sobrenome)\n",
    "        # print('Primeiro nome sem vírgula:',primeiro_nome)\n",
    "        # print('Nomes do meio sem vírgula:',nomes)\n",
    "    \n",
    "    # Encontrar e tratar como abreviaturas termos com apenas uma ou duas letras iniciais juntas, com ou sem ponto\n",
    "    for j in nomes:\n",
    "        # Procura padrões com expressões regulares na string\n",
    "        div_sobrenome      = sobrenome_inicio.findall(j)\n",
    "        div_sbrcomposto    = sobrenome_composto.findall(j)\n",
    "        div_abrevponto     = letra_abrevponto.findall(j)\n",
    "        div_abrevespaco    = letra_abrevespaco.findall(j)\n",
    "        div_ltrdobradasini = letras_dobradasini.findall(j)\n",
    "        div_ltrdobradasfim = letras_dobradasfim.findall(j)\n",
    "        div_ltrdobradas    = letras_dobradas.findall(j)\n",
    "        tamanho=len(j)\n",
    "        # print('\\n', div_ltrdobradasini, div_ltrdobradasfim, tamanho, 'em:',j,len(j))\n",
    "        \n",
    "        #caso houver abreviatura com uma letra em maiúscula nos nomes\n",
    "        if div_abrevponto !=[] or tamanho==1:\n",
    "            cada_nome = j.replace('.','').strip()\n",
    "            if cada_nome not in nomes and cada_nome != sobrenome and nome != primeiro_nome:\n",
    "                nomes.append(cada_nome)\n",
    "        \n",
    "        #caso houver duas inicias juntas em maiúsculas\n",
    "        elif div_ltrdobradasini !=[] or div_ltrdobradasfim !=[] or div_ltrdobradas !=[] :\n",
    "            for letra in j:\n",
    "                if letra not in nomes and letra != sobrenome and letra != primeiro_nome:\n",
    "                    nomes.append(letra)\n",
    "        \n",
    "        #caso haja agnomes ao sobrenome\n",
    "        elif sobrenome in agnomes:\n",
    "            sobrenome = nomes[-1].upper()+' '+sobrenome\n",
    "            # print(sobrenome.split(' '))\n",
    "            # print('Sobrenome composto:',sobrenome)\n",
    "            for i in nomes:\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('Nomes do meio:',nomes)\n",
    "            \n",
    "        else:\n",
    "            if j not in nomes and j not in sobrenome and j != primeiro_nome:\n",
    "                nomes.append(j)\n",
    "    \n",
    "    nomes_meio=' '.join([str[0] for str in nomes]).strip()\n",
    "    # print('Qte nomes do meio',len(nomes),nomes)\n",
    "    if sobrenome != '' and primeiro_nome !='':\n",
    "        sobrenome_iniciais = sobrenome+', '+primeiro_nome[0]+' '+nomes_meio\n",
    "    elif sobrenome != '':\n",
    "        sobrenome_iniciais = sobrenome\n",
    "    \n",
    "    return sobrenome_iniciais.strip()\n",
    "\n",
    "\n",
    "## Agregar aprendizado supervisionado humano à medida que forem sendo identificados erros na situação atual\n",
    "lista_extra = [\n",
    "                # ('ALBUQUERQUE, Adriano B', 'ALBUQUERQUE, Adriano Bessa'),\n",
    "                # ('ALBUQUERQUE, Adriano', 'ALBUQUERQUE, Adriano Bessa'),\n",
    "                # ('COELHO, Andre L V', 'COELHO, Andre Luis Vasconcelos'),\n",
    "                # ('DUARTE, Joao B F', 'DUARTE, Joao Batista Furlan'),\n",
    "                # ('FILHO, Raimir H','HOLANDA FILHO, Raimir'),\n",
    "                # ('FILHO, Raimir','HOLANDA FILHO, Raimir'),\n",
    "                # ('FORMIGO, A','FORMICO, Maria Andreia Rodrigues'),\n",
    "                # ('FORMICO, A','FORMICO, Maria Andreia Rodrigues'),\n",
    "                # ('FURLAN, J B D', 'FURLAN, Joao Batista Duarte'),\n",
    "                # ('FURTADO, Elizabeth', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "                # ('FURTADO, Elizabeth S', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "                # ('FURTADO, Elizabeth Sucupira','FURTADO, Maria Elizabeth Sucupira'),\n",
    "                # ('FURTADO, M E S', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "                # ('FURTADO, Vasco', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "                # ('FURTADO, J P', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "                # ('FURTADO, J V P', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "                # ('FURTADO, Vasco', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "                # ('FURTADO, Elizabeth','FURTADO, Maria Elizabeth Sucupira'),\n",
    "                # ('HOLANDA, Raimir', 'HOLANDA FILHO, Raimir'),\n",
    "                # ('LEITE, G S', 'LEITE, Gleidson Sobreira'),\n",
    "                # ('PEQUENO, T H C', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                # ('PEQUENO, Tarcisio','PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                # ('PEQUENO, Tarcisio Cavalcante', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                # ('PINHEIRO, Placido R', 'PINHEIRO, Placido Rogerio'),\n",
    "                # ('PINHEIRO, Vladia', 'PINHEIRO, Vladia Celia Monteiro'),\n",
    "                # ('RODRIGUES, M A F', 'RODRIGUES, Maria Andreia Formico'),\n",
    "                # ('RODRIGUES, Andreia', 'RODRIGUES, Maria Andreia Formico'),\n",
    "                # ('JOAO, Batista F Duarte,', 'FURLAN, Joao Batista Duarte'),\n",
    "                # ('MACEDO, Antonio Roberto M de', 'MACEDO, Antonio Roberto Menescal de'),\n",
    "                # ('MACEDO, D V', 'MACEDO, Daniel Valente'),\n",
    "                # ('MENDONCA, Nabor C', 'MENDONCA, Nabor das Chagas'),\n",
    "                # ('PEQUENO, Tarcisio', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                # ('PEQUENO, Tarcisio H', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                # ('PINHEIRO, Mirian C D', 'PINHEIRO, Miriam Caliope Dantas'),\n",
    "                # ('PINHEIRO, Mirian Caliope Dantas', 'PINHEIRO, Miriam Caliope Dantas'),\n",
    "                # ('PINHEIRO, P G C D', 'PINHEIRO, Pedro Gabriel Caliope Dantas'),\n",
    "                # ('PINHEIRO, Pedro G C', 'PINHEIRO, Pedro Gabriel Caliope Dantas'),\n",
    "                # ('PINHEIRO, Placido R', 'PINHEIRO, Placido Rogerio'),\n",
    "                # ('PINHEIRO, Vladia', 'PINHEIRO, Vladia Celia Monteiro'),\n",
    "                # ('ROGERIO, Placido Pinheiro', 'PINHEIRO, Placido Rogerio'),\n",
    "                # ('REBOUCRAS FILHO, Pedro', 'REBOUCAS FILHO, Pedro Pedrosa'),\n",
    "                # ('SAMPAIO, A', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "                # ('SAMPAIO, Americo', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "                # ('SAMPAIO, Americo Falcone', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "                # ('SUCUPIRA, Elizabeth Furtado','FURTADO, Maria Elizabeth Sucupira'),\n",
    "                ]\n",
    "\n",
    "\n",
    "def converter_lista_set(lista):\n",
    "    set1 = set(lista)\n",
    "    return set1\n",
    "\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    '''\n",
    "    Recebe dois conjuntos como entradas e retorna a similaridade Jaccard entre eles. \n",
    "    1. calcula a interseção dos dois conjuntos usando a função de interseção e, \n",
    "    2. calcula a união dos dois conjuntos usando a função de união. \n",
    "    3. retorna a razão entre o comprimento da interseção e o comprimento da união, que é a similaridade de Jaccard.\n",
    "    '''\n",
    "    intersection = set1.intersection(set2)\n",
    "    union        = set1.union(set2)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "\n",
    "def similares(lista_autores, lista_grupo, limite_jarowinkler, distancia_levenshtein, lista_extra):\n",
    "    \"\"\"Função para aplicar padronização no nome de autor da lista de pesquisadores e buscar similaridade na lista de coautores\n",
    "     Recebe: Lista de pesquisadores do grupo em análise gerada pela lista de nomes dos coautores das publicações em análise\n",
    "    Utiliza: get_jaro_distance(), editdistance()\n",
    "    Retorna: Lista de autores com fusão de nomes cuja similaridade esteja dentro dos limites definidos nesta função\n",
    "      Autor: Marcos Aires (Fev.2022)\n",
    "      \n",
    "    Refazer: Inserir crítica de, mantendo sequência ordem alfabética, retornar no final nome mais extenso em caso de similaridade;\n",
    "    \"\"\"\n",
    "    from pyjarowinkler.distance import get_jaro_distance\n",
    "    from IPython.display import clear_output\n",
    "    import editdistance\n",
    "    import numpy as np\n",
    "    import time\n",
    "    \n",
    "    t0=time.time()\n",
    "    \n",
    "    # limite_jarowinkler=0.85\n",
    "    # distancia_levenshtein=6\n",
    "    similares_jwl=[]\n",
    "    similares_regras=[]\n",
    "    similares=[]\n",
    "    tempos=[]\n",
    "    \n",
    "    count=0\n",
    "    t1=time.time()\n",
    "    for i in lista_autores:\n",
    "        count+=1\n",
    "        if count > 0:\n",
    "            tp=time.time()-t1\n",
    "            tmed=tp/count*2\n",
    "            tempos.append(tp)\n",
    "        # print(\"Analisar similaridades com: \", nome_padronizado)\n",
    "        \n",
    "        count1=0\n",
    "        for nome in lista_autores:\n",
    "            if count1 > 0:\n",
    "                resta=len(lista_autores)-count\n",
    "                print(f'Analisando {count1:3}/{len(lista_autores)} resta analisar {resta:3} nomes. Previsão de término em {np.round(tmed*resta/60,1)} minutos')\n",
    "            else:\n",
    "                print(f'Analisando {count1:3}/{len(lista_autores)} resta analisar {len(lista_autores)-count1} nomes.')\n",
    "            \n",
    "            t2=time.time()\n",
    "            count1+=1            \n",
    "\n",
    "            try:\n",
    "                similaridade_jarowinkler = get_jaro_distance(i, nome)\n",
    "                print(f'{i:40} | {nome:40} | Jaro-Winkler: {np.round(similaridade_jarowinkler,2):4} Levenshtein: {editdistance.eval(i, nome)}')\n",
    "                similaridade_levenshtein = editdistance.eval(i, nome)\n",
    "\n",
    "                # inferir similaridade para nomes que estejam acima do limite ponderado definido, mas não idênticos e não muito distantes em edição\n",
    "                if  similaridade_jarowinkler > limite_jarowinkler and similaridade_jarowinkler!=1 and similaridade_levenshtein < distancia_levenshtein:\n",
    "                    # Crítica no nome mais extenso como destino no par (origem, destino)\n",
    "                    \n",
    "                    similares_jwl.append((i,nome))\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            clear_output(wait=True)\n",
    "    \n",
    "    # Conjunto de regras de validação de similaridade\n",
    "    # Monta uma lista de nomes a serem retirados antes de montar a lista de troca\n",
    "    trocar=[]\n",
    "    retirar=[]\n",
    "    for i in similares_jwl:\n",
    "        sobrenome_i = i[0].split(',')[0]\n",
    "        sobrenome_j = i[1].split(',')[0]\n",
    "\n",
    "        try:\n",
    "            iniciais_i  = iniciais_nome(i[0]).split(',')[1].strip()\n",
    "        except:\n",
    "            iniciais_i  = ''\n",
    "\n",
    "        try:\n",
    "            iniciais_j  = iniciais_nome(i[1]).split(',')[1].strip()\n",
    "        except:\n",
    "            iniciais_j  = ''\n",
    "\n",
    "        try:\n",
    "            primnome_i = i[0].split(',')[1].strip().split(' ')[0].strip()\n",
    "        except:\n",
    "            primnome_i = ''\n",
    "\n",
    "        try:\n",
    "            primnome_j = i[1].split(',')[1].strip().split(' ')[0].strip()\n",
    "        except:\n",
    "            primnome_j = ''    \n",
    "\n",
    "        try:\n",
    "            inicial_i = i[0].split(',')[1].strip()[0]\n",
    "        except:\n",
    "            inicial_i = ''\n",
    "\n",
    "        try:\n",
    "            resto_i   = i[0].split(',')[1].strip().split(' ')[0][1:]\n",
    "        except:\n",
    "            resto_i   = ''\n",
    "\n",
    "        try:\n",
    "            inicial_j = i[1].split(',')[1].strip()[0]\n",
    "        except:\n",
    "            inicial_j = ''\n",
    "\n",
    "        try:\n",
    "            resto_j   = i[1].split(',')[1].strip().split(' ')[0][1:]\n",
    "        except:\n",
    "            resto_j = ''\n",
    "\n",
    "        # Se a distância de edição entre os sobrenomes\n",
    "        if editdistance.eval(sobrenome_i, sobrenome_j) > 2 or inicial_i!=inicial_j:\n",
    "            retirar.append(i)\n",
    "        else:\n",
    "            if primnome_i!=primnome_j and len(primnome_i)>1:\n",
    "                retirar.append(i)\n",
    "            if primnome_i!=primnome_j and len(primnome_i)>1 and len(primnome_j)>1:\n",
    "                retirar.append(i)\n",
    "            if resto_i!=resto_j and resto_i!='':\n",
    "                retirar.append(i)\n",
    "            if len(i[1]) < len(i[0]):\n",
    "                retirar.append(i)\n",
    "            if len(iniciais_i) != len(iniciais_j):\n",
    "                retirar.append(i)\n",
    "\n",
    "    for i in similares_jwl:\n",
    "        if i not in retirar:\n",
    "            trocar.append(i)\n",
    "\n",
    "        if iniciais_nome(i[0]) in iniciais_nome(i[1]) and len(i[0]) < len(i[1]):\n",
    "            trocar.append(i)\n",
    "\n",
    "        if iniciais_nome(i[0]) == iniciais_nome(i[1]) and len(i[0]) < len(i[1]):\n",
    "             trocar.append(i)\n",
    "    \n",
    "    trocar=trocar+lista_extra\n",
    "    trocar.sort()\n",
    "    \n",
    "    return trocar\n",
    "\n",
    "\n",
    "\n",
    "def extrair_variantes(df_dadosgrupo):\n",
    "    ''' Utiliza campo de Nome em Citações do currículo como filtro para obter variantes do nome de cada membro\n",
    "     Recebe: Dataframe com os dados brutos do grupo de pesquisa agrupados; lista de nomes de pesquisadores de interesse\n",
    "    Retorna: Lista de tuplas com pares a serem trocados da variante pelo nome padronizado na forma (origem, destino)\n",
    "    '''\n",
    "    filtro1   = 'Nome'\n",
    "    lista_nomes = df_dadosgrupo[(df_dadosgrupo.ROTULOS == filtro1)]['CONTEUDOS'].values\n",
    "\n",
    "    variantes=[]\n",
    "    filtro='Nome em citações bibliográficas'\n",
    "    variantes=df_dadosgrupo[(df_dadosgrupo.ROTULOS == filtro)]['CONTEUDOS'].to_list()\n",
    "\n",
    "    trocar=[]\n",
    "    for j in range(len(variantes)):\n",
    "        padrao_destino = padronizar_nome(lista_nomes[j])\n",
    "        trocar.append((lista_nomes[j], padrao_destino))\n",
    "        for k in variantes[j]:\n",
    "            padrao_origem = padronizar_nome(k)\n",
    "            trocar.append((k, padrao_destino))\n",
    "            trocar.append((padrao_origem, padrao_destino))\n",
    "    \n",
    "    return trocar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25e596",
   "metadata": {},
   "source": [
    "    Organizar lista de autores e iniciais de nomes\n",
    "    PROBLEMA: não está quebrando no número de artigos 1115, mas sim em apenas 2 e última vazia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f65f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Montar a lista de autores a partir da lista de strings limpa com nomes de autores\n",
    "def organizar_nomes(str_autores_artigo):\n",
    "    erros_organizar  = []\n",
    "    lista_organizada = []\n",
    "    partes_nomes = str_autores_artigo.split(', ')\n",
    "    n       = len(partes_nomes)\n",
    "    pares   = range(0,n+1,2)\n",
    "    impares = range(1,n+1,2)\n",
    "    try:\n",
    "        for i,j in zip(pares,impares):\n",
    "            nome=[]\n",
    "            try:\n",
    "                nomes_ordenado = str(partes_nomes[j].lower()+' '+partes_nomes[i].lower()).replace('  ',' ').strip()\n",
    "            except:\n",
    "                if len(pares) > len(impares):\n",
    "                    nomes_ordenado = str(partes_nomes[j].lower()).replace('  ',' ').strip()\n",
    "                else:\n",
    "                    nomes_ordenado = str(partes_nomes[i].lower()).replace('  ',' ').strip()\n",
    "            lista_organizada.append(nomes_ordenado)\n",
    "    \n",
    "    except Exception as e1:\n",
    "        print('Erro ao montar listas de nomes de autor:',e1)\n",
    "        erros_organizar.append((m,str_autores_artigo))\n",
    "\n",
    "    return lista_organizada, erros_organizar\n",
    "\n",
    "## Quebrar um nome em seu sobrenome seguido das partes de nome\n",
    "def quebrar_partesnomes(nome):\n",
    "    padrao     = padronizar_nome(nome).lower()\n",
    "    sobrenome  = padrao.split(',')[0].strip()\n",
    "    restonomes = padrao.split(',')[1].strip().split(' ')\n",
    "    try:\n",
    "        partenome1 = restonomes[0].strip()\n",
    "    except:\n",
    "        partenome1 = np.NaN\n",
    "    try:\n",
    "        partenome2 = restonomes[1].strip()\n",
    "    except:\n",
    "        partenome2 = np.NaN\n",
    "    try:\n",
    "        partenome3 = restonomes[2].strip()\n",
    "    except:\n",
    "        partenome3 = np.NaN        \n",
    "    # print(f'{sobrenome:15} | {partenome1:1} | {partenome2:1} | {partenome3}')\n",
    "    \n",
    "    return sobrenome, partenome1, partenome2, partenome3\n",
    "\n",
    "\n",
    "## Quebrar um nome em seu sobrenome seguido as iniciais das partes de nome\n",
    "def quebrar_iniciais(nome):\n",
    "    padrao = iniciais_nome(nome).lower()\n",
    "    sobrenome  = padrao.split(',')[0].strip()\n",
    "    restonomes = padrao.split(',')[1].strip().split(' ')\n",
    "\n",
    "    try:\n",
    "        partenome1 = restonomes[0].strip()\n",
    "    except:\n",
    "        partenome1 = np.NaN\n",
    "    try:\n",
    "        partenome2 = restonomes[1].strip()\n",
    "    except:\n",
    "        partenome2 = np.NaN\n",
    "    try:\n",
    "        partenome3 = restonomes[2].strip()\n",
    "    except:\n",
    "        partenome3 = np.NaN        \n",
    "    # print(f'{sobrenome:15} | {partenome1:1} | {partenome2:1} | {partenome3}')\n",
    "    \n",
    "    return sobrenome, partenome1, partenome2, partenome3\n",
    "\n",
    "\n",
    "## compilar padrão regular expression para buscar ocorência de duas das quatro partes de nome dentro de janela de no máximo 2 palavras de distância\n",
    "def compilar_partes(sobrenome, partenome1, partenome2, partenome3):\n",
    "    return re.compile(r'\\b({0}|{1}|{2}|{3})(?:\\W+\\w+){{0,2}}?\\W+({1}&{2}|{2}&{3}|{0}&{1}|{0}&{3})\\b'.format(sobrenome, partenome1, partenome2, partenome3), flags=re.IGNORECASE)\n",
    "\n",
    "def compilar_iniciais(sobrenome, inicial1, inicial2, inicial3):\n",
    "    return re.compile(r'\\b({0})(?:\\W+\\w+){{0,1}}?\\W+({1}|{2}|{3})\\b'.format(sobrenome, inicial1, inicial2, inicial3), flags=re.IGNORECASE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.spacy3': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "197d8f220c237ea2269a397bcc5571d13b6ee9614ab9ae87aa2d290b25dc373b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
