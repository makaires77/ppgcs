{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear com rede neural em PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código treina uma rede neural simples para aprender a relação entre os dados de entrada x_input e os dados de saída y_input. O objetivo é minimizar a perda, ou seja, a diferença entre as previsões da rede e os valores reais. A visualização da perda ajuda a entender como o modelo está aprendendo ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Importar bibliotecas:\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## 2. Gerar os dados de entrada:\n",
    "# Definir um tensor com valores de entrada (x) e saída (y)\n",
    "x_input = torch.FloatTensor([[0],[1],[2],[3],[4]])\n",
    "y_input = torch.FloatTensor([[8],[10],[9],[21],[12]])\n",
    "\n",
    "## 3. Variáveis do Autograd:\n",
    "# Converter os tensores em variáveis do Autograd, para que o PyTorch rastreie as operações realizadas neles \n",
    "# para calcular gradientes automaticamente durante o treinamento\n",
    "x, y = torch.autograd.Variable(x_input), torch.autograd.Variable(y_input)\n",
    "\n",
    "## 4. Definir a arquitetura da rede neural\n",
    "net = torch.nn.Sequential(\n",
    "          torch.nn.Linear(1,16),\n",
    "          torch.nn.Tanh(),\n",
    "          torch.nn.Linear(16,10),\n",
    "          torch.nn.Linear(10,1)\n",
    "        )\n",
    "\n",
    "## 5. Definir otimizador e função de perda:\n",
    "# Definir o otimizador Adam para atualizar os parâmetros da rede neural com uma taxa de aprendizado de 0.1\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "# Definir a função de perda como Erro Quadrático Médio (MSE)\n",
    "loss_func = torch.nn.MSELoss() \n",
    "\n",
    "## 6. Treinamento:\n",
    "## A cada iteração, o código calcula o erro entre a predição da rede neural e o valor real (loss = loss_func(prediction, y)).\n",
    "# Em seguida, o valor dessa perda é adicionado à lista loss_sequence através do comando loss_sequence.append(loss.data.numpy()).\n",
    "# No final do treinamento, a lista loss_sequence conterá um histórico de como a perda variou ao longo das iterações. O que nos\n",
    "# serve para Visualizar o progresso do treinamento ao plotar um gráfico que mostra como a perda diminui ao longo do tempo, \n",
    "# permitindo que você avalie se o modelo está aprendendo corretamente. E para diagnosticar problemas, caso a perda não \n",
    "# diminuir ou apresentar um comportamento inesperado, isso pode indicar problemas no modelo ou nos dados, e a através da\n",
    "# lista loss_sequence e que teremos informações valiosas para identificar esses problemas.\n",
    "\n",
    "# Criar a lista vazia loss_sequence para armazenar o valor da perda (loss) a cada iteração do loop de treinamento\n",
    "loss_sequence = list()\n",
    "\n",
    "for t in range(1000):                        # itera 1000 vezes\n",
    "    prediction = net(x)                      # Passa os dados de entrada pela rede neural para obter a previsão\n",
    "    loss = loss_func(prediction, y)          # Calcula a perda comparando a previsão com os valores reais\n",
    "    loss_sequence.append(loss.data.numpy())  # Armazena o valor da perda para posterior visualização\n",
    "    optimizer.zero_grad()                    # Zera os gradientes dos parâmetros da rede\n",
    "    loss.backward()                          # Realiza retropropagação para calcular gradientes da perda em relação aos parâmetros\n",
    "    optimizer.step()                         # Atualiza os parâmetros da rede com base nos gradientes calculados\n",
    "\n",
    "plt.plot(loss_sequence)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pesos e Vieses (Bias) em Redes Neurais\n",
    "\n",
    "Os termos **pesos** e **vieses (bias)** são fundamentais em redes neurais, e cada um desempenha um papel distinto no funcionamento do modelo.\n",
    "\n",
    "## Pesos\n",
    "\n",
    "- **Definição**: Os pesos são coeficientes que multiplicam as entradas de um neurônio. Eles determinam a importância de cada entrada na decisão final do neurônio.\n",
    "  \n",
    "- **Função**: Durante o treinamento, os pesos são ajustados para minimizar a função de perda, ou seja, eles aprendem a representar a relação entre as entradas e as saídas. Um peso maior indica que a entrada correspondente tem mais influência na saída do neurônio.\n",
    "  \n",
    "- **Matematicamente**: A soma ponderada das entradas é calculada como:\n",
    "  $$\n",
    "  z = \\sum_{i=1}^{n} w_i \\cdot x_i\n",
    "  $$\n",
    "  onde $w_i$ representa os pesos e $x_i$ as entradas.\n",
    "\n",
    "## Vieses (Bias)\n",
    "\n",
    "- **Definição**: O viés é um termo adicional que permite que o modelo se ajuste melhor aos dados. Ele não está associado a uma entrada específica, mas é adicionado ao resultado da soma ponderada das entradas.\n",
    "  \n",
    "- **Função**: O viés ajuda a deslocar a função de ativação para a esquerda ou para a direita, o que pode ser crucial para modelar corretamente os dados. Sem o viés, a rede neural poderia ser limitada em sua capacidade de aprender funções complexas.\n",
    "  \n",
    "- **Matematicamente**: A equação que inclui o viés é:\n",
    "  $$\n",
    "  z = \\sum_{i=1}^{n} w_i \\cdot x_i + b\n",
    "  $$\n",
    "  onde \\( b \\) é o viés.\n",
    "\n",
    "## Resumo das Diferenças\n",
    "\n",
    "| Aspecto          | Pesos                               | Vieses (Bias)                      |\n",
    "|------------------|-------------------------------------|------------------------------------|\n",
    "| **Definição**    | Coeficientes multiplicadores das entradas | Termo adicional que ajusta a saída |\n",
    "| **Função**       | Determinam a importância das entradas | Permitem deslocar a função de ativação |\n",
    "| **Influência**   | Ajustados durante o treinamento para aprender relações | Contribui para modelar funções complexas sem depender de entradas específicas |\n",
    "\n",
    "Em resumo, enquanto os pesos ajustam as influências das entradas na saída do neurônio, os vieses permitem que o modelo se adapte melhor ao conjunto de dados, oferecendo flexibilidade adicional nas transformações realizadas pela rede neural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais de Kolmogorov-Arnold (KANs)\n",
    "\n",
    "As **Redes de Kolmogorov-Arnold (KANs)** oferecem uma abordagem diferente em relação às redes neurais tradicionais, como os perceptrons de múltiplas camadas (MLPs). Abaixo, discutiremos como os conceitos de pesos e vieses se aplicam em KANs e como eles diferem das redes neurais convencionais.\n",
    "\n",
    "## Pesos em KANs\n",
    "\n",
    "- **Definição**: Assim como nas redes neurais tradicionais, os pesos em KANs são coeficientes que ajustam a importância das entradas. No entanto, em KANs, esses pesos podem ser mais flexíveis devido à capacidade de aprender funções de ativação durante o treinamento.\n",
    "  \n",
    "- **Função**: Os pesos em KANs são ajustados não apenas para minimizar a função de perda, mas também para permitir que a rede aprenda a forma das funções que modelam os dados. Isso significa que os pesos podem ser adaptativos e influenciar diretamente as funções de ativação que a rede utiliza.\n",
    "\n",
    "- **Matematicamente**: A soma ponderada das entradas ainda é representada por:\n",
    "  $$\n",
    "  z = \\sum_{i=1}^{n} w_i \\cdot x_i\n",
    "  $$\n",
    "  mas com a adição da capacidade de aprender as funções de ativação associadas.\n",
    "\n",
    "## Vieses (Bias) em KANs\n",
    "\n",
    "- **Definição**: O viés em KANs continua a ser um termo adicional que ajusta a saída da soma ponderada das entradas. No entanto, sua função pode ser ampliada para incluir a adaptação às mudanças nas funções de ativação aprendidas.\n",
    "  \n",
    "- **Função**: O viés ajuda a deslocar as funções aprendidas, permitindo uma melhor modelagem dos dados. Em KANs, o viés pode interagir com as funções de ativação residuais, proporcionando uma regularização adicional e suavizando as transições entre diferentes regiões da função.\n",
    "\n",
    "- **Matematicamente**: A equação que inclui o viés é:\n",
    "  $$\n",
    "  z = \\sum_{i=1}^{n} w_i \\cdot x_i + b\n",
    "  $$\n",
    "  onde $b$ é o viés, mas agora pode estar associado a várias funções de ativação aprendidas.\n",
    "\n",
    "## Resumo das Diferenças\n",
    "\n",
    "| Aspecto          | Pesos em KANs                     | Vieses (Bias) em KANs                  |\n",
    "|------------------|------------------------------------|-----------------------------------------|\n",
    "| **Definição**    | Coeficientes que ajustam entradas e aprendem funções de ativação | Termo adicional que ajusta a saída e interage com funções aprendidas |\n",
    "| **Função**       | Adaptáveis para modelar relações complexas nos dados | Permitem deslocar funções e suavizar transições |\n",
    "| **Influência**   | Influenciam diretamente as funções de ativação | Contribuem para a regularização e adaptação às mudanças nas ativações |\n",
    "\n",
    "Portanto, nas Redes de Kolmogorov-Arnold, tanto os pesos quanto os vieses desempenham papéis cruciais na adaptação do modelo às complexidades dos dados. A capacidade das KANs de aprender não apenas os pesos, mas também as funções de ativação associadas, representa uma evolução significativa sobre as redes neurais tradicionais. Isso permite que as KANs sejam mais flexíveis e eficientes na modelagem de fenômenos complexos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matemática das Redes Neurais em geral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A arquitetura da rede neural pode ser representada pelas seguintes equações:\n",
    "\n",
    "1. **Camada de entrada**: \n",
    "   $$ h_1 = W_1 x + b_1 $$\n",
    "   onde \\( W_1 \\) é a matriz de pesos da primeira camada (Linear), \\( x \\) é o vetor de entrada, e \\( b_1 \\) é o vetor de bias.\n",
    "\n",
    "2. **Função de ativação Tanh**:\n",
    "   $$ h_2 = \\tanh(h_1) $$\n",
    "\n",
    "3. **Camada oculta**:\n",
    "   $$ h_3 = W_2 h_2 + b_2 $$\n",
    "   onde \\( W_2 \\) é a matriz de pesos da segunda camada (Linear) e \\( b_2 \\) é o vetor de bias.\n",
    "\n",
    "4. **Camada de saída**:\n",
    "   $$ y = W_3 h_3 + b_3 $$\n",
    "   onde \\( W_3 \\) é a matriz de pesos da camada de saída (Linear) e \\( b_3 \\) é o vetor de bias.\n",
    "\n",
    "Assim, a rede neural pode ser expressa como:\n",
    "$$ y = W_3 (W_2 \\tanh(W_1 x + b_1) + b_2) + b_3 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\text{Rede Neural: } \\text{Linear}(1, 16) \\rightarrow \\text{Tanh} \\rightarrow \\text{Linear}(16, 10) \\rightarrow \\text{Linear}(10, 1)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def generate_latex(model):\n",
    "    layers = []\n",
    "    for layer in model.children():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            layers.append(f\"\\\\text{{Linear}}({layer.in_features}, {layer.out_features})\")\n",
    "        elif isinstance(layer, nn.Tanh):\n",
    "            layers.append(\"\\\\text{Tanh}\")\n",
    "    \n",
    "    latex_representation = \" \\\\rightarrow \".join(layers)\n",
    "    return f\"\\\\text{{Rede Neural: }} {latex_representation}\"\n",
    "\n",
    "# Definindo a arquitetura da rede neural\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 16)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(16, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "model = NeuralNetwork()\n",
    "latex_output = generate_latex(model)\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um modelo de regressão linear simples: $Y = \\beta_0 + \\beta_1 x + \\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x;\\mu,\\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{ -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2 }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor de y: 0.0\n",
      "Gradiente dy/dx: 2.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Definindo um tensor com gradiente\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = (x - 1) * (x - 2) * (x - 3)\n",
    "y.backward()  # Calcula o gradiente\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(f\"Valor de y: {y.item()}\")\n",
    "print(f\"Gradiente dy/dx: {x.grad.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado \\(y = (x - 1)(x - 2)(x - 3)\\), calculamos o gradiente \\(dy/dx\\) que resulta em \\(3x^2 - 12x + 11\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.2522],\n",
      "        [10.1062],\n",
      "        [ 9.5178],\n",
      "        [21.3465],\n",
      "        [12.5602]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## 8. Predição final: Após o treinamento, a rede neural é usada para fazer previsões nos dados de entrada.\n",
    "print(net(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa minúscula rede neural possui as seguintes camadas:\n",
    "\n",
    "- torch.nn.Linear(1, 16): 16 neurônios\n",
    "- torch.nn.Tanh(): Esta é uma camada de ativação e não possui neurônios.\n",
    "- torch.nn.Linear(16, 10): 10 neurônios\n",
    "- torch.nn.Linear(10, 1): 1 neurônio\n",
    "\n",
    "Somando os neurônios de cada camada, temos um total de 27 neurônios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraia os parâmetros da rede neural\n",
    "'params = list(net.parameters())\n",
    "print(params)\n",
    "\n",
    "# Imprima os pesos e vieses de cada camada\n",
    "print(\"\\nPesos e vieses por camadas\")\n",
    "for i, param in enumerate(params):\n",
    "    print(f'\\nCamada {i+1}:')\n",
    "    if param.dim() == 2:  # Verifica se o parâmetro é uma matriz (pesos)\n",
    "        print('Pesos:', param.data.numpy())\n",
    "    else:  # Caso contrário, é um vetor (vieses)\n",
    "        print('Vieses:', param.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 8, got 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[38], line 53\u001b[0m\n",
      "\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Exemplo de uso (assumindo que 'net' é sua rede neural treinada):\u001b[39;00m\n",
      "\u001b[1;32m     52\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(net\u001b[38;5;241m.\u001b[39mparameters())\n",
      "\u001b[0;32m---> 53\u001b[0m funcoes_matematicas \u001b[38;5;241m=\u001b[39m \u001b[43mgerar_funcoes_matematicas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Imprime as funções matemáticas (uma para cada neurônio de saída)\u001b[39;00m\n",
      "\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, funcao \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(funcoes_matematicas):\n",
      "\n",
      "Cell \u001b[0;32mIn[38], line 19\u001b[0m, in \u001b[0;36mgerar_funcoes_matematicas\u001b[0;34m(params)\u001b[0m\n",
      "\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39msymbols(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Extrai os pesos e vieses da lista params\u001b[39;00m\n",
      "\u001b[0;32m---> 19\u001b[0m w1, b1, w2, b2, w3, b3, w4, b4 \u001b[38;5;241m=\u001b[39m params\n",
      "\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Converte os tensores NumPy para arrays NumPy\u001b[39;00m\n",
      "\u001b[1;32m     22\u001b[0m w1 \u001b[38;5;241m=\u001b[39m w1\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 8, got 6)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "\n",
    "def gerar_funcoes_matematicas(params):\n",
    "  \"\"\"\n",
    "  Gera as funções matemáticas que representam a rede neural.\n",
    "\n",
    "  Args:\n",
    "    params: Lista de tensores contendo os pesos e vieses da rede.\n",
    "\n",
    "  Returns:\n",
    "    Uma lista de funções matemáticas (expressões Sympy), uma para cada neurônio da camada de saída.\n",
    "  \"\"\"\n",
    "\n",
    "  # Define o símbolo 'x' para a entrada da rede\n",
    "  x = sp.symbols('x')\n",
    "\n",
    "  # Extrai os pesos e vieses da lista params\n",
    "  w1, b1, w2, b2, w3, b3, w4, b4 = params\n",
    "\n",
    "  # Converte os tensores NumPy para arrays NumPy\n",
    "  w1 = w1.data.numpy()\n",
    "  b1 = b1.data.numpy()\n",
    "  w2 = w2.data.numpy()\n",
    "  b2 = b2.data.numpy()\n",
    "  w3 = w3.data.numpy()\n",
    "  b3 = b3.data.numpy()\n",
    "  w4 = w4.data.numpy()\n",
    "  b4 = b4.data.numpy()\n",
    "\n",
    "  # Calcula as saídas da Camada 1 (Linear)\n",
    "  z1 = np.dot(x, w1) + b1\n",
    "\n",
    "  # Calcula as saídas da Camada 2 (Tanh)\n",
    "  h1 = np.tanh(z1)\n",
    "\n",
    "  # Calcula as saídas da Camada 3 (Linear)\n",
    "  z2 = np.dot(h1, w2) + b2\n",
    "\n",
    "  # Calcula as saídas da Camada 4 (Linear)\n",
    "  z3 = np.dot(z2, w3) + b3\n",
    "\n",
    "  # Calcula as saídas da Camada 5 (Linear - Saída)\n",
    "  y_pred = np.dot(z3, w4) + b4\n",
    "\n",
    "  # Converte a saída para expressão Sympy\n",
    "  y_pred_sp = sp.Matrix(y_pred).applyfunc(sp.simplify)\n",
    "\n",
    "  return y_pred_sp\n",
    "\n",
    "# Exemplo de uso (assumindo que 'net' é sua rede neural treinada):\n",
    "params = list(net.parameters())\n",
    "funcoes_matematicas = gerar_funcoes_matematicas(params)\n",
    "\n",
    "# Imprime as funções matemáticas (uma para cada neurônio de saída)\n",
    "for i, funcao in enumerate(funcoes_matematicas):\n",
    "  print(f'Função matemática para o neurônio de saída {i+1}: {funcao}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camada 1 Linear\n",
    "\n",
    "z<sub>1</sub><sup>(1)</sup> = w<sub>11</sub><sup>(1)</sup> * x + b<sub>1</sub><sup>(1)</sup>\n",
    "\n",
    "...\n",
    "\n",
    "z<sub>16</sub><sup>(1)</sup> = w<sub>1,16</sub><sup>(1)</sup> * x + b<sub>16</sub><sup>(1)</sup>\n",
    "\n",
    "Camada 2 (Tanh)\n",
    "\n",
    "h<sub>1</sub><sup>(1)</sup> = f(z<sub>1</sub><sup>(1)</sup>) = tanh(z<sub>1</sub><sup>(1)</sup>)\n",
    "\n",
    "...\n",
    "\n",
    "h<sub>16</sub><sup>(1)</sup> = f(z<sub>16</sub><sup>(1)</sup>) = tanh(z<sub>16</sub><sup>(1)</sup>)\n",
    "\n",
    "Camada 3 (Linear):\n",
    "\n",
    "z<sub>1</sub><sup>(2)</sup> = w<sub>11</sub><sup>(2)</sup> * h<sub>1</sub><sup>(1)</sup> + ... + w<sub>16,1</sub><sup>(2)</sup> * h<sub>16</sub><sup>(1)</sup> + b<sub>1</sub><sup>(2)</sup>\n",
    "\n",
    "...\n",
    "\n",
    "z<sub>10</sub><sup>(2)</sup> = w<sub>1,10</sub><sup>(2)</sup> * h<sub>1</sub><sup>(1)</sup> + ... + w<sub>16,10</sub><sup>(2)</sup> * h<sub>16</sub><sup>(1)</sup> + b<sub>10</sub><sup>(2)</sup>\n",
    "\n",
    "Camada 4 (Linear):\n",
    "\n",
    "z<sub>1</sub><sup>(3)</sup> = w<sub>11</sub><sup>(3)</sup> * z<sub>1</sub><sup>(2)</sup> + ... + w<sub>10,1</sub><sup>(3)</sup> * z<sub>10</sub><sup>(2)</sup> + b<sub>1</sub><sup>(3)</sup>\n",
    "\n",
    "Camada 5 (Linear - Saída):\n",
    "\n",
    "y<sub>pred</sub> = w<sub>11</sub><sup>(4)</sup> * z<sub>1</sub><sup>(3)</sup> + b<sub>1</sub><sup>(4)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "print(f\"       Versão do PyTorch: {torch.__version__}\")\n",
    "print(f\"Versão PyTorch Geometric: {torch_geometric.__version__}\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = None\n",
    "optimizer = None\n",
    "del model\n",
    "del optimizer\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# %pip install scikit-optimize\n",
    "\n",
    "# %pip install --upgrade torch-geometric\n",
    "# %pip uninstall torch-geometric -y\n",
    "# %pip install torch-geometric\n",
    "\n",
    "# %pip show torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset em estrutura de grafo\n",
    "\n",
    "Cora é um conjunto de dados Planetoid, com nós representando artigos acadêmicos e arestas representando citações entre eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora():\n",
      "======================\n",
      "        Number of graphs: 1\n",
      "      Number of features: 1433\n",
      "       Number of classes: 7\n",
      "         Number of nodes: 2708\n",
      "         Number of edges: 10556\n",
      "     Average node degree: 3.90\n",
      "Number of training nodes: 140\n",
      "Training node label rate: 0.05\n",
      " Contains isolated nodes: False\n",
      "     Contains self-loops: False\n",
      "           Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='~/Cora', name='Cora')\n",
    "\n",
    "data = dataset[0]\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'        Number of graphs: {len(dataset)}')\n",
    "print(f'      Number of features: {dataset.num_features}')\n",
    "print(f'       Number of classes: {dataset.num_classes}')\n",
    "\n",
    "print(f'         Number of nodes: {data.num_nodes}')\n",
    "print(f'         Number of edges: {data.num_edges}')\n",
    "print(f'     Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f' Contains isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'     Contains self-loops: {data.has_self_loops()}')\n",
    "print(f'           Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizagem com dataset no Neo4j usando StellarGraph\n",
    "\n",
    "Certos pacotes, como o StellarGraph, permitem aprender com grafos quando armazenados em um banco de dados. Isso abre todos os tipos de possibilidades, especialmente no contexto de grafos de conhecimento, detecção de fraudes e muito mais.\n",
    "\n",
    "Os métodos abaixo ajudam a transferir os dados do Cora para o Neo4j como o armazenamento de grafos de fato atualmente. A técnica é realmente direta, mas observe que o vetor bastante grande de 1433 dimensões que descreve o conteúdo de um artigo está quebrando o navegador Neo4j. Ou seja, o visualizador de rede no Neo4j tenta carregar esses vetores junto com a estrutura de rede, mas isso falha até mesmo para um único nó.\n",
    "\n",
    "O pacote py2neo é a maneira de se conectar ao Neo4j a partir do Python. Simplesmente pip-install py2neo e conecte-se ao armazenamento por meio de algo como"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = py2neo.Graph(host=\"localhost\", port=7687, user=\"neo4j\", password=\"neo4j\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para começar com um banco de dados vazio, você pode truncar tudo com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_db_query = \"\"\"\n",
    "MATCH(n) DETACH\n",
    "DELETE(n)\n",
    "\"\"\"\n",
    "tx = graph.begin(autocommit=True)\n",
    "tx.evaluate(empty_db_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para carregar todos os nós, use o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_node_query = \"\"\"\n",
    "    UNWIND $node_list as node\n",
    "    CREATE( e: paper {\n",
    "        ID: toInteger(node.id),\n",
    "        subject: node.subject,\n",
    "        features: node.features\n",
    "    })\n",
    "    \"\"\"\n",
    "batch_len = 500\n",
    "for batch_start in range(0, len(node_list), batch_len):\n",
    "    batch_end = batch_start + batch_len\n",
    "    # turn node dataframe into a list of records\n",
    "    records = node_list.iloc[batch_start:batch_end].to_dict(\"records\")\n",
    "    tx = graph.begin(autocommit=True)\n",
    "    tx.evaluate(loading_node_query, parameters={\"node_list\": records})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da mesma forma, para as arestas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_edge_query = \"\"\"\n",
    "    UNWIND $edge_list as edge\n",
    "    MATCH(source: paper {ID: toInteger(edge.source)})\n",
    "    MATCH(target: paper {ID: toInteger(edge.target)})\n",
    "    MERGE (source)-[r:cites]->(target)\n",
    "    \"\"\"\n",
    "batch_len = 500\n",
    "for batch_start in range(0, len(edge_list), batch_len):\n",
    "    batch_end = batch_start + batch_len\n",
    "    # turn edge dataframe into a list of records\n",
    "    records = edge_list.iloc[batch_start:batch_end].to_dict(\"records\")\n",
    "    tx = graph.begin(autocommit=True)\n",
    "    tx.evaluate(loading_edge_query, parameters={\"edge_list\": records})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem de Processos com GKANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrar a modelagem de processos com a arquitetura Kolmogorov-Arnold oferece uma abordagem inovadora para otimizar PDI em tecnologias em saúde. Ao desenvolver um sistema de recomendação baseado em agrupamento dinâmico e similaridade semântica, é possível fornecer insights valiosos que podem impulsionar a colaboração e a inovação nesse campo.\n",
    "\n",
    "A seguir, apresento um guia sobre como essa integração pode ser realizada, especialmente no contexto de um sistema de recomendação que utiliza KAGNNs para agrupar dinamicamente entidades e relacionamentos com base em similaridade semântica.\n",
    "\n",
    "1. Estruturação da Modelagem de Processos\n",
    "- Definir Processos e Entidades\n",
    "    - Identificar processos: Comece identificando os principais processos envolvidos em PDI, como pesquisa de mercado, desenvolvimento de produtos e testes clínicos. Cada um desses processos pode ser representado como um nó em um grafo.\n",
    "    - Relacionamentos: Mapeie as interações entre esses processos e as entidades envolvidas (pesquisadores, tecnologias, publicações). As arestas do grafo representarão as relações entre essas entidades.\n",
    "- Mapeamento e Abstração\n",
    "    - Níveis de Abstração: Organize os processos em níveis de abstração. Isso permite que a organização visualize tanto o panorama geral quanto os detalhes específicos de cada processo. A modelagem em níveis ajuda a identificar oportunidades de melhoria e a compreender as dependências entre os processos \\cite{1}.\n",
    "    - Documentação: Documente todos os processos utilizando notações padrão (como BPMN) para garantir que todos os envolvidos tenham acesso às informações necessárias \\cite{2}.\n",
    "\n",
    "2. Implementação da Arquitetura Kolmogorov-Arnold\n",
    "- Desenvolvimento do KAGNN\n",
    "    - Camadas Spline Aprendíveis: Utilize camadas que implementem funções spline aprendíveis para capturar interações complexas entre nós. Isso permite que o modelo aprenda representações não lineares das relações entre entidades \\cite{3}.\n",
    "    - Treinamento Dinâmico: O treinamento do KAGNN deve ser contínuo, permitindo que o modelo se adapte a novas informações e mudanças nos processos ao longo do tempo.\n",
    "\n",
    "- Predição de Links\n",
    "    - Algoritmos de Predição: Implemente algoritmos que utilizem as características aprendidas pelos nós para prever novas conexões ou colaborações potenciais. Isso é essencial para um sistema de recomendação eficaz \\cite{3}.\n",
    "\n",
    "3. Sistema de Recomendação Baseado em Similaridade Semântica\n",
    "- Agrupamento Dinâmico\n",
    "    - Semelhança Semântica: Utilize técnicas de processamento de linguagem natural (NLP) para calcular a similaridade semântica entre as descrições das entidades no grafo. Isso permitirá o agrupamento dinâmico das entidades com base nas suas características \\cite{ruan2021dynamicstructuralclusteringgraphs}.\n",
    "    - Recomendações Personalizadas: Com base nos grupos formados, o sistema pode gerar recomendações personalizadas para pesquisadores, sugerindo colaborações ou tecnologias relevantes.\n",
    "    - Geração de Recomendações em Linguagem Natural: Utilize técnicas de geração de linguagem natural (NLG) para apresentar as recomendações em uma forma compreensível. Isso pode incluir resumos automáticos ou sugestões personalizadas adaptadas ao contexto do usuário.\n",
    "\n",
    "4. Monitoramento e Melhoria Contínua\n",
    "- Análise de Desempenho: Monitore continuamente o desempenho dos processos e do sistema de recomendação. Utilize KPIs (Indicadores-Chave de Desempenho) para avaliar a eficácia das recomendações e identificar áreas para melhorias \\cite{2}.\n",
    "- Ajustes Baseados em Feedback: Implemente um sistema que permita coletar feedback dos usuários sobre as recomendações feitas. Esse feedback pode ser usado para ajustar o modelo e melhorar a precisão das previsões ao longo do tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@article{1,\n",
    "  title={Como Mapear a Arquitetura de Processos da Organização},\n",
    "  author={iProcess},\n",
    "  year={2019},\n",
    "  url={https://blog.iprocess.com.br/2019/05/modelando-a-arquitetura-de-processos-da-organizacao/}\n",
    "}\n",
    "\n",
    "@article{2,\n",
    "  title={Modelagem de Processos: como mapear e otimizar seus fluxos de trabalho},\n",
    "  author={Runrun.it},\n",
    "  year={2024},\n",
    "  url={https://blog.runrun.it/modelagem-de-processos/}\n",
    "}\n",
    "\n",
    "@article{3,\n",
    "  title={Kolmogorov-Arnold Graph Neural Networks},\n",
    "  author={Ryan Zhang et al.},\n",
    "  journal={AI Research Paper Details},\n",
    "  year={2024},\n",
    "  url={https://www.aimodels.fyi/papers/arxiv/kolmogorov-arnold-graph-neural-networks}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrar a modelagem de processos com a arquitetura de Kolmogorov-Arnold (KAN) pode proporcionar melhorias significativas na eficiência de Pesquisa, Desenvolvimento e Inovação (PDI). Abaixo, apresento uma abordagem estruturada para essa integração, considerando os insights dos resultados da pesquisa.\n",
    "\n",
    "1. Estruturação da Modelagem de Processos\n",
    "Definição de Objetivos\n",
    "- Identificar Processos: Comece por identificar os processos-chave envolvidos em PDI, como pesquisa de mercado, desenvolvimento de produtos e testes clínicos. Cada um desses processos deve ser representado como um nó em um grafo.\n",
    "- Mapear Relações: Mapeie as interações entre essas entidades, como colaborações entre pesquisadores e instituições, ou conexões entre tecnologias e suas aplicações. Isso ajudará a visualizar as dependências e interações no sistema \\cite{1}.\n",
    "- Definir nível adequado de detalhamento/abstração\n",
    "    - Níveis de Abstração: Organize os processos em níveis de abstração. Isso permite que a organização identifique oportunidades para melhoria através do desdobramento em níveis incrementais de detalhamento \\cite{1}. A modelagem em níveis ajuda a compreender como cada atividade se encaixa no negócio.\n",
    "\n",
    "2. Implementação da Arquitetura Kolmogorov-Arnold\n",
    "- Desenvolvimento do KAGNN\n",
    "    - Camadas Spline Aprendíveis: Utilize camadas que implementem funções spline aprendíveis para capturar interações complexas entre nós. Essa flexibilidade permite que o modelo se adapte às características dos dados em PDI \\cite{2}.\n",
    "    - Treinamento Contínuo: O treinamento do KAGNN deve ser contínuo, permitindo que o modelo se adapte a novas informações e mudanças nos processos ao longo do tempo.\n",
    "- Predição de Links\n",
    "    - Algoritmos de Predição: Implemente algoritmos que utilizem as características aprendidas pelos nós para prever novas conexões ou colaborações potenciais. Isso é essencial para um sistema de recomendação eficaz \\cite{3}.\n",
    "\n",
    "3. Sistema de Recomendação Baseado em Similaridade Semântica\n",
    "- Agrupamento Dinâmico\n",
    "    - Semelhança Semântica: Utilize técnicas de processamento de linguagem natural (NLP) para calcular a similaridade semântica entre as descrições das entidades no grafo. Isso permitirá o agrupamento dinâmico das entidades com base nas suas características \\cite{ruan2021dynamicstructuralclusteringgraphs}.\n",
    "    - Recomendações Personalizadas: Com base nos grupos formados, o sistema pode gerar recomendações personalizadas para pesquisadores, sugerindo colaborações ou tecnologias relevantes.\n",
    "    - Geração de Recomendações em Linguagem Natural: Utilize técnicas de geração de linguagem natural (NLG) para apresentar as recomendações em uma forma compreensível. Isso pode incluir resumos automáticos ou sugestões personalizadas adaptadas ao contexto do usuário.\n",
    "\n",
    "4. Monitoramento e Melhoria Contínua\n",
    "- Análise de Desempenho: Monitore continuamente o desempenho dos processos e do sistema de recomendação. Utilize KPIs (Indicadores-Chave de Desempenho) para avaliar a eficácia das recomendações e identificar áreas para melhorias \\cite{1}.\n",
    "- Ajustes Baseados em Feedback: Implemente um sistema que permita coletar feedback dos usuários sobre as recomendações feitas. Esse feedback pode ser usado para ajustar o modelo e melhorar a precisão das previsões ao longo do tempo.\n",
    "\n",
    "Integrar a modelagem de processos com a arquitetura Kolmogorov-Arnold oferece uma abordagem inovadora para otimizar PDI em tecnologias em saúde. Ao desenvolver um sistema de recomendação baseado em agrupamento dinâmico e similaridade semântica, é possível fornecer insights valiosos que podem impulsionar a colaboração e a inovação nesse campo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@article{1,\n",
    "  title={Como Mapear a Arquitetura de Processos da Organização},\n",
    "  author={iProcess},\n",
    "  year={2019},\n",
    "  url={https://blog.iprocess.com.br/2019/05/modelando-a-arquitetura-de-processos-da-organizacao/}\n",
    "}\n",
    "\n",
    "@article{2,\n",
    "  title={Kolmogorov-Arnold Graph Neural Networks},\n",
    "  author={Ryan Zhang et al.},\n",
    "  journal={AI Research Paper Details},\n",
    "  year={2024},\n",
    "  url={https://www.aimodels.fyi/papers/arxiv/kolmogorov-arnold-graph-neural-networks}\n",
    "}\n",
    "\n",
    "@INPROCEEDINGS{9888613,\n",
    "  author={Ibrahim, Rowaida Khalil and Zeebaree, Subhi R. M. and Jacksi, Karwan and Ahmed, Sarkar Hasan and Mohammed, Shapol M. and Zebari, Rizgar R. and Alkhayyat, Ahmed and Rashid, Zryan Najat},\n",
    "  booktitle={2022 5th International Conference on Engineering Technology and its Applications (IICETA)}, \n",
    "  title={Clustering Document based on Semantic Similarity Using Graph Base Spectral Algorithm}, \n",
    "  year={2022},\n",
    "  volume={},\n",
    "  number={},\n",
    "  pages={254-259},\n",
    "  keywords={Dictionaries;Databases;Semantics;Clustering algorithms;Encyclopedias;Syntactics;Numerical models;Semantic Similarity;Text Clustering;Spectral Algorithm TFIDF},\n",
    "  doi={10.1109/IICETA54559.2022.9888613}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quais são os principais componentes da arquitetura de Kolmogorov-Arnold que precisam ser considerados na modelagem de processos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para integrar a modelagem de processos com a arquitetura de Kolmogorov-Arnold (KAN), é fundamental considerar os principais componentes da KAN que podem influenciar a eficiência e a eficácia dos processos em Pesquisa, Desenvolvimento e Inovação (PDI). Abaixo estão os principais componentes a serem considerados:\n",
    "1. Definição de Entidades e Relacionamentos\n",
    "- Identificar Entidades e mapear Relacionamentos\n",
    "    - Nós: As entidades relevantes no contexto de PDI, como pesquisadores, instituições, projetos e tecnologias, devem ser claramente definidas como nós no grafo. Cada entidade deve ter atributos que representem suas características semânticas.\n",
    "    - Arestas: As interações entre as entidades devem ser representadas como arestas, que podem incluir colaborações em projetos, coautorias em publicações e conexões entre tecnologias e suas aplicações. A modelagem das relações é crucial para entender como as entidades interagem dentro do processo PDI \\cite{1}.\n",
    "\n",
    "2. Representação de Funções Spline Aprendíveis\n",
    "- Funções Aprendíveis: As KANs utilizam funções spline para modelar relações complexas entre as entidades. Isso permite que o modelo capture interações não lineares e adaptativas, melhorando a capacidade de previsão e recomendação \\cite{2}.\n",
    "- Adaptabilidade: A arquitetura deve ser projetada para se adaptar às mudanças nas relações e nas características das entidades ao longo do tempo, permitindo uma modelagem dinâmica dos processos.\n",
    "\n",
    "3. Predição de Links\n",
    "- Algoritmos de Predição: Utilize algoritmos que aproveitem as representações aprendidas pelos nós para prever novas conexões ou colaborações potenciais. Isso é essencial para um sistema de recomendação eficaz, onde novas oportunidades de colaboração podem ser identificadas com base nas similaridades semânticas \\cite{3}.\n",
    "\n",
    "4. Agrupamento Dinâmico Baseado em Similaridade Semântica\n",
    "- Semelhança Semântica: A similaridade semântica entre as entidades deve ser avaliada utilizando técnicas de processamento de linguagem natural (NLP). Isso permitirá o agrupamento dinâmico das entidades com base nas suas características e na relevância dentro do contexto PDI \\cite{4}.\n",
    "- Recomendações Personalizadas: Com base nos grupos formados, o sistema pode gerar recomendações personalizadas para pesquisadores, sugerindo colaborações ou tecnologias relevantes que podem agregar valor ao processo PDI.\n",
    "\n",
    "5. Monitoramento e Melhoria Contínua\n",
    "- Análise de Desempenho: Monitore continuamente o desempenho dos processos e do sistema de recomendação. Utilize KPIs (Indicadores-Chave de Desempenho) para avaliar a eficácia das recomendações e identificar áreas para melhorias \\cite{1}.\n",
    "- Feedback e Ajustes: Implemente um sistema que permita coletar feedback dos usuários sobre as recomendações feitas. Esse feedback pode ser usado para ajustar o modelo e melhorar a precisão das previsões ao longo do tempo.\n",
    "\n",
    "Integrar a modelagem de processos com a arquitetura Kolmogorov-Arnold oferece uma abordagem inovadora para otimizar PDI em tecnologias em saúde. Ao considerar os principais componentes da KAN na modelagem, é possível desenvolver um sistema de recomendação baseado em agrupamento dinâmico e similaridade semântica, proporcionando insights valiosos que podem impulsionar a colaboração e a inovação nesse campo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@article{1,\n",
    "  title={Como Mapear a Arquitetura de Processos da Organização},\n",
    "  author={iProcess},\n",
    "  year={2019},\n",
    "  url={https://blog.iprocess.com.br/2019/05/modelando-a-arquitetura-de-processos-da-organizacao/}\n",
    "}\n",
    "\n",
    "@article{2,\n",
    "  title={Kolmogorov-Arnold Graph Neural Networks},\n",
    "  author={Ryan Zhang et al.},\n",
    "  journal={AI Research Paper Details},\n",
    "  year={2024},\n",
    "  url={https://www.aimodels.fyi/papers/arxiv/kolmogorov-arnold-graph-neural-networks}\n",
    "}\n",
    "\n",
    "@article{3,\n",
    "  title={Dynamic Clustering for Semantic Similarity in Graphs},\n",
    "  author={Author C},\n",
    "  journal={Journal of Graph Theory},\n",
    "  year={2024}\n",
    "}\n",
    "\n",
    "@article{4,\n",
    "  title={Exploring PyTorch Geometric Impact on Graph Neural Networks},\n",
    "  author={MyScale},\n",
    "  year={2024},\n",
    "  url={https://myscale.com/blog/impact-pytorch-geometric-graph-neural-networks/}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
