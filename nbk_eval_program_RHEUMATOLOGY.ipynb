{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b48e5c3",
   "metadata": {},
   "source": [
    "## <center>Avaliação potencial de reposicionamento por similaridade de<br /> perfil de expressão proteica para tratamento de Artrite Reumatóide</center>\n",
    "\n",
    "    Suzana Benetti Bahlis Aires Barbosa\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "    Avaliar o potencial de reposicionamento de medicamentos para tratamento de Artrite Reumatóide por estudo meio de estudos computacionais em farmacologia de redes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e961c",
   "metadata": {},
   "source": [
    "# Definir Indicadores do Programa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c3005",
   "metadata": {},
   "source": [
    "### 1. Pontuação por Fator de Impacto (PFI >=600)\n",
    "- Meta: PFI >= 600 em pelo menos 70% dos docentes\n",
    "\n",
    "    Indicador: Total de pontos conforme periódicos das publicações no período\n",
    "     Objetivo: Publicar trabalhos em periódicos de elevado impacto\n",
    "               \n",
    "         Meta: 70% dos docentes permanentes com PFI >= 600 pontos no quadriênio\n",
    "               (150/ano e ao menos 03 artigos A, no mínimo 02 em A1, ou 04 artigos A2);\n",
    " \n",
    "      Cálculo: Soma ponderada pela estratificação Qualis de acordo com o que segue:\n",
    "        A1 = 100 pontos\n",
    "        A2 = 80 pontos\n",
    "        B1 = 60 pontos\n",
    "        B2 = 40 pontos\n",
    "        B3 = 20 pontos\n",
    "        B4 = 10 pontos\n",
    "        B5 = 2 pontos.\n",
    "\n",
    "\n",
    "Parâmetro para classificaçao do periódico:\n",
    "\n",
    "        A1: FI Periódico ou CPD >= 4,300\n",
    "        A2: FI Periódico ou CPD entre 2,950 e 4,299\n",
    "        B1: FI Periódico ou CPD entre 1,800 e 2,949\n",
    "        B2: FI Periódico ou CPD entre 1,100 e 1,799\n",
    "        B3: FI Periódico ou CPD entre 0,300 e 1,099\n",
    "        B4: FI Periódico ou CPD entre 0,001 e 0,299, (ou Scielo, Scimago, PubMed ou Web of Science)\n",
    "        B5: Periódicos sem FI ou CPD e indexado nas lases Lilacs ou Latindex    \n",
    "\n",
    "### 2. Produção Conjunta docentes/discentes (IPC >= 50%):\n",
    "    Indicador: Índice de publicações com discentes por orientador (IPC)\n",
    "     Objetivo: Em, pelo menos, 50 % dos artigos publicados deve constar discentes do programa\n",
    "         Meta: IPC >= 50,00\n",
    "      \n",
    "      Cálculo:\n",
    "\n",
    "$$\\sum_{k=1}^{n}\\, 100 * \\frac{QPCD}{QPAT}$$\n",
    "\n",
    "        onde:\n",
    "               n = Artigos completos publicado em periódicos indexados\n",
    "            QPCD = Qte. Publicação de Artigos com discentes do Programa na lista de autores\n",
    "            QPAT = Qte. Publicação de Artigos Total no período avaliado\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3cf167",
   "metadata": {},
   "source": [
    "# <b>F00: Preparar Ambiente local</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9700467c",
   "metadata": {},
   "source": [
    "### Instalações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed4cec7",
   "metadata": {},
   "source": [
    "#### Instalar Git, WSL, amb.virtual ou Contêiner Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc48fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instalar o WSL e integrar ao VSCode, no terminal rodar:\n",
    "## Verificar versões já instaladas\n",
    "#wsl -l -v\n",
    "## Atualizar para WSL2 para que as instalações de distros já rodem em WSL2 por padrão\n",
    "#wsl --set-default-version 2\n",
    "## Reiniciar a máquina e instalar distribuição Linux Ubuntu LTS pelo store do windows\n",
    "## Configurar VScode: iniciar VScode e instalar a extensão \"Remote - WSL\" para desenvolver diretamente no VSCode dentro do ambiente do WSL.\n",
    "# Após a instalação, na parte inferior esquerda da janela do VSCode, aparecerá o ícone verde.\n",
    "# Clicar no ícone verde e selecionar \"New WSL Window\" ou \"Reopen in WSL\" se o projeto já estiver aberto.\n",
    "# Agora, o VSCode estará rodando dentro do contexto do seu WSL, pode-se abrir terminais dentro do VSCode que acessarão diretamente o Linux.\n",
    "\n",
    "## Instalar Python e o Pip:\n",
    "# sudo apt update\n",
    "# sudo apt install python3-pip\n",
    "\n",
    "## Inserir dados do Git no VScode, no terminal rodar:\n",
    "# git config --global user.name \"nome_usuario_gi\"\n",
    "# git config --global user.email \"email_git\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f72ab53",
   "metadata": {},
   "source": [
    "#### Instalar gerenciador e pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3348635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intalar os gerenciador de pacotes PIP  no terminal do WSL executar:\n",
    "# sudo apt update\n",
    "# sudo apt upgrade\n",
    "# sudo apt install python3-pip\n",
    "# python3 -m pip install --upgrade pip\n",
    "\n",
    "## Atualizar o gerenciador de pacotes e ferramentas de compilação\n",
    "# %pip install --upgrade pip setuptools wheel\n",
    "\n",
    "## Instalar primeiro o GraphViz antes do ygraphviz, no terminal do WSL rodar e depois reiniciar o kernel:\n",
    "## Para Linux e WSL instalar a partir do terminal:\n",
    "# sudo apt-get install graphviz graphviz-dev\n",
    "\n",
    "## Para Windows, atualizar o gerenciador de pacotes e ferramentas de compilação:\n",
    "# %pip install --upgrade pip setuptools wheel\n",
    "\n",
    "## Instalar o Chocolatey (Só para Windows, não no WSL)\n",
    "## Baixar e instalar o gerenciador chocolatey em https://jcutrer.com/windows/install-chocolatey-choco-windows10\n",
    "# Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\n",
    "\n",
    "## Baixar e instalar o Graphviz em https://www.graphviz.org/download/\n",
    "## https://savleen307.medium.com/pygraphviz-installation-in-windows-f45cc6fed981\n",
    "## Seguir as instruções em https://pygraphviz.github.io/documentation/stable/install.html#id1\n",
    "# O comando na página acima está errado por conter duas aspas onde não deve, executar o comando abaixo:\n",
    "# python -m pip install --use-pep517 --config-settings=\"--global-option=build_ext\" --config-settings=\"--global-option=-IC:\\Program Files\\Graphviz\\include\" --config-settings=--global-option=\"-LC:\\Program Files\\Graphviz\\lib\" pygraphviz\n",
    "\n",
    "## Instalar o pacote no ambiente local\n",
    "# %pip install pygraphviz\n",
    "\n",
    "## Para instalar o Conda (Miniconda ou Anaconda) no WSL, baixar o script de instalação diretamente do site oficial e executá-lo manualmente.\n",
    "## Passos para instalar o Miniconda como exemplo:\n",
    "## Baixar script de instalação do Miniconda para Linux:\n",
    "# wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "# bash Miniconda3-latest-Linux-x86_64.sh\n",
    "# conda --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af3065f",
   "metadata": {},
   "source": [
    "#### Instalar requirements.txt e importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25a9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Localizar requirements.txt para instalar bibliotecas no ambente\n",
    "# os.listdir('./../../../../')\n",
    "# %pip install -r ./../../../../requirements.txt\n",
    "\n",
    "## Outras instalações pontuais quando necessário, por exemplo:\n",
    "# import os, tqdm\n",
    "# %pip install chardet\n",
    "# print(tqdm.__version__)\n",
    "# %pip3 install --upgrade plotly\n",
    "# %pip3 install omegaconf --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87ef1b",
   "metadata": {},
   "source": [
    "#### Instalar e configurar GPU e CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2bc898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instalar drivers da GPU e compilador CUDA Nvidia\n",
    "## Obter comandos adequados para cada sistema em: https://developer.nvidia.com/cuda-downloads\n",
    "## Exemplo para Linux com Ubuntu\n",
    "# wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin\n",
    "# sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "# wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda-repo-wsl-ubuntu-12-4-local_12.4.0-1_amd64.deb\n",
    "# sudo dpkg -i cuda-repo-wsl-ubuntu-12-4-local_12.4.0-1_amd64.deb\n",
    "# sudo cp /var/cuda-repo-wsl-ubuntu-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/\n",
    "# sudo apt-get update\n",
    "# sudo apt-get -y install cuda-toolkit-12-4\n",
    "\n",
    "## Instruções para instalação do PyTorch para usar a GPU em Windows\n",
    "# https://sh-tsang.medium.com/tutorial-cuda-cudnn-anaconda-jupyter-pytorch-installation-in-windows-10-96b2a2f0ac57\n",
    "\n",
    "## Para máquinas com apenas CPU\n",
    "# !pip install torch torchvision\n",
    "\n",
    "## Testar cálculo na GPU\n",
    "# import torch\n",
    "# x = torch.rand(5, 3)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e551ffdc",
   "metadata": {},
   "source": [
    "#### Implementar classes para obter e preparar dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c921ae65",
   "metadata": {},
   "source": [
    "    LattesScraper (Extrair currículos Lattes)\n",
    "    SoupParser (Extrair dados de Objeto Soup)\n",
    "    Neo4jPersister (Persistir em Neo4j)\n",
    "    DatasetArticlesGenerator (Gerar Datasets)\n",
    "    DictToHDF5 (converter dicionários para HDF5)\n",
    "    ArticlesCounter (Montar qte artigos e atualização)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f6e3cb",
   "metadata": {},
   "source": [
    "### Gerar pastas e classes de processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edfd06ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd, os, re, sys, time, json, subprocess\n",
    "\n",
    "## Configurar exibição do pandas para melhor visualizar os dados\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('colheader_justify', 'left')\n",
    "pd.set_option('display.max_rows', 600)\n",
    "\n",
    "def find_repo_root(path='.', depth=10):\n",
    "    ''' \n",
    "    Busca o arquivo .git e retorna string com a pasta raiz do repositório\n",
    "    '''\n",
    "    # Prevent infinite recursion by limiting depth\n",
    "    if depth < 0:\n",
    "        return None\n",
    "    path = Path(path).absolute()\n",
    "    if (path / '.git').is_dir():\n",
    "        return path\n",
    "    return find_repo_root(path.parent, depth-1)\n",
    "\n",
    "delay = 10\n",
    "\n",
    "## Definir a pasta de base do repositório local\n",
    "base_repo_dir = find_repo_root()\n",
    "\n",
    "## Sempre construir os caminhos usando os.path.join para compatibilidade WxL\n",
    "folder_utils = os.path.join(base_repo_dir, 'utils')\n",
    "folder_domain = os.path.join(base_repo_dir, 'source', 'domain')\n",
    "folder_data_input = os.path.join(base_repo_dir, '_data', 'in_csv')\n",
    "folder_data_output = os.path.join(base_repo_dir, '_data', 'out_json')\n",
    "\n",
    "## Adicionar pastas locais ao sys.path para importar pacotes criados localmente\n",
    "sys.path.append(folder_utils)\n",
    "sys.path.append(folder_domain)\n",
    "# from scraper_pasteur import PasteurScraper\n",
    "# from scraper_sucupira import SucupiraScraper\n",
    "# from scraper_sucupira_edge import SucupiraScraperEdge\n",
    "from environment_setup import EnvironmentSetup\n",
    "from chromedriver_manager import ChromeDriverManager\n",
    "from neo4j_persister import Neo4jPersister\n",
    "from lattes_scrapper import JSONFileManager, LattesScraper, HTMLParser, SoupParser, GetQualis, ArticlesCounter, DictToHDF5, attribute_to_be_non_empty\n",
    "\n",
    "t00 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff45fefc",
   "metadata": {},
   "source": [
    "### Checar Chromedriver e GoogleChrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71efa162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versões 126 Chrome e 126 Chromedriver estão compatíveis\n"
     ]
    }
   ],
   "source": [
    "# Cria instância da classe ChromeDriverManager e verifica compatibilidade entre versões do Chrome e Chromedriver\n",
    "actualizer = ChromeDriverManager()\n",
    "actualizer.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3962aad",
   "metadata": {},
   "source": [
    "### Obter Qualis Periódicos Plataforma Sucupira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d03c0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sucupira = SucupiraScraperEdge()\n",
    "# sucupira.scrape_sucupira()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb1692",
   "metadata": {},
   "source": [
    "# <b>F01: Obter dados de Docentes</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd18ddb",
   "metadata": {},
   "source": [
    "## Rodar testes e definir pastas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b06c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary directories are ensured.\n",
      "Processador em uso: \n",
      "Arquitetura modelo: AMD64 Family 25 Model 33 Stepping 0, AuthenticAMD\n",
      "Arquitetura em uso: 64bit\n",
      "Frequência das CPU: 3801.0 MHz\n",
      "  Qte CPUs físicas: 8\n",
      "  Qte CPUs lógicas: 16\n",
      "Carga total na CPU: 3.4%\n",
      "Ocupação atual CPU: user=1.6%, system=2.0%, idle=95.7%\n",
      "\n",
      "Espaço Total em disco: 465.15 GB\n",
      "Espaço em disco usado: 379.47 GB 81.6%\n",
      "Espaço em disco livre: 85.68 GB 18.4%\n",
      "\n",
      "Capacidade memórias RAM: 63.94 GB\n",
      "Utilização atual da RAM: 15.10 GB\n",
      "\n",
      "VERSÕES DOS DRIVERS CUDA, PYTORCH E GPU\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Wed_Nov_22_10:30:42_Pacific_Standard_Time_2023\n",
      "Cuda compilation tools, release 12.3, V12.3.107\n",
      "Build cuda_12.3.r12.3/compiler.33567101_0\n",
      "\n",
      "    PyTorch: 2.2.0+cu121\n",
      "Dispositivo: cuda\n",
      "Disponível: cuda True  | Inicializado: False | Capacidade: (7, 5)\n",
      "Nome GPU: NVIDIA GeForce RTX 2060  | Quantidade: 1\n",
      "\n",
      "VERSÕES DAS PRINCIPAIS BIBLIOTECAS INSTALADAS NO ENVIROMENT\n",
      "Ambiente Conda ativo: base\n",
      "Interpretador em uso: c:\\Users\\marco\\anaconda3\\python.exe\n",
      " Python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)] \n",
      "    Pip: pip 24.0 from c:\\Users\\marco\\anaconda3\\Lib\\site-packages\\pip (python 3.11)\n",
      "\n",
      "\n",
      "Pasta para xls_zip já existe!\n",
      "Pasta para csv já existe!\n",
      "Pasta para json já existe!\n",
      "Pasta para fig já existe!\n",
      "Pasta para output já existe!\n",
      "\n",
      "Caminho da pasta raiz: C:\\Users\\marco\\reumato\n",
      "Caminho para xls_zip: xls_zip\n",
      "Caminho para csv: csv\n",
      "Caminho para json: json\n",
      "Caminho para fig: fig\n",
      "Caminho para output: output\n"
     ]
    }
   ],
   "source": [
    "# Cria instância da classe EnvironmenSetup e preparar pastas\n",
    "preparer = EnvironmentSetup()\n",
    "folder_name = input(\"Digite o nome da pasta principal: \")\n",
    "preparer.set_root_path(folder_name)\n",
    "preparer.try_cpu()\n",
    "preparer.try_gpu()\n",
    "preparer.try_amb()\n",
    "# preparer.try_browser()\n",
    "preparer.preparar_pastas()\n",
    "\n",
    "## Remover diretórios no linux\n",
    "# !rm -rf /home/mak/fioce\n",
    "# os.listdir('/home/mak/fioce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616b92e7",
   "metadata": {},
   "source": [
    "## Montar lista_busca para dados de Docentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d842eb06",
   "metadata": {},
   "source": [
    "### Carregar nomes de arquivo .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "580d2799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 nomes a buscar\n"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "from environment_setup import EnvironmentSetup\n",
    "preparer = EnvironmentSetup()\n",
    "\n",
    "## Montar lista_nomes com arquivo .csv\n",
    "pathfilename = os.path.join(folder_data_input,'docentes_farmacologia.csv')\n",
    "lista_busca = pd.read_csv(pathfilename,header=None)[0].values\n",
    "print(f'{len(lista_busca)} nomes a buscar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60b70694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plantuml\n",
    "# !pip install ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a886c3",
   "metadata": {},
   "source": [
    "```plantuml\n",
    "    @startuml\n",
    "\n",
    "    left to right direction\n",
    "\n",
    "    rectangle \"H1: Modelagem do Ecossistema CEIS como Grafo de Conhecimento\" as H1\n",
    "    rectangle \"H2: Alinhamento de Competências e Necessidades via Técnicas Computacionais\" as H2\n",
    "    rectangle \"H3: Identificação de Oportunidades de Alinhamento para Maximizar Impacto\" as H3\n",
    "\n",
    "    cloud \"Coleta de Dados\" as Dados\n",
    "    Dados --> H1\n",
    "    Dados --> H2\n",
    "\n",
    "    rectangle \"Construção do Grafo de Conhecimento\" as Grafo\n",
    "    H1 --> Grafo\n",
    "\n",
    "    rectangle \"Análise de Competências\" as Competencias\n",
    "    H2 --> Competencias\n",
    "\n",
    "    rectangle \"Algoritmos de GML\" as GML\n",
    "    Grafo --> GML\n",
    "    Competencias --> GML\n",
    "\n",
    "    rectangle \"Métricas de Alinhamento\" as Metricas\n",
    "    GML --> Metricas\n",
    "\n",
    "    H3 --> Metricas\n",
    "\n",
    "    rectangle \"Identificação de Oportunidades\" as Oportunidades\n",
    "    Metricas --> Oportunidades\n",
    "\n",
    "    rectangle \"Avaliação do Impacto\" as Impacto\n",
    "    Oportunidades --> Impacto\n",
    "\n",
    "    @enduml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35849f4e",
   "metadata": {},
   "source": [
    "## <b>Processar extração de dados de Docentes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95ffba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 currículos Lattes a extrair\n"
     ]
    }
   ],
   "source": [
    "## Definir termos de vínculo\n",
    "repo_root = preparer.find_repo_root(os.getcwd())\n",
    "pasta_dados = os.path.join(repo_root,'_data','out_json')\n",
    "termos_busca = ['Reumatologia', 'Pesquisa', 'Clínica', 'Oncovie']\n",
    "print(f'{len(lista_busca)} currículos Lattes a extrair')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d2a31",
   "metadata": {},
   "source": [
    "### Extrair currículos de Docentes da plataforma Lattes\n",
    "    (12~16min/37nomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07a2e8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando currículos com qualquer nível de formação\n",
      " 1/2: José Aurillo Rocha\n",
      "       005 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      " 2/2: Maria Elisabete Amaral de Moraes\n",
      "       219 artigos extraídos\n",
      "       DOI indisponível em 02 artigos extraídos\n",
      "       Extração bem-sucedida\n",
      "Arquivo salvo em c:\\Users\\marco\\ppgcs\\_data\\in_csv\\temp_dict_list.json\n",
      "\n",
      "00:01:32 para busca de 2 nomes com extração de dados de 2 dicionários\n"
     ]
    }
   ],
   "source": [
    "## Passar parâmetro only_doctors para False para extrair também níveis mestrado e graduação\n",
    "t1 = time.time()\n",
    "scraper = LattesScraper(termos_busca, 'bolt://localhost:7687', 'neo4j', 'password', only_doctors=False)\n",
    "\n",
    "dict_list_docents = scraper.scrape(lista_busca, termos_busca)\n",
    "print(f'\\n{scraper.tempo(t1,time.time())} para busca de {len(lista_busca)} nomes com extração de dados de {len(dict_list_docents)} dicionários')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340ce781",
   "metadata": {},
   "source": [
    "### Identificar currículos remanescentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ed4d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# termos_busca = ['Fiocruz', 'Cruz', 'Imunopatologia', 'Ministerio da Saude']\n",
    "# scraper = LattesScraper(termos_busca, \n",
    "#                         'bolt://localhost:7687', 'neo4j', 'password', \n",
    "#                         only_doctors=False)\n",
    "\n",
    "# lista_restante = scraper.avaliar_remanescentes(lista_busca, dict_list_docents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e08b2e",
   "metadata": {},
   "source": [
    "### Adicionar nomes ou novos termos, se necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11ae091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ciipf = ['Caroline Pereira Bittencourt Passaes',\n",
    "# 'Ana Carolina Matias Dinelly Pinto',\n",
    "# 'Clarissa Perdigao Mello Ferraz',\n",
    "# 'Júlio César Martins Ximenes']\n",
    "\n",
    "# for i in ciipf:\n",
    "#     if i not in lista_restante:\n",
    "#         lista_restante.append(i)\n",
    "# for j in lista_restante:\n",
    "#     print(f'   {j}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d43ba36",
   "metadata": {},
   "source": [
    "### Extrair currículos remanescentes ou adicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b33d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lista_dict_combinado = extract_remanescents(lista_restante, dict_list_actual)\n",
    "# lista_dict_combinado = scraper.extract_remanescents(lista_restante, dict_list_docents, termos_busca)\n",
    "# filepath = os.path.join(folder_data_input,'dict_list_docents.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e369b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista_dict_combinado = dict_list_docents\n",
    "# print(f'{len(lista_dict_combinado)} currículos extraídos')\n",
    "# print('\\n\\nExemplo de dados dos artigos:')\n",
    "# [x.get('Produções') for x in lista_dict_combinado][0].get('Artigos completos publicados em periódicos')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f78b5",
   "metadata": {},
   "source": [
    "### Listar arquivos JSON gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "508b6080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_data_input = os.path.join(os.getcwd(),'_data','in_csv')\n",
    "# os.listdir(folder_data_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27f8ff",
   "metadata": {},
   "source": [
    "### Salvar dados de currículos de Docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4ab5b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 dicionários com currículos completos extraídos\n",
      "\n",
      "\n",
      "Exemplo de dados dos artigos:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ano': '2019',\n",
       " 'fator_impacto_jcr': '',\n",
       " 'ISSN': '01001302',\n",
       " 'titulo': 'Relação entre a atividade inflamatória e o estado nutricional de pacientes com câncer de pulmão',\n",
       " 'revista': 'REVISTA DE MEDICINA DA UNIVERSIDADE FEDERAL DO CEARÁ',\n",
       " 'autores': 'SOUZA, BENEDITA JALES2019SOUZA, BENEDITA JALES ; MESQUITA, ARMÊNIA UCHÔA DE ; MEIRELES, AMANDA ROCHA ; BRITO, JULIANA GIRÃO DE ; BANDEIRA, THALITA EVANGELISTA ;ROCHA, JOSÉ AURILLO. ',\n",
       " 'data_issn': '01001302',\n",
       " 'DOI': 'http://dx.doi.org/10.20513/2447-6595.2019v59n2p9-14',\n",
       " 'Qualis': 'B3'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lattes_scrapper import GetQualis\n",
    "stratifier = GetQualis()\n",
    "\n",
    "# Acrescentar Qualis periódicos aos dicionários de docentes\n",
    "print('\\nAdicionando Qualis Periódicos')\n",
    "pathfilename = os.path.join(folder_data_input,'docents_farmacology_dict_list.json')\n",
    "try:\n",
    "    stratifier.buscar_qualis_e_atualizar_arquivo(lista_dict_combinado, pathfilename)\n",
    "    scraper.save_to_json(lista_dict_combinado, pathfilename)\n",
    "except:\n",
    "    lista_dict_combinado = dict_list_docents\n",
    "\n",
    "stratifier.buscar_qualis_e_atualizar_arquivo(lista_dict_combinado, pathfilename)\n",
    "scraper.save_to_json(lista_dict_combinado, pathfilename)\n",
    "\n",
    "print(f'{len(lista_dict_combinado)} dicionários com currículos completos extraídos')\n",
    "print('\\n\\nExemplo de dados dos artigos:')\n",
    "[x.get('Produções') for x in lista_dict_combinado][0].get('Artigos completos publicados em periódicos')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b193bf",
   "metadata": {},
   "source": [
    "# F01a: Ler dados salvos de Docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a00a8642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos disponíveis na pasta para dados de entrada:\n",
      "  combined_dict_list.json\n",
      "  dict_list_discents_combined.json\n",
      "  dict_list_temp.json\n",
      "  discents_dict_list.json\n",
      "  docents_dict_list.json\n",
      "  docents_farmacology_dict_list.json\n",
      "  temp_dict_list.json\n",
      "\n",
      "2 currículos carregados na lista de dicionários 'docents_farmacology_dict_list.json'\n",
      "Arquivo criado inicialmente em 15/06/2024 16:58:37 carregado com sucesso\n",
      "Extração realizada em 15/06/2024 17:03:40 a 1.2 minutos\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd, os, re, sys, time, pytz, json, subprocess\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('colheader_justify', 'left')\n",
    "pd.set_option('display.max_rows', 600)\n",
    "\n",
    "def find_repo_root(path='.', depth=10):\n",
    "    ''' \n",
    "    Busca o arquivo .git e retorna string com a pasta raiz do repositório\n",
    "    '''\n",
    "    # Prevent infinite recursion by limiting depth\n",
    "    if depth < 0:\n",
    "        return None\n",
    "    path = Path(path).absolute()\n",
    "    if (path / '.git').is_dir():\n",
    "        return path\n",
    "    return find_repo_root(path.parent, depth-1)\n",
    "\n",
    "delay = 10\n",
    "\n",
    "## Definir a pasta de base do repositório local\n",
    "base_repo_dir = find_repo_root()\n",
    "\n",
    "## Sempre construir os caminhos usando os.path.join para compatibilidade WxL\n",
    "folder_utils = os.path.join(base_repo_dir, 'utils')\n",
    "folder_domain = os.path.join(base_repo_dir, 'source', 'domain')\n",
    "folder_data_input = os.path.join(base_repo_dir, '_data', 'in_csv')\n",
    "folder_data_output = os.path.join(base_repo_dir, '_data', 'output')\n",
    "sys.path.append(folder_utils)\n",
    "sys.path.append(folder_domain)\n",
    "# from scraper_pasteur import PasteurScraper\n",
    "# from scraper_sucupira import SucupiraScraper\n",
    "# from scraper_sucupira_edge import SucupiraScraperEdge\n",
    "from environment_setup import EnvironmentSetup\n",
    "from chromedriver_manager import ChromeDriverManager\n",
    "from neo4j_persister import Neo4jPersister\n",
    "from lattes_scrapper import JSONFileManager, LattesScraper, HTMLParser, SoupParser, GetQualis, ArticlesCounter, DiscentCollaborationCounter, DictToHDF5, attribute_to_be_non_empty\n",
    "\n",
    "# Carregar para variável dict_list_docents os dicionários com dados dos Docentes\n",
    "jfm = JSONFileManager()\n",
    "jfm.list_json(folder_data_input)\n",
    "filename = 'docents_farmacology_dict_list.json'\n",
    "\n",
    "dict_list_docents, formatted_creation_date, formatted_modification_date, time_count, unit = jfm.load_from_json(os.path.join(folder_data_input,filename))\n",
    "print(f\"\\n{len(dict_list_docents)} currículos carregados na lista de dicionários '{filename}'\")\n",
    "print(f\"Arquivo criado inicialmente em {formatted_creation_date} carregado com sucesso\")\n",
    "print(f\"Extração realizada em {formatted_modification_date} a {time_count} {unit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a026ea13",
   "metadata": {},
   "source": [
    "### Visualizar nomes extraídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5b42931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 currículos extraídos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Jose Aurillo Rocha', 'Maria Elisabete Amaral de Moraes']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jfm = JSONFileManager()\n",
    "\n",
    "filename = 'docents_farmacology_dict_list.json'\n",
    "pathfilename = os.path.join(folder_data_input, filename)\n",
    "dict_list_docents_complete, formatted_creation_date, formatted_modification_date, time_count, unit = jfm.load_from_json(pathfilename)\n",
    "lista_nomes_extraidos = [i.get('Identificação').get('Nome') for i in dict_list_docents_complete]\n",
    "\n",
    "print(f'{len(lista_nomes_extraidos)} currículos extraídos')\n",
    "lista_nomes_extraidos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d4549",
   "metadata": {},
   "source": [
    "### Acrescentar/Atualizar Qualis Periódicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa835f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 artigos do autor   2/  2\n"
     ]
    }
   ],
   "source": [
    "from lattes_scrapper import GetQualis\n",
    "stratifier = GetQualis()\n",
    "\n",
    "# Definir caminho e nome para escrever o arquivo com dados periódicos qualis dos docentes\n",
    "print('\\nAdicionando Qualis Periódicos')\n",
    "pathfilename = os.path.join(folder_data_input,'docents_dict_list.json')\n",
    "\n",
    "# Atualizar a lista de dicionários dict_list_docents com o Qualis para cara Artigo\n",
    "stratifier.buscar_qualis_e_atualizar_arquivo(dict_list_docents, pathfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aec28b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ano': '2024',\n",
       " 'fator_impacto_jcr': '',\n",
       " 'ISSN': '27327787',\n",
       " 'titulo': 'Development and Clinical Applications of PI3K/AKT/mTOR Pathway Inhibitors as a Therapeutic Option for Leukemias',\n",
       " 'revista': 'Cancer Diagnosis ',\n",
       " 'autores': 'DA COSTA MACHADO, ANNA KAROLYNA2024DA COSTA MACHADO, ANNA KAROLYNA ; MACHADO, CAIO BEZERRA ; DE PINHO PESSOA, FLÁVIA MELO CUNHA ; BARRETO, IGOR VALENTIM ; GADELHA, RENAN BRITO ; DE SOUSA OLIVEIRA, DEIVIDE ; MONTEIRO RIBEIRO, RODRIGO ; SILVA LOPES, GERMISON ; DE MORAES FILHO, MANOEL ODORICO ;Amaral de Moraes, Maria Elisabete; KHAYAT, ANDRÉ SALIM ; MOREIRA-NUNES, CAROLINE AQUINO . ',\n",
       " 'data_issn': '27327787',\n",
       " 'DOI': 'http://dx.doi.org/10.21873/cdp.10279',\n",
       " 'Qualis': 'NA'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirmar se a chave 'Qualis' foi adicionada ao dicionário dos Artigos em dict_list_docents\n",
    "[x.get('Produções') for x in dict_list_docents][-1].get('Artigos completos publicados em periódicos')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb81910",
   "metadata": {},
   "source": [
    "### Visualizar quantitativo de artigos extraídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e00e5447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 dicionários montados\n",
      " 0C 005A 005T Dif:000 None \n",
      " 1C 219A 219T Dif:000 None \n",
      "\n",
      "Total de artigos em todos períodos: 224\n",
      "Total de títulos em todos períodos: 224\n"
     ]
    }
   ],
   "source": [
    "## Contagem de artigos para simples confererência\n",
    "print(f'{len(dict_list_docents)} dicionários montados')\n",
    "qte_artigos=0\n",
    "qte_titulos=0\n",
    "for k,i in enumerate(dict_list_docents):\n",
    "    try:\n",
    "        qte_jcr = len(i.get('Produções').get('Artigos completos publicados em periódicos'))\n",
    "    except:\n",
    "        qte_jcr = 0\n",
    "    try:\n",
    "       qte_jcr2 = len(i['JCR2'])\n",
    "    except:\n",
    "       qte_jcr2 = 0\n",
    "    qte_artigos+=qte_jcr\n",
    "    qte_titulos+=qte_jcr2\n",
    "    status=qte_jcr2-qte_jcr\n",
    "    print(f\"{k:>2}C {qte_jcr:>03}A {qte_jcr2:>03}T Dif:{status:>03} {i.get('Identificação').get('name')} \")\n",
    "\n",
    "print(f'\\nTotal de artigos em todos períodos: {qte_artigos}')\n",
    "print(f'Total de títulos em todos períodos: {qte_titulos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8143a095",
   "metadata": {},
   "source": [
    "## Apurar artigos e atualizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e4e023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x.get('Produções') for x in dict_list_docents][3].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d5a2aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>id_lattes</th>\n",
       "      <th>curriculos</th>\n",
       "      <th>ultima_atualizacao</th>\n",
       "      <th>dias_defasagem</th>\n",
       "      <th>qte_artigos_periodicos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6455001509230446</td>\n",
       "      <td>Jose Aurillo Rocha</td>\n",
       "      <td>18/02/2024</td>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3565768281344086</td>\n",
       "      <td>Maria Elisabete Amaral de Moraes</td>\n",
       "      <td>03/06/2024</td>\n",
       "      <td>12</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_lattes         curriculos                        ultima_atualizacao  \\\n",
       "0  6455001509230446                Jose Aurillo Rocha  18/02/2024          \n",
       "1  3565768281344086  Maria Elisabete Amaral de Moraes  03/06/2024          \n",
       "\n",
       "   dias_defasagem  qte_artigos_periodicos  \n",
       "0  118               5                     \n",
       "1   12             219                     "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "atualizador = ArticlesCounter(dict_list_docents)\n",
    "dtf_atualizado = atualizador.extrair_data_atualizacao(dict_list_docents)\n",
    "dtf_atualizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bc70171",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verificar as chaves disponíveis em cada dicionário\n",
    "# for i,j in enumerate(dict_list_docents):\n",
    "#     print(f'{i:02} {j.keys()}')\n",
    "\n",
    "## Ver dados da planilha da plataforma Sucupira com dados de todo Qualis Periódicos\n",
    "# fonte_planilha = 'classificações_publicadas_todas_as_areas_avaliacao1672761192111.xlsx'\n",
    "# dados_qualis = pd.read_excel(os.path.join(LattesScraper.find_repo_root(),'_data','in_xls',fonte_planilha))\n",
    "# dados_qualis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbd686",
   "metadata": {},
   "source": [
    "#### Contar artigos estratificados pelo Qualis Periódicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0ff30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os anos do período de interesse\n",
    "ano_inicio = 1924\n",
    "ano_final = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bdbcfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_list_docents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49d052e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de publicações (sem filtro de ano): 224\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>Autor</th>\n",
       "      <th>Publicações Qualis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jose Aurillo Rocha</td>\n",
       "      <td>B3, C, NA, A4, NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maria Elisabete Amaral de Moraes</td>\n",
       "      <td>NA, A3, B1, B1, A2, A2, A1, A2, A4, B3, A1, A2, A3, B1, A3, A1, A4, A4, B2, B2, A2, B1, NA, A1, B4, A1, A2, A3, NA, A2, A3, A4, A2, A2, A4, A1, A1, A1, A2, A2, NA, A4, NA, NA, A4, A1, B1, NA, A2, C, A3, A1, NA, A1, A3, C, A4, A2, A4, A1, A3, A1, A4, B1, B3, A4, B1, A1, A1, A3, A1, B4, A1, B1, B3, A2, A4, B1, B1, B1, A4, A1, A3, A3, A3, B2, B2, A2, B3, A2, A2, C, C, B1, C, NA, C, A2, B2, B1, B1, B3, B1, A1, A1, A1, A4, B2, A3, A2, NA, A2, A2, A4, A1, A4, A3, NA, B1, B1, A4, A4, B1, A1, A3, B1, B2, A2, A1, A1, C, A4, A1, B2, B1, NA, B2, A3, B1, A4, A4, A4, A4, A4, NA, A1, A1, A2, A2, B3, A1, A2, A4, B2, A3, A3, B3, A3, A3, A3, B1, A1, A1, B2, A1, B3, B1, B1, B1, B1, A4, B3, B3, B1, B1, A1, NA, NA, NA, B1, A2, NA, NA, NA, NA, B1, B2, B1, NA, NA, NA, B1, B1, NA, NA, NA, A2, NA, NA, A4, NA, A2, B1, B2, B1, A4, B3, A1, A1, A1, A2, A3, NA, NA, B4, B4, B4, A1, A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Autor                              \\\n",
       "0                Jose Aurillo Rocha   \n",
       "1  Maria Elisabete Amaral de Moraes   \n",
       "\n",
       "  Publicações Qualis                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    B3, C, NA, A4, NA  \n",
       "1  NA, A3, B1, B1, A2, A2, A1, A2, A4, B3, A1, A2, A3, B1, A3, A1, A4, A4, B2, B2, A2, B1, NA, A1, B4, A1, A2, A3, NA, A2, A3, A4, A2, A2, A4, A1, A1, A1, A2, A2, NA, A4, NA, NA, A4, A1, B1, NA, A2, C, A3, A1, NA, A1, A3, C, A4, A2, A4, A1, A3, A1, A4, B1, B3, A4, B1, A1, A1, A3, A1, B4, A1, B1, B3, A2, A4, B1, B1, B1, A4, A1, A3, A3, A3, B2, B2, A2, B3, A2, A2, C, C, B1, C, NA, C, A2, B2, B1, B1, B3, B1, A1, A1, A1, A4, B2, A3, A2, NA, A2, A2, A4, A1, A4, A3, NA, B1, B1, A4, A4, B1, A1, A3, B1, B2, A2, A1, A1, C, A4, A1, B2, B1, NA, B2, A3, B1, A4, A4, A4, A4, A4, NA, A1, A1, A2, A2, B3, A1, A2, A4, B2, A3, A3, B3, A3, A3, A3, B1, A1, A1, B2, A1, B3, B1, B1, B1, B1, A4, B3, B3, B1, B1, A1, NA, NA, NA, B1, A2, NA, NA, NA, NA, B1, B2, B1, NA, NA, NA, B1, B1, NA, NA, NA, A2, NA, NA, A4, NA, A2, B1, B2, B1, A4, B3, A1, A1, A1, A2, A3, NA, NA, B4, B4, B4, A1, A1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atualizador.contar_qualis(dict_list_docents, ano_inicio, ano_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a81b8",
   "metadata": {},
   "source": [
    "#### Classificar artigos no período pelo Qualis Periódicos\n",
    "\n",
    "Obs.: 'Não encontrado' significa que o ISSN da revista da publicação não consta na lista de revistas avaliadas no Qualis Periódico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f98d76f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Ano</th>\n",
       "      <th>1980</th>\n",
       "      <th>1982</th>\n",
       "      <th>1988</th>\n",
       "      <th>1989</th>\n",
       "      <th>1991</th>\n",
       "      <th>1994</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>...</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jose Aurillo Rocha</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>B3, C</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maria Elisabete Amaral de Moraes</th>\n",
       "      <td>A1, A1</td>\n",
       "      <td>B4, B4, B4</td>\n",
       "      <td>NA</td>\n",
       "      <td>A1, A2, A3, NA</td>\n",
       "      <td>A1, A1</td>\n",
       "      <td>B3</td>\n",
       "      <td>B1, A4</td>\n",
       "      <td>B1, B2</td>\n",
       "      <td>NA, A2, NA, NA, A4, NA, A2</td>\n",
       "      <td>B1, B1, NA, NA</td>\n",
       "      <td>...</td>\n",
       "      <td>A2, B2, B1, B1, B3</td>\n",
       "      <td>B1, C, NA, C</td>\n",
       "      <td>A2, A2, C, C</td>\n",
       "      <td>A3, A3, A3, B2, B2, A2, B3</td>\n",
       "      <td>A1, B1, B3, A2, A4, B1, B1, B1, A4, A1</td>\n",
       "      <td>C, A4, A2, A4, A1, A3, A1, A4, B1, B3, A4, B1, A1, A1, A3, A1, B4</td>\n",
       "      <td>A4, A1, B1, NA, A2, C, A3, A1, NA, A1, A3</td>\n",
       "      <td>A1, B4, A1, A2, A3, NA, A2, A3, A4, A2, A2, A4, A1, A1, A1, A2, A2, NA, A4, NA, NA</td>\n",
       "      <td>A2, A2, A1, A2, A4, B3, A1, A2, A3, B1, A3, A1, A4, A4, B2, B2, A2, B1, NA</td>\n",
       "      <td>NA, A3, B1, B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ano                              1980    1982        1988 1989             \\\n",
       "Autor                                                                       \n",
       "Jose Aurillo Rocha                                                          \n",
       "Maria Elisabete Amaral de Moraes  A1, A1  B4, B4, B4  NA   A1, A2, A3, NA   \n",
       "\n",
       "Ano                              1991    1994 1997    1998     \\\n",
       "Autor                                                           \n",
       "Jose Aurillo Rocha                        NA                    \n",
       "Maria Elisabete Amaral de Moraes  A1, A1  B3   B1, A4  B1, B2   \n",
       "\n",
       "Ano                              1999                        2000             \\\n",
       "Autor                                                                          \n",
       "Jose Aurillo Rocha                                                             \n",
       "Maria Elisabete Amaral de Moraes  NA, A2, NA, NA, A4, NA, A2  B1, B1, NA, NA   \n",
       "\n",
       "Ano                               ... 2015                2016           \\\n",
       "Autor                             ...                                     \n",
       "Jose Aurillo Rocha                ...                                     \n",
       "Maria Elisabete Amaral de Moraes  ...  A2, B2, B1, B1, B3  B1, C, NA, C   \n",
       "\n",
       "Ano                              2017          2018                         \\\n",
       "Autor                                                                        \n",
       "Jose Aurillo Rocha                                                           \n",
       "Maria Elisabete Amaral de Moraes  A2, A2, C, C  A3, A3, A3, B2, B2, A2, B3   \n",
       "\n",
       "Ano                              2019                                     \\\n",
       "Autor                                                                      \n",
       "Jose Aurillo Rocha                                                 B3, C   \n",
       "Maria Elisabete Amaral de Moraes  A1, B1, B3, A2, A4, B1, B1, B1, A4, A1   \n",
       "\n",
       "Ano                              2020                                                                \\\n",
       "Autor                                                                                                 \n",
       "Jose Aurillo Rocha                                                                                    \n",
       "Maria Elisabete Amaral de Moraes  C, A4, A2, A4, A1, A3, A1, A4, B1, B3, A4, B1, A1, A1, A3, A1, B4   \n",
       "\n",
       "Ano                              2021                                        \\\n",
       "Autor                                                                         \n",
       "Jose Aurillo Rocha                                                            \n",
       "Maria Elisabete Amaral de Moraes  A4, A1, B1, NA, A2, C, A3, A1, NA, A1, A3   \n",
       "\n",
       "Ano                              2022                                                                                 \\\n",
       "Autor                                                                                                                  \n",
       "Jose Aurillo Rocha                                                                                                     \n",
       "Maria Elisabete Amaral de Moraes  A1, B4, A1, A2, A3, NA, A2, A3, A4, A2, A2, A4, A1, A1, A1, A2, A2, NA, A4, NA, NA   \n",
       "\n",
       "Ano                              2023                                                                         \\\n",
       "Autor                                                                                                          \n",
       "Jose Aurillo Rocha                                                                                             \n",
       "Maria Elisabete Amaral de Moraes  A2, A2, A1, A2, A4, B3, A1, A2, A3, B1, A3, A1, A4, A4, B2, B2, A2, B1, NA   \n",
       "\n",
       "Ano                              2024             \n",
       "Autor                                             \n",
       "Jose Aurillo Rocha                                \n",
       "Maria Elisabete Amaral de Moraes  NA, A3, B1, B1  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atualizador.apurar_qualis_periodo(dict_list_docents, ano_inicio, ano_final).fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57866783",
   "metadata": {},
   "source": [
    "### Pontuar por ano ponderado pelo Qualis\n",
    "\n",
    "- Buscar pelos artigos completos publicados em periódicos de cada pesquisador\n",
    "- Buscar ISSN da revista na classificação do Qualis Periódicos da Capes (Plataforma Sucupira)\n",
    "- Ponderar pela pontuação que o programa de pós-graduação em análise atribui para cada estrato"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b958e62",
   "metadata": {},
   "source": [
    "### Contar publicação c/participação discente\n",
    "\n",
    "- Buscar por nomes de discentes nas publicações dos currículos dos docentes e \n",
    "- Calcular o percentual de publicações com participação de discente da lista fornecida pelo programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ba17bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pontuacao = atualizador.apurar_pontos_periodo(dict_list_docents, ano_inicio, ano_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5721e21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Ano</th>\n",
       "      <th>1980</th>\n",
       "      <th>1982</th>\n",
       "      <th>1988</th>\n",
       "      <th>1989</th>\n",
       "      <th>1991</th>\n",
       "      <th>1994</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>...</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "      <th>Soma de Pontos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Maria Elisabete Amaral de Moraes</th>\n",
       "      <td>180</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>180</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>35</td>\n",
       "      <td>200</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>300</td>\n",
       "      <td>430</td>\n",
       "      <td>865</td>\n",
       "      <td>530</td>\n",
       "      <td>1175</td>\n",
       "      <td>990</td>\n",
       "      <td>100</td>\n",
       "      <td>9210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jose Aurillo Rocha</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ano                               1980  1982  1988  1989  1991  1994  1997  \\\n",
       "Autor                                                                        \n",
       "Maria Elisabete Amaral de Moraes  180   15    0     230   180   10    60     \n",
       "Jose Aurillo Rocha                  0    0    0       0     0    0     0     \n",
       "\n",
       "Ano                               1998  1999  2000  ...  2016  2017  2018  \\\n",
       "Autor                                               ...                     \n",
       "Maria Elisabete Amaral de Moraes  35    200   40    ...  20    160   300    \n",
       "Jose Aurillo Rocha                 0      0    0    ...   0      0     0    \n",
       "\n",
       "Ano                               2019  2020  2021  2022  2023  2024  \\\n",
       "Autor                                                                  \n",
       "Maria Elisabete Amaral de Moraes  430   865   530   1175  990   100    \n",
       "Jose Aurillo Rocha                 10     0     0      0    0     0    \n",
       "\n",
       "Ano                               Soma de Pontos  \n",
       "Autor                                             \n",
       "Maria Elisabete Amaral de Moraes  9210            \n",
       "Jose Aurillo Rocha                  50            \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pontuacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b40af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Load data from the table\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Atividade\": [\n",
    "            \"Matrícula em disciplinas (Doc)\",\n",
    "            \"Revisão bibliográfica (Doc)\",\n",
    "            \"Elaborar projeto de pesquisa\t(Doc)\",\n",
    "            \"Revisão bibliográfica (B01-InSilico)\",\n",
    "            \"Treinamento em softwares (B01-InSilico)\",\n",
    "            \"Revisão bibliográfica (B02-InVitro)\",\n",
    "            \"Preparação cultura celular (B02-InVitro)\",\n",
    "            \"Cursar disciplinas teóricas\",\n",
    "            \"Aprofundar revisão bibliográfica (Doc)\",\n",
    "            \"Montar a base de dados (B01-InSilico)\",\n",
    "            \"Padronizar técnicas de cultura(B02-InVitro)\",\n",
    "            \"Experimentos preliminares (B02-InVitro)\",\n",
    "            \"Concluir disciplinas teóricas\t(Doc)\",\n",
    "            \"Apresentação do projeto de pesquisa\",\n",
    "            \"Desenvolver modelo computacional (B01-InSilico)\",\n",
    "            \"Otimizar condições de cultura (B02-InVitro)\",\n",
    "            \"Experimentos principais (B02-InVitro)\",\n",
    "            \"Analisar resultados preliminares(Doc)\",\n",
    "            \"Refinamento do projeto de pesquisa(Doc)\",\n",
    "            \"Validar modelo computacional (B01-InSilico)\",\n",
    "            \"Análise de resultados (B02-InVitro)\",\n",
    "            \"Redigir artigo científico 01(Doc)\",\n",
    "            \"Integração de modelos e dados experimentais (B01-InSilico)\",\n",
    "            \"Experimentos complementares (B02-InVitro)\",\n",
    "            \"Apresentação em congressos(Doc)\",\n",
    "            \"Análise estatística dos resultados (B02-InVitro)\",\n",
    "            \"Submissão do primeiro artigo científico(Doc)\",\n",
    "        ],\n",
    "        \"Duração (Semanas)\": [\n",
    "            1,\n",
    "            4,\n",
    "            4,\n",
    "            4,\n",
    "            4,\n",
    "            4,\n",
    "            4,\n",
    "            8,\n",
    "            4,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            4,\n",
    "            4,\n",
    "            8,\n",
    "            8,\n",
    "            12,\n",
    "            4,\n",
    "            4,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            4,\n",
    "            4,\n",
    "            4,\n",
    "        ],\n",
    "        \"Trimestre\": [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            2,\n",
    "            2,\n",
    "            2,\n",
    "            2,\n",
    "            2,\n",
    "            3,\n",
    "            3,\n",
    "            3,\n",
    "            3,\n",
    "            4,\n",
    "            4,\n",
    "            4,\n",
    "            4,\n",
    "            4,\n",
    "            5,\n",
    "            5,\n",
    "            5,\n",
    "            5,\n",
    "            5,\n",
    "            5,\n",
    "        ],\n",
    "        \"Responsável\": [\n",
    "            \"Doutorando(a)\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Bolsista In Silico\",\n",
    "            \"Bolsista In Silico\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Bolsista In Silico\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Bolsista In Silico\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Bolsista In Silico\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Bolsista In Silico\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Doutorando(a)\",\n",
    "        ],\n",
    "        \"Predecessora\": [\n",
    "            \"-\",\n",
    "            \"-\",\n",
    "            \"Revisão bibliográfica (Doc)\",\n",
    "            \"-\",\n",
    "            \"Revisão bibliográfica (B01-InSilico)\",\n",
    "            \"-\",\n",
    "            \"Revisão bibliográfica (B02-InVitro)\",\n",
    "            \"Matrícula em disciplinas (Doc)\",\n",
    "            \"Cursar disciplinas teóricas\",\n",
    "            \"Treinamento em softwares (B01-InSilico)\",\n",
    "            \"Preparação cultura celular (B02-InVitro)\",\n",
    "            \"Padronizar técnicas de cultura(B02-InVitro)\",\n",
    "            \"Cursar disciplinas teóricas\",\n",
    "            \"Concluir disciplinas teóricas\t(Doc)\",\n",
    "            \"Montar a base de dados (B01-InSilico)\",\n",
    "            \"Experimentos preliminares (B02-InVitro)\",\n",
    "            \"Otimizar condições de cultura (B02-InVitro)\",\n",
    "            \"Apresentação do projeto de pesquisa\",\n",
    "            \"Analisar resultados preliminares(Doc)\",\n",
    "            \"Desenvolver modelo computacional (B01-InSilico)\",\n",
    "            \"Experimentos principais (B02-InVitro)\",\n",
    "            \"Analisar resultados preliminares(Doc)\",\n",
    "            \"Validar modelo computacional (B01-InSilico)\",\n",
    "            \"Análise de resultados (B02-InVitro)\",\n",
    "            \"Redigir artigo científico 01(Doc)\",\n",
    "            \"Experimentos complementares (B02-InVitro)\",\n",
    "            \"Redigir artigo científico 01(Doc)\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Transform data for Gantt chart\n",
    "df[\"inicio_trimestre\"] = (df[\"Trimestre\"] - 1) * 12\n",
    "df[\"inicio\"] = df.apply(\n",
    "    lambda row: row[\"inicio_trimestre\"]\n",
    "    + (row[\"Duração (Semanas)\"] * (row[\"Trimestre\"] - 1)),\n",
    "    axis=1,\n",
    ")\n",
    "df[\"fim\"] = df[\"inicio\"] + df[\"Duração (Semanas)\"]\n",
    "\n",
    "# Base chart\n",
    "base = alt.Chart(df).encode(\n",
    "    y=alt.Y(\"Atividade:N\", axis=alt.Axis(labelAngle=-45)),\n",
    "    x=alt.X(\"inicio:Q\", title=\"Semanas\"),\n",
    "    x2=\"fim:Q\",\n",
    "    color=alt.Color(\"Responsável:N\", legend=alt.Legend(title=\"Responsável\")),\n",
    "    tooltip=[\"Atividade\", \"inicio\", \"fim\", \"Duração (Semanas)\", \"Responsável\"],\n",
    ")\n",
    "\n",
    "# Gantt bars\n",
    "bars = base.mark_bar().encode(\n",
    ")\n",
    "\n",
    "# Dependency lines\n",
    "dependencies = (\n",
    "    base.mark_rule(point=True)\n",
    "    .transform_filter(alt.datum.Predecessora != \"-\")\n",
    "    .transform_lookup(\n",
    "        lookup=\"Predecessora\",\n",
    "        from_=alt.LookupData(df, \"Atividade\", [\"fim\"]),\n",
    "        as_=\"fim_predecessora\",\n",
    "    )\n",
    "    .encode(\n",
    "        x=\"fim_predecessora:Q\",\n",
    "        x2=\"inicio:Q\",\n",
    "        y=\"Atividade:N\",\n",
    "        y2=\"Atividade:N\",\n",
    "        detail=\"Predecessora:N\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine everything\n",
    "chart = (\n",
    "    alt.layer(bars, dependencies)\n",
    "    .resolve_scale(\n",
    "        x=\"shared\",\n",
    "    )\n",
    "    .properties(\n",
    "        width=800,\n",
    "        height=1200,\n",
    "        title=(\n",
    "            \"Diagrama de Gantt para o Projeto de Doutorado em Terapias Personalizadas para Artrite Reumatóide\"\n",
    "        ),\n",
    "    )\n",
    "    .interactive()\n",
    ")\n",
    "\n",
    "chart.save(\"diagrama_gantt_projeto_doutorado.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "82cc1ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Load data from the table\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Atividade\": [\n",
    "            \"Matrícula em disciplinas (Doc)\",\n",
    "            \"Revisão bibliográfica (Doc)\",\n",
    "            \"Elaborar projeto de pesquisa (Doc)\",\n",
    "            \"Revisão bibliográfica (B01-InSilico)\",\n",
    "            \"Treinamento em softwares (B01-InSilico)\",\n",
    "            \"Revisão bibliográfica (B02-InVitro)\",\n",
    "            \"Preparação cultura celular (B02-InVitro)\",\n",
    "            \"Cursar disciplinas teóricas (Doc)\",\n",
    "            \"Aprofundar revisão bibliográfica (Doc)\",\n",
    "            \"Montar a base de dados (B01-InSilico)\",\n",
    "            \"Padronizar técnicas de cultura(B02-InVitro)\",\n",
    "            \"Experimentos preliminares (B02-InVitro)\",\n",
    "            \"Concluir disciplinas teóricas (Doc)\",\n",
    "            \"Apresentar projeto de pesquisa (Doc)\",\n",
    "            \"Desenvolver modelo computacional (B01-InSilico)\",\n",
    "            \"Otimizar condições de cultura (B02-InVitro)\",\n",
    "            \"Experimentos principais (B02-InVitro)\",\n",
    "            \"Analisar resultados preliminares(Doc)\",\n",
    "            \"Refinar projeto de pesquisa (Doc)\",\n",
    "            \"Validar modelo computacional (B01-InSilico)\",\n",
    "            \"Análise de resultados (B02-InVitro)\",\n",
    "            \"Redigir artigo científico 01 (Doc)\",\n",
    "            \"Integrar modelos e dados experimentais (B01-InSilico)\",\n",
    "            \"Experimentos complementares (B02-InVitro)\",\n",
    "            \"Apresentação em congressos (Doc)\",\n",
    "            \"Análise estatística dos resultados (B02-InVitro)\",\n",
    "            \"Submissão do primeiro artigo científico (Doc)\",\n",
    "        ],\n",
    "        \"Duração (Semanas)\": [\n",
    "            1,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            12,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "            8,\n",
    "        ],\n",
    "        \"Trimestre\": [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "            2,\n",
    "            2,\n",
    "            2,\n",
    "            2,\n",
    "            2,\n",
    "            3,\n",
    "            3,\n",
    "            3,\n",
    "            3,\n",
    "            4,\n",
    "            4,\n",
    "            4,\n",
    "            4,\n",
    "            4,\n",
    "            5,\n",
    "            5,\n",
    "            5,\n",
    "            5,\n",
    "            5,\n",
    "            5,\n",
    "        ],\n",
    "        \"Responsável\": [\n",
    "            \"Doutorando(a)\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Bolsista In Silico\",\n",
    "            \"Bolsista In Silico\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Bolsista In Silico\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Bolsista In Silico\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Bolsista In Silico\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Bolsista In Silico\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Doutorando(a)\",\n",
    "            \"Bolsista In Vitro\",\n",
    "            \"Doutorando(a)\",\n",
    "        ],\n",
    "        \"Predecessora\": [\n",
    "            \"-\",\n",
    "            \"-\",\n",
    "            \"Revisão bibliográfica (Doc)\",\n",
    "            \"-\",\n",
    "            \"Revisão bibliográfica (B01-InSilico)\",\n",
    "            \"-\",\n",
    "            \"Revisão bibliográfica (B02-InVitro)\",\n",
    "            \"Matrícula em disciplinas (Doc)\",\n",
    "            \"Cursar disciplinas teóricas (Doc)\",\n",
    "            \"Treinamento em softwares (B01-InSilico)\",\n",
    "            \"Preparação cultura celular (B02-InVitro)\",\n",
    "            \"Padronizar técnicas de cultura (B02-InVitro)\",\n",
    "            \"Cursar disciplinas teóricas (Doc)\",\n",
    "            \"Concluir disciplinas teóricas (Doc)\",\n",
    "            \"Montar a base de dados (B01-InSilico)\",\n",
    "            \"Experimentos preliminares (B02-InVitro)\",\n",
    "            \"Otimizar condições de cultura (B02-InVitro)\",\n",
    "            \"Apresentar projeto de pesquisa (Doc)\",\n",
    "            \"Analisar resultados preliminares (Doc)\",\n",
    "            \"Desenvolver modelo computacional (B01-InSilico)\",\n",
    "            \"Experimentos principais (B02-InVitro)\",\n",
    "            \"Analisar resultados preliminares(Doc)\",\n",
    "            \"Validar modelo computacional (B01-InSilico)\",\n",
    "            \"Análise de resultados (B02-InVitro)\",\n",
    "            \"Redigir artigo científico 01 (Doc)\",\n",
    "            \"Experimentos complementares (B02-InVitro)\",\n",
    "            \"Redigir artigo científico 01(Doc)\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a new column to specify the order of activities\n",
    "df[\"Ordem\"] = df[\"Responsável\"].map(\n",
    "    {\"Bolsista In Silico\": 1, \"Bolsista In Vitro\": 2, \"Doutorando(a)\": 3}\n",
    ")\n",
    "df[\"Ordem\"] = df.groupby(\"Responsável\").cumcount() + df[\"Ordem\"] * 100\n",
    "df = df.sort_values(\"Ordem\")\n",
    "\n",
    "# Transform data for Gantt chart\n",
    "df[\"inicio_trimestre\"] = (df[\"Trimestre\"] - 1) * 12\n",
    "df[\"inicio\"] = df.apply(\n",
    "    lambda row: row[\"inicio_trimestre\"]\n",
    "    + (row[\"Duração (Semanas)\"] * (row[\"Trimestre\"] - 1)),\n",
    "    axis=1,\n",
    ")\n",
    "df[\"fim\"] = df[\"inicio\"] + df[\"Duração (Semanas)\"]\n",
    "\n",
    "# Base chart (updated with sorted data)\n",
    "base = alt.Chart(df).encode(\n",
    "    y=alt.Y(\n",
    "        \"Atividade:N\",\n",
    "        sort=list(df[\"Atividade\"]),  # Ordenar explicitamente o eixo Y\n",
    "        axis=alt.Axis(\n",
    "            labelAngle=0,\n",
    "            # labelExpr=\"split(datum.label, ' ')\",\n",
    "            labelFontSize=12,  # Aumentar o tamanho da fonte dos rótulos\n",
    "            titlePadding=120,\n",
    "            labelAlign=\"right\",\n",
    "        ),\n",
    "    ),\n",
    "    x=alt.X(\"inicio:T\", title=\"Semanas\", axis=alt.Axis(labelAngle=-45)),  # Escala de tempo para o eixo X\n",
    "    x2=\"fim:T\",  # Escala de tempo para o eixo X2\n",
    "    color=alt.Color(\"Responsável:N\", legend=alt.Legend(title=\"Responsável\")),\n",
    "    tooltip=[\"Atividade\", \"inicio\", \"fim\", \"Duração (Semanas)\", \"Responsável\"],\n",
    ")\n",
    "\n",
    "# Gantt bars\n",
    "bars = base.mark_bar(size=20).encode()  # largura barras\n",
    "\n",
    "# Dependency lines\n",
    "dependencies = (\n",
    "    base.mark_rule(point=True)\n",
    "    .transform_filter(alt.datum.Predecessora != \"-\")\n",
    "    .transform_lookup(\n",
    "        lookup=\"Predecessora\",\n",
    "        from_=alt.LookupData(df, \"Atividade\", [\"fim\"]),\n",
    "        as_=\"fim_predecessora\",\n",
    "    )\n",
    "    .encode(\n",
    "        x=\"fim_predecessora:T\",  # Escala de tempo para as linhas de dependência\n",
    "        x2=\"inicio:T\",\n",
    "        y=\"Atividade:N\",\n",
    "        y2=\"Atividade:N\",\n",
    "        detail=\"Predecessora:N\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine everything\n",
    "chart = (\n",
    "    alt.layer(bars, dependencies)\n",
    "    .resolve_scale(x=\"shared\")\n",
    "    .configure_scale(\n",
    "        bandPaddingInner=0.5  # Aumentar o espaçamento entre as barras\n",
    "    )\n",
    "    .properties(\n",
    "        width=800,  # Aumentar a largura do gráfico\n",
    "        height=600,  # Aumentar a altura do gráfico\n",
    "        title=(\n",
    "            \"Diagrama de Gantt para o Projeto de Doutorado em Terapias Personalizadas para Artrite Reumatóide\"\n",
    "        ),\n",
    "    )\n",
    "    .interactive()\n",
    ")\n",
    "\n",
    "\n",
    "chart.save(\"diagrama_gantt_projeto_doutorado_ordenado.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1240e7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-b03182232fe94c6bb4725906cfd58433.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-b03182232fe94c6bb4725906cfd58433.vega-embed details,\n",
       "  #altair-viz-b03182232fe94c6bb4725906cfd58433.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-b03182232fe94c6bb4725906cfd58433\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b03182232fe94c6bb4725906cfd58433\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b03182232fe94c6bb4725906cfd58433\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"bar\", \"width\": 60}, \"encoding\": {\"tooltip\": [{\"field\": \"Regi\\u00e3o\", \"type\": \"nominal\"}, {\"field\": \"Preval\\u00eancia\", \"format\": \".1%\", \"title\": \"Preval\\u00eancia\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"labelAngle\": -60, \"title\": \"Regi\\u00e3o\"}, \"field\": \"Regi\\u00e3o\", \"sort\": [\"Norte\", \"Centro-Oeste\", \"Sul\", \"Sudeste\", \"Nordeste\"], \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \"Preval\\u00eancia (%)\"}, \"field\": \"Preval\\u00eancia\", \"scale\": {\"domain\": [0, 0.66]}, \"type\": \"quantitative\"}}, \"name\": \"view_125\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"dy\": -10, \"fontSize\": 18, \"fontWeight\": \"bold\"}, \"encoding\": {\"text\": {\"field\": \"Preval\\u00eancia\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"Regi\\u00e3o\", \"type\": \"nominal\"}, {\"field\": \"Preval\\u00eancia\", \"format\": \".1%\", \"title\": \"Preval\\u00eancia\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"labelAngle\": -60, \"title\": \"Regi\\u00e3o\"}, \"field\": \"Regi\\u00e3o\", \"sort\": [\"Norte\", \"Centro-Oeste\", \"Sul\", \"Sudeste\", \"Nordeste\"], \"type\": \"nominal\"}, \"y\": {\"axis\": {\"title\": \" \"}, \"field\": \"Preval\\u00eancia\", \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-cacf3221b626f19def2c0bbd1192b269\"}, \"height\": 400, \"params\": [{\"name\": \"param_119\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\", \"views\": [\"view_125\"]}], \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-cacf3221b626f19def2c0bbd1192b269\": [{\"Regi\\u00e3o\": \"Norte\", \"Preval\\u00eancia\": 0.28}, {\"Regi\\u00e3o\": \"Centro-Oeste\", \"Preval\\u00eancia\": 0.33}, {\"Regi\\u00e3o\": \"Sul\", \"Preval\\u00eancia\": 0.44}, {\"Regi\\u00e3o\": \"Sudeste\", \"Preval\\u00eancia\": 0.48}, {\"Regi\\u00e3o\": \"Nordeste\", \"Preval\\u00eancia\": 0.63}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "\n",
    "# 1. Crie um DataFrame com os dados (sem multiplicar por 100)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Região\": [\"Nordeste\", \"Sudeste\", \"Sul\", \"Centro-Oeste\", \"Norte\"],\n",
    "        \"Prevalência\": [0.63, 0.48, 0.44, 0.33, 0.28],\n",
    "    }\n",
    ")\n",
    "\n",
    "# 2. Classifique o DataFrame `df` em ordem crescente com base na coluna `Prevalência`.\n",
    "df_sorted = df.sort_values(\"Prevalência\")\n",
    "\n",
    "# Encontre o próximo múltiplo de 0.05 superior ao maior valor\n",
    "max_value = df_sorted['Prevalência'].max()\n",
    "next_multiple_of_5 = 0.05 * (int(max_value / 0.05) + 1)+0.01\n",
    "\n",
    "# 3. Crie um gráfico de barras com `Região` no eixo x e `Prevalência` no eixo y.\n",
    "# 4. Formate o eixo y como porcentagem sem arredondamento e defina o limite superior.\n",
    "# 5. Adicione o título \"Prevalência de Artrite Reumatoide nas Regiões do Brasil\" ao gráfico.\n",
    "# 6. Defina a ordem das barras no eixo x de acordo com a ordem das regiões no DataFrame `df` classificado.\n",
    "# 7. Controle a largura e altura da imagem.\n",
    "chart = (\n",
    "    alt.Chart(df_sorted)\n",
    "    .mark_bar(width=60)  # Controle da largura das barras\n",
    "    .encode(\n",
    "        x=alt.X(\"Região:N\", sort=list(df_sorted[\"Região\"]), axis=alt.Axis(title=\"Região\", labelAngle=-60)),  # Ordenação explícita das barras\n",
    "        y=alt.Y(\n",
    "            \"Prevalência:Q\",\n",
    "            axis=alt.Axis(title=\"Prevalência (%)\"),\n",
    "            scale=alt.Scale(domain=[0, next_multiple_of_5]),  # Definir o limite superior do eixo Y\n",
    "        ),  # Formatar como porcentagem e definir o número de ticks no eixo y\n",
    "        tooltip=[\n",
    "            \"Região\",\n",
    "            alt.Tooltip(\"Prevalência\", title=\"Prevalência\", format=\".1%\"),\n",
    "        ],  # Formatar como porcentagem com uma casa decimal no tooltip\n",
    "    )\n",
    "    .properties(\n",
    "        # title=\"Prevalência de Artrite Reumatoide nas Regiões do Brasil\",\n",
    "        width=600,  # Largura da imagem\n",
    "        height=400,  # Altura da imagem\n",
    "    )\n",
    "    .interactive()\n",
    ")\n",
    "\n",
    "# Adicione os rótulos de dados centralizados nas barras\n",
    "text = chart.mark_text(align='center', baseline='middle', dy=-10, fontSize=18, fontWeight='bold').encode(\n",
    "    text=alt.Text('Prevalência:Q', format='.2f'),\n",
    "    y=alt.Y('Prevalência:Q', axis=alt.Axis(title=' ')), # Remove o título do eixo Y da camada de texto\n",
    ")\n",
    "\n",
    "# Combine o gráfico de barras com os rótulos de dados\n",
    "chart_with_labels = chart + text\n",
    "\n",
    "# 8. Exiba o gráfico\n",
    "chart_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6b39351b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "fill": "toself",
         "fillcolor": "rgb(0, 0, 255)",
         "hoverinfo": "name",
         "legendgroup": "rgb(0, 0, 255)",
         "mode": "none",
         "name": "Bolsista In Silico",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2024-07-01",
          "2026-01-01",
          "2026-01-01",
          "2024-07-01",
          "2024-07-01",
          "2025-07-01",
          "2026-07-01",
          "2026-07-01",
          "2025-07-01",
          "2025-07-01",
          "2026-01-01",
          "2026-07-01",
          "2026-07-01",
          "2026-01-01",
          "2026-01-01",
          "2026-07-01",
          "2027-01-01",
          "2027-01-01",
          "2026-07-01",
          "2026-07-01",
          "2027-01-01",
          "2027-07-01",
          "2027-07-01",
          "2027-01-01"
         ],
         "y": [
          4.8,
          4.8,
          5.2,
          5.2,
          null,
          5.8,
          5.8,
          6.2,
          6.2,
          null,
          7.8,
          7.8,
          8.2,
          8.2,
          null,
          10.8,
          10.8,
          11.2,
          11.2,
          null,
          12.8,
          12.8,
          13.2,
          13.2
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgb(0, 160, 0)",
         "hoverinfo": "name",
         "legendgroup": "rgb(0, 160, 0)",
         "mode": "none",
         "name": "Médicos Reumatologistas",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2024-04-01",
          "2025-01-01",
          "2025-01-01",
          "2024-04-01"
         ],
         "y": [
          1.8,
          1.8,
          2.2,
          2.2
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgb(0, 255, 0)",
         "hoverinfo": "name",
         "legendgroup": "rgb(0, 255, 0)",
         "mode": "none",
         "name": "Técnicos de Laboratório",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2024-05-01",
          "2025-01-01",
          "2025-01-01",
          "2024-05-01"
         ],
         "y": [
          3.8,
          3.8,
          4.2,
          4.2
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgb(255, 0, 140)",
         "hoverinfo": "name",
         "legendgroup": "rgb(255, 0, 140)",
         "mode": "none",
         "name": "Doutoranda",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2024-01-01",
          "2024-04-01",
          "2024-04-01",
          "2024-01-01",
          "2024-01-01",
          "2024-02-01",
          "2024-05-01",
          "2024-05-01",
          "2024-02-01",
          "2024-02-01",
          "2024-05-01",
          "2025-01-01",
          "2025-01-01",
          "2024-05-01",
          "2024-05-01",
          "2026-01-01",
          "2026-07-01",
          "2026-07-01",
          "2026-01-01",
          "2026-01-01",
          "2026-07-01",
          "2027-01-01",
          "2027-01-01",
          "2026-07-01",
          "2026-07-01",
          "2027-07-01",
          "2028-01-01",
          "2028-01-01",
          "2027-07-01",
          "2027-07-01",
          "2027-07-01",
          "2028-01-01",
          "2028-01-01",
          "2027-07-01",
          "2027-07-01",
          "2027-07-01",
          "2028-01-01",
          "2028-01-01",
          "2027-07-01"
         ],
         "y": [
          -0.2,
          -0.2,
          0.2,
          0.2,
          null,
          0.8,
          0.8,
          1.2,
          1.2,
          null,
          2.8,
          2.8,
          3.2,
          3.2,
          null,
          8.8,
          8.8,
          9.2,
          9.2,
          null,
          9.8,
          9.8,
          10.2,
          10.2,
          null,
          13.8,
          13.8,
          14.2,
          14.2,
          null,
          14.8,
          14.8,
          15.2,
          15.2,
          null,
          15.8,
          15.8,
          16.2,
          16.2
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgb(255, 255, 0)",
         "hoverinfo": "name",
         "legendgroup": "rgb(255, 255, 0)",
         "mode": "none",
         "name": "Bolsista In Vitro",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2025-07-01",
          "2026-01-01",
          "2026-01-01",
          "2025-07-01",
          "2025-07-01",
          "2027-01-01",
          "2027-07-01",
          "2027-07-01",
          "2027-01-01"
         ],
         "y": [
          6.8,
          6.8,
          7.2,
          7.2,
          null,
          11.8,
          11.8,
          12.2,
          12.2
         ]
        },
        {
         "legendgroup": "rgb(0, 0, 255)",
         "marker": {
          "color": "rgb(0, 0, 255)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2024-07-01",
          "2026-01-01",
          "2025-07-01",
          "2026-07-01",
          "2026-01-01",
          "2026-07-01",
          "2026-07-01",
          "2027-01-01",
          "2027-01-01",
          "2027-07-01"
         ],
         "y": [
          5,
          5,
          6,
          6,
          8,
          8,
          11,
          11,
          13,
          13
         ]
        },
        {
         "legendgroup": "rgb(0, 160, 0)",
         "marker": {
          "color": "rgb(0, 160, 0)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2024-04-01",
          "2025-01-01"
         ],
         "y": [
          2,
          2
         ]
        },
        {
         "legendgroup": "rgb(0, 255, 0)",
         "marker": {
          "color": "rgb(0, 255, 0)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2024-05-01",
          "2025-01-01"
         ],
         "y": [
          4,
          4
         ]
        },
        {
         "legendgroup": "rgb(255, 0, 140)",
         "marker": {
          "color": "rgb(255, 0, 140)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2024-01-01",
          "2024-04-01",
          "2024-02-01",
          "2024-05-01",
          "2024-05-01",
          "2025-01-01",
          "2026-01-01",
          "2026-07-01",
          "2026-07-01",
          "2027-01-01",
          "2027-07-01",
          "2028-01-01",
          "2027-07-01",
          "2028-01-01",
          "2027-07-01",
          "2028-01-01"
         ],
         "y": [
          0,
          0,
          1,
          1,
          3,
          3,
          9,
          9,
          10,
          10,
          14,
          14,
          15,
          15,
          16,
          16
         ]
        },
        {
         "legendgroup": "rgb(255, 255, 0)",
         "marker": {
          "color": "rgb(255, 255, 0)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null,
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2025-07-01",
          "2026-01-01",
          "2027-01-01",
          "2027-07-01"
         ],
         "y": [
          7,
          7,
          12,
          12
         ]
        }
       ],
       "layout": {
        "height": 600,
        "hovermode": "closest",
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cronograma do Projeto de Doutorado em Medicina de Precisão e Personalizada na Artrite Reumatoide"
        },
        "xaxis": {
         "rangeselector": {
          "buttons": [
           {
            "count": 7,
            "label": "1w",
            "step": "day",
            "stepmode": "backward"
           },
           {
            "count": 1,
            "label": "1m",
            "step": "month",
            "stepmode": "backward"
           },
           {
            "count": 6,
            "label": "6m",
            "step": "month",
            "stepmode": "backward"
           },
           {
            "count": 1,
            "label": "YTD",
            "step": "year",
            "stepmode": "todate"
           },
           {
            "count": 1,
            "label": "1y",
            "step": "year",
            "stepmode": "backward"
           },
           {
            "step": "all"
           }
          ]
         },
         "rangeslider": {
          "visible": true
         },
         "showgrid": true,
         "tickangle": -45,
         "type": "date",
         "zeroline": false
        },
        "yaxis": {
         "autorange": false,
         "range": [
          -1,
          18
         ],
         "showgrid": true,
         "ticktext": [
          "Revisão sistemática da literatura e elaboração do projeto",
          "Obtenção de aprovação ética",
          "Recrutamento de pacientes",
          "Coleta de amostras de LS",
          "Processamento e armazenamento de amostras",
          "Desenvolvimento do modelo computacional",
          "Análise genômica, transcriptômica e proteômica",
          "Análise de citometria de fluxo",
          "Validação do modelo computacional",
          "Análise estatística e integração de dados",
          "Identificação de biomarcadores e vias de sinalização",
          "Avaliação da dissimilaridade",
          "Análise da metabolização de fármacos",
          "Refinamento e validação final do modelo",
          "Redação e submissão de artigos",
          "Apresentação em congressos",
          "Elaboração e defesa da tese"
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16
         ],
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "\n",
    "# Dados do cronograma\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        dict(Task=\"Revisão sistemática da literatura e elaboração do projeto\", Start=\"2024-01-01\", Finish=\"2024-04-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Obtenção de aprovação ética\", Start=\"2024-02-01\", Finish=\"2024-05-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Recrutamento de pacientes\", Start=\"2024-04-01\", Finish=\"2025-01-01\", Resource=\"Médicos Reumatologistas\"),\n",
    "        dict(Task=\"Coleta de amostras de LS\", Start=\"2024-05-01\", Finish=\"2025-01-01\", Resource=\"Médicos Reumatologistas\"),\n",
    "        dict(Task=\"Processamento e armazenamento de amostras\", Start=\"2024-05-01\", Finish=\"2025-01-01\", Resource=\"Técnicos de Laboratório\"),\n",
    "        dict(Task=\"Análise genômica, transcriptômica e proteômica\", Start=\"2025-01-01\", Finish=\"2026-07-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Análise de citometria de fluxo\", Start=\"2025-07-01\", Finish=\"2026-01-01\", Resource=\"Bolsista In Vitro\"),\n",
    "        dict(Task=\"Desenvolvimento do modelo computacional\", Start=\"2025-01-01\", Finish=\"2026-01-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Validação do modelo computacional\", Start=\"2026-01-01\", Finish=\"2026-07-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Análise estatística e integração de dados\", Start=\"2026-01-01\", Finish=\"2026-07-01\", Resource=\"Doutorando(a)\"),\n",
    "        dict(Task=\"Identificação de biomarcadores e vias de sinalização\", Start=\"2026-07-01\", Finish=\"2027-01-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Avaliação da dissimilaridade\", Start=\"2026-07-01\", Finish=\"2027-01-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Análise da metabolização de fármacos\", Start=\"2027-01-01\", Finish=\"2027-07-01\", Resource=\"Bolsista In Vitro\"),\n",
    "        dict(Task=\"Refinamento e validação final do modelo\", Start=\"2027-01-01\", Finish=\"2027-07-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Redação e submissão de artigos\", Start=\"2027-07-01\", Finish=\"2028-01-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Apresentação em congressos\", Start=\"2027-07-01\", Finish=\"2028-01-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Elaboração e defesa da tese\", Start=\"2027-07-01\", Finish=\"2028-01-01\", Resource=\"Doutoranda\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Criação do gráfico de Gantt\n",
    "fig = ff.create_gantt(\n",
    "    df,\n",
    "    colors={\"Doutorando(a)\": \"rgb(220, 0, 0)\", \"Bolsista In Silico\": \"rgb(0, 255, 100)\", \"Bolsista In Vitro\": \"rgb(0, 100, 255)\", \"Médicos Reumatologistas\": \"rgb(255, 150, 0)\", \"Técnicos de Laboratório\": \"rgb(150, 0, 255)\"},\n",
    "    index_col=\"Resource\",\n",
    "    title=\"Cronograma do Projeto de Doutorado em Medicina de Precisão e Personalizada na Artrite Reumatoide\",\n",
    "    show_colorbar=True,\n",
    "    bar_width=0.2,\n",
    "    showgrid_x=True,\n",
    "    showgrid_y=True,\n",
    ")\n",
    "\n",
    "# Personalização do layout\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=-45, \n",
    "    xaxis=dict(\n",
    "        rangeslider=dict(visible=True),\n",
    "        type=\"date\"  # Defina o tipo do eixo x como data\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Exibir o gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "75538a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "fill": "toself",
         "fillcolor": "rgb(0, 0, 0)",
         "hoverinfo": "name",
         "legendgroup": "rgb(0, 0, 0)",
         "mode": "none",
         "name": "Doutoranda",
         "type": "scatter",
         "x": [
          "2024-01-01",
          "2024-04-01",
          "2024-04-01",
          "2024-01-01",
          "2024-01-01",
          "2024-02-01",
          "2024-05-01",
          "2024-05-01",
          "2024-02-01",
          "2024-02-01",
          "2026-01-01",
          "2026-07-01",
          "2026-07-01",
          "2026-01-01",
          "2026-01-01",
          "2026-07-01",
          "2027-01-01",
          "2027-01-01",
          "2026-07-01",
          "2026-07-01",
          "2027-07-01",
          "2028-01-01",
          "2028-01-01",
          "2027-07-01",
          "2027-07-01",
          "2027-07-01",
          "2028-01-01",
          "2028-01-01",
          "2027-07-01",
          "2027-07-01",
          "2027-07-01",
          "2028-01-01",
          "2028-01-01",
          "2027-07-01"
         ],
         "y": [
          -0.2,
          -0.2,
          0.2,
          0.2,
          null,
          0.8,
          0.8,
          1.2,
          1.2,
          null,
          8.8,
          8.8,
          9.2,
          9.2,
          null,
          9.8,
          9.8,
          10.2,
          10.2,
          null,
          13.8,
          13.8,
          14.2,
          14.2,
          null,
          14.8,
          14.8,
          15.2,
          15.2,
          null,
          15.8,
          15.8,
          16.2,
          16.2
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgb(150, 150, 44)",
         "hoverinfo": "name",
         "legendgroup": "rgb(150, 150, 44)",
         "mode": "none",
         "name": "Técnicos de Laboratório",
         "type": "scatter",
         "x": [
          "2024-05-01",
          "2025-01-01",
          "2025-01-01",
          "2024-05-01"
         ],
         "y": [
          3.8,
          3.8,
          4.2,
          4.2
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgb(225, 225, 194)",
         "hoverinfo": "name",
         "legendgroup": "rgb(225, 225, 194)",
         "mode": "none",
         "name": "Bolsista In Silico",
         "type": "scatter",
         "x": [
          "2025-01-01",
          "2026-07-01",
          "2026-07-01",
          "2025-01-01",
          "2025-01-01",
          "2025-01-01",
          "2026-01-01",
          "2026-01-01",
          "2025-01-01",
          "2025-01-01",
          "2026-01-01",
          "2026-07-01",
          "2026-07-01",
          "2026-01-01",
          "2026-01-01",
          "2026-07-01",
          "2027-01-01",
          "2027-01-01",
          "2026-07-01",
          "2026-07-01",
          "2027-01-01",
          "2027-07-01",
          "2027-07-01",
          "2027-01-01"
         ],
         "y": [
          4.8,
          4.8,
          5.2,
          5.2,
          null,
          6.8,
          6.8,
          7.2,
          7.2,
          null,
          7.8,
          7.8,
          8.2,
          8.2,
          null,
          10.8,
          10.8,
          11.2,
          11.2,
          null,
          12.8,
          12.8,
          13.2,
          13.2
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgb(44, 44, 88)",
         "hoverinfo": "name",
         "legendgroup": "rgb(44, 44, 88)",
         "mode": "none",
         "name": "Bolsista In Vitro",
         "type": "scatter",
         "x": [
          "2025-07-01",
          "2026-01-01",
          "2026-01-01",
          "2025-07-01",
          "2025-07-01",
          "2027-01-01",
          "2027-07-01",
          "2027-07-01",
          "2027-01-01"
         ],
         "y": [
          5.8,
          5.8,
          6.2,
          6.2,
          null,
          11.8,
          11.8,
          12.2,
          12.2
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgb(75, 75, 150)",
         "hoverinfo": "name",
         "legendgroup": "rgb(75, 75, 150)",
         "mode": "none",
         "name": "Médicos Reumatologistas",
         "type": "scatter",
         "x": [
          "2024-04-01",
          "2025-01-01",
          "2025-01-01",
          "2024-04-01",
          "2024-04-01",
          "2024-05-01",
          "2025-01-01",
          "2025-01-01",
          "2024-05-01"
         ],
         "y": [
          1.8,
          1.8,
          2.2,
          2.2,
          null,
          2.8,
          2.8,
          3.2,
          3.2
         ]
        },
        {
         "legendgroup": "rgb(0, 0, 0)",
         "marker": {
          "color": "rgb(0, 0, 0)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2024-01-01",
          "2024-04-01",
          "2024-02-01",
          "2024-05-01",
          "2026-01-01",
          "2026-07-01",
          "2026-07-01",
          "2027-01-01",
          "2027-07-01",
          "2028-01-01",
          "2027-07-01",
          "2028-01-01",
          "2027-07-01",
          "2028-01-01"
         ],
         "y": [
          0,
          0,
          1,
          1,
          9,
          9,
          10,
          10,
          14,
          14,
          15,
          15,
          16,
          16
         ]
        },
        {
         "legendgroup": "rgb(150, 150, 44)",
         "marker": {
          "color": "rgb(150, 150, 44)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2024-05-01",
          "2025-01-01"
         ],
         "y": [
          4,
          4
         ]
        },
        {
         "legendgroup": "rgb(225, 225, 194)",
         "marker": {
          "color": "rgb(225, 225, 194)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2025-01-01",
          "2026-07-01",
          "2025-01-01",
          "2026-01-01",
          "2026-01-01",
          "2026-07-01",
          "2026-07-01",
          "2027-01-01",
          "2027-01-01",
          "2027-07-01"
         ],
         "y": [
          5,
          5,
          7,
          7,
          8,
          8,
          11,
          11,
          13,
          13
         ]
        },
        {
         "legendgroup": "rgb(44, 44, 88)",
         "marker": {
          "color": "rgb(44, 44, 88)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null,
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2025-07-01",
          "2026-01-01",
          "2027-01-01",
          "2027-07-01"
         ],
         "y": [
          6,
          6,
          12,
          12
         ]
        },
        {
         "legendgroup": "rgb(75, 75, 150)",
         "marker": {
          "color": "rgb(75, 75, 150)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null,
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2024-04-01",
          "2025-01-01",
          "2024-05-01",
          "2025-01-01"
         ],
         "y": [
          2,
          2,
          3,
          3
         ]
        }
       ],
       "layout": {
        "height": 600,
        "hovermode": "closest",
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cronograma do Projeto de Doutorado em Medicina de Precisão e Personalizada na Artrite Reumatoide"
        },
        "xaxis": {
         "rangeselector": {
          "buttons": [
           {
            "count": 7,
            "label": "1w",
            "step": "day",
            "stepmode": "backward"
           },
           {
            "count": 1,
            "label": "1m",
            "step": "month",
            "stepmode": "backward"
           },
           {
            "count": 6,
            "label": "6m",
            "step": "month",
            "stepmode": "backward"
           },
           {
            "count": 1,
            "label": "YTD",
            "step": "year",
            "stepmode": "todate"
           },
           {
            "count": 1,
            "label": "1y",
            "step": "year",
            "stepmode": "backward"
           },
           {
            "step": "all"
           }
          ]
         },
         "rangeslider": {
          "visible": true
         },
         "showgrid": true,
         "tickangle": -45,
         "type": "date",
         "zeroline": false
        },
        "yaxis": {
         "autorange": false,
         "range": [
          -1,
          18
         ],
         "showgrid": true,
         "ticktext": [
          "Revisão sistemática da literatura e elaboração do projeto",
          "Obtenção de aprovação ética",
          "Recrutamento de pacientes",
          "Coleta de amostras de LS",
          "Processamento e armazenamento de amostras",
          "Análise genômica, transcriptômica e proteômica",
          "Análise de citometria de fluxo",
          "Desenvolvimento do modelo computacional",
          "Validação do modelo computacional",
          "Análise estatística e integração de dados",
          "Identificação de biomarcadores e vias de sinalização",
          "Avaliação da dissimilaridade",
          "Análise da metabolização de fármacos",
          "Refinamento e validação final do modelo",
          "Redação e submissão de artigos",
          "Apresentação em congressos",
          "Elaboração e defesa da tese"
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16
         ],
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "\n",
    "# Dados do cronograma\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        dict(Task=\"Revisão sistemática da literatura e elaboração do projeto\", Start=\"2024-01-01\", Finish=\"2024-04-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Obtenção de aprovação ética\", Start=\"2024-02-01\", Finish=\"2024-05-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Recrutamento de pacientes\", Start=\"2024-04-01\", Finish=\"2025-01-01\", Resource=\"Médicos Reumatologistas\"),\n",
    "        dict(Task=\"Coleta de amostras de LS\", Start=\"2024-05-01\", Finish=\"2025-01-01\", Resource=\"Médicos Reumatologistas\"),\n",
    "        dict(Task=\"Processamento e armazenamento de amostras\", Start=\"2024-05-01\", Finish=\"2025-01-01\", Resource=\"Técnicos de Laboratório\"),\n",
    "        dict(Task=\"Análise genômica, transcriptômica e proteômica\", Start=\"2025-01-01\", Finish=\"2026-07-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Análise de citometria de fluxo\", Start=\"2025-07-01\", Finish=\"2026-01-01\", Resource=\"Bolsista In Vitro\"),\n",
    "        dict(Task=\"Desenvolvimento do modelo computacional\", Start=\"2025-01-01\", Finish=\"2026-01-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Validação do modelo computacional\", Start=\"2026-01-01\", Finish=\"2026-07-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Análise estatística e integração de dados\", Start=\"2026-01-01\", Finish=\"2026-07-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Identificação de biomarcadores e vias de sinalização\", Start=\"2026-07-01\", Finish=\"2027-01-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Avaliação da dissimilaridade\", Start=\"2026-07-01\", Finish=\"2027-01-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Análise da metabolização de fármacos\", Start=\"2027-01-01\", Finish=\"2027-07-01\", Resource=\"Bolsista In Vitro\"),\n",
    "        dict(Task=\"Refinamento e validação final do modelo\", Start=\"2027-01-01\", Finish=\"2027-07-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Redação e submissão de artigos\", Start=\"2027-07-01\", Finish=\"2028-01-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Apresentação em congressos\", Start=\"2027-07-01\", Finish=\"2028-01-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Elaboração e defesa da tese\", Start=\"2027-07-01\", Finish=\"2028-01-01\", Resource=\"Doutoranda\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Ajustar os valores únicos da coluna \"Resource\"\n",
    "resources = df[\"Resource\"].unique()\n",
    "\n",
    "# Criação do gráfico de Gantt\n",
    "fig = ff.create_gantt(\n",
    "    df,\n",
    "    colors= {r: f\"rgb({(i*75)%256}, {(i*75)%256}, {(i*150)%256})\" for i, r in enumerate(resources)}, # O operador % 256 (módulo) garante que os valores de RGB fiquem dentro do intervalo válido de 0 a 255.\n",
    "    index_col=\"Resource\",\n",
    "    title=\"Cronograma do Projeto de Doutorado em Medicina de Precisão e Personalizada na Artrite Reumatoide\",\n",
    "    show_colorbar=True,\n",
    "    bar_width=0.2,\n",
    "    showgrid_x=True,\n",
    "    showgrid_y=True,\n",
    ")\n",
    "\n",
    "# Personalização do layout\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=-45, \n",
    "    xaxis=dict(\n",
    "        rangeslider=dict(visible=True),\n",
    "        type=\"date\"  # Defina o tipo do eixo x como data\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Exibir o gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d65c8035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "fill": "toself",
         "fillcolor": "rgb(146, 182, 235)",
         "hoverinfo": "name",
         "legendgroup": "rgb(146, 182, 235)",
         "mode": "none",
         "name": "Médicos Reumatologistas",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2024-10-01T00:00:00",
          "2025-07-01T00:00:00",
          "2025-07-01T00:00:00",
          "2024-10-01T00:00:00",
          "2024-10-01T00:00:00",
          "2024-11-01T00:00:00",
          "2025-07-01T00:00:00",
          "2025-07-01T00:00:00",
          "2024-11-01T00:00:00"
         ],
         "y": [
          1.8,
          1.8,
          2.2,
          2.2,
          null,
          2.8,
          2.8,
          3.2,
          3.2
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgb(146, 235, 182)",
         "hoverinfo": "name",
         "legendgroup": "rgb(146, 235, 182)",
         "mode": "none",
         "name": "Doutoranda",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2024-07-01T00:00:00",
          "2024-10-01T00:00:00",
          "2024-10-01T00:00:00",
          "2024-07-01T00:00:00",
          "2024-07-01T00:00:00",
          "2024-08-01T00:00:00",
          "2024-11-01T00:00:00",
          "2024-11-01T00:00:00",
          "2024-08-01T00:00:00",
          "2024-08-01T00:00:00",
          "2026-07-01T00:00:00",
          "2027-01-01T00:00:00",
          "2027-01-01T00:00:00",
          "2026-07-01T00:00:00",
          "2026-07-01T00:00:00",
          "2027-01-01T00:00:00",
          "2027-07-01T00:00:00",
          "2027-07-01T00:00:00",
          "2027-01-01T00:00:00",
          "2027-01-01T00:00:00",
          "2028-01-01T00:00:00",
          "2028-07-01T00:00:00",
          "2028-07-01T00:00:00",
          "2028-01-01T00:00:00",
          "2028-01-01T00:00:00",
          "2028-01-01T00:00:00",
          "2028-07-01T00:00:00",
          "2028-07-01T00:00:00",
          "2028-01-01T00:00:00",
          "2028-01-01T00:00:00",
          "2028-01-01T00:00:00",
          "2028-07-01T00:00:00",
          "2028-07-01T00:00:00",
          "2028-01-01T00:00:00"
         ],
         "y": [
          -0.2,
          -0.2,
          0.2,
          0.2,
          null,
          0.8,
          0.8,
          1.2,
          1.2,
          null,
          8.8,
          8.8,
          9.2,
          9.2,
          null,
          9.8,
          9.8,
          10.2,
          10.2,
          null,
          13.8,
          13.8,
          14.2,
          14.2,
          null,
          14.8,
          14.8,
          15.2,
          15.2,
          null,
          15.8,
          15.8,
          16.2,
          16.2
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgb(218, 146, 235)",
         "hoverinfo": "name",
         "legendgroup": "rgb(218, 146, 235)",
         "mode": "none",
         "name": "Técnicos de Laboratório",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2024-11-01T00:00:00",
          "2025-07-01T00:00:00",
          "2025-07-01T00:00:00",
          "2024-11-01T00:00:00"
         ],
         "y": [
          3.8,
          3.8,
          4.2,
          4.2
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgb(218, 235, 146)",
         "hoverinfo": "name",
         "legendgroup": "rgb(218, 235, 146)",
         "mode": "none",
         "name": "Bolsista In Vitro",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2025-01-01T00:00:00",
          "2026-07-01T00:00:00",
          "2026-07-01T00:00:00",
          "2025-01-01T00:00:00",
          "2025-01-01T00:00:00",
          "2027-07-01T00:00:00",
          "2028-01-01T00:00:00",
          "2028-01-01T00:00:00",
          "2027-07-01T00:00:00"
         ],
         "y": [
          4.8,
          4.8,
          5.2,
          5.2,
          null,
          11.8,
          11.8,
          12.2,
          12.2
         ]
        },
        {
         "fill": "toself",
         "fillcolor": "rgb(235, 146, 146)",
         "hoverinfo": "name",
         "legendgroup": "rgb(235, 146, 146)",
         "mode": "none",
         "name": "Bolsista In Silico",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "2025-01-01T00:00:00",
          "2026-07-01T00:00:00",
          "2026-07-01T00:00:00",
          "2025-01-01T00:00:00",
          "2025-01-01T00:00:00",
          "2025-07-01T00:00:00",
          "2027-01-01T00:00:00",
          "2027-01-01T00:00:00",
          "2025-07-01T00:00:00",
          "2025-07-01T00:00:00",
          "2026-07-01T00:00:00",
          "2027-01-01T00:00:00",
          "2027-01-01T00:00:00",
          "2026-07-01T00:00:00",
          "2026-07-01T00:00:00",
          "2027-01-01T00:00:00",
          "2027-07-01T00:00:00",
          "2027-07-01T00:00:00",
          "2027-01-01T00:00:00",
          "2027-01-01T00:00:00",
          "2027-07-01T00:00:00",
          "2028-01-01T00:00:00",
          "2028-01-01T00:00:00",
          "2027-07-01T00:00:00"
         ],
         "y": [
          5.8,
          5.8,
          6.2,
          6.2,
          null,
          6.8,
          6.8,
          7.2,
          7.2,
          null,
          7.8,
          7.8,
          8.2,
          8.2,
          null,
          10.8,
          10.8,
          11.2,
          11.2,
          null,
          12.8,
          12.8,
          13.2,
          13.2
         ]
        },
        {
         "legendgroup": "rgb(146, 182, 235)",
         "marker": {
          "color": "rgb(146, 182, 235)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null,
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2024-10-01T00:00:00",
          "2025-07-01T00:00:00",
          "2024-11-01T00:00:00",
          "2025-07-01T00:00:00"
         ],
         "y": [
          2,
          2,
          3,
          3
         ]
        },
        {
         "legendgroup": "rgb(146, 235, 182)",
         "marker": {
          "color": "rgb(146, 235, 182)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2024-07-01T00:00:00",
          "2024-10-01T00:00:00",
          "2024-08-01T00:00:00",
          "2024-11-01T00:00:00",
          "2026-07-01T00:00:00",
          "2027-01-01T00:00:00",
          "2027-01-01T00:00:00",
          "2027-07-01T00:00:00",
          "2028-01-01T00:00:00",
          "2028-07-01T00:00:00",
          "2028-01-01T00:00:00",
          "2028-07-01T00:00:00",
          "2028-01-01T00:00:00",
          "2028-07-01T00:00:00"
         ],
         "y": [
          0,
          0,
          1,
          1,
          9,
          9,
          10,
          10,
          14,
          14,
          15,
          15,
          16,
          16
         ]
        },
        {
         "legendgroup": "rgb(218, 146, 235)",
         "marker": {
          "color": "rgb(218, 146, 235)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2024-11-01T00:00:00",
          "2025-07-01T00:00:00"
         ],
         "y": [
          4,
          4
         ]
        },
        {
         "legendgroup": "rgb(218, 235, 146)",
         "marker": {
          "color": "rgb(218, 235, 146)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null,
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2025-01-01T00:00:00",
          "2026-07-01T00:00:00",
          "2027-07-01T00:00:00",
          "2028-01-01T00:00:00"
         ],
         "y": [
          5,
          5,
          12,
          12
         ]
        },
        {
         "legendgroup": "rgb(235, 146, 146)",
         "marker": {
          "color": "rgb(235, 146, 146)",
          "opacity": 0,
          "size": 1
         },
         "mode": "markers",
         "name": "",
         "showlegend": false,
         "text": [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null
         ],
         "type": "scatter",
         "x": [
          "2025-01-01T00:00:00",
          "2026-07-01T00:00:00",
          "2025-07-01T00:00:00",
          "2027-01-01T00:00:00",
          "2026-07-01T00:00:00",
          "2027-01-01T00:00:00",
          "2027-01-01T00:00:00",
          "2027-07-01T00:00:00",
          "2027-07-01T00:00:00",
          "2028-01-01T00:00:00"
         ],
         "y": [
          6,
          6,
          7,
          7,
          8,
          8,
          11,
          11,
          13,
          13
         ]
        }
       ],
       "layout": {
        "height": 800,
        "hovermode": "closest",
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cronograma do Projeto de Doutorado em Medicina de Precisão e Personalizada na Artrite Reumatoide"
        },
        "width": 1200,
        "xaxis": {
         "rangeselector": {
          "buttons": [
           {
            "count": 7,
            "label": "1w",
            "step": "day",
            "stepmode": "backward"
           },
           {
            "count": 1,
            "label": "1m",
            "step": "month",
            "stepmode": "backward"
           },
           {
            "count": 6,
            "label": "6m",
            "step": "month",
            "stepmode": "backward"
           },
           {
            "count": 1,
            "label": "YTD",
            "step": "year",
            "stepmode": "todate"
           },
           {
            "count": 1,
            "label": "1y",
            "step": "year",
            "stepmode": "backward"
           },
           {
            "step": "all"
           }
          ]
         },
         "rangeslider": {
          "visible": true
         },
         "showgrid": true,
         "tickangle": -45,
         "type": "date",
         "zeroline": false
        },
        "yaxis": {
         "autorange": false,
         "range": [
          -1,
          18
         ],
         "showgrid": true,
         "ticktext": [
          "Revisão sistemática da literatura",
          "Obter aprovação ética",
          "Recrutar pacientes",
          "Coletar amostras de LS",
          "Processar e armazenar amostras",
          "Analisar de citometria de fluxo",
          "Desenvolver modelo computacional",
          "Analisar genômica, transcriptômica e proteômica",
          "Validar modelo computacional",
          "Analisar estatística e integrar dados",
          "Identificar biomarcadores e vias de sinalização",
          "Avaliar dissimilaridade",
          "Analisar metabolização de fármacos",
          "Refinar e validação final do modelo",
          "Redigir e submeter artigos",
          "Apresentar em congressos",
          "Elaborar defesa da tese"
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16
         ],
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "import colorsys  # Para trabalhar com o sistema de cores HSL\n",
    "\n",
    "# Dados do cronograma\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        dict(Task=\"Revisão sistemática da literatura\", Start=\"2024-01-01\", Finish=\"2024-04-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Obter aprovação ética\", Start=\"2024-02-01\", Finish=\"2024-05-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Recrutar pacientes\", Start=\"2024-04-01\", Finish=\"2025-01-01\", Resource=\"Médicos Reumatologistas\"),\n",
    "        dict(Task=\"Coletar amostras de LS\", Start=\"2024-05-01\", Finish=\"2025-01-01\", Resource=\"Médicos Reumatologistas\"),\n",
    "        dict(Task=\"Processar e armazenar amostras\", Start=\"2024-05-01\", Finish=\"2025-01-01\", Resource=\"Técnicos de Laboratório\"),\n",
    "        dict(Task=\"Analisar de citometria de fluxo\", Start=\"2024-07-01\", Finish=\"2026-01-01\", Resource=\"Bolsista In Vitro\"),\n",
    "        dict(Task=\"Desenvolver modelo computacional\", Start=\"2024-07-01\", Finish=\"2026-01-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Analisar genômica, transcriptômica e proteômica\", Start=\"2025-01-01\", Finish=\"2026-07-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Validar modelo computacional\", Start=\"2026-01-01\", Finish=\"2026-07-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Analisar estatística e integrar dados\", Start=\"2026-01-01\", Finish=\"2026-07-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Identificar biomarcadores e vias de sinalização\", Start=\"2026-07-01\", Finish=\"2027-01-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Avaliar dissimilaridade\", Start=\"2026-07-01\", Finish=\"2027-01-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Analisar metabolização de fármacos\", Start=\"2027-01-01\", Finish=\"2027-07-01\", Resource=\"Bolsista In Vitro\"),\n",
    "        dict(Task=\"Refinar e validação final do modelo\", Start=\"2027-01-01\", Finish=\"2027-07-01\", Resource=\"Bolsista In Silico\"),\n",
    "        dict(Task=\"Redigir e submeter artigos\", Start=\"2027-07-01\", Finish=\"2028-01-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Apresentar em congressos\", Start=\"2027-07-01\", Finish=\"2028-01-01\", Resource=\"Doutoranda\"),\n",
    "        dict(Task=\"Elaborar defesa da tese\", Start=\"2027-07-01\", Finish=\"2028-01-01\", Resource=\"Doutoranda\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Convertendo colunas para datetime\n",
    "df['Start'] = pd.to_datetime(df['Start'])\n",
    "df['Finish'] = pd.to_datetime(df['Finish'])\n",
    "\n",
    "# Adicionando 6 meses às datas\n",
    "df['Start'] = df['Start'] + pd.DateOffset(months=6)\n",
    "df['Finish'] = df['Finish'] + pd.DateOffset(months=6)\n",
    "\n",
    "# Ajustar os valores únicos da coluna \"Resource\"\n",
    "resources = df[\"Resource\"].unique()\n",
    "\n",
    "# Função para gerar cores complementares\n",
    "def generate_complementary_colors(num_colors):\n",
    "    colors = []\n",
    "    for i in range(num_colors):\n",
    "        hue = (i * 360 / num_colors) % 360  # Ângulo Hue igualmente espaçado\n",
    "        saturation = 0.7  # Saturação (pode ser ajustada)\n",
    "        lightness = 0.75  # Luminosidade (pode ser ajustada)\n",
    "        r, g, b = colorsys.hls_to_rgb(hue / 360, lightness, saturation)\n",
    "        complementary_hue = (hue + 180) % 360\n",
    "        cr, cg, cb = colorsys.hls_to_rgb(complementary_hue / 360, lightness, saturation)\n",
    "        colors.append(f\"rgb({int(r*255)}, {int(g*255)}, {int(b*255)})\")\n",
    "    return colors\n",
    "\n",
    "# Gerar cores complementares\n",
    "colors = generate_complementary_colors(len(df[\"Resource\"].unique()))\n",
    "\n",
    "# Criação do gráfico de Gantt\n",
    "fig = ff.create_gantt(\n",
    "    df,\n",
    "    colors=colors,\n",
    "    index_col=\"Resource\",\n",
    "    title=\"Cronograma do Projeto de Doutorado em Medicina de Precisão e Personalizada na Artrite Reumatoide\",\n",
    "    show_colorbar=True,\n",
    "    bar_width=0.2,\n",
    "    showgrid_x=True,\n",
    "    showgrid_y=True,\n",
    ")\n",
    "\n",
    "# Personalização do layout\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=-45, \n",
    "    xaxis=dict(\n",
    "        rangeslider=dict(visible=True),\n",
    "        type=\"date\"  # Defina o tipo do eixo x como data\n",
    "    ),\n",
    "    height=800,  # Altura do gráfico em pixels\n",
    "    width=1200,  # Largura do gráfico em pixels\n",
    ")\n",
    "\n",
    "# Exibir o gráfico\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "91d12db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>Atividade</th>\n",
       "      <th>Duração (Semanas)</th>\n",
       "      <th>Trimestre</th>\n",
       "      <th>Responsável</th>\n",
       "      <th>Predecessora</th>\n",
       "      <th>Ordem</th>\n",
       "      <th>inicio_trimestre</th>\n",
       "      <th>inicio</th>\n",
       "      <th>fim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Revisão bibliográfica (B01-InSilico)</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Bolsista In Silico</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Treinamento em softwares (B01-InSilico)</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Bolsista In Silico</td>\n",
       "      <td>Revisão bibliográfica (B01-InSilico)</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Montar a base de dados (B01-InSilico)</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Bolsista In Silico</td>\n",
       "      <td>Treinamento em softwares (B01-InSilico)</td>\n",
       "      <td>102</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Desenvolver modelo computacional (B01-InSilico)</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Bolsista In Silico</td>\n",
       "      <td>Montar a base de dados (B01-InSilico)</td>\n",
       "      <td>103</td>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Validar modelo computacional (B01-InSilico)</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Bolsista In Silico</td>\n",
       "      <td>Desenvolver modelo computacional (B01-InSilico)</td>\n",
       "      <td>104</td>\n",
       "      <td>36</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Integrar modelos e dados experimentais (B01-InSilico)</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Bolsista In Silico</td>\n",
       "      <td>Validar modelo computacional (B01-InSilico)</td>\n",
       "      <td>105</td>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Revisão bibliográfica (B02-InVitro)</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Bolsista In Vitro</td>\n",
       "      <td>-</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Preparação cultura celular (B02-InVitro)</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Bolsista In Vitro</td>\n",
       "      <td>Revisão bibliográfica (B02-InVitro)</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Padronizar técnicas de cultura(B02-InVitro)</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Bolsista In Vitro</td>\n",
       "      <td>Preparação cultura celular (B02-InVitro)</td>\n",
       "      <td>202</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Experimentos preliminares (B02-InVitro)</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Bolsista In Vitro</td>\n",
       "      <td>Padronizar técnicas de cultura (B02-InVitro)</td>\n",
       "      <td>203</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Otimizar condições de cultura (B02-InVitro)</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Bolsista In Vitro</td>\n",
       "      <td>Experimentos preliminares (B02-InVitro)</td>\n",
       "      <td>204</td>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Experimentos principais (B02-InVitro)</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>Bolsista In Vitro</td>\n",
       "      <td>Otimizar condições de cultura (B02-InVitro)</td>\n",
       "      <td>205</td>\n",
       "      <td>36</td>\n",
       "      <td>72</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Análise de resultados (B02-InVitro)</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Bolsista In Vitro</td>\n",
       "      <td>Experimentos principais (B02-InVitro)</td>\n",
       "      <td>206</td>\n",
       "      <td>36</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Experimentos complementares (B02-InVitro)</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Bolsista In Vitro</td>\n",
       "      <td>Análise de resultados (B02-InVitro)</td>\n",
       "      <td>207</td>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Análise estatística dos resultados (B02-InVitro)</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Bolsista In Vitro</td>\n",
       "      <td>Experimentos complementares (B02-InVitro)</td>\n",
       "      <td>208</td>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matrícula em disciplinas (Doc)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Doutorando(a)</td>\n",
       "      <td>-</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Revisão bibliográfica (Doc)</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Doutorando(a)</td>\n",
       "      <td>-</td>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elaborar projeto de pesquisa (Doc)</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Doutorando(a)</td>\n",
       "      <td>Revisão bibliográfica (Doc)</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cursar disciplinas teóricas (Doc)</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Doutorando(a)</td>\n",
       "      <td>Matrícula em disciplinas (Doc)</td>\n",
       "      <td>303</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aprofundar revisão bibliográfica (Doc)</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Doutorando(a)</td>\n",
       "      <td>Cursar disciplinas teóricas (Doc)</td>\n",
       "      <td>304</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Concluir disciplinas teóricas (Doc)</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Doutorando(a)</td>\n",
       "      <td>Cursar disciplinas teóricas (Doc)</td>\n",
       "      <td>305</td>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Apresentar projeto de pesquisa (Doc)</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Doutorando(a)</td>\n",
       "      <td>Concluir disciplinas teóricas (Doc)</td>\n",
       "      <td>306</td>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Analisar resultados preliminares(Doc)</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Doutorando(a)</td>\n",
       "      <td>Apresentar projeto de pesquisa (Doc)</td>\n",
       "      <td>307</td>\n",
       "      <td>36</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Refinar projeto de pesquisa (Doc)</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Doutorando(a)</td>\n",
       "      <td>Analisar resultados preliminares (Doc)</td>\n",
       "      <td>308</td>\n",
       "      <td>36</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Redigir artigo científico 01 (Doc)</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Doutorando(a)</td>\n",
       "      <td>Analisar resultados preliminares(Doc)</td>\n",
       "      <td>309</td>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Apresentação em congressos (Doc)</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Doutorando(a)</td>\n",
       "      <td>Redigir artigo científico 01 (Doc)</td>\n",
       "      <td>310</td>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Submissão do primeiro artigo científico (Doc)</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Doutorando(a)</td>\n",
       "      <td>Redigir artigo científico 01(Doc)</td>\n",
       "      <td>311</td>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Atividade                                               Duração (Semanas)  \\\n",
       "3                    Revisão bibliográfica (B01-InSilico)   8                  \n",
       "4                 Treinamento em softwares (B01-InSilico)   8                  \n",
       "9                   Montar a base de dados (B01-InSilico)   8                  \n",
       "14        Desenvolver modelo computacional (B01-InSilico)   8                  \n",
       "19            Validar modelo computacional (B01-InSilico)   8                  \n",
       "22  Integrar modelos e dados experimentais (B01-InSilico)   8                  \n",
       "5                     Revisão bibliográfica (B02-InVitro)   8                  \n",
       "6                Preparação cultura celular (B02-InVitro)   8                  \n",
       "10            Padronizar técnicas de cultura(B02-InVitro)   8                  \n",
       "11                Experimentos preliminares (B02-InVitro)   8                  \n",
       "15            Otimizar condições de cultura (B02-InVitro)   8                  \n",
       "16                  Experimentos principais (B02-InVitro)  12                  \n",
       "20                    Análise de resultados (B02-InVitro)   8                  \n",
       "23              Experimentos complementares (B02-InVitro)   8                  \n",
       "25       Análise estatística dos resultados (B02-InVitro)   8                  \n",
       "0                          Matrícula em disciplinas (Doc)   1                  \n",
       "1                             Revisão bibliográfica (Doc)   8                  \n",
       "2                      Elaborar projeto de pesquisa (Doc)   8                  \n",
       "7                       Cursar disciplinas teóricas (Doc)   8                  \n",
       "8                  Aprofundar revisão bibliográfica (Doc)   8                  \n",
       "12                    Concluir disciplinas teóricas (Doc)   8                  \n",
       "13                   Apresentar projeto de pesquisa (Doc)   8                  \n",
       "17                  Analisar resultados preliminares(Doc)   8                  \n",
       "18                      Refinar projeto de pesquisa (Doc)   8                  \n",
       "21                     Redigir artigo científico 01 (Doc)   8                  \n",
       "24                       Apresentação em congressos (Doc)   8                  \n",
       "26          Submissão do primeiro artigo científico (Doc)   8                  \n",
       "\n",
       "    Trimestre Responsável          \\\n",
       "3   1          Bolsista In Silico   \n",
       "4   1          Bolsista In Silico   \n",
       "9   2          Bolsista In Silico   \n",
       "14  3          Bolsista In Silico   \n",
       "19  4          Bolsista In Silico   \n",
       "22  5          Bolsista In Silico   \n",
       "5   1           Bolsista In Vitro   \n",
       "6   1           Bolsista In Vitro   \n",
       "10  2           Bolsista In Vitro   \n",
       "11  2           Bolsista In Vitro   \n",
       "15  3           Bolsista In Vitro   \n",
       "16  4           Bolsista In Vitro   \n",
       "20  4           Bolsista In Vitro   \n",
       "23  5           Bolsista In Vitro   \n",
       "25  5           Bolsista In Vitro   \n",
       "0   1               Doutorando(a)   \n",
       "1   1               Doutorando(a)   \n",
       "2   1               Doutorando(a)   \n",
       "7   2               Doutorando(a)   \n",
       "8   2               Doutorando(a)   \n",
       "12  3               Doutorando(a)   \n",
       "13  3               Doutorando(a)   \n",
       "17  4               Doutorando(a)   \n",
       "18  4               Doutorando(a)   \n",
       "21  5               Doutorando(a)   \n",
       "24  5               Doutorando(a)   \n",
       "26  5               Doutorando(a)   \n",
       "\n",
       "   Predecessora                                      Ordem  inicio_trimestre  \\\n",
       "3                                                 -  100     0                 \n",
       "4              Revisão bibliográfica (B01-InSilico)  101     0                 \n",
       "9           Treinamento em softwares (B01-InSilico)  102    12                 \n",
       "14            Montar a base de dados (B01-InSilico)  103    24                 \n",
       "19  Desenvolver modelo computacional (B01-InSilico)  104    36                 \n",
       "22      Validar modelo computacional (B01-InSilico)  105    48                 \n",
       "5                                                 -  200     0                 \n",
       "6               Revisão bibliográfica (B02-InVitro)  201     0                 \n",
       "10         Preparação cultura celular (B02-InVitro)  202    12                 \n",
       "11     Padronizar técnicas de cultura (B02-InVitro)  203    12                 \n",
       "15          Experimentos preliminares (B02-InVitro)  204    24                 \n",
       "16      Otimizar condições de cultura (B02-InVitro)  205    36                 \n",
       "20            Experimentos principais (B02-InVitro)  206    36                 \n",
       "23              Análise de resultados (B02-InVitro)  207    48                 \n",
       "25        Experimentos complementares (B02-InVitro)  208    48                 \n",
       "0                                                 -  300     0                 \n",
       "1                                                 -  301     0                 \n",
       "2                       Revisão bibliográfica (Doc)  302     0                 \n",
       "7                    Matrícula em disciplinas (Doc)  303    12                 \n",
       "8                 Cursar disciplinas teóricas (Doc)  304    12                 \n",
       "12                Cursar disciplinas teóricas (Doc)  305    24                 \n",
       "13              Concluir disciplinas teóricas (Doc)  306    24                 \n",
       "17             Apresentar projeto de pesquisa (Doc)  307    36                 \n",
       "18           Analisar resultados preliminares (Doc)  308    36                 \n",
       "21            Analisar resultados preliminares(Doc)  309    48                 \n",
       "24               Redigir artigo científico 01 (Doc)  310    48                 \n",
       "26                Redigir artigo científico 01(Doc)  311    48                 \n",
       "\n",
       "    inicio  fim  \n",
       "3    0       8   \n",
       "4    0       8   \n",
       "9   20      28   \n",
       "14  40      48   \n",
       "19  60      68   \n",
       "22  80      88   \n",
       "5    0       8   \n",
       "6    0       8   \n",
       "10  20      28   \n",
       "11  20      28   \n",
       "15  40      48   \n",
       "16  72      84   \n",
       "20  60      68   \n",
       "23  80      88   \n",
       "25  80      88   \n",
       "0    0       1   \n",
       "1    0       8   \n",
       "2    0       8   \n",
       "7   20      28   \n",
       "8   20      28   \n",
       "12  40      48   \n",
       "13  40      48   \n",
       "17  60      68   \n",
       "18  60      68   \n",
       "21  80      88   \n",
       "24  80      88   \n",
       "26  80      88   "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1cd2e7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a4ea7415ca5d40349c9fd29d32e7d07e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a4ea7415ca5d40349c9fd29d32e7d07e.vega-embed details,\n",
       "  #altair-viz-a4ea7415ca5d40349c9fd29d32e7d07e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a4ea7415ca5d40349c9fd29d32e7d07e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a4ea7415ca5d40349c9fd29d32e7d07e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a4ea7415ca5d40349c9fd29d32e7d07e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"scale\": {\"bandPaddingInner\": 0.5}}, \"layer\": [{\"mark\": {\"type\": \"bar\", \"size\": 20}, \"encoding\": {\"color\": {\"field\": \"Respons\\u00e1vel\", \"legend\": {\"title\": \"Respons\\u00e1vel\"}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Atividade\", \"type\": \"nominal\"}, {\"field\": \"inicio\", \"type\": \"quantitative\"}, {\"field\": \"fim\", \"type\": \"quantitative\"}, {\"field\": \"Dura\\u00e7\\u00e3o (Semanas)\", \"type\": \"quantitative\"}, {\"field\": \"Respons\\u00e1vel\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"inicio\", \"title\": \"Semanas\", \"type\": \"temporal\"}, \"x2\": {\"field\": \"fim\"}, \"y\": {\"axis\": {\"labelAlign\": \"right\", \"labelAngle\": 0, \"labelFontSize\": 12, \"titlePadding\": 120}, \"field\": \"Atividade\", \"sort\": [\"Revis\\u00e3o bibliogr\\u00e1fica (B01-InSilico)\", \"Treinamento em softwares (B01-InSilico)\", \"Montar a base de dados (B01-InSilico)\", \"Desenvolver modelo computacional (B01-InSilico)\", \"Validar modelo computacional (B01-InSilico)\", \"Integrar modelos e dados experimentais (B01-InSilico)\", \"Revis\\u00e3o bibliogr\\u00e1fica (B02-InVitro)\", \"Prepara\\u00e7\\u00e3o cultura celular (B02-InVitro)\", \"Padronizar t\\u00e9cnicas de cultura(B02-InVitro)\", \"Experimentos preliminares (B02-InVitro)\", \"Otimizar condi\\u00e7\\u00f5es de cultura (B02-InVitro)\", \"Experimentos principais (B02-InVitro)\", \"An\\u00e1lise de resultados (B02-InVitro)\", \"Experimentos complementares (B02-InVitro)\", \"An\\u00e1lise estat\\u00edstica dos resultados (B02-InVitro)\", \"Matr\\u00edcula em disciplinas (Doc)\", \"Revis\\u00e3o bibliogr\\u00e1fica (Doc)\", \"Elaborar projeto de pesquisa (Doc)\", \"Cursar disciplinas te\\u00f3ricas (Doc)\", \"Aprofundar revis\\u00e3o bibliogr\\u00e1fica (Doc)\", \"Concluir disciplinas te\\u00f3ricas (Doc)\", \"Apresentar projeto de pesquisa (Doc)\", \"Analisar resultados preliminares(Doc)\", \"Refinar projeto de pesquisa (Doc)\", \"Redigir artigo cient\\u00edfico 01 (Doc)\", \"Apresenta\\u00e7\\u00e3o em congressos (Doc)\", \"Submiss\\u00e3o do primeiro artigo cient\\u00edfico (Doc)\"], \"type\": \"nominal\"}}, \"name\": \"view_75\"}, {\"mark\": {\"type\": \"rule\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Respons\\u00e1vel\", \"legend\": {\"title\": \"Respons\\u00e1vel\"}, \"type\": \"nominal\"}, \"detail\": {\"field\": \"Predecessora\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Atividade\", \"type\": \"nominal\"}, {\"field\": \"inicio\", \"type\": \"quantitative\"}, {\"field\": \"fim\", \"type\": \"quantitative\"}, {\"field\": \"Dura\\u00e7\\u00e3o (Semanas)\", \"type\": \"quantitative\"}, {\"field\": \"Respons\\u00e1vel\", \"type\": \"nominal\"}], \"x\": {\"field\": \"fim_predecessora\", \"type\": \"temporal\"}, \"x2\": {\"field\": \"inicio\"}, \"y\": {\"field\": \"Atividade\", \"type\": \"nominal\"}, \"y2\": {\"field\": \"Atividade\"}}, \"transform\": [{\"filter\": \"(datum.Predecessora !== '-')\"}, {\"lookup\": \"Predecessora\", \"as\": \"fim_predecessora\", \"from\": {\"data\": {\"name\": \"data-4e397e691557f6b578b30a337d041307\"}, \"key\": \"Atividade\", \"fields\": [\"fim\"]}}]}], \"data\": {\"name\": \"data-4e397e691557f6b578b30a337d041307\"}, \"height\": 600, \"params\": [{\"name\": \"param_48\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\", \"views\": [\"view_75\"]}], \"resolve\": {\"scale\": {\"x\": \"shared\"}}, \"title\": \"Diagrama de Gantt para o Projeto de Doutorado em Terapias Personalizadas para Artrite Reumat\\u00f3ide\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-4e397e691557f6b578b30a337d041307\": [{\"Atividade\": \"Revis\\u00e3o bibliogr\\u00e1fica (B01-InSilico)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 1, \"Respons\\u00e1vel\": \"Bolsista In Silico\", \"Predecessora\": \"-\", \"Ordem\": 100, \"inicio_trimestre\": 0, \"inicio\": 0, \"fim\": 8}, {\"Atividade\": \"Treinamento em softwares (B01-InSilico)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 1, \"Respons\\u00e1vel\": \"Bolsista In Silico\", \"Predecessora\": \"Revis\\u00e3o bibliogr\\u00e1fica (B01-InSilico)\", \"Ordem\": 101, \"inicio_trimestre\": 0, \"inicio\": 0, \"fim\": 8}, {\"Atividade\": \"Montar a base de dados (B01-InSilico)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 2, \"Respons\\u00e1vel\": \"Bolsista In Silico\", \"Predecessora\": \"Treinamento em softwares (B01-InSilico)\", \"Ordem\": 102, \"inicio_trimestre\": 12, \"inicio\": 20, \"fim\": 28}, {\"Atividade\": \"Desenvolver modelo computacional (B01-InSilico)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 3, \"Respons\\u00e1vel\": \"Bolsista In Silico\", \"Predecessora\": \"Montar a base de dados (B01-InSilico)\", \"Ordem\": 103, \"inicio_trimestre\": 24, \"inicio\": 40, \"fim\": 48}, {\"Atividade\": \"Validar modelo computacional (B01-InSilico)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 4, \"Respons\\u00e1vel\": \"Bolsista In Silico\", \"Predecessora\": \"Desenvolver modelo computacional (B01-InSilico)\", \"Ordem\": 104, \"inicio_trimestre\": 36, \"inicio\": 60, \"fim\": 68}, {\"Atividade\": \"Integrar modelos e dados experimentais (B01-InSilico)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 5, \"Respons\\u00e1vel\": \"Bolsista In Silico\", \"Predecessora\": \"Validar modelo computacional (B01-InSilico)\", \"Ordem\": 105, \"inicio_trimestre\": 48, \"inicio\": 80, \"fim\": 88}, {\"Atividade\": \"Revis\\u00e3o bibliogr\\u00e1fica (B02-InVitro)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 1, \"Respons\\u00e1vel\": \"Bolsista In Vitro\", \"Predecessora\": \"-\", \"Ordem\": 200, \"inicio_trimestre\": 0, \"inicio\": 0, \"fim\": 8}, {\"Atividade\": \"Prepara\\u00e7\\u00e3o cultura celular (B02-InVitro)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 1, \"Respons\\u00e1vel\": \"Bolsista In Vitro\", \"Predecessora\": \"Revis\\u00e3o bibliogr\\u00e1fica (B02-InVitro)\", \"Ordem\": 201, \"inicio_trimestre\": 0, \"inicio\": 0, \"fim\": 8}, {\"Atividade\": \"Padronizar t\\u00e9cnicas de cultura(B02-InVitro)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 2, \"Respons\\u00e1vel\": \"Bolsista In Vitro\", \"Predecessora\": \"Prepara\\u00e7\\u00e3o cultura celular (B02-InVitro)\", \"Ordem\": 202, \"inicio_trimestre\": 12, \"inicio\": 20, \"fim\": 28}, {\"Atividade\": \"Experimentos preliminares (B02-InVitro)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 2, \"Respons\\u00e1vel\": \"Bolsista In Vitro\", \"Predecessora\": \"Padronizar t\\u00e9cnicas de cultura (B02-InVitro)\", \"Ordem\": 203, \"inicio_trimestre\": 12, \"inicio\": 20, \"fim\": 28}, {\"Atividade\": \"Otimizar condi\\u00e7\\u00f5es de cultura (B02-InVitro)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 3, \"Respons\\u00e1vel\": \"Bolsista In Vitro\", \"Predecessora\": \"Experimentos preliminares (B02-InVitro)\", \"Ordem\": 204, \"inicio_trimestre\": 24, \"inicio\": 40, \"fim\": 48}, {\"Atividade\": \"Experimentos principais (B02-InVitro)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 12, \"Trimestre\": 4, \"Respons\\u00e1vel\": \"Bolsista In Vitro\", \"Predecessora\": \"Otimizar condi\\u00e7\\u00f5es de cultura (B02-InVitro)\", \"Ordem\": 205, \"inicio_trimestre\": 36, \"inicio\": 72, \"fim\": 84}, {\"Atividade\": \"An\\u00e1lise de resultados (B02-InVitro)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 4, \"Respons\\u00e1vel\": \"Bolsista In Vitro\", \"Predecessora\": \"Experimentos principais (B02-InVitro)\", \"Ordem\": 206, \"inicio_trimestre\": 36, \"inicio\": 60, \"fim\": 68}, {\"Atividade\": \"Experimentos complementares (B02-InVitro)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 5, \"Respons\\u00e1vel\": \"Bolsista In Vitro\", \"Predecessora\": \"An\\u00e1lise de resultados (B02-InVitro)\", \"Ordem\": 207, \"inicio_trimestre\": 48, \"inicio\": 80, \"fim\": 88}, {\"Atividade\": \"An\\u00e1lise estat\\u00edstica dos resultados (B02-InVitro)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 5, \"Respons\\u00e1vel\": \"Bolsista In Vitro\", \"Predecessora\": \"Experimentos complementares (B02-InVitro)\", \"Ordem\": 208, \"inicio_trimestre\": 48, \"inicio\": 80, \"fim\": 88}, {\"Atividade\": \"Matr\\u00edcula em disciplinas (Doc)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 1, \"Trimestre\": 1, \"Respons\\u00e1vel\": \"Doutorando(a)\", \"Predecessora\": \"-\", \"Ordem\": 300, \"inicio_trimestre\": 0, \"inicio\": 0, \"fim\": 1}, {\"Atividade\": \"Revis\\u00e3o bibliogr\\u00e1fica (Doc)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 1, \"Respons\\u00e1vel\": \"Doutorando(a)\", \"Predecessora\": \"-\", \"Ordem\": 301, \"inicio_trimestre\": 0, \"inicio\": 0, \"fim\": 8}, {\"Atividade\": \"Elaborar projeto de pesquisa (Doc)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 1, \"Respons\\u00e1vel\": \"Doutorando(a)\", \"Predecessora\": \"Revis\\u00e3o bibliogr\\u00e1fica (Doc)\", \"Ordem\": 302, \"inicio_trimestre\": 0, \"inicio\": 0, \"fim\": 8}, {\"Atividade\": \"Cursar disciplinas te\\u00f3ricas (Doc)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 2, \"Respons\\u00e1vel\": \"Doutorando(a)\", \"Predecessora\": \"Matr\\u00edcula em disciplinas (Doc)\", \"Ordem\": 303, \"inicio_trimestre\": 12, \"inicio\": 20, \"fim\": 28}, {\"Atividade\": \"Aprofundar revis\\u00e3o bibliogr\\u00e1fica (Doc)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 2, \"Respons\\u00e1vel\": \"Doutorando(a)\", \"Predecessora\": \"Cursar disciplinas te\\u00f3ricas (Doc)\", \"Ordem\": 304, \"inicio_trimestre\": 12, \"inicio\": 20, \"fim\": 28}, {\"Atividade\": \"Concluir disciplinas te\\u00f3ricas (Doc)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 3, \"Respons\\u00e1vel\": \"Doutorando(a)\", \"Predecessora\": \"Cursar disciplinas te\\u00f3ricas (Doc)\", \"Ordem\": 305, \"inicio_trimestre\": 24, \"inicio\": 40, \"fim\": 48}, {\"Atividade\": \"Apresentar projeto de pesquisa (Doc)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 3, \"Respons\\u00e1vel\": \"Doutorando(a)\", \"Predecessora\": \"Concluir disciplinas te\\u00f3ricas (Doc)\", \"Ordem\": 306, \"inicio_trimestre\": 24, \"inicio\": 40, \"fim\": 48}, {\"Atividade\": \"Analisar resultados preliminares(Doc)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 4, \"Respons\\u00e1vel\": \"Doutorando(a)\", \"Predecessora\": \"Apresentar projeto de pesquisa (Doc)\", \"Ordem\": 307, \"inicio_trimestre\": 36, \"inicio\": 60, \"fim\": 68}, {\"Atividade\": \"Refinar projeto de pesquisa (Doc)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 4, \"Respons\\u00e1vel\": \"Doutorando(a)\", \"Predecessora\": \"Analisar resultados preliminares (Doc)\", \"Ordem\": 308, \"inicio_trimestre\": 36, \"inicio\": 60, \"fim\": 68}, {\"Atividade\": \"Redigir artigo cient\\u00edfico 01 (Doc)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 5, \"Respons\\u00e1vel\": \"Doutorando(a)\", \"Predecessora\": \"Analisar resultados preliminares(Doc)\", \"Ordem\": 309, \"inicio_trimestre\": 48, \"inicio\": 80, \"fim\": 88}, {\"Atividade\": \"Apresenta\\u00e7\\u00e3o em congressos (Doc)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 5, \"Respons\\u00e1vel\": \"Doutorando(a)\", \"Predecessora\": \"Redigir artigo cient\\u00edfico 01 (Doc)\", \"Ordem\": 310, \"inicio_trimestre\": 48, \"inicio\": 80, \"fim\": 88}, {\"Atividade\": \"Submiss\\u00e3o do primeiro artigo cient\\u00edfico (Doc)\", \"Dura\\u00e7\\u00e3o (Semanas)\": 8, \"Trimestre\": 5, \"Respons\\u00e1vel\": \"Doutorando(a)\", \"Predecessora\": \"Redigir artigo cient\\u00edfico 01(Doc)\", \"Ordem\": 311, \"inicio_trimestre\": 48, \"inicio\": 80, \"fim\": 88}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "79651f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao criar o link simbólico: [WinError 183] Não é possível criar um arquivo já existente: 'arquivo_original.txt' -> 'link_simbolico.txt'\n"
     ]
    }
   ],
   "source": [
    "## Teste de criação de link simbólico\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.symlink(\"arquivo_original.txt\", \"link_simbolico.txt\")\n",
    "    print(\"Link simbólico criado com sucesso!\")\n",
    "except OSError as e:\n",
    "    print(f\"Erro ao criar o link simbólico: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e9c6c0",
   "metadata": {},
   "source": [
    "### Extrair quantidade de orientações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ee9bd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identificação\n",
      "Idiomas\n",
      "Formação\n",
      "Atuação Profissional\n",
      "Linhas de Pesquisa\n",
      "Áreas\n",
      "Produções\n",
      "ProjetosPesquisa\n",
      "ProjetosExtensão\n",
      "ProjetosDesenvolvimento\n",
      "ProjetosOutros\n",
      "Bancas\n",
      "Orientações\n",
      "JCR2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dict_list_docents[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m----> 3\u001b[0m dict_list_docents[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAtuação Profissional\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstituição\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "for i in dict_list_docents[1].keys():\n",
    "    print(i)\n",
    "dict_list_docents[1].get('Atuação Profissional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdcb4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.get('Orientações') for x in dict_list_docents if x.get('Orientações')][1]['Orientações e supervisões em andamento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33443973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tese de doutorado': {'1.': 'TIAGO SILVA HOLANDA FERREIRA. EFETIVIDADE E SEGURANÇA DO ÁCIDO TRANEXÂMICO NO CONTROLE DA PERDA VOLÊMICA PERIOPERATÓRIA EM CIRURGIAS ENDOSCÓPICAS DE ADENOMAS DE HIPÓFISE. Início: 2024. Tese (Doutorado em MEDICINA TRANSLACIONAL)  - Universidade Federal do Ceará. (Orientador).', '2.': 'SAULO ARAÚJO TEIXEIRA. USO DE PREGABALINA NO PÓS-OPERATÓRIO IMEDIATO COMO PREVENÇÃO DE DOR E PARESTESIA ASSOCIADAS A CRANIOTOMIAS. Início: 2022. Tese (Doutorado em MEDICINA TRANSLACIONAL)  - Universidade Federal do Ceará. (Orientador).', '3.': 'IANNY DE ASSIS DANTAS. USO DA IVERMECTINA COMO TRATAMENTO PROFILÁTICO PARA A COVID-19: ESTUDO DE COORTE PROSPECTIVO NO MUNICÍPIO DE JAGUARIBARA ? CE. Início: 2021. Tese (Doutorado em MEDICINA TRANSLACIONAL)  - Universidade Federal do Ceará. (Orientador).', '4.': 'ALANA FERREIRA GOMES DIAS. AVALIAÇÃO DA VASCULARIZAÇÃO RETINIANA POR MEIO DA ANGIOGRAFIA POR TOMOGRAFIA DE COERÊNCIA ÓPTICA EM USUÁRIAS DE CONTRACEPTIVOS HORMONAIS ORAIS. Início: 2020. Tese (Doutorado em PROGRAMA DE PÓS-GRADUAÇÃO EM MEDICINA TRANSLACIONAL (22001018178P6))  - Universidade Federal do Ceará. (Orientador).', '5.': 'LAÍS LACERDA BRASIL DE OLIVEIRA. ANÁLISE COMPARATIVA DE ASPARAGINASES POR ESPECTROMETRIA DE MASSAS DE ALTA RESOLUÇÃO: IMPLANTAÇÃO DE UM BANCO DE DADOS PARA PROTEÔMICA TOP- DOWN. Início: 2020. Tese (Doutorado em PROGRAMA DE PÓS-GRADUAÇÃO EM MEDICINA TRANSLACIONAL (22001018178P6))  - Universidade Federal do Ceará. (Orientador).', '6.': 'SABRINA MAGALHÃES PEDROSA ROCHA PINHEIRO. PADRONIZAÇÃO E IMPLEMENTAÇÃO DO SEQUENCIAMENTO DE SANGER NA NEOPLASIA ENDÓCRINA MÚLTIPLA TIPO 1 NO ESTADO DO CEARÁ. Início: 2020. Tese (Doutorado em PROGRAMA DE PÓS-GRADUAÇÃO EM MEDICINA TRANSLACIONAL (22001018178P6))  - Universidade Federal do Ceará. (Orientador).', '7.': 'VICTOR HUGO MEDEIROS ALENCAR. EFEITO DO CANADIBIOL NA NEUROPATIA PERIFÉRICA INDUZIDA POR PACLITAXEL, PÓS QUIMIOTERAPIA PARA CÂNCER DE MAMA. Início: 2020. Tese (Doutorado em PROGRAMA DE PÓS-GRADUAÇÃO EM MEDICINA TRANSLACIONAL (22001018178P6))  - Universidade Federal do Ceará. (Orientador).'}}\n",
      "{'Iniciação científica': {'1.': 'JHONATAN LUCAS BARBOSA SILVA. Avaliação de parâmetros da composição corporal e da densidade mineral óssea em pacientes portadoras de Síndrome de Turner. Início: 2023 - Universidade Federal do Ceará, CONSELHO  Nacional de Desenvolviemnto Científico e Tecnológico. (Orientador).', '2.': 'BEATRIZ ALVES HOLANDA. Avaliação de parâmetros da composição corporal e da densidade mineral óssea em pacientes portadoras de Síndrome de Turner. Início: 2023 - Universidade Federal do Ceará, CONSELHO  Nacional de Desenvolviemnto Científico e Tecnológico. (Orientador).'}}\n",
      "{'Dissertação de mestrado': {'1.': 'HIPÓLITO SOUZA MONTE. APENDICITE E LAPAROSCOPIA COM CLIPAGEM DO CÔTO APENDICULAR E ANÁLISE INTERVENCIONISTA. 2019.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA (PROFISSIONAL))  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '2.': 'GERMANA GRAICY DE VASCONCELOS. ESTUDOS DOS MECANISMOS DE AÇÃO DE 2 DERIVADOS SEMISSINTÉTICOS (MC-D7, MC-D9 E MC-H) OBTIDOS DA Moringa Oleifera EM ENSAIO PRÉ-CLINICOS DE DOR NA ATM DE RATOS. 2019.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM CIRURGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '3.': 'CARLA ANTONIANA FERREIRA DE ALMEIDA VIEIRA. AVALIAÇÃO DE PARÂMETROS DA COMPOSIÇÃO CORPORAL E DA DENSIDADE MINERAL ÓSSEA EM PACIENTES COM SÍNDROME DE TURNER. 2019.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '4.': 'DIANA CARLA PEREIRA DA SILVA. AVALIAÇÃO DO USO DA PELE DA TILÁPIA (ORECHROMIS NILOTICUS)  LIOFILIZADA COMO CURATIVO EM QUEIMADURAS DE SEGUNDO GRAU  SUPERFICIAL E PROFUNDA: ESTUDO CLÍNICO. 2019.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, . Coorientador: Maria Elisabete Amaral de Moraes.', '5.': 'AMAURILIO OLIVEIRA NOGUEIRA. PERFIL CLÍNICO EPIDEMIOLÓGICO E AVALIAÇÃO SÉRICA DE ESTRESSE OXIDATIVO EM PACIENTES COM TRANSTORNO DE ESPECTRO AUTISTA SOB O TRATAMENTO DE METILFENIDATO. 2019.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, . Coorientador: Maria Elisabete Amaral de Moraes.', '6.': 'POLIANA NORONHA BARROSO. DESENVOLVIMENTO DE UM MODELO EXPERIMENTAL DE TRANSTORNO BIPOLAR BIFÁSICO EM RATOS. 2019.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, . Coorientador: Maria Elisabete Amaral de Moraes.', '7.': 'Francisco Vagnaldo Fechine Jamacaru. Desenvolvimento e Validação de Um Método Para Análise Morfométrica e Fractal da Rede  Vascular Peritumoral em Modelos Experimentais de Câncer. 2018.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA (PROFISSIONAL))  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '8.': 'Mariane Cinthya Nogueira Lima. Avaliação dos Parâmetros Farmacocinéticos do Ciprofloxacino em Pacientes Submetidos à Cirurgia Bariátrica. 2018.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, Fundação Cearense de Apoio ao Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '9.': 'Maria José Martins Sudário Alencar. Abordagem Odontológica de Pacientes Oncológicos Antes, Durante e Após o Tratamento de  Quimioterapia e Radioterapia. 2018.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA (PROFISSIONAL))  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '10.': 'Eduardo Henrique Cronemberger Costa e Silva. Tendências de Incidência e Mortalidade Por Câncer de Mama em Fortaleza. 2018.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA (PROFISSIONAL))  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '11.': 'Ana Paula Dajtenko Lemos. Avaliação da Biodisponibilidade Relativa/Bioequivalência entre Duas Formulações De Lansoprazol 30mg em Voluntários Sadios de Ambos os Sexos.. 2018.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '12.': 'Valden Luis Matos Capistrano Junior. Avaliação da Relação Entre Composição Corporal e Biodisponibilidade de Uma Formulação de Diclofenaco Sódico. 2017.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '13.': 'ALEXANDRE DE AQUINO CÂMARA. ESTUDO PRELIMINAR DE SEGURANÇA E EFICÁCIA DO USO DO LABCAT TCJUS NO TRATAMENTO DO TRANSTORNO DEPRESSIVO MAIOR. 2017.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA (PROFISSIONAL))  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '14.': 'ISMAEL FERNANDO NOGUEIRA LOPES. APLICAÇÃO DE INSTRUMENTO DE INSPEÇÃO DA VIGILÂNCIA SANITÁRIA EM CLÍNICAS ONCOLÓGICAS PRIVADAS DA CIDADE DE FORTALEZA. 2017.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA (PROFISSIONAL))  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '15.': 'MARIO VILANY GOMES BONFIM OLIVEIRA. AVALIAÇÃO DE TRATAMENTO ADJUVANTE COM RADIOTERAPIA ASSOCIADO A QUIMIOTERAPIA DE RADIOSSENSIBILIZAÇÃO COM 5FU E LEUCOVORIN EM PACIENTES COM CÂNCER GÁSTRICO NO INSTITUTO DO CÂNCER DO CEARÁ NO PERÍODO DE 2002 A 2017: UM ESTUDO RESTROSPECTIVO. 2017.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA (PROFISSIONAL))  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '16.': 'DIANA SILVEIRA DE ARAÚJO. VIAS ALTERNATIVAS DE REGISTRO DE MEDICAMENTOS: ANÁLISE DE DADOS DA ANVISA. 2017.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '17.': 'ANA EUGÊNIA MAGALHÃES SANTIAGO. AVALIAÇÃO DA EFICÁCIA DO TRATAMENTO FISIOTERÁPICO EM PACIENTES PÓS MASTECTOMIA. 2017.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM CIRURGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '18.': 'Maria de Fátima Lemos do Monte.. Perfil Clínico e Epidemiológico de Pacientes Hemofílicos Atendidos no Centro de HEMATOLOGIA e HEMOTERAPIA do Piauí - HEMOPI.. 2016.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '19.': 'Maria do Carmo Melo Mascarenhas.. Análise das Práticas de Higienização das Mãos Executadas por Profissionais de Saúde em Hospitais Públicos do Estado do Piauí.. 2016.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '20.': 'Thiago José Vieira Chaves.. Avaliação da Funcionalidade Pulmonar de Trabalhodes Expostos a Produtos Químicos em Oficinas Automotivas.. 2016.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '21.': 'Veronésia Maria de Sena Rosal.. Efeitos Comportamentais do uso Prolongado de Levodopa em Pacientes com Doença de Parkinson.. 2016.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '22.': 'Yara Vanessa Trindade Xavier.. Caracterização Clínica e Epidemiológica de Pacientes Portadores de Hepatite C em um Serviço de Referência de Teresina ? PI.. 2016.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '23.': 'Kayline de Souza Pereira. Avaliação das Alterações Dermatológicas e Estudo Imunohistoquimico da Proteína MENIN Em Pacientes Portadores de Neoplasia Endócrina Múltipla Tipo 1. 2016.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '24.': 'MARCIA CRISTINA COLARES REGIS DE ARAUJO. EXPRESSÃO DA SUBUNIDADE NR2B DO RECEPTOR N-METIL-D-ASPARTATO (NMDA) E DA INDOLAMINA-2-3-DIOXIGENASE (IDO) NO CÂNCER DE MAMA DUCTAL. 2016.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '25.': 'Thyago Araujo Fernandes. Delineamento Crítico Da Vigente Prática Clínica Adotada Por Especialistas No Brasil. 2016.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM CIRURGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '26.': 'Edilson Martins Rodrigues Neto. Estudo de biodisponibilidade comparativa entre duas formulações de Cloridrato de Metformina, comprimidos revestidos de 850mg, administrados em voluntários sadios. 2015.  Dissertação  (Mestrado em Odontologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '27.': 'Patrícia Francisco Branco.. Boas práticas de fabricação de insumos de origem vegetal: evolução das normas que norteiam a produção e o panorama do Parque Fabril brasileiro.. 2015.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '28.': 'Cristiane Maria Cavalcante Silveira. Avaliação da qualidade de vida de pacientes submetidos à derivação gástrica em y de roux há mais de cinco anos. 2014.  Dissertação  (Mestrado em Curso de Pós Graduação Em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '29.': 'Elna Joelane Lopes da Silva do Amaral. Estudo dos possíveis efeitos mutagênicos do HIV e de dois esquemas antirretrovirais contendo Zidovudina ou Tenofovir. 2014.  Dissertação  (Mestrado em Curso de Pós Graduação Em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '30.': 'Ronaldo Costa. Avaliação dos Possíveis Efeitos Citogenéticos, Hematológicos e Bioquímicos de Profissionais Ocupacionalmente Expostos a Quimioterápicos em Teresina, Piauí. 2014.  Dissertação  (Mestrado em Curso de Pós Graduação Em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '31.': 'Tacyana Pires de Carvalho Costa. Biomonitoramento Citogenético, Hematológico e Bioquímico em Agentes de Endemias Expostos a Agrotóxicos no Município de Valença ? Piauí. 2014.  Dissertação  (Mestrado em Curso de Pós Graduação Em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '32.': 'Marcela de Lacerda Valença Queiroz. Estudo comparativo entre testes de sorologia e teste de ácido nucleico (nat) para triagem de HIV e HCV em doadores de sangue do Centro de Hematologia e Hemoterapia do estado do Piaui - Hemopi. 2014.  Dissertação  (Mestrado em MESTRADO PROFISSIONAL FARMACOLOGIA CLÍNICA)  - Universidade Federal do Ceará - Programa de Pós-Graduação em Farmacologia, . Orientador: Maria Elisabete Amaral de Moraes.', '33.': 'Maria Veloso Soares. Avaliação do impacto do uso de agrotóxicos na saúde de trabalhadores rurais dos municípios de Picos e Piripiri- PI. 2014.  Dissertação  (Mestrado em MESTRADO PROFISSIONAL FARMACOLOGIA CLÍNICA)  - Universidade Federal do Ceará - Programa de Pós-Graduação em Farmacologia, . Orientador: Maria Elisabete Amaral de Moraes.', '34.': 'Antônio Carlos de Carvalho. Efeito do tratamento com antirretrovirais em pacientes portadores de HIV nos parâmetros hematológicos e bioquímicos.. 2014.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '35.': 'Marinus de Moraes Lima. Importância Clínica de um estudo de Bioequivalência ntre duas formulações de diclofenaco Sódico de Liberação prolongada.. 2013.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '36.': 'Vânia Maria de Oliveira Dias. Infecção relacionada à assistência à saúde precoce em unidade neonatal de alto risco. 2013.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '37.': 'Ticiana Pessoa Tabosa e Silva. Avaliação in vitro do efeito de agentes clareadores na microdureza e rugosidade do esmalte.. 2013.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '38.': 'Nelson Fernandes Leal. Benefícios da aspiração manual intrauterina associada ao uso do Misoprostol, via vaginal, nos casos de abortamento retido. 2013.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '39.': 'Marina Becker Sales Rocha. Influência da Alimentação na Biodisponibilidade da Venlafaxina Administrada em Cápsulas de Liberação Prolongada.. 2012.  Dissertação  (Mestrado em Farmacologia)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '40.': 'Ana Lourdes de Almeida e Silva Leite. Perfil Farmacocinético de Uma Formulação de Talidomida em Voluntários Sadios. 2012.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '41.': 'José Henrique Linhares.. valiação da eficacia terapêutica do xarope de chambá.( Justicia Pectoralis) em asma. 2012.  Dissertação  (Mestrado em Curso de Pós Graduação Em Cirurgia)  - Universidade Federal do Ceará, . Coorientador: Maria Elisabete Amaral de Moraes.', '42.': 'Cleber Soares Pimenta Costa. Determinação do Perfil Farmacocinético do Cetorolaco de Trometamina Comprimido de 30mg Administrado por Via Sublingual em Voluntários Saudáveis. 2011.  Dissertação  (Mestrado em Farmacologia)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '43.': 'Symonara Karina Medeiros Faustino. Prevalência dos Subtipos do Vírus da Imunodeficiência Humana do Tipo 1 (HIV-1) no Estado do Piauí ? Brasil e o Perfil de Resistência das Cepas Identificadas. 2011.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, Secretaria Estadual da Saúde do Piauí. Coorientador: Maria Elisabete Amaral de Moraes.', '44.': 'Ana Luisa Eulálio Dantas Aragão. Prevalência e Fatores de Risco Associados à Coinfecção do Vírus da Hepatite Tipo B (HBV) em Pacientes HIV Positivos no Estado do Piauí. 2011.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, Secretaria Estadual da Saúde do Piauí. Coorientador: Maria Elisabete Amaral de Moraes.', '45.': 'Jonaina Costa de Oliveira. Abordagem Farmacológica e Terapêutica da Lepidium meyenii WALP. (Maca). 2011.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '46.': 'Vera Regina Cavalcante Barros Rodrigues. Avaliação das Alterações Hematológicas, Bioquímicas e Genotóxicas nos Trabalhadores Expostos a Agrotóxicos em Municípios do Estado do Piauí. 2011.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, Secretaria Estadual da Saúde do Piauí. Orientador: Maria Elisabete Amaral de Moraes.', '47.': 'Maria do Amparo da Silva Bida Mesquit. Avaliação Mutagênica em Epitélio Esfoliado de Mucosa Bucal de Dentistas Expostos Ocupacionalmente a Radiação Ionizante. 2011.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, Secretaria Estadual da Saúde do Piauí. Orientador: Maria Elisabete Amaral de Moraes.', '48.': 'Antonio Carlos de Carvalho. Efeito do Tratamento com Antirretrovirais Em Pacientes Portadores de HIV nos Parâmetros Hematológicos e Bioquímicos. 2010.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Secretaria Estadual da Saúde do Piauí. Orientador: Maria Elisabete Amaral de Moraes.', '49.': 'Oswaldo Jose Queiroz Dias. Avaliação da Eficácia do Fitoterápico à Base de Cymbopogon citratus Stapf em Candidiase Vaginal: Estudo Controlado, Duplo-Cego e Randomizado. 2010.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, . Coorientador: Maria Elisabete Amaral de Moraes.', '50.': 'Ticiana Pessoa Tabosa e Silva. Avaliação In Vitro do Efeito de Fármacos Clareadores na Microdureza e Rugosidade das Superfícies Dentais. 2010.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '51.': 'João José Ferreira Evangelista. Ação Farmacológica das Vitaminas A & E na Produção de Oócitos e Embriões Bovinos. 2010.  Dissertação  (Mestrado em RENORBIO)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '52.': 'Renata Amaral de Moraes. Avaliação Farmacocinética de Duas Formulações de Nnorfloxacino em Voluntários Sadios de Ambos os Sexos. 2010.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Coorientador: Maria Elisabete Amaral de Moraes.', '53.': 'Deysi Viviana Tenazoa Wong. Avaliação da Equivalência Farmacêutica da Carbamazepina e Diazepam Comercializados no Programa de Farmacia Popular do Brasil. 2009.  Dissertação  (Mestrado em Farmacologia)  - Universidade Federal do Ceará, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Orientador: Maria Elisabete Amaral de Moraes.', '54.': 'Luciana Kelly Ximenes dos Santos. Estudo de Toxicologia Clínica da Tintura de jalapa na Costipação Intestinal.. 2009.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '55.': 'Ana Paula Macedo Santana. Avaliação da Segurança e Genotoxicidade do Chá de Alpinia zerumbet em Voluntários Sadios. 2009.  Dissertação  (Mestrado em Farmacologia)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '56.': 'Daniela Lima Chow Castillo. Análise Comparativa do Perfil de Segurança e Eficácia Analgésica da S(+) Cetamina com ou sem Morfina na Anestesia Peridural para Histerectomia Abdominal. 2009.  Dissertação  (Mestrado em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '57.': 'Gilmara Holanda da Cunha. Avaliação das Eficácia Terapêutica da Tintura de Jalapa no Tratamento da Constipação Intestinal Funcional. 2009.  Dissertação  (Mestrado em Farmacologia)  - Universidade Federal do Ceará, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Orientador: Maria Elisabete Amaral de Moraes.', '58.': 'Ana Hermínia Portela Bandeira de Melo Falcão. Avaliação da Farmacovigilância de Pacientes com Câncer de Mama sob Quimioterapia Antineoplásica. 2009.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '59.': 'Jose Aurillo Rocha. Avaliação do Tratamento Adjuvante com Tamoxifeno em Pacientes com Câncer de Mama no Hospital do Câncer do Ceará: Abril/1999 a Abril/2004. 2009.  Dissertação  (Mestrado em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '60.': 'José Tarcisio Feitosa Vieira da Silva Júnior. Estudo farmacocinético comparativo do xarope Notuss versus Difenidramina, Dropropizina e Pseudoefedrina. 2008.  Dissertação  (Mestrado em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '61.': 'Thaise Cavalcante Vieira Da Silva. Estudo de biodisponibilidade das cápsulas de Digeplus contendo cloridrato de metoclopramida (7mg), dimeticona (40 mg) e pepsina (50 mg) versus cápsulas de cloridrato de metoclopramida (7mg). 2008.  Dissertação  (Mestrado em Farmacologia)  - Universidade Federal do Ceará, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Orientador: Maria Elisabete Amaral de Moraes.', '62.': 'Naracélia Sousa Barbosa Teles. Avaliação da Eficácia Terapêutica da Mentha crispa no Tratamento da Giardíase. 2008.  Dissertação  (Mestrado em Farmacologia)  - Universidade Federal do Ceará, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Orientador: Maria Elisabete Amaral de Moraes.', '63.': 'Hebert Lima Batista. Atividade Antimicrobiana de Extratos Vegetais de Plantas do Estado do Tocantins.. 2008.  Dissertação  (Mestrado em MESTRADO PROFISSIONAL FARMACOLOGIA CLÍNICA)  - Universidade Federal do Ceará - Programa de Pós-Graduação em Farmacologia, Fundação de Medicina Tropical do Tocantins. Orientador: Maria Elisabete Amaral de Moraes.', '64.': 'Silvana Maria Neves Solon. Análise dos Procedimentos de Estimativa da Idade Cronológica do Indivíduo pela Avaliação Dentária no Instituto Médico Legal de Fortaleza. 2008.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '65.': 'Marcela Saad. Políticas Regulatórias do Brasil, Canadá, EUA e Portugal (CEE). Estudo Comparativo dos Diferentes Níveis de Exigência para o Registro de Medicamentos Genéricos.. 2008.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, . Coorientador: Maria Elisabete Amaral de Moraes.', '66.': 'Fernando Andre Campos Viana. Estudo Comparativo, Randomizado para Avaliar a Eficácia Terapêutica da Piperazina Hexahidratada com Extrato Fluido de Rhamnus Purshiana no Tratamento da Ascaridíase. 2007.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '67.': 'Márcia Vieira Barreira Barroso. Eficácia e segurança dos inibidores da ciclooxigenase celecoxib e diclofenaco na periodontite induzida em ratos. 2007.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '68.': 'Tatiana Vieira Souza Chaves. Avaliação do Impacto do Uso de Agrotóxicos nos Trabalhadores Rurais dos Municípios de Ribeiro Gonçalves, Baixa Grande do Ribeiro e Uruçuí ? Piauí. 2007.  Dissertação  (Mestrado em MESTRADO PROFISSIONAL FARMACOLOGIA CLÍNICA)  - Universidade Federal do Ceará - Programa de Pós-Graduação em Farmacologia, Secretaria Estadual da Saúde do Piauí. Orientador: Maria Elisabete Amaral de Moraes.', '69.': 'Josineire Melo Costa Sallum. Estudo Comparativo da Eficácia do Diclofenaco e da Hidrocortisona no Tratamento do Eritema Induzido por Radiação Ultravioleta. 2007.  Dissertação  (Mestrado em MESTRADO PROFISSIONAL FARMACOLOGIA CLÍNICA)  - Universidade Federal do Ceará - Programa de Pós-Graduação em Farmacologia, . Orientador: Maria Elisabete Amaral de Moraes.', '70.': 'José Divino Bezerra Ferreira. Avaliação dos Parâmetros Cardiovasculares em Pacientes Submetidos à Sedação Consciente com Óxido Nitroso.. 2007.  Dissertação  (Mestrado em MESTRADO PROFISSIONAL FARMACOLOGIA CLÍNICA)  - Universidade Federal do Ceará - Programa de Pós-Graduação em Farmacologia, . Orientador: Maria Elisabete Amaral de Moraes.', '71.': 'Victor Hugo Medeiros Alencar. Avaliação do tratamento adjuvante com Tamoxifeno em mulheres com câncer de mama. 2006.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '72.': 'Antonio Botelho Barroso. Avaliação do uso do Rheumazin uma  associação do Piroxicam, Dexametasona, Cianocobalamina e Orfenadrina na exodontia do terceiro molar. 2006.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '73.': 'Marcelo Moraes Freire. Avaliação da eficácia do diclofenaco sódico no controle da dor, após a instalação de separadores elásticos ortodônticos. 2006.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '74.': 'Andrea Pinheiro de Moraes. Avaliação Terapêutica do Pimecrolimo Creme 1% no Tratamento da Dermatite Seborreica da Face em Pacientes HIV-Positivos. 2006.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '75.': 'Fabricio Pires de Moura Amaral. Avaliação do Sistema de Farmacovigilância do Instituto de Doenças Tropicais NATAN Portella em Teresina - Pi. 2006.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, Secretaria Estadual da Saúde do Piauí. Orientador: Maria Elisabete Amaral de Moraes.', '76.': 'Verginia Therezinha Barros Maciel Schiavo. Caminhos para o Desenvolvimento Estratégico na Pesquisa e Impulsionar o Progresso na Indústria Farmacêutica Brasileira. 2006.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '77.': 'Francisco Arnaldo Viana Lima. Implantação do Centro de Equivalência Farmacêutica da Unidade de Farmacologia Clínica - UFC. 2006.  Dissertação  (Mestrado em Farmacologia)  - Universidade Federal do Ceará, Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '78.': 'Daniel Riani Gotardelo. Avaliação do Custo e Equivalência Farmacêutica de Hidroclorotiazida em Formulações Industrializadas e Magistrais.. 2006.  Dissertação  (Mestrado em MESTRADO PROFISSIONAL FARMACOLOGIA CLÍNICA)  - Universidade Federal do Ceará - Programa de Pós-Graduação em Farmacologia, . Coorientador: Maria Elisabete Amaral de Moraes.', '79.': 'Janaina Pinho Tavares. Estudo de toxicologia clínica de três fitoterápicos à base de associações de plantas, mel e própolis em voluntários sadios. 2005.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '80.': 'Demetrius Fernandes do Nascimento. Determinação de Nimodipino em Plasma Humano Através de Cromatografia Líquida de Alta Eficiência Acoplada a Espectrometria de Massa (LC-MS-MS). 2005.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '81.': 'Isabele Beserra Santos Gomes. Avaliação dos parâmetros hematológicos e bioquímicos dos voluntários sadios da Unidade de Farmacologia Clínica. 2005.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '82.': 'Lilian Alves Amorim Beltrão. A Política de Medicamentos no Brasil: uma Avaliação da Qualidade do Medicamento Essencial Captopril Distribuído na Rede de Saúde do Estado do Ceará. 2005.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, Secretaria da Saúde do Estado do Ceará. Coorientador: Maria Elisabete Amaral de Moraes.', '83.': 'Pacifica Pinheiro Cavalcanti. Estudo de biodisponibilidade compra entre duas formulações contendo Levotiroxina sódica em voluntários sadios. 2005.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Orientador: Maria Elisabete Amaral de Moraes.', '84.': 'Emanuele Tourinho da Cruz Marques. Avaliação do Nível de Conhecimento do Cirurgião Dentista em Relação á Prescrição de Medicamentos. 2005.  Dissertação  (Mestrado em Farmacologia Clínica CAPES 22001018052P2)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '85.': 'Patrícia Mandali de Figueiredo. Utilização da Flutamida em Indicações Não Aprovadas pela ANVISA ? Aspectos Referentes à Segurança, Efetividade e Avaliação do Risco. 2004.  Dissertação  (Mestrado em MESTRADO PROFISSIONAL FARMACOLOGIA CLÍNICA)  - Universidade Federal do Ceará - Programa de Pós-Graduação em Farmacologia, . Orientador: Maria Elisabete Amaral de Moraes.', '86.': 'Giovanni Carvalho Guzzo. Estudo Retrospectivo da Freqüência e Causalidade dos Eventos Adversos Registrados nos Estudos de Bioequivalência Realizados na Unidade de Farmacologia Clínica no Período de 2000 a 2003. 2004.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '87.': 'Walter Jardim Alarcon. A implantação de medicamentos genéricos no Brasil. 2004.  Dissertação  (Mestrado em MESTRADO PROFISSIONAL FARMACOLOGIA CLÍNICA)  - Universidade Federal do Ceará - Programa de Pós-Graduação em Farmacologia, . Orientador: Maria Elisabete Amaral de Moraes.', '88.': 'Marne Carvalho de Vasconcellos. Estudo de toxicologia clínica e genotoxicidade do fitoterápico Tamaril cápsula em voluntários sadios. 2004.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '89.': 'Ismael Leite Martins. Determinação do acetato de Megestrol em Plasma humano por cromatrografia líquida de alta eficiência acoplada ao espectrômetro de massa: aplicação em estudo de bioequivalência. 2004.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '90.': 'Maria do Carmo Gomes Pinheiro. Equivalência Farmacêutica: Proposta de Manual para a Implantação e a Padronização de Centros em Conformidade com as Normas Técnicas e a Legislação Sanitária Vigentes. 2004.  Dissertação  (Mestrado em MESTRADO PROFISSIONAL FARMACOLOGIA CLÍNICA)  - Universidade Federal do Ceará - Programa de Pós-Graduação em Farmacologia, . Orientador: Maria Elisabete Amaral de Moraes.', '91.': 'Tercio Carneiro Ramos. Eficácia do Rofecoxib e do Diclofenaco Sódico no Controle da Dor, Edema e Trismo em Exodontia dos Terceiros Molares Inferiore. 2004.  Dissertação  (Mestrado em MESTRADO PROFISSIONAL FARMACOLOGIA CLÍNICA)  - Universidade Federal do Ceará - Programa de Pós-Graduação em Farmacologia, . Orientador: Maria Elisabete Amaral de Moraes.', '92.': 'Roberta Meneses Marquez de Amorim. Biodisponibilidade como Parâmetro de Qualidade e sua Importância no Registro de Medicamentos. 2004.  Dissertação  (Mestrado em MESTRADO PROFISSIONAL FARMACOLOGIA CLÍNICA)  - Universidade Federal do Ceará - Programa de Pós-Graduação em Farmacologia, . Orientador: Maria Elisabete Amaral de Moraes.', '93.': 'Adriana Vanessa Costa Gomes. Avaliação Comparativa dos Procedimentos Adotados pelas Agências Regulatórias do Brasil, Estados Unidos, Canadá e Comunidade Européia. 2003.  Dissertação  (Mestrado em Mestrado em Farmacologia Clínica)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '94.': 'Aline Kércia Alves Soares. Biodisponibilidade comparativa de três formulações de Captopril 25mg. 2002.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '95.': 'Ana Paula de Azevedo Leitão. Avaliação farmacocinética de duas formulações de Minociclina em condicões de jejum e após dieta rica em cálcio. 2001.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '96.': 'Inácia Gonçalves Simões. Estudo Fase II Aberto Prospectivo da Segurança e Eficácia da Cartilagem de Tubarão em Pacientes com Osteoartrite de Joelho. 2001.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '97.': 'Gilmara Silva de Melo Santana. Estudo de Toxicologia Clínica e Fitoterápicos em Voluntários Sadios. 1999. 0 f.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Fundação Cearense de Apoio ao Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '98.': 'Fátima Maria Fernandes Veras. Estudo de biodisponibilidade comparativa de duas formulações de Amoxicilina. 1999.  Dissertação  (Mestrado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '99.': 'Sandra Maria Nunes Monteiro. Estudo metabólico do hospedeiro portador de tumor gástrico (Carcinossarcoma 256 de Walker) submetido à hipertermia. 1998. 0 f.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '100.': 'Haroldo Moura Pinheiro. Efeitos de substâncias que interferem na Nefrotoxicidade da Ciclosporina na perfusão do rim isolado do coelho. 1995. 0 f.  Dissertação  (Mestrado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.'}}\n",
      "{'Tese de doutorado': {'1.': 'JOSÉ HENRIQUE LINHARES. AVALIAÇÃO DA EFICÁCIA TERAPÊUTICA DO CETOROLACO TROMETAMOL EM COMPARAÇÃO AO TRATAMENTO FISIOTERÁPICO EM PACIENTES COM DISFUNÇÃO TEMPORO-MANDIBULAR. 2020. Tese  (Doutorado em PROGRAMA DE PÓS-GRADUAÇÃO EM CIRURGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '2.': 'Marina Becker Sales Rocha. Impacto da obesidade e cirurgia bariátrica nos parâmetros farmacocinéticos da amoxicilina. 2017. Tese  (Doutorado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Orientador: Maria Elisabete Amaral de Moraes.', '3.': 'Ana Lourdes Almeida e Silva Leite. Ensaio Clínico Fase III Para Avaliação Da Eficácia Terapêutica De Um Medicamento Fitoterápico Contendo Passiflora incarnata L., Salix alba L., Crataegus oxyacantha L., Em Paciente Com Transtorno de Ansiedade Leve e Moderada.. 2017. Tese  (Doutorado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '4.': 'VALDEN LUIS MATOS CAPISTRANO JUNIOR. INVESTIGAÇÃO DOS EFEITOS DA SUPLEMENTAÇÃO DE L-ISOLEUCINA SOBRE O CONTROLE GLICÊMICO EM PACIENTES COM RESISTÊNCIA À INSULINA E DIABETES TIPO 2. 2017. Tese  (Doutorado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '5.': 'Cleber Soares Pimenta Costa.. Avaliação da eficácia terapêutica de um Fitoterápico contendo Cordia verbenacea associado ao ultrassom pulsado na contusão muscular.. 2016. Tese  (Doutorado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '6.': 'José Aurillo Rocha. Perfil epidemiológico e molecular em pacientes com câncer de pulmão.. 2015. Tese  (Doutorado em Medicina)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '7.': 'Maria Araci de Andrade Pontes.. Estudo dos efeitos adversos da multifarmacoterapia no Tratamento da Hanseníase.. 2015. Tese  (Doutorado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '8.': 'João José Ferreira Evangelista.. Estudo da ação farmacológica dos indutores de ovulação em Equus asinus.. 2015. Tese  (Doutorado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '9.': 'Andrea Vieira Pontes.. Estudo Fase I para avaliar a segurança e tolerabilidade do LBCT-TCJSS administrado por via oral em voluntários sadios do sexo masculino. 2014. Tese  (Doutorado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '10.': 'Ana Rosa Pinto Quidute. Expressão dos genes GNAS e BTG2 e de um painel de microRNAs em somatotrofinomas esporádicos com e sem mutação no gene GNAS. 2013. Tese  (Doutorado em Curso de Pós Graduação Em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '11.': 'Eveline Gadelha Pereira Fontenele. Impacto de cinco polimorfismno sobre a altura de crianças brasileiras na cidade de Fortaleza. 2013. Tese  (Doutorado em Programa de Pós-Graduação em Biotecnologia (RENORB)  - Universidade Federal do Ceará (RENORBIO), . Orientador: Maria Elisabete Amaral de Moraes.', '12.': 'Gilmara Holanda da Cunha. Efeito Farmacológico das Frações Hexânica, Clorofórmica e Metanólica do Óleo Essencial da Alpinia Zerumbet na Reatividade Vascular In Vitro e nos Parâmetros Cardiovasculares In Vivo. 2012. Tese  (Doutorado em Farmacologia CAPES 22001018007P7)  - Universidade Federal do Ceará, Fundação Cearense de Apoio ao Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '13.': 'Renan Magalhães Montenegro. Estudo da Associação entre a Acromegalia e a Presença da Mutação BRAFV600E e a Expressão Imunohistoquímica de IGF-1 e GAL-3 no Carcinoma Papilífero de Tireoide. 2012. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '14.': 'Fernando Andre Campos Viana. Estudo Comparativo da Associação da Mepivacaína 2% com Epinefrina versus Mepivacaína 2% com Norepinefrina em Seres Humanos. 2012. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '15.': 'Carlene de Souza Bitu. Estudo das Atitudes, Comportamentos e Efeitos Audiológicos e Bioquímicos Ocasionados aos Indivíduos Expostos a Ruído e Tolueno em Gráficas. 2012. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '16.': 'Samira Rêgo Martins de Deus. Avaliação genotóxica e mutagênica da exposição ocupacional ao formaldeído. 2012. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '17.': 'Ismenia Osório Leite Viana. Estudo Prospectivo, Randomizado, para Avaliação da Segurança e Eficácia Terapêutica do Fitomedicamento Melagrião. 2011. 0 f. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '18.': 'Demetrius Fernandes do Nascimento. Quantificação de Fármacos com Atividade Antimicrobiana em Plasma Humano por Cromatografia Líquida de Alta Eficiência Acoplada à Espectrometria de Massa (LC-MS-MS): Aplicação em Estudos de Farmacocinética Comparada.. 2011. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '19.': 'Tatiana Vieira Souza Chaves. Estudo das Alterações Hematológicas, Bioquímicas e Genotóxicas Induzidas por Agrotóxicos em Agricultores do Estado do Piauí. 2011. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '20.': 'Tércio Carneiro Ramos. Avaliação de eficácia e segurança de acetazolamida na doença periodontal experimental.. 2010. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '21.': 'Anastácio de Queiroz Sousa. Leishmaniose Cutânea no Ceará: Aspectos Históricos, Clínicos e Evolução Terapêutica. 2010. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Orientador: Maria Elisabete Amaral de Moraes.', '22.': 'Joelma Inês Tagliapietra. Efeito da Sitagliptina nas Alterações Neurológicas Subclínicas em Potenciais Evocados (Somato-Sensitivo e Visual) e no Controle Metabólico do Diabetes Mellitus Tipo 2. 2010. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '23.': 'Heitor de Sa Gonçalves. Esquema Único de Tratamento da Hanseníase: Influência das formas clínicas nos efeitos indesejáveis dos fármacos.. 2010. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '24.': 'Oswaldo Augusto Gutiérrez Andriazén. Alterações Fisiológicas, Cardiovasculares, Neuroendócrinas e Suas Correlações com a Hipertensão Arterial Intradialítica em Pacientes cCom Insuficiência Renal Crônica. 2010. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '25.': 'Pacifica Pinheiro Cavalcanti. Estudo Comparativo, randomizado para avaliar a eficácia terapêutica da Mentha crispa e do Secnidazol no tratamento da tricomoníase.. 2009. 0 f. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Orientador: Maria Elisabete Amaral de Moraes.', '26.': 'Patricia Leal Dantas Lobo. Avaliação in vivo do óleo essencial de Lippia sidoides, apresentações farmacêuticas : bochecho, gel e dentifrício, na inibição  de Streptococcus mutans em crianças com cárie.. 2009. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Orientador: Maria Elisabete Amaral de Moraes.', '27.': 'Ismael Leite Martins. Desenvolvimento e Validação de Métodos Bioanalíticos para Quantificação da Amoxicilina, Norfloxacino e Oxcarbazepina em Estudos Farmacocinéticos. 2009. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '28.': 'Elisete Mendes Carvalho. Xarope de Cumaru como Terapia Complementar na Asma Persistente Leve. 2009. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Orientador: Maria Elisabete Amaral de Moraes.', '29.': 'Andréa Vieira Pontes. Estudo Fase I do Fitomedicamento NPDM-01. 2009. Tese  (Doutorado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Orientador: Maria Elisabete Amaral de Moraes.', '30.': 'Janaina Serra Azul Monteiro Evangelista. Estudo de Efeitos Vasculares, Renais e Citotóxicoss do Veneno da Serpente Crotalus durissus cascavella. 2008. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '31.': 'Aline Kércia Alves Soares. Avaliação da Segurança e Eficácia Terapêutica da Associação de Cassia fistula, Cassia angustifolia, Coriandrum sativum L, Glycyrrhiza glabra L e Tamarindus indica L na Constipação Intestinal. 2008. Tese  (Doutorado em Farmacologia)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '32.': 'Andréa Gifoni Siebra de Holanda. Avaliação da eficácia e Segurança da Combinação Fixa de Bimatoprost e Timolol Versus Travoprost e Timolol. 2007. Tese  (Doutorado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará - Programa de Pós-Graduação em Farmacologia, . Orientador: Maria Elisabete Amaral de Moraes.', '33.': 'Gilmara Silva de Melo Santana. Estudo da fenotipagem de quatro enzimas metabolizadoras de fármacos em uma amostra da população do Estado do Ceará. 2004. Tese  (Doutorado em Programa de Pós-Graduação em Farmacologia da UFC)  - Universidade Federal do Ceará, Fundação Cearense de Apoio ao Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '34.': 'Sonia Leite da Silva. Efeito de Imunossupressores no Crescimento Tumoral e Formação de Metástase ou Regressão do Tumor, em Ratos Wistar Inoculados com o Carcinossarcoma 256 de Walker. 2003. Tese  (Doutorado em PROGRAMA DE PÓS-GRADUAÇÃO EM FARMACOLOGIA)  - Universidade Federal do Ceará, . Orientador: Maria Elisabete Amaral de Moraes.', '35.': 'Cristiane Sá Roriz Fonteles. Estudo da Incorporação de Flúor no Esmalte e Dentina de Incisivos Decíduos após Exposição ao Flúor nos Períodos Pré e Pós-Natais. 2001. Tese  (Doutorado em Farmacologia CAPES 22001018007P7)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.'}}\n",
      "{'Supervisão de pós-doutorado': {'1.': 'Catarina Brasil d?Alva. 2010. Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Maria Elisabete Amaral de Moraes.', '2.': 'Catarina Brasil dÁlva. 2007. UNIVERSIDADE FEDERAL DO CEARÁ - UNIDADE DE FARMACOLOGIA CLÍNICA, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Maria Elisabete Amaral de Moraes.', '3.': 'Maria Bernadete de Sousa Maia. 2007. Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Maria Elisabete Amaral de Moraes.', '4.': 'Mirna Marques Bezerra. 2007. Universidade Federal do Ceará/Unidade de Farmacologia Clínica-UNIFAC, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Maria Elisabete Amaral de Moraes.', '5.': 'Maria Bernadete de Sousa Maia. 2006. Universidade Federal do Ceará/Unidade de Farmacologia Clínica-UNIFAC, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Maria Elisabete Amaral de Moraes.', '6.': 'Gilmara Silva de Melo Santana. 2005. Universidade Federal do Ceará/Unidade de Farmacologia Clínica-UNIFAC, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Maria Elisabete Amaral de Moraes.'}}\n",
      "{'Iniciação científica': {'1.': 'BEATRIZ ALVES HOLANDA. Identificação de Proteínas Plasmáticas Associadas a Complicações Neurológicas da COVID-19: Análise Proteômica Aplicada ao Prognóstico e Entendimento da Doença. 2022. Iniciação Científica - Universidade Federal do Ceará, CONSELHO  Nacional de Desenvolviemnto Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '2.': \"JHONATAN LUCAS BARBOSA SILVA. Identificação de Proteínas Plasmáticas Associadas a Complicações Neurológicas da COVID-19: Análise Proteômica Aplicada ao Prognóstico e Entendimento da Doença'. 2022. Iniciação Científica - Universidade Federal do Ceará, CONSELHO  Nacional de Desenvolviemnto Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.\", '3.': 'ANDREZA RIBEIRO PINHO. Análise da Densidade Mineral Óssea em Pacientes com Síndrome de Turner. 2021. Iniciação Científica - Universidade Federal do Ceará, CONSELHO  Nacional de Desenvolviemnto Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '4.': 'GABRIEL COELHO BRITO DIAS. Análise da Densidade Mineral Óssea em Pacientes com Síndrome de Turner. 2021. Iniciação Científica - Universidade Federal do Ceará, CONSELHO  Nacional de Desenvolviemnto Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '5.': 'GABRIEL COELHO BRITO DIAS. Estudo Clínico Fase I Para Avaliar a Segurança,Tolerabilidade e a Farmacocinética da Fosfoetanolamina Sintética. 2020. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '6.': 'ANDREZA RIBEIRO PINHO. Padronização e Implementação do Sequenciamento de Sanger na Neoplasia Endocrina Múltipla Tipo 1 no Estado do Ceará. 2020. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '7.': 'GABRIEL COELHO BRITO DIAS. Padronização e Implementação do Sequenciamento de Sanger na Neoplasia Endocrina Múltipla Tipo 1 no Estado do Ceará. 2020. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Fundação Cearense de Apoio ao Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '8.': \"THOMAZ ALEXANDRE COSTA. PADRONIZAÇÃO E IMPLEMENTAÇÃO DO SEQUENCIAMENTO DE SANGER NA NEOPLASIA ENDÓCRINA MÚLTIPLA TIPO 1 NO ESTADO DO CEARÁ'. 2020. Iniciação Científica - Universidade Federal do Ceará, CONSELHO  Nacional de Desenvolviemnto Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.\", '9.': 'Bruno Almeida Costa. Estudo Clínico Fase I Para Avaliar a Segurança,Tolerabilidade e a Farmacocinética da Fosfoetanolamina Sintética.. 2018. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, CONSELHO  Nacional de Desenvolviemnto Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '10.': 'THOMAZ ALEXANDRE COSTA. Estudo Clínico Fase I Para Avaliar a Segurança,Tolerabilidade e a Farmacocinética da Fosfoetanolamina Sintética.. 2018. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, CONSELHO  Nacional de Desenvolviemnto Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '11.': 'Deusene Rodrigues de Carvalho. Estudo de Biodisponibilidade Relativa/Bioequivalência Entre Duas Formulações de Diclofenaco Sódico Cápsulas de Liberação Prolongada de 100mg, em Participantes da Pesquisa Sadios de Ambos os Sexos na Condição de Jejum e Alimentado.. 2018. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, CONSELHO  Nacional de Desenvolviemnto Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '12.': 'Thaylana Saraiva Barroso. Estudo de Biodisponibilidade Relativa/Bioequivalência Entre Duas Formulações de Diclofenaco Sódico Cápsulas de Liberação Prolongada de 100mg, em Participantes da Pesquisa Sadios de Ambos os Sexos na Condição de Jejum e Alimentado.. 2018. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, CONSELHO  Nacional de Desenvolviemnto Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '13.': 'Leandro de Castro Sales. Estudo de Biodisponibilidade Relativa/Bioequivalência Entre Duas Formulações de Nimodipino Comprimidos de 30mg, em Voluntários Sadios de Ambos os Sexos na Condição de Jejum. 2016. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, CONSELHO  Nacional de Desenvolviemnto Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '14.': 'Thaylana Saraiva Barroso. Estudo de Biodisponibilidade Relativa/Bioequivalência Entre Duas Formulações de Nimodipino Comprimidos de 30mg, em Voluntários Sadios de Ambos os Sexos na Condição de Jejum. 2016. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, CONSELHO  Nacional de Desenvolviemnto Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '15.': 'Leandro de Castro Sales. Avaliação do efeito do passiflorine® (Passiflora incarnata l., Crataegus oxyacantha l. E salix alba l.) Na ansiedade leve e moderada: estudo duplo-cego, randomizado, controlado por valeriana officinalis L.. 2014. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '16.': 'Karine Sampaio Sena. Estudo duplo-cego, randomizado, controlado por placebo da eficácia da associação de Senna alexandrina Mill (sena), Cassia fistula L., Tamarindus indica L., Coriandrum sativum L., Periandra mediterranea Taub. em pacientes com constipação intestinal funcional. 2013. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '17.': 'Layana Vieira Nobre. Estudo duplo-cego, randomizado, controlado por placebo da eficácia da associação de Senna alexandrina Mill (sena), Cassia fistula L., Tamarindus indica L., Coriandrum sativum L., Periandra mediterranea Taub. em pacientes com constipação intestinal funcional. 2012. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '18.': 'Rafael Pascoalino Pinheiro. Estudo duplo-cego, randomizado, controlado por placebo da eficácia da associação de Senna alexandrina Mill (sena), Cassia fistula L., Tamarindus indica L., Coriandrum sativum L., Periandra mediterranea Taub. em pacientes com constipação intestinal funcional. 2012. Iniciação Científica. (Graduando em Odontologia)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '19.': 'Letícia Matoso Freire. Estudo duplo-cego, randomizado, controlado por placebo da eficácia da associação de Senna alexandrina Mill (sena), Cassia fistula L., Tamarindus indica L., Coriandrum sativum L., Periandra mediterranea Taub. em pacientes com constipação intestinal funcional. 2012. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '20.': 'Hugo Siqueira Robert Pinto. Avaliação do efeito da Passiflora incarnata L, Crataegus oxyacantha L e Salix alba L na ansiedade leve e moderada: estudo duplo-cego, randomizado, controlado por Valeriana officinalis L. 2011. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '21.': 'Layana Vieira Nobre. Avaliação do efeito da Passiflora incarnata L, Crataegus oxyacantha L e Salix alba L na ansiedade leve e moderada: estudo duplo-cego, randomizado, controlado por Valeriana officinalis L. 2010. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '22.': 'Hugo Siqueira Robert. Avaliação do Efeito Incretina e dos Potenciais Evocados Somato-Sensitivo e Visual em Pacientes com Diabetes Mellitus Tipo 2 Recém-Diagnosticados Antes e Após Terapia com Sitagliptina. 2010. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '23.': 'Gabriela Coutinho Gondim da Justa. Avaliação do Efeito Incretina e dos Potenciais Evocados Somato-Sensitivo e Visual em Pacientes com Diabetes Mellitus Tipo 2 Recém-Diagnosticados Antes e Após Terapia com Sitagliptina. 2009. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '24.': 'Maria Izabel Pinheiro de Oliveira. Influência das formas clínicas de hanseníase no metabolismo, concentrações plasmáticas e efeitos indesejáveis dos fármacos utilizados na poliquimioterapia da doença. 2007. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '25.': 'Ana Karine Sales Faria Viana. Toxicologia e Potencial Genotóxico do Melagrião. 2007. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '26.': 'Daniele Pinheiro de Almeida. Estudo de toxicologia clínica da solução oral-Ovariofloria (fitoterápico) produzido pelo laboratório Flora Medicinal em voluntários sadios. 2006. Iniciação Científica. (Graduando em Enfermagem)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '27.': 'Naiana Cunha Martins. Estudo comparativo, randomizado para avaliar a eficácia clínica entre o Giamebil e o secnidazol no tratamento da amebíase e da giardíase. 2006. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '28.': 'Germana Vasconcelos Mesquita Martiniano. Estudo comparativo, randomizado para avaliar a eficácia clínica entre o Giamebil e o secnidazol no tratamento da amebíase e da giardíase. 2006. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '29.': 'Ariane de Sá Vieira. Determinação do Perfil Cromatográfico e Avaliação da Segurança e Eficácia Terapêutica da Colônia. 2005. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '30.': 'Ariane Sá Vieira. Determinação do Perfil Cromatográfico e Avaliação da Segurança e Eficácia Terapêutica do Fitoterápico Colônia (cápsulas). 2004. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '31.': 'Ana Paula Macedo Santana. Determinação do Perfil Cromatográfico e Avaliação da Segurança e Eficácia Terapêutica do Fitoterápico Colônia (cápsulas). 2004. Iniciação Científica. (Graduando em Farmácia)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '32.': 'Gardênia Costa do Carmo. Estudo de Toxicologia Clínica e Laboratorial do Xarope de Tamarine. 2003. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '33.': 'Diana Pierre Quental. Estudo de Biodisponibilidade do Atenolol em Voluntários Sadios. 2003. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '34.': 'Daniele Pinheiro de Almeida. Estudo de toxicologia clínica da solução oral- Ovarioflora (fitoterápico) produzido pelo Laboratório Flora Medicinal em voluntários sadios. 2003. Iniciação Científica. (Graduando em Enfermagem)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '35.': 'Amaury de Castro e Silva Filho. Estudo de biodisponibilidade de uma formulação de Bromazepam em voluntários sadios.. 2003. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '36.': 'Luciana Bessa Teixeira. Estudo de bioequivalência de uma formulação contendo besilato de Amlodipina produzida pela EMS Indústria Farmacêutica Ltda (comprimido de 10mg) versus Norvas (comprimido de 10mg-formulação Referência) em voluntários sadios. 2003. Iniciação Científica. (Graduando em Farmácia)  - Universidade Federal do Ceará, Instituto Claude Bernard. Orientador: Maria Elisabete Amaral de Moraes.', '37.': 'Andréa Fontenele Rocha. Estudo de bioequivalência de três formulações de Captopril (comprimido de 25mg) em voluntários sadios. 2003. Iniciação Científica. (Graduando em Enfermagem)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '38.': 'Dower Moraes Cavalcante Filho. Estudo de bioequivalência de duas formulações de hidroclorotiazida comprimido de 50mg em voluntários sadios de ambos os sexos. 2003. Iniciação Científica. (Graduando em Farmácia)  - Universidade Federal do Ceará, Instituto Claude Bernard. Orientador: Maria Elisabete Amaral de Moraes.', '39.': 'Ismael Leite Martins. Estudo de bioequivalência de duas formulações de Amlodipina em voluntários sadios. 2003. Iniciação Científica. (Graduando em Farmácia)  - Universidade Federal do Ceará, Instituto Claude Bernard. Orientador: Maria Elisabete Amaral de Moraes.', '40.': 'Fabrine Sousa Martins. Fabrine Sousa Martins. 2003. Iniciação Científica. (Graduando em Enfermagem)  - Universidade Federal do Ceará, Instituto Claude Bernard. Orientador: Maria Elisabete Amaral de Moraes.', '41.': 'Raquel Fernandes de Lima. Estudo de toxicologia clínica do xarope da casca do Cumaru (fitoterápico) em voluntários sadios. 2003. Iniciação Científica. (Graduando em Farmácia)  - Universidade Federal do Ceará, Instituto Claude Bernard. Orientador: Maria Elisabete Amaral de Moraes.', '42.': 'Suellen Vieira Neves. Estudo de bioequivalência de duas formulações (suspensão oral 250mg/5ml) de Cefalexina em voluntários sadios. 2003. Iniciação Científica. (Graduando em Farmácia)  - Universidade Federal do Ceará, Instituto Claude Bernard. Orientador: Maria Elisabete Amaral de Moraes.', '43.': 'Raquel Fernandes de Lima. Avaliação da toxicologia clínica e eficácia terapêutica do fitoterápico Melparatosse (Pronatus). 2002. 0 f. Iniciação Científica. (Graduando em Farmácia)  - Universidade Federal do Ceará, Instituto Claude Bernard. Orientador: Maria Elisabete Amaral de Moraes.', '44.': 'Leonardo Pierre Quental. Estudo de toxicologia clínica do pasalix (fitoterápico) em voluntários sadios. 2001. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '45.': 'Amaury de Castro e Silva Filho. Estudo de bioequivalência de uma formulação de Bromazepam (comprimidos de 6mg) em voluntários sadios. 2001. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '46.': 'Rosa Ester Fontenele Chaves. Estudo de bioequivalência de uma formulação de Ritonavir produzida pela Cristália (produtos Químicos Farmacêuticos Ltda (cápsula de 100mg) versus Norvir (cápsula de 100mg, formulação referência) em voluntários sadios. 2001. Iniciação Científica. (Graduando em Enfermagem)  - Universidade Federal do Ceará, Instituto Claude Bernard. Orientador: Maria Elisabete Amaral de Moraes.', '47.': 'Demetrius Fernandes do Nascimento. Estudo de toxicologia clínica da solução nasal - Sinustrat. 2001. Iniciação Científica. (Graduando em Farmácia)  - Universidade Federal do Ceará, Instituto Claude Bernard. Orientador: Maria Elisabete Amaral de Moraes.', '48.': 'Maria Neide Antero Pinheiro. Estudo de bioequivalência de duas formulações de Deflazacort em voluntários sadios. 2000. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '49.': 'Stela Cybele Costa. Estudo de bioequivalência de duas formulações de Cefalexina (250mg/5mL) em voluntários sadios. 2000. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '50.': 'Amaury de Castro e Silva Filho. Estudo de bioequivalência de 4 preparações farmacêuticas de comprimido de Sinvastatina em voluntários sdios. 2000. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '51.': 'GERMANA AMARAL DE MORAES. Influência da alimentação na biodisponibilidade de duas preparações farmacêuticas de Minociclina em voluntários sadios. 1999. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '52.': 'Gina Rodrigues Belém. Estudo comparativo da biodisponibilidade de duas formulações de Amoxicilina. 1999. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '53.': 'Ed Wilson Custódio Francelino. Influência da alimentação na biodisponibilidade de duas formulações de Minociclina em voluntários sadios. 1999. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '54.': 'Daniela Lima Chow Castillo. Estudo e bioequivalência de duas formulações farmacêuticas Etinilestradiol e Ciproterona em voluntários sadios do sexo feminino. 1998. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '55.': 'José Nilson Nunes Anselmo. Estudo de biodisponibilidade de duas preparações farmacêuticas de Claritromicina. 1998. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Orientador: Maria Elisabete Amaral de Moraes.', '56.': 'Raquel Autran Coelho. Ação farmacológica de extratos de plantas medicinais sobre a musculatura lisa de preparações de órgãos isolados de rato. 1998. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '57.': 'Antônia Célia de Castro Alcântara. Estudo de bioequivalência de duas preparações de Fluconazol em voluntários sadios. 1998. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '58.': 'Antônia Célia de Castro Alcantara. Pesquisa Clínica com Medicamentos e Fitoterápicos. 1998. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '59.': 'Madja Luciana de Lima Pimentel. Biodisponibilidade Comparativa de Duas Formulações de Fluconazol em Voluntários Sadios. 1997. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '60.': 'Raquel Autran Coelho. Estudo de bioequivalência de duas formulações de Amlodipina. 1997. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '61.': 'Melissa Soares Medeiros. Bioequivalência de duas preparações farmacêuticas de Omeprazol. 1997. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '62.': 'Inácia Gonçalves Simões. Estudo metabólico do hospedeiro portador de tumor gástrico (carcinossarcoma 256 de Walker) submetido à hipertermia. 1997. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '63.': 'Gilmasa Daniele  Freire Rios. Efeitos renais da peçonha da Crotalus durissus cascavella em perfusão do rim isolado. 1996. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '64.': 'Jonaina Costa de Oliveira. Estudo da toxicidade aguda e determinação da DL50 de Spondias mombi. 1996. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '65.': 'Raquel Autran Coelho. Caracterização farmacológica de Terramicina (Alternanthera brasiliana linn e janaguba (Plumeria bracteata A. DC). 1996. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '66.': 'Melissa Soares Medeiros. Ação farmacológica de extratos de plantas medicinais sobre a musculatura lisa de preparações de órgãos isolados de rato. 1996. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '67.': 'Paulo Rogers Parente Gomes. Estudo da toxicidade aguda e determinação da DL50 da Psydium guava (goiabeira). 1996. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '68.': 'Inácia Gonçalves Simões. Estabelecimento de um protocolo experimental para estudo metabólico de hospedeiros portador de tumor gástrico (carcinoma 256 de Walker) submetido a hipertermia. 1995. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '69.': 'José Ítalo Soares Mota. Efeitos do extrato de Limãozinho (Zanthoxylum syncarpum) sobre a contratilidade de jejuno isolado de rato. 1994. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '70.': 'Paulo Rogers Parente Gomes. Alterações renais induzidas pela Ciclosporina e PCA. 1994. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '71.': 'Fernanda Martins Maia. Estudo da toxicidade aguda e determinação da DL50 da Solieria filiformis. 1993. Iniciação Científica. (Graduando em Medicina)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '72.': 'Josenília Maria Alves Gomes. Efeitos da Nifedipina na Nefrotoxicidade Induzida por Ciclosporina. 1992. Iniciação Científica. (Graduando em Medicina-Farmacologia)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.'}}\n",
      "{'Orientações de outra natureza': {'1.': 'Maria Teresa Rocha. Realização de Atividades Técnicas de Pesquisa. 2012. Orientação de outra natureza - Universidade Federal do Ceará/Unidade de Farmacologia Clínica-UNIFAC, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '2.': 'Israel Farias da Costa. Pesquisa Clínica com Medicamentos e Fitoterápicos na UNIFAC. 2011. Orientação de outra natureza. (Biotecnologia)  - Universidade Estadual do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '3.': 'Raimundo das Chagas Marques. Realização de Atividades Técnicas de Laboratório. 2011. Orientação de outra natureza - Universidade Federal do Ceará/Unidade de Farmacologia Clínica-UNIFAC, Fundação Cearense de Apoio ao Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '4.': 'Maria Paula Vieira Mariz. Pesquisa Clínica com Medicamentos e Fitoterápicos na UNIFAC. 2009. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '5.': 'Luzirene Xavier Ribeiro. Realização de Atividades Técnicas de Pesquisa. 2009. Orientação de outra natureza. (Ciências Sociais)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '6.': 'Raimundo das Chagas Marques. Realização de Atividades Técnicas de Laboratório. 2009. Orientação de outra natureza - Universidade Federal do Ceará/Unidade de Farmacologia Clínica-UNIFAC, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '7.': 'Cibelle Ferreira Teixeira. Pesquisa Clínica com Medicamentos e Fitoterápicos na UNIFAC. 2007. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '8.': 'José Jalber de Souza Silva. Realização de Atividades Técnicas de Laboratório. 2007. Orientação de outra natureza. (Ciências Sociais)  - Universidade Federal do Ceará, Conselho Nacional de Desenvolvimento Científico e Tecnológico. Orientador: Maria Elisabete Amaral de Moraes.', '9.': 'Silvia Farfan. Farmacologia Clínica - Polimorfismo de Fármacos. 2006. Orientação de outra natureza - Universidade de Cordoba, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior. Orientador: Maria Elisabete Amaral de Moraes.', '10.': 'Jairo Carlos da Silva Gomes. Realização de Atividades de Extensão. 2006. Orientação de outra natureza. (Letras)  - Universidade Federal do Ceará, Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '11.': 'Danielle Leite Cunha. Pesquisa Clínica com Medicamentos e Fitoterápicos na UNIFAC. 2005. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '12.': 'Parla Greta França Lima. Pesquisa Clínica com Medicamentos e Fitoterápicos na UNIFAC. 2005. Orientação de outra natureza. (Farmácia)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '13.': 'Eduardo Duarte Ferreira. Realização de Atividades de Extensão. 2005. Orientação de outra natureza. (Pedagogia)  - Universidade Federal do Ceará, Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '14.': 'Camilla Torres Ferraz. Pesquisa Clínica com Medicamentos e Fitoterápicos na UNIFAC. 2004. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '15.': 'Fabrine Souza Martins. Pesquisa Clínica com Medicamentos e Fitoterápicos. 2003. Orientação de outra natureza. (Enfermagem)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '16.': 'Cíntia Gioconda Honorato Nascimento. Pesquisa Clínica com Medicamentos e Fitoterápicos. 2003. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '17.': 'Clarissa Férrer Carvalho. Pesquisa Clínica com Medicamentos e Fitoterápicos na UNIFAC. 2003. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '18.': 'Grazielle Gomes da Silva. Pesquisa Clínica com Medicamentos e Fitoterápicos. 2002. Orientação de outra natureza. (Farmácia)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '19.': 'Renata Amaral de Moraes. Pesquisa Clínica com Medicamentos e Fitoterápicos. 2001. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '20.': 'Darla Viana Ramos. Pesquisa Clínica com Medicamentos e Fitoterápicos. 2001. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '21.': 'Geórgia de Holanda Freire. Pesquisa Clínica com Medicamentos e Fitoterápicos. 2001. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '22.': 'Vânia Angélica Feitosa Viana. Pesquisa Clínica com Medicamentos e Fitoterápicos. 2001. Orientação de outra natureza. (Farmácia)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '23.': 'Iolanda Santos da Silva. Realização de Atividades de Extensão. 2001. Orientação de outra natureza. (Letras)  - Universidade Federal do Ceará, Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '24.': 'Ianna Lacerda Sampaio. Estudo de Toxicologia Clínica e de Eficácia Terapêutica de Fitoterápicos. 2000. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '25.': 'Firmina Hermelinda Saldanha Albuquerque. Pesquisa Clínica com Medicamentos e Fitoterápicos. 2000. Orientação de outra natureza. (Enfermagem)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '26.': 'Luciana Said Fontenele. Pesquisa Clínica com Medicamentos e Fitoterápicos. 2000. Orientação de outra natureza. (Farmácia)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '27.': 'Francisco Adoniran Braga Ramos. Realização de Atividades de Extensão. 2000. Orientação de outra natureza. (História)  - Universidade Federal do Ceará, Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '28.': 'Edmar Oliveira Guedes Jr. Alterações Renais de Venenos. 1998. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '29.': 'João Aragão Ximenes Filho. Alterações Renais de Venenos. 1996. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '30.': 'Karla Barreto Ivo. Alterações Renais de Venenos. 1996. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '31.': 'Andrea Alcantara Vieira. Alterações Renais de Venenos. 1996. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '32.': 'Alexandre A. Holanda. Alterações Renais de Venenos. 1996. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.', '33.': 'Alessandra Costa da Silva. Alterações Renais de Venenos. 1993. Orientação de outra natureza. (Medicina)  - Universidade Federal do Ceará. Orientador: Maria Elisabete Amaral de Moraes.'}}\n"
     ]
    }
   ],
   "source": [
    "# Verificar orientações nos dados de docentes\n",
    "for i in [x.get('Orientações') for x in dict_list_docents if x.get('Orientações')][1]['Orientações e supervisões em andamento']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922feca2",
   "metadata": {},
   "source": [
    "# <b>F02: Obter dados de Discentes</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19872560",
   "metadata": {},
   "source": [
    "## Montar lista_busca para dados de Docentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39722ea",
   "metadata": {},
   "source": [
    "### Carregar nomes de planilha com dados de Discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "391dac31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>ativo</th>\n",
       "      <th>vinculo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALANA LIGIA SALDANHA FERNANDES</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALICE SOARES DE QUEIROZ</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALINE DE OLIVEIRA ALBUQUERQUE</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALINE PINTO MONTEIRO COSTA SOUSA</td>\n",
       "      <td>False</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALISON DE SOUSA REBOUÇAS</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alissan Karine Lima Martins</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMANDA CAVALCANTE FROTA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANA FLAVIA PONTES AGUIAR</td>\n",
       "      <td>False</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ANA JULIA FERREIRA LIMA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ANA JULIA FERREIRA LIMA</td>\n",
       "      <td>False</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ana Keyla Oliveira da Silva</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ANA MARILIA SOARES CRUZ</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ANA PATRICIA PEREIRA MORAIS</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ANA PAULA PIRES GADELHA DE LIMA</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ANA VIRGINIA FROTA GUIMARAES</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Andréa Silvia Walter de Aguiar</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ANDRIELLY HENRIQUES DOS SANTOS COSTA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ANGELA DONATO MAIA MALAQUIAS</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ANGELA DONATO MAIA MALAQUIAS</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ANTONIA VANDERLI ALVES DO NASCIMENTO</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BARBARA NEPOMUCENO GUIMARAES</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BEATRIZ CHAVES</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bruna de Sousa Lima</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BRUNHELD MAIA DUTRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CAMILA SILLOS ROSAS BRISIGHELLO</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CARLOS ANTONIO DE ARROXELAS SILVA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CARLOS EDUARDO DE SOUSA PRAXEDES</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Carollyne Ferreira Santiago</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CASSIO PINHEIRO OLIVEIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CRISTIAN VICSON GOMES PINHEIRO</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CRISTIANE FRANÇA MARTINS TEODORO</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cristiane Mourao Carvalhedo Mesquita</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DIEGO DA SILVA DE ALMEIDA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DIEGO RAMOS AGUIAR</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DISRAELI CAVALCANTE ARAUJO VASCONCELOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EDUARDO MENEZES GAIETA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ELLEN MARIA LIMA GONÇALVES</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ERIKA ROMERIA FORMIGA DE SOUSA</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Erlemus Ponte Soares</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>EVANILDO HENRIQUE MACEDO DA COSTA</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Evanizia Pinheiro de Oliveira</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FABIO JOSE GOMES DE SOUSA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Filipe Oliveira de Brito</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Francisca Raquel de Vasconcelos Silveira</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>GABRIEL ACACIO DE MOURA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Georgea Bezerra Carvalho</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>GERALDO RODRIGUES SARTORI</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>GERMANA SILVA VASCONCELOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Gilcelene de Castro Andrade</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gilmara Maria Batista Tavares da Silva</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Gilmara Maria Batista Tavares da Silva</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>GLAZIANE DA SILVA PAIVA BANDEIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>GRAYCE ALENCAR ALBUQUERQUE</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Graziela Jones de Oliveira</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>GUILHERME ANGELO LOBO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>HASSA PEREIRA LEMOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>HERQUIMEDES GLAUDYS DA SILVA AVELINO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>HEVERTON MENDES ARAUJO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>IGOR CABRAL STUDART</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ISABELLA LIMA BARBOSA CAMPELO</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>JEAN VIEIRA SAMPAIO</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>JOAO EUDES LEMOS DE BARROS</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>JOAO MATHEUS FONTELES SILVA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>JOAO PEDRO VIANA RODRIGUES</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>JOAQUIM CESAR DO NASCIMENTO SOUSA JUNIOR</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>JOSE MARIA XIMENES GUIMARAES</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>JOSE SAMUEL DOS SANTOS BARBOSA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>JOSETE MALHEIRO TAVARES</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>JUCILENE PEREIRA DE SOUSA</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>JULIANA MENESES DE SENA SILVA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>JULIANA RAMOS DE OLIVEIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>KAMILA MARIA OLIVEIRA SALES</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>KETLEN CHRISTINE OHSE</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Kilvia Helane Cardoso Mesquita</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>LAECIO PAULO SOUSA DOS SANTOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>LARISSE CADEIRA BRANDAO</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>LEA DIAS PIMENTEL GOMES VASCONCELOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>LENIR SANTOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>LETICIA BASTOS CONRADO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>LETICIA FERREIRA ESPINOSA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>LIANDRA ELLEN COELHO PEREIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Libia Lopes Martiniano</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Lílian Fernandes Amarante</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>LIVIA COELHO DE ASSIS</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Lorena Lodo Santiago</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Lorena Morais Nogueira</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>LUCA MILERIO ANDRADE</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>LUCAS ALMEIDA DE FREITAS</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Lucelia Gois de oliveira</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Luciana Carvalho de Albuquerque</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Luis Lopes Sombra Neto</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>MAISA PESSOA PINHEIRO</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>MARA MILVIA PONTES MELO RESENDE</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>MARCUS RAFAEL LOBO BEZERRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Maria Alexandrina Perez da Justa</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>MARIA JOSYCLEY NOVAIS LANDIM SOARES</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>MARILIA FAÇANHA TAVARES</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>MATHIAS COELHO BATISTA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Naila Saskia Melo Andrade</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NATALIA CAMPOS PARENTE</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Neyliane Maria Brito Costa</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>PATRICIA PEREIRA TAVARES DE ALCANTARA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Paulo Ricardo Nazario Viecili</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>PEDRO MIGUEL CARNEIRO JERONIMO</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>PLACIDO EYMARD GOMES SARAIVA FILHO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>RAFAELLE DANTAS BEZERRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Raquel Bomfim Castelo</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>REGINA GLAUCIA LUCENA AGUIAR FERREIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>REJANE FERREIRA COSTA</td>\n",
       "      <td>True</td>\n",
       "      <td>Mestrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Renata Castelo da Nobrega</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>RENATO THALES MEDEIROS HOLANDA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>ROGERIO SAMPAIO DE OLIVEIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ROMULO ALVES DE ARAUJO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>RONNY PETTERSON DOS SANTOS ARAUJO</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SAMUEL LUCAS DE ALMEIDA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>SAMUEL MENESES FELICIO DE ARAUJO COSTA</td>\n",
       "      <td>True</td>\n",
       "      <td>Profsaúde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Sandhara Ribeiro Rodrigues</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>SANDY KAENA SOARES DE FREITAS</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>TAINA MARIA LIMA FREIRE</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Vandre Cabral Gomes Carneiro</td>\n",
       "      <td>False</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>VANESSA PINHEIRO GONÇALVES FERREIRA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>VANIA CARLA DE SOUSA</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>VERA LUCIA DE AZEVEDO DANTAS</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>VERIDIANA PESSOA MIYAJIMA</td>\n",
       "      <td>True</td>\n",
       "      <td>Pós-Doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Vinicius Saraiva Barretto</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Vitória Taiana de Melo Lima Albuquerque</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>VIVIAN MAGALHAES BRANDÃO DOS SANTOS</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>YANA PAULA COELHO CORREIA SAMPAIO</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Yasmim Mendes Rocha</td>\n",
       "      <td>True</td>\n",
       "      <td>Graduação</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>YASMIM MENDES ROCHA</td>\n",
       "      <td>True</td>\n",
       "      <td>Doutorado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nome                                       ativo vinculo   \n",
       "0              ALANA LIGIA SALDANHA FERNANDES   True  Graduação\n",
       "1                     ALICE SOARES DE QUEIROZ   True   Mestrado\n",
       "2               ALINE DE OLIVEIRA ALBUQUERQUE   True  Doutorado\n",
       "3            ALINE PINTO MONTEIRO COSTA SOUSA  False   Mestrado\n",
       "4                    ALISON DE SOUSA REBOUÇAS   True  Doutorado\n",
       "5                 Alissan Karine Lima Martins  False  Graduação\n",
       "6                     AMANDA CAVALCANTE FROTA   True  Graduação\n",
       "7                    ANA FLAVIA PONTES AGUIAR  False   Mestrado\n",
       "8                     ANA JULIA FERREIRA LIMA   True  Doutorado\n",
       "9                     ANA JULIA FERREIRA LIMA  False  Doutorado\n",
       "10                Ana Keyla Oliveira da Silva   True  Graduação\n",
       "11                    ANA MARILIA SOARES CRUZ   True  Graduação\n",
       "12                ANA PATRICIA PEREIRA MORAIS   True    Pós-Doc\n",
       "13            ANA PAULA PIRES GADELHA DE LIMA   True  Profsaúde\n",
       "14               ANA VIRGINIA FROTA GUIMARAES   True  Doutorado\n",
       "15             Andréa Silvia Walter de Aguiar   True    Pós-Doc\n",
       "16       ANDRIELLY HENRIQUES DOS SANTOS COSTA   True  Graduação\n",
       "17               ANGELA DONATO MAIA MALAQUIAS   True  Graduação\n",
       "18               ANGELA DONATO MAIA MALAQUIAS  False  Graduação\n",
       "19       ANTONIA VANDERLI ALVES DO NASCIMENTO   True  Profsaúde\n",
       "20               BARBARA NEPOMUCENO GUIMARAES   True  Graduação\n",
       "21                             BEATRIZ CHAVES   True  Doutorado\n",
       "22                        Bruna de Sousa Lima  False  Graduação\n",
       "23                        BRUNHELD MAIA DUTRA   True  Doutorado\n",
       "24            CAMILA SILLOS ROSAS BRISIGHELLO   True   Mestrado\n",
       "25          CARLOS ANTONIO DE ARROXELAS SILVA   True   Mestrado\n",
       "26           CARLOS EDUARDO DE SOUSA PRAXEDES   True  Doutorado\n",
       "27                Carollyne Ferreira Santiago   True  Graduação\n",
       "28                   CASSIO PINHEIRO OLIVEIRA   True  Doutorado\n",
       "29             CRISTIAN VICSON GOMES PINHEIRO   True   Mestrado\n",
       "30           CRISTIANE FRANÇA MARTINS TEODORO   True    Pós-Doc\n",
       "31       Cristiane Mourao Carvalhedo Mesquita  False  Graduação\n",
       "32                  DIEGO DA SILVA DE ALMEIDA   True   Mestrado\n",
       "33                         DIEGO RAMOS AGUIAR   True  Graduação\n",
       "34     DISRAELI CAVALCANTE ARAUJO VASCONCELOS   True  Graduação\n",
       "35                     EDUARDO MENEZES GAIETA   True   Mestrado\n",
       "36                 ELLEN MARIA LIMA GONÇALVES   True  Graduação\n",
       "37             ERIKA ROMERIA FORMIGA DE SOUSA   True  Profsaúde\n",
       "38                       Erlemus Ponte Soares  False  Graduação\n",
       "39          EVANILDO HENRIQUE MACEDO DA COSTA   True  Profsaúde\n",
       "40              Evanizia Pinheiro de Oliveira  False  Graduação\n",
       "41                  FABIO JOSE GOMES DE SOUSA   True  Doutorado\n",
       "42                   Filipe Oliveira de Brito   True  Doutorado\n",
       "43   Francisca Raquel de Vasconcelos Silveira  False  Graduação\n",
       "44                    GABRIEL ACACIO DE MOURA   True  Doutorado\n",
       "45                   Georgea Bezerra Carvalho  False  Graduação\n",
       "46                  GERALDO RODRIGUES SARTORI   True    Pós-Doc\n",
       "47                  GERMANA SILVA VASCONCELOS   True    Pós-Doc\n",
       "48                Gilcelene de Castro Andrade  False  Graduação\n",
       "49     Gilmara Maria Batista Tavares da Silva  False  Graduação\n",
       "50     Gilmara Maria Batista Tavares da Silva   True  Graduação\n",
       "51           GLAZIANE DA SILVA PAIVA BANDEIRA   True    Pós-Doc\n",
       "52                 GRAYCE ALENCAR ALBUQUERQUE   True    Pós-Doc\n",
       "53                 Graziela Jones de Oliveira  False  Graduação\n",
       "54                      GUILHERME ANGELO LOBO   True  Graduação\n",
       "55                        HASSA PEREIRA LEMOS   True  Profsaúde\n",
       "56       HERQUIMEDES GLAUDYS DA SILVA AVELINO   True  Graduação\n",
       "57                     HEVERTON MENDES ARAUJO   True  Graduação\n",
       "58                        IGOR CABRAL STUDART   True  Doutorado\n",
       "59              ISABELLA LIMA BARBOSA CAMPELO   True    Pós-Doc\n",
       "60                        JEAN VIEIRA SAMPAIO   True   Mestrado\n",
       "61                 JOAO EUDES LEMOS DE BARROS   True  Graduação\n",
       "62                JOAO MATHEUS FONTELES SILVA   True  Graduação\n",
       "63                 JOAO PEDRO VIANA RODRIGUES   True  Doutorado\n",
       "64   JOAQUIM CESAR DO NASCIMENTO SOUSA JUNIOR   True   Mestrado\n",
       "65               JOSE MARIA XIMENES GUIMARAES   True    Pós-Doc\n",
       "66             JOSE SAMUEL DOS SANTOS BARBOSA   True   Mestrado\n",
       "67                    JOSETE MALHEIRO TAVARES   True  Graduação\n",
       "68                  JUCILENE PEREIRA DE SOUSA   True    Pós-Doc\n",
       "69              JULIANA MENESES DE SENA SILVA   True   Mestrado\n",
       "70                  JULIANA RAMOS DE OLIVEIRA   True  Doutorado\n",
       "71                KAMILA MARIA OLIVEIRA SALES   True    Pós-Doc\n",
       "72                      KETLEN CHRISTINE OHSE   True  Graduação\n",
       "73             Kilvia Helane Cardoso Mesquita   True    Pós-Doc\n",
       "74              LAECIO PAULO SOUSA DOS SANTOS   True  Doutorado\n",
       "75                    LARISSE CADEIRA BRANDAO   True  Doutorado\n",
       "76        LEA DIAS PIMENTEL GOMES VASCONCELOS   True  Doutorado\n",
       "77                               LENIR SANTOS   True    Pós-Doc\n",
       "78                     LETICIA BASTOS CONRADO   True  Graduação\n",
       "79                  LETICIA FERREIRA ESPINOSA   True  Graduação\n",
       "80               LIANDRA ELLEN COELHO PEREIRA   True   Mestrado\n",
       "81                     Libia Lopes Martiniano  False  Graduação\n",
       "82                  Lílian Fernandes Amarante  False  Graduação\n",
       "83                      LIVIA COELHO DE ASSIS   True  Doutorado\n",
       "84                       Lorena Lodo Santiago  False  Graduação\n",
       "85                     Lorena Morais Nogueira  False  Graduação\n",
       "86                       LUCA MILERIO ANDRADE   True  Doutorado\n",
       "87                   LUCAS ALMEIDA DE FREITAS   True   Mestrado\n",
       "88                   Lucelia Gois de oliveira  False  Graduação\n",
       "89            Luciana Carvalho de Albuquerque  False  Graduação\n",
       "90                     Luis Lopes Sombra Neto  False  Graduação\n",
       "91                      MAISA PESSOA PINHEIRO   True  Doutorado\n",
       "92            MARA MILVIA PONTES MELO RESENDE   True  Profsaúde\n",
       "93                 MARCUS RAFAEL LOBO BEZERRA   True  Doutorado\n",
       "94           Maria Alexandrina Perez da Justa  False  Graduação\n",
       "95        MARIA JOSYCLEY NOVAIS LANDIM SOARES   True   Mestrado\n",
       "96                    MARILIA FAÇANHA TAVARES   True   Mestrado\n",
       "97                     MATHIAS COELHO BATISTA   True   Mestrado\n",
       "98                  Naila Saskia Melo Andrade  False  Graduação\n",
       "99                     NATALIA CAMPOS PARENTE   True   Mestrado\n",
       "100                Neyliane Maria Brito Costa  False  Graduação\n",
       "101     PATRICIA PEREIRA TAVARES DE ALCANTARA   True  Graduação\n",
       "102             Paulo Ricardo Nazario Viecili  False  Graduação\n",
       "103            PEDRO MIGUEL CARNEIRO JERONIMO   True   Mestrado\n",
       "104        PLACIDO EYMARD GOMES SARAIVA FILHO   True  Graduação\n",
       "105                   RAFAELLE DANTAS BEZERRA   True   Mestrado\n",
       "106                     Raquel Bomfim Castelo  False  Graduação\n",
       "107     REGINA GLAUCIA LUCENA AGUIAR FERREIRA   True    Pós-Doc\n",
       "108                     REJANE FERREIRA COSTA   True   Mestrado\n",
       "109                 Renata Castelo da Nobrega  False  Graduação\n",
       "110            RENATO THALES MEDEIROS HOLANDA   True  Graduação\n",
       "111               ROGERIO SAMPAIO DE OLIVEIRA   True  Graduação\n",
       "112                    ROMULO ALVES DE ARAUJO   True  Graduação\n",
       "113         RONNY PETTERSON DOS SANTOS ARAUJO   True    Pós-Doc\n",
       "114                   SAMUEL LUCAS DE ALMEIDA   True  Graduação\n",
       "115    SAMUEL MENESES FELICIO DE ARAUJO COSTA   True  Profsaúde\n",
       "116                Sandhara Ribeiro Rodrigues  False  Graduação\n",
       "117             SANDY KAENA SOARES DE FREITAS  False  Graduação\n",
       "118                   TAINA MARIA LIMA FREIRE   True  Graduação\n",
       "119              Vandre Cabral Gomes Carneiro  False  Graduação\n",
       "120       VANESSA PINHEIRO GONÇALVES FERREIRA   True  Graduação\n",
       "121                      VANIA CARLA DE SOUSA   True  Graduação\n",
       "122              VERA LUCIA DE AZEVEDO DANTAS   True    Pós-Doc\n",
       "123                 VERIDIANA PESSOA MIYAJIMA   True    Pós-Doc\n",
       "124                 Vinicius Saraiva Barretto   True  Graduação\n",
       "125   Vitória Taiana de Melo Lima Albuquerque   True  Graduação\n",
       "126       VIVIAN MAGALHAES BRANDÃO DOS SANTOS   True  Doutorado\n",
       "127         YANA PAULA COELHO CORREIA SAMPAIO   True  Graduação\n",
       "128                       Yasmim Mendes Rocha   True  Graduação\n",
       "129                       YASMIM MENDES ROCHA   True  Doutorado"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preparer = EnvironmentSetup()\n",
    "discent_collab_counter = DiscentCollaborationCounter(dict_list_docents)\n",
    "\n",
    "# fonte_planilha = 'ppgcs_estudantes_2021-2024.xlsx'\n",
    "fonte_planilha = 'fioce_lista_alunos.xlsx'\n",
    "dados_discentes = pd.read_excel(os.path.join(LattesScraper.find_repo_root(),'_data','in_xls',fonte_planilha), header=0)\n",
    "dados_discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d00d9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 quantidade total de alunos, todos vínculos e status\n",
      "127 nomes únicos\n",
      "\n",
      "Tipos de vínculos ['Graduação', 'Mestrado', 'Doutorado', 'Pós-Doc', 'Profsaúde']\n",
      "Quantidades por Nível de graduação\n",
      "vinculo\n",
      "Graduação    61\n",
      "Doutorado    24\n",
      "Mestrado     21\n",
      "Pós-Doc      17\n",
      "Profsaúde     7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  Tipos de status [True, False]\n",
      "Quantidades por Tipos de status\n",
      " ativo\n",
      "True     100\n",
      "False     30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "127 nomes de alunos em todos os status\n",
      " 1. Alana Ligia Saldanha Fernandes\n",
      " 2. Alice Soares De Queiroz\n",
      " 3. Aline De Oliveira Albuquerque\n",
      " 4. Aline Pinto Monteiro Costa Sousa\n",
      " 5. Alison De Sousa Rebouças\n",
      " 6. Alissan Karine Lima Martins\n",
      " 7. Amanda Cavalcante Frota\n",
      " 8. Ana Flavia Pontes Aguiar\n",
      " 9. Ana Julia Ferreira Lima\n",
      "10. Ana Keyla Oliveira Da Silva\n",
      "11. Ana Marilia Soares Cruz\n",
      "12. Ana Patricia Pereira Morais\n",
      "13. Ana Paula Pires Gadelha De Lima\n",
      "14. Ana Virginia Frota Guimaraes\n",
      "15. Andréa Silvia Walter De Aguiar\n",
      "16. Andrielly Henriques Dos Santos Costa\n",
      "17. Angela Donato Maia Malaquias\n",
      "18. Antonia Vanderli Alves Do Nascimento\n",
      "19. Barbara Nepomuceno Guimaraes\n",
      "20. Beatriz Chaves\n",
      "21. Bruna De Sousa Lima\n",
      "22. Brunheld Maia Dutra\n",
      "23. Camila Sillos Rosas Brisighello\n",
      "24. Carlos Antonio De Arroxelas Silva\n",
      "25. Carlos Eduardo De Sousa Praxedes\n",
      "26. Carollyne Ferreira Santiago\n",
      "27. Cassio Pinheiro Oliveira\n",
      "28. Cristian Vicson Gomes Pinheiro\n",
      "29. Cristiane França Martins Teodoro\n",
      "30. Cristiane Mourao Carvalhedo Mesquita\n",
      "31. Diego Da Silva De Almeida\n",
      "32. Diego Ramos Aguiar\n",
      "33. Disraeli Cavalcante Araujo Vasconcelos\n",
      "34. Eduardo Menezes Gaieta\n",
      "35. Ellen Maria Lima Gonçalves\n",
      "36. Erika Romeria Formiga De Sousa\n",
      "37. Erlemus Ponte Soares\n",
      "38. Evanildo Henrique Macedo Da Costa\n",
      "39. Evanizia Pinheiro De Oliveira\n",
      "40. Fabio Jose Gomes De Sousa\n",
      "41. Filipe Oliveira De Brito\n",
      "42. Francisca Raquel De Vasconcelos Silveira\n",
      "43. Gabriel Acacio De Moura\n",
      "44. Georgea Bezerra Carvalho\n",
      "45. Geraldo Rodrigues Sartori\n",
      "46. Germana Silva Vasconcelos\n",
      "47. Gilcelene De Castro Andrade\n",
      "48. Gilmara Maria Batista Tavares Da Silva\n",
      "49. Glaziane Da Silva Paiva Bandeira\n",
      "50. Grayce Alencar Albuquerque\n",
      "51. Graziela Jones De Oliveira\n",
      "52. Guilherme Angelo Lobo\n",
      "53. Hassa Pereira Lemos\n",
      "54. Herquimedes Glaudys Da Silva Avelino\n",
      "55. Heverton Mendes Araujo\n",
      "56. Igor Cabral Studart\n",
      "57. Isabella Lima Barbosa Campelo\n",
      "58. Jean Vieira Sampaio\n",
      "59. Joao Eudes Lemos De Barros\n",
      "60. Joao Matheus Fonteles Silva\n",
      "61. Joao Pedro Viana Rodrigues\n",
      "62. Joaquim Cesar Do Nascimento Sousa Junior\n",
      "63. Jose Maria Ximenes Guimaraes\n",
      "64. Jose Samuel Dos Santos Barbosa\n",
      "65. Josete Malheiro Tavares\n",
      "66. Jucilene Pereira De Sousa\n",
      "67. Juliana Meneses De Sena Silva\n",
      "68. Juliana Ramos De Oliveira\n",
      "69. Kamila Maria Oliveira Sales\n",
      "70. Ketlen Christine Ohse\n",
      "71. Kilvia Helane Cardoso Mesquita\n",
      "72. Laecio Paulo Sousa Dos Santos\n",
      "73. Larisse Cadeira Brandao\n",
      "74. Lea Dias Pimentel Gomes Vasconcelos\n",
      "75. Lenir Santos\n",
      "76. Leticia Bastos Conrado\n",
      "77. Leticia Ferreira Espinosa\n",
      "78. Liandra Ellen Coelho Pereira\n",
      "79. Libia Lopes Martiniano\n",
      "80. Lílian Fernandes Amarante\n",
      "81. Livia Coelho De Assis\n",
      "82. Lorena Lodo Santiago\n",
      "83. Lorena Morais Nogueira\n",
      "84. Luca Milerio Andrade\n",
      "85. Lucas Almeida De Freitas\n",
      "86. Lucelia Gois De Oliveira\n",
      "87. Luciana Carvalho De Albuquerque\n",
      "88. Luis Lopes Sombra Neto\n",
      "89. Maisa Pessoa Pinheiro\n",
      "90. Mara Milvia Pontes Melo Resende\n",
      "91. Marcus Rafael Lobo Bezerra\n",
      "92. Maria Alexandrina Perez Da Justa\n",
      "93. Maria Josycley Novais Landim Soares\n",
      "94. Marilia Façanha Tavares\n",
      "95. Mathias Coelho Batista\n",
      "96. Naila Saskia Melo Andrade\n",
      "97. Natalia Campos Parente\n",
      "98. Neyliane Maria Brito Costa\n",
      "99. Patricia Pereira Tavares De Alcantara\n",
      "100. Paulo Ricardo Nazario Viecili\n",
      "101. Pedro Miguel Carneiro Jeronimo\n",
      "102. Placido Eymard Gomes Saraiva Filho\n",
      "103. Rafaelle Dantas Bezerra\n",
      "104. Raquel Bomfim Castelo\n",
      "105. Regina Glaucia Lucena Aguiar Ferreira\n",
      "106. Rejane Ferreira Costa\n",
      "107. Renata Castelo Da Nobrega\n",
      "108. Renato Thales Medeiros Holanda\n",
      "109. Rogerio Sampaio De Oliveira\n",
      "110. Romulo Alves De Araujo\n",
      "111. Ronny Petterson Dos Santos Araujo\n",
      "112. Samuel Lucas De Almeida\n",
      "113. Samuel Meneses Felicio De Araujo Costa\n",
      "114. Sandhara Ribeiro Rodrigues\n",
      "115. Sandy Kaena Soares De Freitas\n",
      "116. Taina Maria Lima Freire\n",
      "117. Vandre Cabral Gomes Carneiro\n",
      "118. Vanessa Pinheiro Gonçalves Ferreira\n",
      "119. Vania Carla De Sousa\n",
      "120. Vera Lucia De Azevedo Dantas\n",
      "121. Veridiana Pessoa Miyajima\n",
      "122. Vinicius Saraiva Barretto\n",
      "123. Vitória Taiana De Melo Lima Albuquerque\n",
      "124. Vivian Magalhaes Brandão Dos Santos\n",
      "125. Yana Paula Coelho Correia Sampaio\n",
      "126. Yasmim Mendes Rocha\n",
      "\n",
      "126 nomes únicos de alunos para extrair currículos\n"
     ]
    }
   ],
   "source": [
    "# Ler dados do arquivo Excel do Setor de Recursos Humanos\n",
    "pathdata = '_data/in_xls/'\n",
    "datasheet = 'fioce_lista_alunos.xlsx'\n",
    "\n",
    "# Ler apenas os cabeçalhos do arquivo Excel\n",
    "headers = pd.read_excel(pathdata+datasheet, skiprows=0, header=0, nrows=0).columns\n",
    "# headers\n",
    "\n",
    "# Indicar quais colunas devem ser eliminadas na leitura\n",
    "def cols_to_keep(col_name):\n",
    "    return col_name not in []\n",
    "\n",
    "# Filtrar cabeçalhos com base na função\n",
    "selected_columns = [col for col in headers if cols_to_keep(col)]\n",
    "\n",
    "# Ler dados do arquivo Excel do Setor de Recursos Humanos\n",
    "fioce_alunos = pd.read_excel(pathdata+datasheet, skiprows=0, header=0, usecols=selected_columns)\n",
    "print(f'{len(fioce_alunos.index)} quantidade total de alunos, todos vínculos e status')\n",
    "print(f'{len(fioce_alunos[\"nome\"].unique()):3} nomes únicos')\n",
    "\n",
    "print('\\nTipos de vínculos',list(fioce_alunos['vinculo'].unique()))\n",
    "print(f\"Quantidades por Nível de graduação\\n{fioce_alunos['vinculo'].value_counts()}\")\n",
    "\n",
    "print('\\n  Tipos de status',list(fioce_alunos['ativo'].unique()))\n",
    "print('Quantidades por Tipos de status\\n',(fioce_alunos['ativo'].value_counts()))\n",
    "filtro1 = fioce_alunos['vinculo'].isin(['Graduação', 'Mestrado', 'Doutorado', 'Pós-Doc', 'Profsaúde'])\n",
    "filtro2 = fioce_alunos['ativo'].isin([True, False])\n",
    "# filtro2 = fioce_alunos['ativo'].isin([True])\n",
    "lista_nomes = fioce_alunos[(filtro1) & (filtro2)]['nome'].unique().tolist()\n",
    "\n",
    "print(f'\\n{len(lista_nomes)} nomes de alunos em todos os status')\n",
    "lista_busca_alunos = []\n",
    "for i,nome in enumerate(lista_nomes):\n",
    "    if nome.strip().title() not in lista_busca_alunos:\n",
    "        lista_busca_alunos.append(nome.strip().title())\n",
    "        print(f'{i+1:2}. {nome.title()}')\n",
    "\n",
    "print(f'\\n{len(lista_busca_alunos)} nomes únicos de alunos para extrair currículos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd233282",
   "metadata": {},
   "source": [
    "## <b>Processar extração de dados de Discentes</b>\n",
    "    (~80min/93nomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f53916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discent_collab_counter = DiscentCollaborationCounter(dict_list_docents)\n",
    "# print(f'{len(lista_busca_alunos)} discentes relacionados aos programas')\n",
    "\n",
    "# lista_normalizada_discentes=[]\n",
    "# for i in lista_busca_alunos:\n",
    "#     lista_normalizada_discentes.append(discent_collab_counter.iniciais_nome(i))\n",
    "\n",
    "# t1 = time.time()\n",
    "# termos_busca = ['Cruz', 'Família', 'Biotecnologia', 'Ceará']\n",
    "# scraper = LattesScraper(termos_busca, \n",
    "#                         'bolt://localhost:7687', 'neo4j', 'password', \n",
    "#                         only_doctors=False)\n",
    "\n",
    "# # Extrai e monta JSON com a lista de dicionários\n",
    "# discents_dict_list = scraper.scrape(lista_busca_alunos, termos_busca)\n",
    "# print(f'\\n{scraper.tempo(t1,time.time())} para busca de {len(lista_busca_alunos)} nomes com extração de dados de {len(discents_dict_list)} dicionários')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Contagem de artigos para simples confererência\n",
    "# print(f'{len(discents_dict_list)} dicionários montados')\n",
    "# qte_artigos=0\n",
    "# qte_titulos=0\n",
    "# for k,i in enumerate(discents_dict_list):\n",
    "#     try:\n",
    "#         qte_jcr = len(i.get('Produções').get('Artigos completos publicados em periódicos'))\n",
    "#     except:\n",
    "#         qte_jcr = 0\n",
    "#     try:\n",
    "#         qte_jcr2 = len(i['JCR2'])\n",
    "#     except:\n",
    "#         qte_jcr2 = 0\n",
    "\n",
    "#     qte_artigos+=qte_jcr\n",
    "#     qte_titulos+=qte_jcr2\n",
    "#     status=qte_jcr2-qte_jcr\n",
    "#     print(f\"{k:>2}C {qte_jcr:>03}A {qte_jcr2:>03}T Dif:{status:>03} {i.get('Identificação').get('name')} \")\n",
    "\n",
    "# print(f'\\nTotal de artigos em todos períodos: {qte_artigos}')\n",
    "# print(f'Total de títulos em todos períodos: {qte_titulos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee9510",
   "metadata": {},
   "source": [
    "### Identificar currículos remanescentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d50745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# termos_busca = ['Cruz', 'Família', 'Biotecnologia', 'Ceará']\n",
    "# lista_restante = scraper.avaliar_remanescentes(lista_busca_alunos, discents_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff94827d",
   "metadata": {},
   "source": [
    "### Adicionar nomes ou novos termos, se necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ddca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lista_restante.append('Caroline Pereira Bittencourt Passaes')\n",
    "# for i in lista_restante:\n",
    "#     print(f'   {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a0e284",
   "metadata": {},
   "source": [
    "### Extrair currículos remanescentes ou adicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lista_dict_combinado = extract_remanescents(lista_restante, dict_list_actual)\n",
    "# lista_dict_combinado = scraper.extract_remanescents(lista_restante, discents_dict_list, termos_busca)\n",
    "# filepath = os.path.join(folder_data_input,'dict_list_discents.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b62ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'{len(lista_dict_combinado)} dicionários de discentes extraídos')\n",
    "# try:\n",
    "#     exemplo = [x.get('Produções') for x in lista_dict_combinado][0].get('Artigos completos publicados em periódicos')[0]\n",
    "#     if exemplo:\n",
    "#         print('\\n\\nExemplo de dados dos artigos:')\n",
    "#         print(exemplo)\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6063e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 dicionários com currículos completos extraídos\n",
      "\n",
      "\n",
      "Exemplo de dados dos artigos:\n",
      "\n",
      "\n",
      "Exemplo de dados dos artigos:\n",
      "{'ano': '2019', 'fator_impacto_jcr': '', 'ISSN': '01001302', 'titulo': 'Relação entre a atividade inflamatória e o estado nutricional de pacientes com câncer de pulmão', 'revista': 'REVISTA DE MEDICINA DA UNIVERSIDADE FEDERAL DO CEARÁ', 'autores': 'SOUZA, BENEDITA JALES2019SOUZA, BENEDITA JALES ; MESQUITA, ARMÊNIA UCHÔA DE ; MEIRELES, AMANDA ROCHA ; BRITO, JULIANA GIRÃO DE ; BANDEIRA, THALITA EVANGELISTA ;ROCHA, JOSÉ AURILLO. ', 'data_issn': '01001302', 'DOI': 'http://dx.doi.org/10.20513/2447-6595.2019v59n2p9-14', 'Qualis': 'B3'}\n"
     ]
    }
   ],
   "source": [
    "from lattes_scrapper import GetQualis\n",
    "stratifier = GetQualis()\n",
    "\n",
    "# Acrescentar Qualis periódicos aos dicionários de docentes\n",
    "print('\\nAdicionando Qualis Periódicos')\n",
    "pathfilename = os.path.join(folder_data_input,'docents_farmacology_dict_list.json')\n",
    "stratifier.buscar_qualis_e_atualizar_arquivo(lista_dict_combinado, pathfilename)\n",
    "scraper.save_to_json(lista_dict_combinado, pathfilename)\n",
    "\n",
    "print(f'{len(lista_dict_combinado)} dicionários com currículos completos extraídos')\n",
    "print('\\n\\nExemplo de dados dos artigos:')\n",
    "try:\n",
    "    exemplo = [x.get('Produções') for x in lista_dict_combinado][0].get('Artigos completos publicados em periódicos')[0]\n",
    "    if exemplo:\n",
    "        print('\\n\\nExemplo de dados dos artigos:')\n",
    "        print(exemplo)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd1f79a",
   "metadata": {},
   "source": [
    "# F02a: Ler dados salvos de Discentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc99d37",
   "metadata": {},
   "source": [
    "### Listar arquivos salvos na pasta de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15d44b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['categorias_capes.txt',\n",
       " 'classificações_publicadas_todas_as_areas_avaliacao1672761192111.xlsx',\n",
       " 'cnpq_tabela-areas-conhecimento.pdf',\n",
       " 'combined_dict_list.json',\n",
       " 'dict_list_discents_combined.json',\n",
       " 'dict_list_temp.json',\n",
       " 'discents_dict_list.json',\n",
       " 'docents_dict_list.json',\n",
       " 'indicadores.csv',\n",
       " 'nomesdocentes.csv',\n",
       " 'portal_fiocruz_tecnologias.csv',\n",
       " 'ppgcs',\n",
       " 'prompts_hardware.txt',\n",
       " 'qlattes',\n",
       " 'temp_dict_list.json',\n",
       " 'veiculos.csv']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_data_input = os.path.join(os.getcwd(),'_data','in_csv')\n",
    "os.listdir(folder_data_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e72eea",
   "metadata": {},
   "source": [
    "### Carregar dados completos dos Discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83177667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 Total de currículos extaídos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Alana Lígia Saldanha Fernandes',\n",
       " 'Alice Soares de Queiroz',\n",
       " 'Aline de Albuquerque Oliveira',\n",
       " 'Aline Pinto Monteiro Costa Sousa',\n",
       " 'Alison de Sousa Rebouças',\n",
       " 'Alissan Karine Lima Martins',\n",
       " 'Amanda Cavalcante Frota',\n",
       " 'Ana Júlia Ferreira Lima',\n",
       " 'Ana Keyla Oliveira da Silva',\n",
       " 'Ana Marilia Soares Cruz',\n",
       " 'Ana Patrícia Pereira Morais',\n",
       " 'Ana Paula Pires Gadelha de Lima',\n",
       " 'Ana Virgínia Frota Guimarães',\n",
       " 'Andréa Silvia Walter de Aguiar',\n",
       " 'Andrielly Henriques dos Santos Costa',\n",
       " 'Angela Donato Maia Malaquias',\n",
       " 'Antonia Vanderli Alves do Nascimento',\n",
       " 'Carlos Antônio de Arroxelas Silva',\n",
       " 'Carlos Eduardo de Sousa Praxedes',\n",
       " 'Carollyne Ferreira Santiago',\n",
       " 'Cassio Pinheiro Oliveira',\n",
       " 'Cristian Vicson Gomes Pinheiro',\n",
       " 'Cristiane Mourao Carvalhedo Mesquita',\n",
       " 'Diego da Silva de Almeida',\n",
       " 'Diego Ramos Aguiar',\n",
       " 'Disraeli Cavalcante Araujo Vasconcelos',\n",
       " 'Eduardo Menezes Gaieta',\n",
       " 'Ellen Maria Lima Gonçalves',\n",
       " 'Érika Roméria Formiga de Sousa',\n",
       " 'Erlemus Ponte Soares',\n",
       " 'Evanildo Henrique Macêdo da Costa',\n",
       " 'Evanizia Pinheiro de Oliveira',\n",
       " 'Fábio José Gomes de Sousa',\n",
       " 'Filipe Oliveira de Brito',\n",
       " 'Francisca Raquel de Vasconcelos Silveira',\n",
       " 'Gabriel Acácio de Moura',\n",
       " 'Georgea Bezerra Carvalho',\n",
       " 'Geraldo Rodrigues Sartori',\n",
       " 'Germana Silva Vasconcelos',\n",
       " 'Gilcelene de Castro Andrade',\n",
       " 'Gilmara Maria Batista Tavares da Silva',\n",
       " 'Glaziane da Silva Paiva Bandeira',\n",
       " 'Grayce Alencar Albuquerque',\n",
       " 'Graziela Jones de Oliveira',\n",
       " 'Guilherme Angelo Lobo',\n",
       " 'Hassã Pereira Lemos',\n",
       " 'Herqüimedes Glaudys da Silva Avelino',\n",
       " 'Héverton Mendes Araújo',\n",
       " 'Igor Cabral Studart',\n",
       " 'Isabella Lima Barbosa Campelo',\n",
       " 'Jean Vieira Sampaio',\n",
       " 'João Eudes Lemos de Barros',\n",
       " 'João Matheus Fonteles Silva',\n",
       " 'João Pedro Viana Rodrigues',\n",
       " 'Joaquim Cesar do Nascimento Sousa Júnior',\n",
       " 'Jose Maria Ximenes Guimaraes',\n",
       " 'Jose Samuel dos santos barbosa',\n",
       " 'Josete Malheiro Tavares',\n",
       " 'Jucilene Pereira de Sousa',\n",
       " 'Juliana Meneses de Sena Silva',\n",
       " 'Juliana Ramos de Oliveira',\n",
       " 'Kamila Maria Oliveira Sales',\n",
       " 'Ketlen Christine Ohse',\n",
       " 'Kilvia Helane Cardoso Mesquita',\n",
       " 'Laécio Paulo Sousa dos Santos',\n",
       " 'Larisse Cadeira Brandão',\n",
       " 'Léa Dias Pimentel Gomes Vasconcelos',\n",
       " 'Leticia Bastos Conrado',\n",
       " 'Letícia Ferreira Espinosa',\n",
       " 'Liandra Éllen Coelho Pereira',\n",
       " 'Líbia Lopes Martiniano',\n",
       " 'Lílian Fernandes Amarante',\n",
       " 'Lívia Coêlho de Assis',\n",
       " 'Lorena Lodo Santiago',\n",
       " 'Lorena Morais Nogueira',\n",
       " 'Luca Milério Andrade',\n",
       " 'Lucas Almeida de Freitas',\n",
       " 'Lucélia Góis de Oliveira Arruda',\n",
       " 'Luciana Carvalho de Albuquerque',\n",
       " 'Luis Lopes Sombra Neto',\n",
       " 'Maísa Pessoa Pinheiro',\n",
       " 'Mara Milvia Pontes Melo Resende',\n",
       " 'Marcus Rafael Lobo Bezerra',\n",
       " 'Maria Alexandrina Perez da Justa',\n",
       " 'Maria Josycley Novais Landim Soares',\n",
       " 'Marília Façanha Tavares',\n",
       " 'Mathias Coelho Batista',\n",
       " 'Naila Saskia Melo Andrade',\n",
       " 'Natália Campos Parente',\n",
       " 'Neyliane Maria Brito Costa',\n",
       " 'Patrícia Pereira Tavares de Alcantara',\n",
       " 'Paulo Ricardo Nazário Viecili',\n",
       " 'Pedro Miguel Carneiro Jeronimo',\n",
       " 'Plácido Eymard Gomes Saraiva Filho',\n",
       " 'Rafaelle Dantas Bezerra',\n",
       " 'Raquel Bomfim Castelo',\n",
       " 'Regina Glaucia Lucena Aguiar Ferreira',\n",
       " 'Rejane Ferreira Costa',\n",
       " 'Renato Thales Medeiros Holanda',\n",
       " 'Rogério Sampaio de Oliveira',\n",
       " 'Rômulo Mendanha de Araújo Alves',\n",
       " 'Ronny Petterson dos Santos Araújo',\n",
       " 'Samuel Lucas de Almeida',\n",
       " 'Samuel Meneses Felicio de Araujo Costa',\n",
       " 'Sandhara Ribeiro Rodrigues',\n",
       " 'Sandy Kaena Soares de Freitas',\n",
       " 'Tainá Maria Lima Freire',\n",
       " 'Vandré Cabral Gomes Carneiro',\n",
       " 'Vânia Carla de Sousa',\n",
       " 'Vera Lúcia de Azevedo Dantas',\n",
       " 'Veridiana Pessoa Miyajima',\n",
       " 'Vinícius Saraiva Barretto',\n",
       " 'Vitória Taiana de Melo Lima Albuquerque',\n",
       " 'Vivian Magalhães Brandão dos Santos',\n",
       " 'Yana Paula Coêlho Correia Sampaio',\n",
       " 'Yasmim Mendes Rocha',\n",
       " 'Barbara Nepomuceno Guimarães',\n",
       " 'Beatriz Chaves',\n",
       " 'Bruna de Sousa Lima',\n",
       " 'Brunheld Maia Dutra',\n",
       " 'Camila Sillos Rosas Brisighello']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'discents_dict_list.json'\n",
    "pathfilename = os.path.join(folder_data_input, filename)\n",
    "dict_list_discents, formatted_creation_date, formatted_modification_date, time_count, unit = jfm.load_from_json(pathfilename)\n",
    "print(f'{len(dict_list_discents)} Total de currículos extaídos')\n",
    "[i.get('Identificação').get('Nome') for i in dict_list_discents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7838e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar orientações nos dados de docentes\n",
    "# [x.get('Orientações') for x in dict_list_discents if x.get('Orientações')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cd37f",
   "metadata": {},
   "source": [
    "# <b>F03: Avaliar colaboração discente/docentes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8666c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dic in dict_list_discents:\n",
    "#     a = dic.get('Produções', {}).get('Artigos completos publicados em periódicos', {})\n",
    "#     print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e25a3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 discentes no período 2021-2024 informados pelos programa\n",
      "========================================================================================================================\n",
      "42 currículos a analisar colaborações\n",
      "ANO 2021 DOI http://dx.doi.org/10.1038/s41598-021-83203-2        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.ijid.2021.01.001        com colaboração com discente 'SILVA, P d C d'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 1 dos 2 artigos de Alice Paula Di Sabatino Guimarães, perfazendo 50.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/1413-81232023289.13142022 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/1981-7746-ojs275          nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 1 dos 2 artigos de Ana Cláudia de Araújo Teixeira, perfazendo 50.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2022 DOI http://dx.doi.org/10.3390/microorganisms10112188    nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.parint.2020.102273      com colaboração com discente 'SILVA, P d C d'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 1 dos 2 artigos de Ana Camila Oliveira Alves, perfazendo 50.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.1186/s12911-023-02406-x        nome de discente em coautorias não encontrado\n",
      "ANO 2024 DOI http://dx.doi.org/10.1016/j.nutos.2024.02.008       nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.12873/424pereira               nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.clnesp.2022.11.004      nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.12662/2317-3076jhbs.v9i1.3386.p1-5.2021 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2019 DOI http://dx.doi.org/10.1016/j.clnesp.2019.09.007      com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2019 DOI http://dx.doi.org/10.3390/nu11092211                nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.clnesp.2016.11.001      nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.12957/demetra.2016.22542       com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2017 DOI http://dx.doi.org/10.12957/demetra.2016.22542       nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 3 dos 10 artigos de Adriana Costa Bacelo, perfazendo 30.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.1016/j.drudis.2024.103967      nome de discente em coautorias não encontrado\n",
      "ANO 2024 DOI http://dx.doi.org/10.1007/s40291-024-00713-1        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.jviromet.2023.114787    nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.ijbiomac.2021.06.043    com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1007/s40291-021-00533-7        nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.22239/2317-269x.01033          nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 2 dos 6 artigos de Anna Carolina Machado Marinho, perfazendo 33.33% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/v15091903                 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2018 DOI http://dx.doi.org/10.9771/cp.v12i3.27256            com colaboração com discente 'SILVA, P d C d'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 2 dos 2 artigos de Antonio Marcos Aires Barbosa, perfazendo 100.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.4317/jced.61247                nome de discente em coautorias não encontrado\n",
      "ANO 2024 DOI http://dx.doi.org/10.1590/1980-549720240022         nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/0102-311XEN022122         nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1007/s10900-023-01221-9        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/1413-81232023288.07272023 nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/1413-81232023288.06462023 nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/1413-81232023288.07042023 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/0102-311XEN007223         nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1093/ijcoms/lyad014            nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.54620/cadesp.v17i1.1712        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.22161/ijaers.91.33             nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.22161/ijaers.94.27             nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.37118/ijdr.24443.05.2022       nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.37118/ijdr.24443.05.2022       nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/interface.210530          com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/interface.220555          nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.4215/rm2022.e21021             nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1093/trstmh/traa182            nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/interface.200516          nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021262.29922020 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/0034-7167-2019-0769       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1371/journal.pone.0249275      nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.05352021 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.03722021 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/0103-1104202112912        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.5005/jp-journals-10024-3096    nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.04432021 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.04352021 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.22161/ijaers.74.42             nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.22161/ijaers.74.42             nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.11606/s1518-8787.2020054001878 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1111/scd.12495                 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.1017/dmp.2020.342              nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/interface.190640          nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1089/tmj.2020.0138             nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1089/tmj.2020.0138             nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/1413-81232018243.30922016 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/0034-7167-2018-0033       nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.17269/s41997-019-00246-9       nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1093/fampra/cmz040             nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1017/s1041610218000145         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1111/phn.12529                 nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1186/s12889-018-6084-3         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1186/s12889-018-6084-3         nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1981-22562017020.160070   nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1981-22562017020.160070   nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1981-7746-sol00072        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1981-7746-sol00072        nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 7 dos 48 artigos de Anya Pimentel Gomes Fernandes Vieira Meyer, perfazendo 14.58% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.1016/j.drudis.2024.103967      nome de discente em coautorias não encontrado\n",
      "ANO 2024 DOI http://dx.doi.org/10.1007/s40291-024-00713-1        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2024 DOI http://dx.doi.org/10.1016/j.intimp.2024.112215      com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.jviromet.2023.114787    nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1007/s12033-023-00831-x        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.15406/japlr.2022.11.00399      nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1155/2022/2748962              com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.1080/07391102.2022.2148128     nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1080/07391102.2022.2107072     nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.bbrc.2020.12.074        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.ijbiomac.2021.06.043    com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1007/s40291-021-00533-7        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.ijbiomac.2021.10.126    nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.ijbiomac.2020.10.031    com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.ijbiomac.2020.10.062    com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/s1678-3921.pab2020.v55.01756 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2019 DOI http://dx.doi.org/10.1002/jlb.ma1118-463r           com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/0037-8682-0526-2018       com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2018 DOI http://dx.doi.org/10.3390/toxins10040142            nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.3390/toxins10040142            com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.ijbiomac.2018.07.141    nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.3389/fimmu.2017.00653          nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.tiv.2017.02.003         com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.ijbiomac.2017.05.076    com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.ttbdis.2017.05.006      nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.ijbiomac.2017.07.140    com colaboração com discente 'SILVA, P d C d'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 13 dos 26 artigos de Carla Freire Celedonio Fernandes, perfazendo 50.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.3389/fimmu.2024.1354786        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/ph16060814                nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3389/fmed.2022.839389          nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1007/s11696-020-01383-z        nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 0 dos 4 artigos de Claudia Stutz Zubieta, perfazendo 0.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.1123/jpah.2023-0370            nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1371/journal.pntd.0011388      nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1371/journal.pone.0287665      nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1111/pim.12947                 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1111/pim.12805                 nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.actatropica.2017.10.009 nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.3389/fmicb.2018.00881          nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.3389/fimmu.2018.02779          com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2018 DOI http://dx.doi.org/10.3389/fimmu.2018.02558          com colaboração com discente 'SILVA, P d C d'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 2 dos 9 artigos de Clarissa Romero Teixeira, perfazendo 22.22% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2023 DOI                                                     com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.6061/clinics/2021/e2902        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2017 DOI http://dx.doi.org/10.1097/QAD.0000000000001580      com colaboração com discente 'SILVA, P d C d'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 3 dos 3 artigos de Dayane Alves Costa, perfazendo 100.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2019 DOI http://dx.doi.org/10.1002/pro.3605                  nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.3390/toxins10090373            nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1080/08916934.2017.1344975     com colaboração com discente 'SILVA, P d C d'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 1 dos 3 artigos de Donat Alexander de Chapeaurouge, perfazendo 33.33% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.3389/fpubh.2023.1330347        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3201/eid2806.220061            nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1128/spectrum.02641-21         com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.1128/spectrum.02366-21         nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 1 dos 4 artigos de Eduardo Ruback dos Santos, perfazendo 25.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.vaccine.2023.02.019     nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.26633/rpsp.2022.101            nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1128/spectrum.02641-21         nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3389/fmed.2022.1008600         nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.7554/elife.78233               nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3390/vaccines10091437          nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.isci.2022.104156        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1099/mgen.0.000751             nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1128/spectrum.02366-21         nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.bjid.2021.102082        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1038/s41467-022-33713-y        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/s1678-9946202264014       com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1371/journal.ppat.1010015      nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.3389/fphar.2021.766293         nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1371/journal.pone.0260087      nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.bjid.2020.101102        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.jep.2020.113735         nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.biopha.2021.111677      nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.3390/v13050724                 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1097/INF.0000000000002559      nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1093/cid/ciaa1038              nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1186/s12879-020-05611-5        nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.3389/fonc.2020.01565           nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.3389/fimmu.2019.01207          nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1038/s41419-019-2129-5         nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1089/acm.2019.0134             nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1177/0269881119875979          nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1007/s12031-018-1044-z         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/0037-8682-0440-2017       nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.jpsychires.2018.10.003  nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.jep.2018.07.025         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.jneuroim.2018.04.009    nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.jep.2017.02.026         nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.3389/fphar.2017.00092          nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.22159/ijpps.2017v9i5.17086     nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1371/journal.pntd.0005679      nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1007/s12035-017-0616-1         nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1128/JCM.01384-17              nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 2 dos 38 artigos de Fabio Miyajima, perfazendo 5.26% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.vaccine                 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1128/spectrum.02641-21         com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.3389/fmed.2022.1008600         nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1128/spectrum.02366-21         nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1038/s41598-021-89409-8        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.3389/fmicb.2021.711107         nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1371/journal.pntd.0009556      nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.3390/insects11020092           nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1371/journal.pntd.0007023      nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1371/journal.pntd.0006339      nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1371/journal.pntd.0005947      nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 1 dos 11 artigos de Fernando Braga Stehling Dias, perfazendo 9.09% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI                                                     nome de discente em coautorias não encontrado\n",
      "ANO 2024 DOI                                                     nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/1413-81232023289.13142022 nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/1413-81232023289.13542022 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/1413-81232023289.13542022 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.31011/reaid-2022-v.96-n.39-art.1461 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/0103-1104202213210        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/1981-7746-ojs275          nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/2317-6369000028719        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/2317-6369000028719        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/2317-6369000028719        nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/1981-7746-sol00298        nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/1413-812320202512.30692020 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/1413-812320202512.30692020 nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/0103-11042019S8031        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/0103-11042019S8031        nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/0103-11042019S8031        nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1371/currents.dis.c226851ebd64290e619a4d1ed79c8639 nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1371/currents.dis.c226851ebd64290e619a4d1ed79c8639 nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1371/currents.dis.c226851ebd64290e619a4d1ed79c8639 nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1807-57622016.0666        nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1413-812320172210.17112017 nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1807-57622016.0235        nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 2 dos 23 artigos de Fernando Ferreira Carneiro, perfazendo 8.7% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2022 DOI http://dx.doi.org/10.14295/aps.v4i2.250             nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.25761/anaisihmt.371            nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.25761/anaisihmt.374            nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.14295/aps.v3i2.210             nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.33805/2573.3877.151            com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.21874/rsp.v71i3.3955           nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.21874/rsp.v70i2.3142           nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/0103-11042019s519         nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/0103-11042019s519         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.21450/rahis.v14i4.4482         nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 1 dos 10 artigos de Galba Freire Moita, perfazendo 10.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.12933/therya_notes-24-151      nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.9771/cp.v16i5.51758            nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.4322/2675-9225.00042022        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1186/s42826-020-00082-w        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1186/s42826-020-00082-w        nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1111/mmi.13653                 nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 0 dos 6 artigos de Giovanny Augusto Camacho Antevere Mazzarotto, perfazendo 0.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2023 DOI http://dx.doi.org/10.3389/fcell.2023.1116805        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/v15091903                 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.ijbiomac.2021.12.104    nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1017/s0967199422000478         com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.foodchem.2021.130460    nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1038/s41598-021-97058-0        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.ijbiomac.2021.06.043    com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2019 DOI http://dx.doi.org/10.1016/j.foodchem.2019.125574    nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1080/15592294.2019.1640546     nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1186/s13104-019-4836-5         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.ijbiomac.2018.07.141    nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.ijbiomac.2018.09.022    nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.3389/fimmu.2017.00653          nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1042/bsr20170969               nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 2 dos 14 artigos de Gilvan Pessoa Furtado, perfazendo 14.29% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.procs.2023.01.411       nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.29397/reciis.v17i3.3728        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.20513/2447-6595.2023v63n1e81352p1-6 nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/0102-311XPT048823         com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2023 DOI http://dx.doi.org/10.55905/revconv.16n.11-013       nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/0103-11042022E109         nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/0103-1104202213406        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.srhc.2022.100722        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1017/dmp.2022.214              nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.11606/s1518-8787.2022056004907 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1177/20552076221129071         nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/S0104-12902022210601      nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1093/trstmh/traa182            nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.04432021 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.04072021 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/0103-1104202113114        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.04162021 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.1371/journal.pone.0236091      nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/interface.190640          nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1177/2632077020970875          nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/interface.170691          nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.36517/resdite.v4.n2.2019.a9    nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.36517/resdite.v4.n2.2019.a9    nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/1807-57622017.0183        nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/0103-11042018s108         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.5020/18061230.2018.8774        nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/1807-57622016.0860        nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1413.81232017224.26982016 nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.2471/blt.16.178236             nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.2471/blt.16.178236             nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.2471/blt.16.178236             nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.2471/blt.16.178236             nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1807-57622016.0859        nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1807-57622016.0859        nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 2 dos 34 artigos de Ivana Cristina de Holanda Cunha Barreto, perfazendo 5.88% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.1007/s11756-023-01516-1        nome de discente em coautorias não encontrado\n",
      "ANO 2024 DOI http://dx.doi.org/10.1016/j.actatropica.2024.107168 nome de discente em coautorias não encontrado\n",
      "ANO 2024 DOI http://dx.doi.org/10.1002/cbdv.202400187            nome de discente em coautorias não encontrado\n",
      "ANO 2024 DOI http://dx.doi.org/10.1111/fcp.13007                 nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1111/fcp.13007                 nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1080/00275514.2023.2170209     nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.3389/fphar.2023.1144074        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/molecules28041819         com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.micpath.2023.106058     nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.fbio.2023.102621        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/plants12081587            nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.sajb.2023.04.021        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2023 DOI http://dx.doi.org/10.16891/2317-434X.v11.e2.a2023.pp2125-2134 nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/plants12081675            nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/analytica4020012          com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2023 DOI http://dx.doi.org/10.18332/popmed/163804            nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.18332/popmed/163802            nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/plants12122377            nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.micpath.2023.106246     nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/molecules28155653         nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/pharmaceutics15102400     nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1002/cbdv.202300906            nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.cbi.2023.110751         com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/antibiotics12111565       nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.sdentj.2023.09.011      nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.biopha.2023.115249      nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.ijbiomac.2021.11.209    nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1007/s43450-022-00230-4        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1007/s13205-022-03126-1        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.hermed.2021.100506      nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.foodchem.2022.132614    nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.sajb.2022.03.017        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.jksus.2022.101995       nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1155/2022/8217380              nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.phyplu.2022.100306      nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1155/2022/2260083              nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3389/fphar.2022.975079         nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.biopha.2022.113478      nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.32811/25954482-2022v5n3.685    nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3389/fphar.2022.953982         nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.jiph.2021.09.028        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.2174/1389200221999210104204718 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.16891/2317-434x.v9.e1.a2021.pp823-832 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1007/s10668-021-01281-8        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.3390/biom11030361              nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.bcab.2021.101958        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1000/riec.v4i1.214.g156        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.33448/rsd-v10i3.13202          nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1007/s00203-021-02304-8        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1007/s00284-021-02611-9        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.sajb.2021.07.017        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.phyplu.2021.100100      com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.sajb.2021.07.046        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1007/s00011-021-01461-2        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1080/22311866.2021.1987322     com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.3390/antibiotics10091074       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.phymed.2021.153768      nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.3390/foods10112683             nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.3390/molecules26237400         com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.jgar.2020.11.027        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.2174/1389200221999200730212721 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.fct.2019.111023         nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.indcrop.2020.112106     nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.foodchem.2020.126277    nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.3390/molecules25092181         nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.micpath.2020.104223     nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.3390/antibiotics9050247        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.3390/biology9060114            nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1515/znc-2020-0034             nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.foodchem.2020.127776    nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.34117/bjdv6n8-001              nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.3390/antibiotics9010027        nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.3390/membranes10090194         nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1080/17474086.2020.1817736     nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.chemphyslip.2020.104987 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1007/s12088-020-00910-6        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.3390/ijms21239209              com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.34119/bjhrv3n6-074             nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.4103/2221-1691.254606          nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.16891/2317-434x.v7.e2.a2019.pp318-324 nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.3390/toxins11120705            nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.fct.2018.04.041         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.micpath.2018.07.040     nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.fct.2018.08.068         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.7717/peerj.5991                nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.biopha.2017.02.005      nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.fct.2017.02.027         nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.fct.2017.02.027         nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1080/0972060X.2017.1301220     nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.sajb.2017.06.029        nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.jphotobiol.2017.07.027  nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.apjtb.2017.09.018       nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.micpath.2017.10.052     nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1080/14786419.2017.1312396     nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 14 dos 94 artigos de Jaime Ribeiro Filho, perfazendo 14.89% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2023 DOI                                                     nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.csbj.2023.04.008        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.compbiomed.2023.106941  nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1186/s12936-021-04020-6        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1021/acs.jcim.1c01122          nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3390/life12070932              nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1021/acs.jcim.2c00596          nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3390/ph15101260                nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3389/fddsv.2022.1032587        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1111/ppl.13847                 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1080/07391102.2021.1885492     nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/0074-02760200584          nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1159/000518721                 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.intimp.2020.106640      nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1021/acsomega.0c00226          nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1007/s10863-018-9784-6         nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1007/s10863-019-09810-x        nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.2147/AABC.S197119              nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1371/journal.pntd.0005344      nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.3389/fimmu.2017.00077          nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.bbrc.2017.03.070        nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.jmgm.2017.08.007        nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 0 dos 22 artigos de João Hermínio Martins da Silva, perfazendo 0.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.15560/20.1.1                   nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1007/s10531-023-02553-7        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1017/ext.2022.2                nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1126/sciadv.abo5774            nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.31687/saremnms22.5.1           nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1515/mammalia-2021-0196        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.5091/plecevo.90511             com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1111/gcb.15712                 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.1002/ecy.3115                  nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.5380/avs.v25i2.72238           nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/1678-4162-11507           nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/S0140-6736(20)31920-6     nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.31687/saremMN.20.27.1.0.25     nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.geobios.2020.06.007     nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1002/ecy.3128                  nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.3390/ijerph16152679            nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.4257/oeco.2019.2303.20         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.7717/peerj.4200                nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.17525/vrrjournal.v23i1.334     nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1186/s13071-018-2742-7         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.actatropica.2018.08.026 nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1186/s12917-018-1603-0         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/0001-3765201820180460     nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 2 dos 23 artigos de José Luís Passos Cordeiro, perfazendo 8.7% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI                                                     nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.procs.2023.01.411       nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.molimm.2023.09.001      nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.55905/revconv.16n.11-013       nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.29397/reciis.v17i3.3728        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1002/jmv.27604                 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1002/jmv.27822                 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1177/20552076221129071         nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3201/eid2806.220061            nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3201/eid2806.220061            com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/s0104-12902022210601en    nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.03382021 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.04072021 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.04162021 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.16891/2317-434X.v9.e2.a2021.pp1026-1033 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.16891/2317-434X.v9.e2.a2021.pp1026-1033 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1371/journal.pone.0236091      nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/interface.190640          nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.36925/sanare.v18i2.1375        nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.36517/resdite.v4.n2.2019.a9    nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/0103-11042018s108         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/1807-57622016.0860        nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.5020/18061230.2018.8778        nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.5020/18061230.2018.8773        nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1413-81232017224.26982016 nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.21529/RESI.2017.160200         nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/s0104-12902016161198      nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 1 dos 27 artigos de Luiz Odorico Monteiro de Andrade, perfazendo 3.7% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.34119/bjhrv7n1-036             nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.vaccine.2023.02.019     nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.molimm.2023.03.007      nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.molimm.2023.09.001      nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1002/jmv29055                  nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1002/jmv.27604                 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3201/eid2806.220061            nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1002/jmv.27822                 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/0037-8682-0606-2021       com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.1002/jmv.28169                 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.biopha.2021.111616      nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.ijbiomac.2021.06.043    com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2019 DOI http://dx.doi.org/10.1186/s13104-019-4836-5         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.ijbiomac.2018.07.141    nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 2 dos 14 artigos de Marcela Helena Gambim Fonseca, perfazendo 14.29% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.cbd.2022.101055         nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1080/21655979.2023.2281059     com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.carbpol.2022.119150     nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3390/ijms23158708              nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.toxicon.2022.08.009     com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.jmgm.2021.107949        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.jmgm.2021.108007        nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1007/s43153-019-00004-x        nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.jprot.2020.103818       nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.exppara.2020.107934     com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2019 DOI http://dx.doi.org/10.1042/bcj20180605               nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1016/j.ijbiomac.2018.10.050    nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.ijbiomac.2018.09.022    nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1042/bsr20170969               nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.ijbiomac.2017.01.054    nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 3 dos 15 artigos de Marcos Roberto Lourenzoni, perfazendo 20.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.3390/biomedicines12020310      nome de discente em coautorias não encontrado\n",
      "ANO 2024 DOI http://dx.doi.org/10.4236/jhrss.2024.121007         nome de discente em coautorias não encontrado\n",
      "ANO 2024 DOI http://dx.doi.org/10.1016/j.jtumed.2024.03.006      nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.25110/arqsaude.v27i1.20239112  com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2023 DOI http://dx.doi.org/10.34119/bjhrv6n3-008             nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.34119/bjhrv6n3-009             nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.17665/1676-4285.20236626       nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.26694/reufpi.v12i1.3931        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1093/trstmh/trad056            nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/1983-1447.2023.20230051.en nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/0102-311xpt048823         com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2023 DOI http://dx.doi.org/10.3389/fpubh.2023.1219271        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.1111/jfbc.14081                nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1111/jfbc.14081                nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.33233/eb.v21i1.4865            nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.33233/eb.v21i1.4865            com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.3390/tropicalmed7050071        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.31744/einstein_journal/2022AO6959 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3855/jidc.15797                nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1111/tmi.13795                 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.13105/wjma.v10.i5.244          nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1080/09637486.2021.1885015     nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.gerinurse.2020.11.002   nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.jcpo.2021.100277        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.15517/revenf.v0i40.41631       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1080/07315724.2021.1878967     nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.jtumed.2020.12.020      nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.15517/revenf.v0i41.44093       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.37118/ijdr.23607.12.2021       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.04522021 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.04602021 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1097/md.0000000000018553       nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1155/2020/5619315              com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.18471/rbe.v34.34097            nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1177/1099800420941254          nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1177/1099800420941254          nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.5430/cns.v8n3p22               nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/1518-8345.3870.3369       nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1080/07315724.2020.1823909     com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.33448/rsd-v9i6.3692            com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.37689/acta-ape/2020ao0305      nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.18471/rbe.v35.38280            nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.2174/1573399815666191026125941 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1155/2020/6980754              com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/0034-7167-2018-0033       nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/0034-7167-2018-0033       nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1007/s40200-019-00386-2        nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1155/2019/5738924              com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2019 DOI http://dx.doi.org/10.1016/j.puhe.2019.03.021        nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.15253/2175-6783.20192041359    nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.15253/2175-6783.20192041359    nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.15253/2175-6783.20192041359    nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.17711/sm.0185-3325.2018.015    nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.17711/sm.0185-3325.2018.015    nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.17711/sm.0185-3325.2018.015    nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/0104-070720180003900016   nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/1982-0194201800037        nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/s1980-220x2017035803387   nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.12968/bjon.2018.27.19.1115     nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.12968/bjon.2018.27.19.1115     nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.12968/bjon.2018.27.19.1115     nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.12968/bjon.2018.27.19.1115     nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/1982-0194201800066        nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.11606/issn.1806-6976.v13i1p45-51 nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1108/nfs-08-2016-0126          nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/0034-7167-2016-0145       nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1186/s40200-017-0300-z         nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1982-0194201700005        nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.puhe.2017.04.014        nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1982-0194201700024        nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 10 dos 70 artigos de Márcio Flávio Moura de Araújo, perfazendo 14.29% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2021 DOI http://dx.doi.org/10.22478/ufpb.1981-1268.2021v15n2.53654 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.21577/0103-5053.20210111       nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.21577/0103-5053.20210111       nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.21577/0103-5053.20210111       nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 1 dos 4 artigos de Margareth Borges Coutinho Gallo, perfazendo 25.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2022 DOI http://dx.doi.org/10.1007/s00436-022-07554-z        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1071/fp21161                   nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1071/bt19170                   nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.22256/pubvet.v12n7a123.1-8     nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.ttbdis.2018.06.007      com colaboração com discente 'SILVA, P d C d'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 1 dos 5 artigos de Marlos de Medeiros Chaves, perfazendo 20.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2023 DOI http://dx.doi.org/10.1111/scd.12837                 nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1177/00207640231196743         nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1177/00207640221097826         nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.31365/issn.2595-1769.v22i1p2-6 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/0047-2085000000307        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.20513/2447-6595.2021v61n1e67977p1-4 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.12662/2317-3206jhbs.v9i1.4148.p1-4.2021 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.12662/2317-3206jhbs.v9i1.4148.p1-4.2021 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1177/00207640211004999         nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/1516-4446-2020-0928       nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/2237-6089-2019-0064       nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/0102-311x00019219         nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1016/j.rcp.2017.12.001         nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/s0104-12902018170201      nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/s1678-9946201860063       nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.5123/S1679-49742017000400019   nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.11606/s1518-8787.2017051007059 nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.5123/S1679-49742016000200018   nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/S0104-12902016145974      nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 1 dos 19 artigos de Maximiliano Ponte, perfazendo 5.26% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2017 DOI http://dx.doi.org/10.1371/journal.pone.0170131      nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 0 dos 1 artigos de Raphael Trevizani, perfazendo 0.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.1590/0074-02760230181          com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2024 DOI http://dx.doi.org/10.3389/fimmu.2024.1335307        nome de discente em coautorias não encontrado\n",
      "ANO 2024 DOI http://dx.doi.org/10.1123/jpah.2023-0370            nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1371/journal.pntd.0011388      nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1371/journal.pone.0287665      nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3389/fitd.2021.766273          nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3389/fcimb.2022.977511         nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1111/pim.12947                 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.25248/reas.e8567.2021          nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.21527/2176-7114.2020.38.5-9    nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.34117/bjdv6n9-547              nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 1 dos 11 artigos de Regis Bernardo Brandim Gomes, perfazendo 9.09% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.2174/0126667975279621240124115409 nome de discente em coautorias não encontrado\n",
      "ANO 2024 DOI http://dx.doi.org/10.1016/j.cbi.2024.110945         nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.34024/rnc.2023.v31.14571       nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.5935/1518-0557.20230044        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1080/14786419.2023.2254457     nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/pharmaceutics15102400     nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/pharmaceutics15102400     nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.3390/pharmaceutics15102400     nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.2174/0113862073268297231025110913 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.2174/0929867329666220507011719 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.2174/0929867329666220507011719 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1007/s00436-022-07554-z        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.2174/0929867329666220929145619 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.toxicon.2022.08.009     com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2022 DOI http://dx.doi.org/10.3390/antibiotics11121834       nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3390/antibiotics11121834       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.intimp.2020.107302      nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.jddst.2021.102348       com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.ejmech.2021.113472      nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.ijbiomac.2021.06.043    com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1007/s12639-021-01455-1        nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1007/s12639-021-01455-1        nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.intimp.2020.106640      nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.intimp.2020.106640      com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.2174/0929867327666201005113204 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.bcab.2020.101880        nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1016/j.exppara.2019.107738     nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1007/s12639-019-01162-y        nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1155/2018/3161045              nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1080/00397911.2018.1509350     nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1080/00397911.2018.1509350     nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.intimp.2017.04.014      nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.intimp.2017.04.014      com colaboração com discente 'SILVA, P d C d'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 5 dos 33 artigos de Roberto Nicolete, perfazendo 15.15% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.26694/reufpi.v13i1.4160        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.34119/bjhrv6n3-009             nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/0102-311XPT048823         com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/0102-311XPT048823         nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/0102-311XPT048823         nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1111/jfbc.14081                nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/interface.220555          nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/Interface.200516          com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1080/09637486.2021.1885015     com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2021 DOI http://dx.doi.org/10.1080/07315724.2021.1878967     nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/0034-7167-2019-0769       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/0034-7167-2019-0769       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/0034-7167-2019-0769       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/0034-7167-2019-0769       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.15517/revenf.v0i41.44093       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.37118/ijdr.23607.12.2021       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.37118/ijdr.23607.12.2021       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.37118/ijdr.23607.12.2021       nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1097/md.0000000000018553       nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1155/2020/5619315              com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/0034-7167-2018-0863       nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/0034-7167-2018-0863       nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/0034-7167-2018-0863       nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.11606/s1518-8787.2020054001878 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.11606/s1518-8787.2020054001878 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/1518-8345.3870.3369       nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.5430/cns.v8n3p22               nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.5430/cns.v8n3p22               nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1080/07315724.2020.1823909     com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2020 DOI http://dx.doi.org/10.33448/rsd-v9i11.10338          nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/0034-7167-2018-0033       nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/interface.170691          nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/0034-7167-2017-0702       nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/0034-7167-2018-0601       nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.5205/1981-8963.2019.242175     nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.2174/1573399815666191026125941 nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/1518-8345.2961.3210       nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/0034-7167-2017-0554       nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/0034-7167-2017-0554       nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/0104-070720180003900016   nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.12968/bjon.2018.27.19.1115     nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.12968/bjon.2018.27.19.1115     nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.12968/bjon.2018.27.19.1115     nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.12968/bjon.2018.27.19.1115     nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.12968/bjon.2018.27.19.1115     nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1186/s40200-017-0300-z         nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/0034-7167-2016-0145       nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/0034-7167-2016-0145       nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1108/nfs-08-2016-0126          nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1982-0194201700024        nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 5 dos 50 artigos de Roberto Wagner Júnior Freire de Freitas, perfazendo 10.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.1590/2358-289820241408535p     nome de discente em coautorias não encontrado\n",
      "ANO 2024 DOI http://dx.doi.org/10.26694/reufpi.v13i1.4160        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.53660/clm-2242-23r02           nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/1413-81232023288.0727023  nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.34019/1809-8363.2022.v25.34726 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.53660/conj-1358-w16            nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.4215/rm2022.e21021             nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/interface.200516          nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.34117/bjdv7n1-449              nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.04292021 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.04352021 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-81232021265.04432021 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/0103-1104202112912        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.5020/18061230.2021.11152       nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.5020/18061230.2021.11152       nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.11606/s1518-8787.2020054001878 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/interface.190740          nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.34117/bjdv6n7-568              nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/0102-311x00177719         nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/0034-7167-2018-0033       nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.30979/rev.abeno.v19i1.661      nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.5020/18061230.2017.6653        nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.5020/18061230.2017.6653        nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1981-22562017020.160070   nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1981-52712015v41n1rb20160018 nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 0 dos 25 artigos de Sharmênia de Araújo Soares Nuto, perfazendo 0.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/1413-81232023289.13142022 com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2023 DOI http://dx.doi.org/10.25110/arqsaude.v27i10.2023-034 nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1590/2317-6369/14422pt2023v48e20 nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.28998/rpss.e02308004esp        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/0103-1104202213210        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/0103-1104202213210        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/0103-1104202213210        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1590/1981-7746-ojs275          nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.20513/2447-6595.2022v62n1e78065p1-5 nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/2317-6369000028719        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.5020/18061230.2021.11152       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1590/1413-812320212612.15172021 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1590/1981-7746-sol00298        nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/0103-11042019S8031        com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/0103-11042018s108         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1590/0103-11042018s120         nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.2471/BLT.16.178236             nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/1807-57622016.0235        nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 2 dos 18 artigos de Vanira Matos Pessoa, perfazendo 11.11% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.toxicon.2020.12.004     nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1590/1414-431x20188251         nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1016/j.intimp.2018.06.031      nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.taap.2017.04.023        nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 0 dos 4 artigos de Venúcia Bruna Magalhães Pereira, perfazendo 0.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2023 DOI http://dx.doi.org/10.33240/rba.v18i5.51275          nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.22276/ethnoscientia.v6i2.387   nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.22276/ethnoscientia.v6i2.387   nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.22276/ethnoscientia.v6i2.387   nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 0 dos 4 artigos de Fernanda Savicki de Almeida, perfazendo 0.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.1038/s41467-023-44389-3        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1038/s41591-023-02213-x        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1172/JCI167843                 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1038/s42003-022-03619-y        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1016/j.ebiom.2022.103985       nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.3390/vaccines9080886           nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.3389/fimmu.2021.695148         nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1128/JVI.00016-21              nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1016/j.isci.2021.102314        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1038/s41467-021-21402-1        nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.1093/cid/ciaa1047              nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.celrep.2020.108174      nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1172/jci.insight.136047        nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1126/scitranslmed.aay9355      nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1128/JVI.00611-20              nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1038/s42255-019-0081-4         nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1016/j.cmet.2018.11.015        nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1371/journal.pone.0193629      nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1128/JVI.02296-16              nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 0 dos 19 artigos de Caroline Pereira Bittencourt Passaes, perfazendo 0.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.1186/s42358-023-00346-8        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.33448/rsd-v12i1.39548          nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.molimm.2023.09.001      nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1002/jmv.29055                 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.31011/reaid-2022-v.96-n.37-art.1310 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.31011/reaid-2022-v.96-n.37-art.1290 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3201/eid2806.220061            nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1002/jmv.27822                 nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.3389/fimmu.2022.1049368        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1186/s42358-022-00277-w        nome de discente em coautorias não encontrado\n",
      "ANO 2022 DOI http://dx.doi.org/10.1002/jmv.28169                 nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1016/j.berh.2020.101528        nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.34117/bjdv6n7-155              nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1186/s42358-020-00127-7        nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1007/s10067-020-05519-0        nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.1080/03008207.2020.1825700     nome de discente em coautorias não encontrado\n",
      "ANO 2020 DOI http://dx.doi.org/10.25248/reas.e4729.2020          nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1371/journal.pone.0226986      nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1038/s41598-017-01400-4        nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.rbr.2017.07.575         nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 0 dos 20 artigos de Ana Carolina Matias Dinelly Pinto, perfazendo 0.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2024 DOI http://dx.doi.org/10.1016/j.chom.2024.02.011        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.vaccine.2023.02.019     nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.bjid.2023.103208        nome de discente em coautorias não encontrado\n",
      "ANO 2023 DOI http://dx.doi.org/10.1016/j.bjid.2023.103648        nome de discente em coautorias não encontrado\n",
      "ANO 2018 DOI http://dx.doi.org/10.1515/hsz-2017-0198             com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2018 DOI http://dx.doi.org/10.1017/s0031182018000197         com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.toxicon.2016.11.249     com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.toxicon.2017.02.031     com colaboração com discente 'SILVA, P d C d'\n",
      "ANO 2017 DOI http://dx.doi.org/10.1017/s0031182017001846         nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.toxicon.2017.08.002     com colaboração com discente 'SILVA, P d C d'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 5 dos 10 artigos de Clarissa Perdigao Mello Ferraz, perfazendo 50.0% de colaborações com discente\n",
      "========================================================================================================================\n",
      "ANO 2021 DOI                                                     nome de discente em coautorias não encontrado\n",
      "ANO 2021 DOI http://dx.doi.org/10.3390/en14092519                nome de discente em coautorias não encontrado\n",
      "ANO 2019 DOI http://dx.doi.org/10.1007/s42770-018-0024-3         nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1590/s0100-204x2017001000010   nome de discente em coautorias não encontrado\n",
      "ANO 2017 DOI http://dx.doi.org/10.1016/j.jpcs.2011.10.037        nome de discente em coautorias não encontrado\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Nome de discente detectado em 0 dos 5 artigos de Júlio César Martins Ximenes, perfazendo 0.0% de colaborações com discente\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#### TO-DO #### corrigir busca pelo nome de discentes nos dados de pulicação de docentes.\n",
    "discent_collab_counter = DiscentCollaborationCounter(dict_list_docents)\n",
    "colaboracoes, percentuais = discent_collab_counter.get_articles_coauthorings(dict_list_docents, ano_inicio=2017, ano_final=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4e90742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1497"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(colaboracoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "001bbb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(percentuais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5b0bdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_pontuacao.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91c7954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Acrescentar a coluna de percentual de colaboração docente/discente\n",
    "df_pontuacao['colab_disc'] = percentuais\n",
    "filepath = os.path.join(os.path.join(\"./\",\"_data\",\"powerbi\",'fioce_prodpubl_2017_2024.xlsx'))\n",
    "df_pontuacao.to_excel(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f886d8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 pesquisadores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Ano</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "      <th>Soma de Pontos</th>\n",
       "      <th>colab_disc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jaime Ribeiro Filho</th>\n",
       "      <td>575</td>\n",
       "      <td>320</td>\n",
       "      <td>200</td>\n",
       "      <td>1060</td>\n",
       "      <td>955</td>\n",
       "      <td>865</td>\n",
       "      <td>1155</td>\n",
       "      <td>200</td>\n",
       "      <td>5330</td>\n",
       "      <td>14.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Márcio Flávio Moura de Araújo</th>\n",
       "      <td>285</td>\n",
       "      <td>570</td>\n",
       "      <td>315</td>\n",
       "      <td>385</td>\n",
       "      <td>475</td>\n",
       "      <td>260</td>\n",
       "      <td>380</td>\n",
       "      <td>80</td>\n",
       "      <td>2750</td>\n",
       "      <td>14.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fabio Miyajima</th>\n",
       "      <td>350</td>\n",
       "      <td>270</td>\n",
       "      <td>330</td>\n",
       "      <td>270</td>\n",
       "      <td>530</td>\n",
       "      <td>770</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>2600</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anya Pimentel Gomes Fernandes Vieira Meyer</th>\n",
       "      <td>100</td>\n",
       "      <td>310</td>\n",
       "      <td>230</td>\n",
       "      <td>355</td>\n",
       "      <td>755</td>\n",
       "      <td>300</td>\n",
       "      <td>445</td>\n",
       "      <td>100</td>\n",
       "      <td>2595</td>\n",
       "      <td>14.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roberto Wagner Júnior Freire de Freitas</th>\n",
       "      <td>175</td>\n",
       "      <td>390</td>\n",
       "      <td>320</td>\n",
       "      <td>365</td>\n",
       "      <td>580</td>\n",
       "      <td>80</td>\n",
       "      <td>190</td>\n",
       "      <td>20</td>\n",
       "      <td>2120</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roberto Nicolete</th>\n",
       "      <td>160</td>\n",
       "      <td>80</td>\n",
       "      <td>55</td>\n",
       "      <td>270</td>\n",
       "      <td>335</td>\n",
       "      <td>510</td>\n",
       "      <td>285</td>\n",
       "      <td>80</td>\n",
       "      <td>1775</td>\n",
       "      <td>15.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivana Cristina de Holanda Cunha Barreto</th>\n",
       "      <td>335</td>\n",
       "      <td>180</td>\n",
       "      <td>65</td>\n",
       "      <td>150</td>\n",
       "      <td>370</td>\n",
       "      <td>340</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1640</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carla Freire Celedonio Fernandes</th>\n",
       "      <td>410</td>\n",
       "      <td>170</td>\n",
       "      <td>100</td>\n",
       "      <td>220</td>\n",
       "      <td>320</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>230</td>\n",
       "      <td>1525</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caroline Pereira Bittencourt Passaes</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>110</td>\n",
       "      <td>360</td>\n",
       "      <td>490</td>\n",
       "      <td>170</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>1490</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>João Hermínio Martins da Silva</th>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>120</td>\n",
       "      <td>55</td>\n",
       "      <td>520</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1415</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luiz Odorico Monteiro de Andrade</th>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>420</td>\n",
       "      <td>260</td>\n",
       "      <td>140</td>\n",
       "      <td>40</td>\n",
       "      <td>1325</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>José Luís Passos Cordeiro</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>100</td>\n",
       "      <td>375</td>\n",
       "      <td>90</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>1190</td>\n",
       "      <td>8.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharmênia de Araújo Soares Nuto</th>\n",
       "      <td>80</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>240</td>\n",
       "      <td>385</td>\n",
       "      <td>115</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>1155</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fernando Ferreira Carneiro</th>\n",
       "      <td>170</td>\n",
       "      <td>205</td>\n",
       "      <td>40</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>100</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>1135</td>\n",
       "      <td>8.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcos Roberto Lourenzoni</th>\n",
       "      <td>110</td>\n",
       "      <td>90</td>\n",
       "      <td>180</td>\n",
       "      <td>190</td>\n",
       "      <td>120</td>\n",
       "      <td>210</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fernando Braga Stehling Dias</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>260</td>\n",
       "      <td>270</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>9.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gilvan Pessoa Furtado</th>\n",
       "      <td>100</td>\n",
       "      <td>180</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>100</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>14.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clarissa Romero Teixeira</th>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>740</td>\n",
       "      <td>22.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ana Carolina Matias Dinelly Pinto</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>730</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maximiliano Ponte</th>\n",
       "      <td>270</td>\n",
       "      <td>20</td>\n",
       "      <td>75</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>680</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanira Matos Pessoa</th>\n",
       "      <td>150</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>125</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>675</td>\n",
       "      <td>11.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marcela Helena Gambim Fonseca</th>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>180</td>\n",
       "      <td>10</td>\n",
       "      <td>640</td>\n",
       "      <td>14.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regis Bernardo Brandim Gomes</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>200</td>\n",
       "      <td>600</td>\n",
       "      <td>9.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clarissa Perdigao Mello Ferraz</th>\n",
       "      <td>210</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>590</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eduardo Ruback dos Santos</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>360</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anna Carolina Machado Marinho</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>330</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marlos de Medeiros Chaves</th>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adriana Costa Bacelo</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>285</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Júlio César Martins Ximenes</th>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claudia Stutz Zubieta</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>260</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venúcia Bruna Magalhães Pereira</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Galba Freire Moita</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alice Paula Di Sabatino Guimarães</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dayane Alves Costa</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ana Camila Oliveira Alves</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ana Cláudia de Araújo Teixeira</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Giovanny Augusto Camacho Antevere Mazzarotto</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Margareth Borges Coutinho Gallo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antonio Marcos Aires Barbosa</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raphael Trevizani</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donat Alexander de Chapeaurouge</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fernanda Savicki de Almeida</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ano                                           2017  2018  2019  2020  2021  \\\n",
       "Autor                                                                        \n",
       "Jaime Ribeiro Filho                           575   320   200   1060  955    \n",
       "Márcio Flávio Moura de Araújo                 285   570   315    385  475    \n",
       "Fabio Miyajima                                350   270   330    270  530    \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer    100   310   230    355  755    \n",
       "Roberto Wagner Júnior Freire de Freitas       175   390   320    365  580    \n",
       "Roberto Nicolete                              160    80    55    270  335    \n",
       "Ivana Cristina de Holanda Cunha Barreto       335   180    65    150  370    \n",
       "Carla Freire Celedonio Fernandes              410   170   100    220  320    \n",
       "Caroline Pereira Bittencourt Passaes           90    90   110    360  490    \n",
       "João Hermínio Martins da Silva                310     0   210    120   55    \n",
       "Luiz Odorico Monteiro de Andrade              170   130    15    150  420    \n",
       "José Luís Passos Cordeiro                       0   400   100    375   90    \n",
       "Sharmênia de Araújo Soares Nuto                80    55    50    240  385    \n",
       "Fernando Ferreira Carneiro                    170   205    40    130  130    \n",
       "Marcos Roberto Lourenzoni                     110    90   180    190  120    \n",
       "Fernando Braga Stehling Dias                   90    90    90     80  260    \n",
       "Gilvan Pessoa Furtado                         100   180   110      0  270    \n",
       "Clarissa Romero Teixeira                        0   320     0     80    0    \n",
       "Ana Carolina Matias Dinelly Pinto             105     0    90    195    0    \n",
       "Maximiliano Ponte                             270    20    75    130   90    \n",
       "Vanira Matos Pessoa                           150    80    40     20  125    \n",
       "Marcela Helena Gambim Fonseca                   0    90    20      0  170    \n",
       "Regis Bernardo Brandim Gomes                    0     0     0     40   20    \n",
       "Clarissa Perdigao Mello Ferraz                210   170     0      0    0    \n",
       "Eduardo Ruback dos Santos                       0     0     0      0    0    \n",
       "Anna Carolina Machado Marinho                   0    15     0      0  150    \n",
       "Marlos de Medeiros Chaves                       0    90     0     40   80    \n",
       "Adriana Costa Bacelo                           50     0   110      0   10    \n",
       "Júlio César Martins Ximenes                   120     0    80      0   80    \n",
       "Claudia Stutz Zubieta                           0     0     0      0    0    \n",
       "Venúcia Bruna Magalhães Pereira                80    80    60      0   40    \n",
       "Galba Freire Moita                              0    20    95     40   25    \n",
       "Alice Paula Di Sabatino Guimarães               0     0     0      0  170    \n",
       "Dayane Alves Costa                             90     0     0      0   40    \n",
       "Ana Camila Oliveira Alves                       0     0     0      0   60    \n",
       "Ana Cláudia de Araújo Teixeira                  0     0     0      0    0    \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto   80     0     0      0    5    \n",
       "Margareth Borges Coutinho Gallo                 0     0     0      0  100    \n",
       "Antonio Marcos Aires Barbosa                    0    15     0      0    0    \n",
       "Raphael Trevizani                              90     0     0      0    0    \n",
       "Donat Alexander de Chapeaurouge                 0    80     0      0    0    \n",
       "Fernanda Savicki de Almeida                     0     0     0      0    0    \n",
       "\n",
       "Ano                                           2022  2023  2024  \\\n",
       "Autor                                                            \n",
       "Jaime Ribeiro Filho                           865   1155  200    \n",
       "Márcio Flávio Moura de Araújo                 260    380   80    \n",
       "Fabio Miyajima                                770     80    0    \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer    300    445  100    \n",
       "Roberto Wagner Júnior Freire de Freitas        80    190   20    \n",
       "Roberto Nicolete                              510    285   80    \n",
       "Ivana Cristina de Holanda Cunha Barreto       340    200    0    \n",
       "Carla Freire Celedonio Fernandes               60     15  230    \n",
       "Caroline Pereira Bittencourt Passaes          170     90   90    \n",
       "João Hermínio Martins da Silva                520    200    0    \n",
       "Luiz Odorico Monteiro de Andrade              260    140   40    \n",
       "José Luís Passos Cordeiro                     130     80   15    \n",
       "Sharmênia de Araújo Soares Nuto               115    170   60    \n",
       "Fernando Ferreira Carneiro                    100    180  180    \n",
       "Marcos Roberto Lourenzoni                     210    100    0    \n",
       "Fernando Braga Stehling Dias                  270     80    0    \n",
       "Gilvan Pessoa Furtado                         100    160    0    \n",
       "Clarissa Romero Teixeira                       80    180   80    \n",
       "Ana Carolina Matias Dinelly Pinto             265     60   15    \n",
       "Maximiliano Ponte                               0     95    0    \n",
       "Vanira Matos Pessoa                           110    150    0    \n",
       "Marcela Helena Gambim Fonseca                 170    180   10    \n",
       "Regis Bernardo Brandim Gomes                  160    180  200    \n",
       "Clarissa Perdigao Mello Ferraz                  0    120   90    \n",
       "Eduardo Ruback dos Santos                     270      0   90    \n",
       "Anna Carolina Machado Marinho                   0     15  150    \n",
       "Marlos de Medeiros Chaves                      90      0    0    \n",
       "Adriana Costa Bacelo                           35      0   80    \n",
       "Júlio César Martins Ximenes                     0      0    0    \n",
       "Claudia Stutz Zubieta                          90     90   80    \n",
       "Venúcia Bruna Magalhães Pereira                 0      0    0    \n",
       "Galba Freire Moita                              5      0    0    \n",
       "Alice Paula Di Sabatino Guimarães               0      0    0    \n",
       "Dayane Alves Costa                              0     20    0    \n",
       "Ana Camila Oliveira Alves                      60      0    0    \n",
       "Ana Cláudia de Araújo Teixeira                 20     90    0    \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto    0     15    0    \n",
       "Margareth Borges Coutinho Gallo                 0      0    0    \n",
       "Antonio Marcos Aires Barbosa                    0     80    0    \n",
       "Raphael Trevizani                               0      0    0    \n",
       "Donat Alexander de Chapeaurouge                 0      0    0    \n",
       "Fernanda Savicki de Almeida                     0      5    0    \n",
       "\n",
       "Ano                                           Soma de Pontos  colab_disc  \n",
       "Autor                                                                     \n",
       "Jaime Ribeiro Filho                           5330             14.89      \n",
       "Márcio Flávio Moura de Araújo                 2750             14.29      \n",
       "Fabio Miyajima                                2600              5.26      \n",
       "Anya Pimentel Gomes Fernandes Vieira Meyer    2595             14.58      \n",
       "Roberto Wagner Júnior Freire de Freitas       2120             10.00      \n",
       "Roberto Nicolete                              1775             15.15      \n",
       "Ivana Cristina de Holanda Cunha Barreto       1640              5.88      \n",
       "Carla Freire Celedonio Fernandes              1525             50.00      \n",
       "Caroline Pereira Bittencourt Passaes          1490              0.00      \n",
       "João Hermínio Martins da Silva                1415              0.00      \n",
       "Luiz Odorico Monteiro de Andrade              1325              3.70      \n",
       "José Luís Passos Cordeiro                     1190              8.70      \n",
       "Sharmênia de Araújo Soares Nuto               1155              0.00      \n",
       "Fernando Ferreira Carneiro                    1135              8.70      \n",
       "Marcos Roberto Lourenzoni                     1000             20.00      \n",
       "Fernando Braga Stehling Dias                   960              9.09      \n",
       "Gilvan Pessoa Furtado                          920             14.29      \n",
       "Clarissa Romero Teixeira                       740             22.22      \n",
       "Ana Carolina Matias Dinelly Pinto              730              0.00      \n",
       "Maximiliano Ponte                              680              5.26      \n",
       "Vanira Matos Pessoa                            675             11.11      \n",
       "Marcela Helena Gambim Fonseca                  640             14.29      \n",
       "Regis Bernardo Brandim Gomes                   600              9.09      \n",
       "Clarissa Perdigao Mello Ferraz                 590             50.00      \n",
       "Eduardo Ruback dos Santos                      360             25.00      \n",
       "Anna Carolina Machado Marinho                  330             33.33      \n",
       "Marlos de Medeiros Chaves                      300             20.00      \n",
       "Adriana Costa Bacelo                           285             30.00      \n",
       "Júlio César Martins Ximenes                    280              0.00      \n",
       "Claudia Stutz Zubieta                          260              0.00      \n",
       "Venúcia Bruna Magalhães Pereira                260              0.00      \n",
       "Galba Freire Moita                             185             10.00      \n",
       "Alice Paula Di Sabatino Guimarães              170             50.00      \n",
       "Dayane Alves Costa                             150            100.00      \n",
       "Ana Camila Oliveira Alves                      120             50.00      \n",
       "Ana Cláudia de Araújo Teixeira                 110             50.00      \n",
       "Giovanny Augusto Camacho Antevere Mazzarotto   100              0.00      \n",
       "Margareth Borges Coutinho Gallo                100             25.00      \n",
       "Antonio Marcos Aires Barbosa                    95            100.00      \n",
       "Raphael Trevizani                               90              0.00      \n",
       "Donat Alexander de Chapeaurouge                 80             33.33      \n",
       "Fernanda Savicki de Almeida                      5              0.00      "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'{len(df_pontuacao.index)} pesquisadores')\n",
    "df_pontuacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b12f804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfilename = os.path.join(os.path.join(\"./\",\"_data\",\"powerbi\",'fioce_prodpubl_discentcollab_2017_2024.xlsx'))\n",
    "df_pontuacao.to_excel(pathfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17da8026",
   "metadata": {},
   "source": [
    "# <b>F04: Acrescentar Qualis Periódicos</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36721f73",
   "metadata": {},
   "source": [
    "### Abrir dados salvos localmente de Docentes e Discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8802f09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos disponíveis na pasta para dados de entrada:\n",
      "  combined_dict_list.json\n",
      "  dict_list_discents_combined.json\n",
      "  dict_list_temp.json\n",
      "  discents_dict_list.json\n",
      "  docents_dict_list.json\n",
      "  temp_dict_list.json\n",
      "\n",
      "42 currículos carregados na lista de dicionários de docentes 'docents_dict_list.json'\n",
      "Arquivo criado inicialmente em 23/05/2024 06:06:04 carregado com sucesso\n",
      "Extração realizada em 11/06/2024 18:43:18 a 2.5 dias\n",
      "\n",
      "Exemplo dos dados das publicações de docentes:\n",
      "{'DOI': '',\n",
      " 'ISSN': '23181400',\n",
      " 'Qualis': 'C',\n",
      " 'ano': '2021',\n",
      " 'autores': 'MUNOZ, A. E. P.2021MUNOZ, A. E. P. ; CHICRALA, P. C. M. S. '\n",
      "            ';XIMENES, J. C. M.;XIMENES, J. C. M.. ',\n",
      " 'data_issn': '23181400',\n",
      " 'fator_impacto_jcr': '',\n",
      " 'revista': 'DOCUMENTOS / EMBRAPA PESCA E AQUICULTURA',\n",
      " 'titulo': 'Análise de viabilidade econômica de um Entreposto Móvel de Pescado '\n",
      "           '(EMP) em operação'}\n",
      "\n",
      "121 currículos carregados na lista de dicionários de discentes 'discents_dict_list.json'\n",
      "Arquivo criado inicialmente em 23/05/2024 06:06:04 carregado com sucesso\n",
      "Extração realizada em 11/06/2024 18:43:53 a 2.5 dias\n",
      "\n",
      "Exemplo dos dados das publicações de discentes:\n",
      "{'DOI': 'http://dx.doi.org/10.5935/1518-0557.20240030',\n",
      " 'ISSN': '15180557',\n",
      " 'Qualis': 'A4',\n",
      " 'ano': '2024',\n",
      " 'autores': 'MOURA, G. A.2024MOURA, G. A. ; LOURENCO, M. L. ; ROCHA, Y. M. ; '\n",
      "            'RODRIGUES, J. P. V. ; PINHEIRO, C. V. ;QUEIROZ, Alice Soares de; '\n",
      "            'MIRANDA, D. P. ; TORQUATO FILHO, S. E. ;NICOLETE, ROBERTO. ',\n",
      " 'data_issn': '15180557',\n",
      " 'fator_impacto_jcr': '1.5',\n",
      " 'revista': 'JORNAL BRASILEIRO DE REPRODUÇÃO ASSISTIDA',\n",
      " 'titulo': 'ASSESSMENT OF DIFFERENTIALLY EXPRESSED GENES FROM IN VITRO MATURED '\n",
      "           'HUMAN OOCYTES: A BIOINFORMATICS APPROACH'}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd, os, re, sys, time, pytz, json, subprocess\n",
    "\n",
    "## Configurar exibição do pandas para melhor visualizar os dados\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('colheader_justify', 'left')\n",
    "pd.set_option('display.max_rows', 600)\n",
    "\n",
    "def find_repo_root(path='.', depth=10):\n",
    "    ''' \n",
    "    Busca o arquivo .git e retorna string com a pasta raiz do repositório\n",
    "    '''\n",
    "    # Prevent infinite recursion by limiting depth\n",
    "    if depth < 0:\n",
    "        return None\n",
    "    path = Path(path).absolute()\n",
    "    if (path / '.git').is_dir():\n",
    "        return path\n",
    "    return find_repo_root(path.parent, depth-1)\n",
    "\n",
    "delay = 10\n",
    "\n",
    "## Definir a pasta de base do repositório local\n",
    "base_repo_dir = find_repo_root()\n",
    "\n",
    "## Sempre construir os caminhos usando os.path.join para compatibilidade WxL\n",
    "folder_utils = os.path.join(base_repo_dir, 'utils')\n",
    "folder_domain = os.path.join(base_repo_dir, 'source', 'domain')\n",
    "folder_data_xls = os.path.join(base_repo_dir, '_data', 'in_xls')\n",
    "folder_data_input = os.path.join(base_repo_dir, '_data', 'in_csv')\n",
    "folder_data_output = os.path.join(base_repo_dir, '_data', 'output')\n",
    "\n",
    "## Adicionar pastas locais ao sys.path para importar pacotes criados localmente\n",
    "sys.path.append(folder_utils)\n",
    "sys.path.append(folder_domain)\n",
    "from scraper_pasteur import PasteurScraper\n",
    "from environment_setup import EnvironmentSetup\n",
    "from scraper_sucupira import SucupiraScraper\n",
    "from scraper_sucupira_edge import SucupiraScraperEdge\n",
    "from chromedriver_manager import ChromeDriverManager\n",
    "from neo4j_persister import Neo4jPersister\n",
    "from lattes_scrapper import JSONFileManager, LattesScraper, HTMLParser, SoupParser, GetQualis, ArticlesCounter, DiscentCollaborationCounter, DictToHDF5, attribute_to_be_non_empty\n",
    "\n",
    "# Carregar o conteúdo do arquivo 'dict_list.json' para a variável dict_list\n",
    "jfm = JSONFileManager()\n",
    "jfm.list_json(folder_data_input)\n",
    "\n",
    "# Carregar o conteúdo do arquivo da extração de docentes para a variável dict_list_docents\n",
    "filename_docents = 'docents_dict_list.json'\n",
    "dict_list_docents, formatted_creation_date, formatted_modification_date, time_count, unit = jfm.load_from_json(os.path.join(folder_data_input,filename_docents))\n",
    "\n",
    "print(f\"\\n{len(dict_list_docents)} currículos carregados na lista de dicionários de docentes '{filename_docents}'\")\n",
    "print(f\"Arquivo criado inicialmente em {formatted_creation_date} carregado com sucesso\")\n",
    "print(f\"Extração realizada em {formatted_modification_date} a {time_count} {unit}\")\n",
    "print('\\nExemplo dos dados das publicações de docentes:')\n",
    "pprint([x.get('Produções') for x in dict_list_docents][-1].get('Artigos completos publicados em periódicos')[0])\n",
    "\n",
    "# Carregar o conteúdo do arquivo da extração de discentes para a variável dict_list_discents\n",
    "filename_discents = 'discents_dict_list.json'\n",
    "dict_list_discents, formatted_creation_date_discents, formatted_modification_date_discents, time_count, unit = jfm.load_from_json(os.path.join(folder_data_input,filename_discents))\n",
    "\n",
    "print(f\"\\n{len(dict_list_discents)} currículos carregados na lista de dicionários de discentes '{filename_discents}'\")\n",
    "print(f\"Arquivo criado inicialmente em {formatted_creation_date_discents} carregado com sucesso\")\n",
    "print(f\"Extração realizada em {formatted_modification_date_discents} a {time_count} {unit}\")\n",
    "print('\\nExemplo dos dados das publicações de discentes:')\n",
    "pprint([x.get('Produções') for x in dict_list_discents][1].get('Artigos completos publicados em periódicos')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7a804",
   "metadata": {},
   "source": [
    "### Atualizar dados dos Qualis Periódicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8747fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratifier = GetQualis()\n",
    "\n",
    "# print('\\nAdicionar Qualis Periódicos a publicações dos docentes...')\n",
    "# pathfilename = os.path.join(folder_data_input,'docents_dict_list.json')\n",
    "# json_data_discents = stratifier.buscar_qualis_e_atualizar_arquivo(dict_list_docents, pathfilename)\n",
    "\n",
    "# print('\\nAdicionar Qualis Periódicos a publicações dos discentes...')\n",
    "# pathfilename = os.path.join(folder_data_input,'discents_dict_list.json')\n",
    "# json_data_discents = stratifier.buscar_qualis_e_atualizar_arquivo(dict_list_discents, pathfilename)\n",
    "\n",
    "# print('\\nExemplo atualizado dos dados das publicações de docentes:')\n",
    "# # Verificar se o dado Qualis está presente no arquivo de dados de docentes\n",
    "# pprint([x.get('Produções') for x in dict_list_docents][-1].get('Artigos completos publicados em periódicos')[0])\n",
    "\n",
    "# print('\\nExemplo atualizado dos dados das publicações de discentes:')\n",
    "# # Verificar se o dado Qualis está presente no arquivo de dados de discentes\n",
    "# pprint([x.get('Produções') for x in dict_list_discents][1].get('Artigos completos publicados em periódicos')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433c0e93",
   "metadata": {},
   "source": [
    "## F05a Montar Grafo com NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6753e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install community\n",
    "# %pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7f177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link simbólico criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "## Teste de criação de link simbólico\n",
    "# import os\n",
    "\n",
    "# try:\n",
    "#     os.symlink(\"arquivo_original.txt\", \"link_simbolico.txt\")\n",
    "#     print(\"Link simbólico criado com sucesso!\")\n",
    "# except OSError as e:\n",
    "#     print(f\"Erro ao criar o link simbólico: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3c66e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from neo4j import GraphDatabase\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "# from sklearn.metrics.pairwise import cosine_similarity # apresentou erro de sincronização CUDA\n",
    "from torch.nn.functional import cosine_similarity  # Similaridade do cosseno no PyTorch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Configurar o logger\n",
    "logging.basicConfig(filename='app_semantic_similarity.log', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def test_gpu():\n",
    "    \"\"\"\n",
    "    Testa se a GPU está disponível e retorna informações sobre ela.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        logging.info(\"GPU disponível. Informações:\")\n",
    "        logging.info(torch.cuda.get_device_name(0))\n",
    "        logging.info(f\"Memória total: {torch.cuda.get_device_properties(0).total_memory / 1024**2:.2f} MB\")\n",
    "        return True\n",
    "    else:\n",
    "        logging.warning(\"GPU não disponível.\")\n",
    "        return False\n",
    "\n",
    "def is_gpu_memory_sufficient(model_name):\n",
    "    \"\"\"\n",
    "    Verifica se a memória da GPU é suficiente para o modelo especificado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = SentenceTransformer(model_name)\n",
    "        del model\n",
    "        return True\n",
    "    except RuntimeError as e:\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            logging.warning(f\"Memória da GPU insuficiente para o modelo {model_name}.\")\n",
    "            return False\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"\n",
    "    Limpa a memória da GPU.\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    logging.info(\"Memória da GPU limpa.\")\n",
    "\n",
    "class Neo4jError(Exception):\n",
    "    \"\"\"Exceção personalizada para erros relacionados ao Neo4j.\"\"\"\n",
    "    pass\n",
    "\n",
    "class CommunityDetectionError(Exception):\n",
    "    \"\"\"Exceção personalizada para erros na detecção de comunidades.\"\"\"\n",
    "    pass\n",
    "\n",
    "def get_graph_from_neo4j(uri, user, password, query):\n",
    "    \"\"\"\n",
    "    Conecta ao Neo4j, executa a consulta Cypher e retorna o grafo NetworkX.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao conectar ao Neo4j: {e}\")\n",
    "        raise ConnectionError(f\"Erro ao conectar ao Neo4j: {e}\")\n",
    "\n",
    "    with driver.session() as session:\n",
    "        try:\n",
    "            result = session.run(query)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erro ao executar a consulta Cypher: {e}\")\n",
    "            raise Neo4jError(f\"Erro ao executar a consulta Cypher: {e}\")\n",
    "\n",
    "        G = nx.Graph()\n",
    "        for record in result:\n",
    "            try:\n",
    "                node1 = record['n']\n",
    "                node2 = record['r']\n",
    "\n",
    "                # Adicionar nós ao grafo\n",
    "                G.add_node(node1.id, label=list(node1.labels)[0], name=node1.get('name', ''))\n",
    "                if node2:\n",
    "                    G.add_node(node2.id, label=node2.type)\n",
    "\n",
    "                    # Adicionar aresta ao grafo\n",
    "                    G.add_edge(node1.id, node2.id)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Erro ao processar os dados do Neo4j: {e}\")\n",
    "                raise ValueError(f\"Erro ao processar os dados do Neo4j: {e}\")\n",
    "\n",
    "    driver.close()\n",
    "    return G\n",
    "\n",
    "def semantic_approximation_and_modularity(graph, label1, label2, threshold_range, model_name='bert-base-uncased'):\n",
    "    \"\"\"\n",
    "    Calcula a aproximação semântica entre dois labels de nós e avalia a modularidade.\n",
    "\n",
    "    Args:\n",
    "        graph: Grafo NetworkX contendo os nós e arestas.\n",
    "        label1: Primeiro label de nó.\n",
    "        label2: Segundo label de nó.\n",
    "        threshold_range: Range de valores de threshold para testar.\n",
    "        model_name: Nome do modelo a ser usado para cálculo de embeedings.\n",
    "\n",
    "    Returns:\n",
    "        Dicionário com resultados para cada threshold, incluindo:\n",
    "            - modularity: Valor de modularidade.\n",
    "            - communities: Dicionário com as comunidades encontradas.\n",
    "            - edges: Lista de arestas adicionadas ao grafo.\n",
    "    \"\"\"\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Obter nós com os labels especificados\n",
    "    nodes_label1 = [node for node, data in graph.nodes(data=True) if data.get('label') == label1]\n",
    "    nodes_label2 = [node for node, data in graph.nodes(data=True) if data.get('label') == label2]\n",
    "\n",
    "    if not nodes_label1 or not nodes_label2:\n",
    "        raise ValueError(f\"Labels de nós não encontrados no grafo: {label1}, {label2}\")\n",
    "\n",
    "    for threshold in threshold_range:\n",
    "        edges_to_add = []\n",
    "        for node1 in nodes_label1:\n",
    "            for node2 in nodes_label2:\n",
    "                try:\n",
    "                    text1 = graph.nodes[node1].get('name', '')\n",
    "                    text2 = graph.nodes[node2].get('name', '')\n",
    "\n",
    "                    # Tokenizar e obter embeddings com PyTorch\n",
    "                    inputs1 = tokenizer(text1, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "                    inputs2 = tokenizer(text2, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "                    with torch.no_grad():\n",
    "                        outputs1 = model(**inputs1)\n",
    "                        outputs2 = model(**inputs2)\n",
    "                    embedding1 = outputs1.pooler_output.cpu().numpy()  # Converter para numpy\n",
    "                    embedding2 = outputs2.pooler_output.cpu().numpy()  # Converter para numpy\n",
    "\n",
    "                    similarity = cosine_similarity(torch.from_numpy(embedding1), torch.from_numpy(embedding2))[0][0].item()  # Converter para escalar\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Erro ao calcular a similaridade entre embeddings: {e}\")\n",
    "                    raise\n",
    "\n",
    "                if similarity >= threshold:\n",
    "                    edges_to_add.append((node1, node2))    \n",
    "\n",
    "        # Criar subgrafo com os nós e arestas relevantes\n",
    "        subgraph = graph.subgraph(nodes_label1 + nodes_label2 + ['CompetenciaPesquisa'])\n",
    "        subgraph.add_edges_from(edges_to_add)\n",
    "\n",
    "        # Calcular modularidade\n",
    "        try:\n",
    "            partition = community_louvain.best_partition(subgraph)\n",
    "            modularity = community_louvain.modularity(partition, subgraph)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erro ao detectar comunidades: {e}\")\n",
    "            raise CommunityDetectionError(f\"Erro ao detectar comunidades: {e}\")\n",
    "\n",
    "        results[threshold] = {\n",
    "            'modularity': modularity,\n",
    "            'communities': partition,\n",
    "            'edges': edges_to_add\n",
    "        }\n",
    "\n",
    "    return results                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def semantic_approximation_and_modularity(graph, label1, label2, threshold_range, model_name='paraphrase-distilroberta-base-v2'):\n",
    "#     \"\"\"\n",
    "#     Calcula a aproximação semântica entre dois labels de nós e avalia a modularidade.\n",
    "\n",
    "#     Args:\n",
    "#         graph: Grafo NetworkX contendo os nós e arestas.\n",
    "#         label1: Primeiro label de nó.\n",
    "#         label2: Segundo label de nó.\n",
    "#         threshold_range: Range de valores de threshold para testar.\n",
    "#         model_name: Nome do modelo SentenceTransformer a ser usado (opcional).\n",
    "\n",
    "#     Returns:\n",
    "#         Dicionário com resultados para cada threshold, incluindo:\n",
    "#             - modularity: Valor de modularidade.\n",
    "#             - communities: Dicionário com as comunidades encontradas.\n",
    "#             - edges: Lista de arestas adicionadas ao grafo.\n",
    "#     \"\"\"\n",
    "\n",
    "#     if test_gpu():\n",
    "#         if not is_gpu_memory_sufficient(model_name):\n",
    "#             model_name = 'all-mpnet-base-v2'  # Modelo menor\n",
    "#             logging.info(f\"Usando modelo menor: {model_name}\")\n",
    "#     else:\n",
    "#         logging.info(\"Usando CPU.\")\n",
    "\n",
    "#     clear_gpu_memory()  # Limpar a memória da GPU antes de usar o modelo\n",
    "\n",
    "#     try:\n",
    "#         # Tentar usar a GPU primeiro\n",
    "#         model = SentenceTransformer(model_name)\n",
    "#     except RuntimeError as e:\n",
    "#         if \"CUDA\" in str(e):\n",
    "#             logging.warning(f\"Erro de CUDA: {e}. Forçando o uso da CPU...\")\n",
    "#             # Forçar o uso da CPU\n",
    "#             model = SentenceTransformer(model_name, device='cpu')\n",
    "#         else:\n",
    "#             raise  # Re-lançar a exceção se não for um erro CUDA\n",
    "\n",
    "#     results = {}\n",
    "\n",
    "#     # Obter nós com os labels especificados\n",
    "#     nodes_label1 = [node for node, data in graph.nodes(data=True) if data.get('label') == label1]\n",
    "#     nodes_label2 = [node for node, data in graph.nodes(data=True) if data.get('label') == label2]\n",
    "\n",
    "#     if not nodes_label1 or not nodes_label2:\n",
    "#         raise ValueError(f\"Labels de nós não encontrados no grafo: {label1}, {label2}\")\n",
    "\n",
    "#     for threshold in threshold_range:\n",
    "#         edges_to_add = []\n",
    "#         for node1 in nodes_label1:\n",
    "#             for node2 in nodes_label2:\n",
    "#                 try:\n",
    "#                     text1 = graph.nodes[node1].get('name', '')\n",
    "#                     text2 = graph.nodes[node2].get('name', '')\n",
    "#                     embedding1 = model.encode(text1).reshape(1, -1)\n",
    "#                     embedding2 = model.encode(text2).reshape(1, -1)\n",
    "#                     similarity = cosine_similarity(embedding1, embedding2)[0][0]\n",
    "#                 except Exception as e:\n",
    "#                     logging.error(f\"Erro ao calcular a similaridade entre embeddings: {e}\")\n",
    "#                     raise\n",
    "\n",
    "#                 if similarity >= threshold:\n",
    "#                     edges_to_add.append((node1, node2))\n",
    "\n",
    "#         # Criar subgrafo com os nós e arestas relevantes\n",
    "#         subgraph = graph.subgraph(nodes_label1 + nodes_label2 + ['CompetenciaPesquisa'])\n",
    "#         subgraph.add_edges_from(edges_to_add)\n",
    "\n",
    "#         # Calcular modularidade\n",
    "#         try:\n",
    "#             partition = community_louvain.best_partition(subgraph)\n",
    "#             modularity = community_louvain.modularity(partition, subgraph)\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"Erro ao detectar comunidades: {e}\")\n",
    "#             raise CommunityDetectionError(f\"Erro ao detectar comunidades: {e}\")\n",
    "\n",
    "#         results[threshold] = {\n",
    "#             'modularity': modularity,\n",
    "#             'communities': partition,\n",
    "#             'edges': edges_to_add\n",
    "#         }\n",
    "\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25dfb14f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 14\u001b[0m\n\u001b[0;32m      6\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124mMATCH (n)\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124mWHERE NOT n:Revista OR EXISTS(()-[:PUBLICADO_EM]->(n))\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mOPTIONAL MATCH (n)-[r]-() \u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124mRETURN n, r\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     13\u001b[0m G \u001b[38;5;241m=\u001b[39m get_graph_from_neo4j(uri, user, password, query)\n\u001b[1;32m---> 14\u001b[0m results \u001b[38;5;241m=\u001b[39m semantic_approximation_and_modularity(G, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAreaAvaliacao\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrandeArea\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.8\u001b[39m])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "Cell \u001b[1;32mIn[51], line 144\u001b[0m, in \u001b[0;36msemantic_approximation_and_modularity\u001b[1;34m(graph, label1, label2, threshold_range, model_name)\u001b[0m\n\u001b[0;32m    141\u001b[0m     embedding1 \u001b[38;5;241m=\u001b[39m outputs1\u001b[38;5;241m.\u001b[39mpooler_output\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Converter para numpy\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     embedding2 \u001b[38;5;241m=\u001b[39m outputs2\u001b[38;5;241m.\u001b[39mpooler_output\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Converter para numpy\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m cosine_similarity(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(embedding1), torch\u001b[38;5;241m.\u001b[39mfrom_numpy(embedding2))[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Converter para escalar\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    146\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErro ao calcular a similaridade entre embeddings: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"password\"\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (n)\n",
    "WHERE NOT n:Revista OR EXISTS(()-[:PUBLICADO_EM]->(n))\n",
    "OPTIONAL MATCH (n)-[r]-() \n",
    "RETURN n, r\n",
    "\"\"\"\n",
    "\n",
    "G = get_graph_from_neo4j(uri, user, password, query)\n",
    "results = semantic_approximation_and_modularity(G, 'AreaAvaliacao', 'GrandeArea', [0.5, 0.6, 0.7, 0.8])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19c6417b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec67ce0",
   "metadata": {},
   "source": [
    "# <b>F05: Montar Grafo e analisar redes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e29eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"password\"\n",
    "persister = Neo4jPersister(uri, user, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2243df4d",
   "metadata": {},
   "source": [
    "### Persistir dados de revistas (14min 31.625 periódicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ccb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Persiste dados da lista Sucupira no Neo4j dados de > 31.000 revistas\n",
    "# t1 = time.time()\n",
    "# persister.persistir_revistas_da_planilha()\n",
    "# print(f'\\n{preparer.tempo(t1,time.time())} para persistir dados de todas 31.625 revistas da Plataforma Sucupira')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b89197",
   "metadata": {},
   "source": [
    "### Persistir dados dos docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47feea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_docent_nodes(dict_list_docents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b121f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_areas_nodes(dict_list_docents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc3190",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_producoes_pesquisador(dict_list_docents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7fe94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_pesquisador_grande_area_relationships(dict_list_docents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f2dc5a",
   "metadata": {},
   "source": [
    "### Persistir dados de discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d2526",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_discent_nodes(dict_list_discents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2adf899",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_producoes_pesquisador(dict_list_discents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_areas_nodes(dict_list_discents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de886282",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.persist_pesquisador_grande_area_relationships(dict_list_discents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00eb003",
   "metadata": {},
   "source": [
    "### Persistir dados de orientações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fefdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "preparer = EnvironmentSetup()\n",
    "persister.persist_advices_relationships(dict_list_docents)\n",
    "print(f'\\n{preparer.tempo(t1,time.time())} para persistir dados de todas orientações nos dados de docentes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x.keys() for x in dict_list_docents]\n",
    "[x.get('Produções') for x in dict_list_docents][1].get('Artigos completos publicados em periódicos')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14621d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.get('Orientações') for x in dict_list_docents][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60164ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.get('Orientações') for x in dict_list_discents][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b056f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\n{preparer.tempo(t00,time.time())} para recuperar, processar e persistir dados.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b615a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbd0a4ba",
   "metadata": {},
   "source": [
    "# <b>F06: Visualizar Grafos renderizados</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9431b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"password\"\n",
    "persister = Neo4jPersister(uri, user, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa17ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "persister.desenhar_grafo_revistas_capes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install groq\n",
    "# %pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f46865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5fc82d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "882cd6f7",
   "metadata": {},
   "source": [
    "# Interação via LLM Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419bb124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "keys,_,_,_,_ = jfm.load_from_json(os.path.join('../../../','secrets.json'))\n",
    "client = Groq(\n",
    "    api_key=keys.get('groq'),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    # model=\"llama3-8b-8192\",\n",
    "    model = 'llama3-70b-8192',\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001df8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "keys,_,_,_,_ = jfm.load_from_json(os.path.join('../../../','secrets.json'))\n",
    "client = Groq(\n",
    "    api_key=keys.get('groq'),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Gerenate a anime history about StarWars, and present the response in Brazilian Portuguese\",\n",
    "        }\n",
    "    ],\n",
    "    # model=\"llama3-8b-8192\",\n",
    "    model = 'llama3-70b-8192',\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b170f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "keys,_,_,_,_ = jfm.load_from_json(os.path.join('../../../','secrets.json'))\n",
    "client = Groq(\n",
    "    api_key=keys.get('groq'),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    # model=\"llama3-8b-8192\",\n",
    "    model = 'llama3-70b-8192',\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cypher from Natural Language\n",
    "from typing import List, Optional\n",
    "import json\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from groq import Groq\n",
    "\n",
    "groq = Groq(\n",
    "    api_key=keys.get('groq'),\n",
    ")\n",
    "\n",
    "# Data model for LLM to generate\n",
    "class Ingredient(BaseModel):\n",
    "    name: str\n",
    "    quantity: str\n",
    "    quantity_unit: Optional[str]\n",
    "\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    recipe_name: str\n",
    "    ingredients: List[Ingredient]\n",
    "    directions: List[str]\n",
    "\n",
    "\n",
    "def get_recipe(recipe_name: str) -> Recipe:\n",
    "    chat_completion = groq.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a recipe database that outputs recipes in JSON.\\n\"\n",
    "                # Pass the json schema to the model. Pretty printing improves results.\n",
    "                f\" The JSON object must use the schema: {json.dumps(Recipe.model_json_schema(), indent=2)}\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Fetch a recipe for {recipe_name}\",\n",
    "            },\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "        temperature=0,\n",
    "        # Streaming is not supported in JSON mode\n",
    "        stream=False,\n",
    "        # Enable JSON mode by setting the response format\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return Recipe.model_validate_json(chat_completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "def print_recipe(recipe: Recipe):\n",
    "    print(\"Recipe:\", recipe.recipe_name)\n",
    "\n",
    "    print(\"\\nIngredients:\")\n",
    "    for ingredient in recipe.ingredients:\n",
    "        print(\n",
    "            f\"- {ingredient.name}: {ingredient.quantity} {ingredient.quantity_unit or ''}\"\n",
    "        )\n",
    "    print(\"\\nDirections:\")\n",
    "    for step, direction in enumerate(recipe.directions, start=1):\n",
    "        print(f\"{step}. {direction}\")\n",
    "\n",
    "\n",
    "recipe = get_recipe(\"apple pie\")\n",
    "print_recipe(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db57dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "import json\n",
    "\n",
    "client = Groq(api_key = keys.get('groq'))\n",
    "MODEL = 'llama3-70b-8192'\n",
    "\n",
    "\n",
    "# Example dummy function hard coded to return the score of an NBA game\n",
    "def get_game_score(team_name):\n",
    "    \"\"\"Get the current score for a given NBA game\"\"\"\n",
    "    if \"warriors\" in team_name.lower():\n",
    "        return json.dumps({\"game_id\": \"401585601\", \"status\": 'Final', \"home_team\": \"Los Angeles Lakers\", \"home_team_score\": 121, \"away_team\": \"Golden State Warriors\", \"away_team_score\": 128})\n",
    "    elif \"lakers\" in team_name.lower():\n",
    "        return json.dumps({\"game_id\": \"401585601\", \"status\": 'Final', \"home_team\": \"Los Angeles Lakers\", \"home_team_score\": 121, \"away_team\": \"Golden State Warriors\", \"away_team_score\": 128})\n",
    "    elif \"nuggets\" in team_name.lower():\n",
    "        return json.dumps({\"game_id\": \"401585577\", \"status\": 'Final', \"home_team\": \"Miami Heat\", \"home_team_score\": 88, \"away_team\": \"Denver Nuggets\", \"away_team_score\": 100})\n",
    "    elif \"heat\" in team_name.lower():\n",
    "        return json.dumps({\"game_id\": \"401585577\", \"status\": 'Final', \"home_team\": \"Miami Heat\", \"home_team_score\": 88, \"away_team\": \"Denver Nuggets\", \"away_team_score\": 100})\n",
    "    else:\n",
    "        return json.dumps({\"team_name\": team_name, \"score\": \"unknown\"})\n",
    "\n",
    "def run_conversation(user_prompt):\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a function calling LLM that uses the data extracted from the get_game_score function to answer questions around NBA game scores. Include the team and their opponent in your response.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_game_score\",\n",
    "                \"description\": \"Get the score for a given NBA game\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"team_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The name of the NBA team (e.g. 'Golden State Warriors')\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"team_name\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        max_tokens=4096\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_game_score\": get_game_score,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                team_name=function_args.get(\"team_name\")\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response.choices[0].message.content\n",
    "\n",
    "user_prompt = \"What was the score of the Warriors game?\"\n",
    "print(run_conversation(user_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be0009",
   "metadata": {},
   "source": [
    "# Outros testes e experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a77e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_tipo_instancias_arvore(estrutura, nivel=1, identacao=\"\"):\n",
    "    \"\"\"\n",
    "    Função recursiva que avalia o tipo e a quantidade de instâncias em cada nível da estrutura, exibindo-a em formato de árvore.\n",
    "\n",
    "    Args:\n",
    "        estrutura (list|dict): A estrutura a ser avaliada.\n",
    "        nivel (int): Nível atual da recurssão (inicia em 1).\n",
    "        identacao (str): String de indentação para cada nível (inicia vazia).\n",
    "\n",
    "    Returns:\n",
    "        None: A função imprime os resultados na tela e não retorna nada.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(estrutura, list):\n",
    "        print(f\"{identacao}N{nivel}. Lista: {len(estrutura)} elementos\")\n",
    "        for item in estrutura:\n",
    "            avaliar_tipo_instancias_arvore(item, nivel + 1, identacao + \"    \")\n",
    "\n",
    "    elif isinstance(estrutura, dict):\n",
    "        print(f\"{identacao}N{nivel}. Mapa: {estrutura.keys()}\")\n",
    "        for chave, valor in estrutura.items():\n",
    "            print(f\"{identacao}  {chave}:\")\n",
    "            avaliar_tipo_instancias_arvore(valor, nivel + 1, identacao + \"    \")\n",
    "\n",
    "    elif isinstance(estrutura, str):\n",
    "        print(f\"{identacao}N{nivel}. String: {estrutura}\")\n",
    "\n",
    "for dict_pesq in dict_list_docents[:3]:\n",
    "    avaliar_tipo_instancias_arvore(dict_pesq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc6c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict_pesq in dict_list_docents:\n",
    "    if isinstance(dict_pesq, list):\n",
    "        print(f'L1. Lista: {dict_pesq}')\n",
    "    elif isinstance(dict_pesq, dict):\n",
    "        print(f'L1. Mapa: {dict_pesq.keys()}')\n",
    "        for tipo in dict_pesq.values():\n",
    "            if isinstance(tipo, list):\n",
    "                print(f'    L2. Lista: {tipo}')\n",
    "            elif isinstance(tipo, dict):\n",
    "                print(f'    L2. Mapa: {tipo}')\n",
    "                for subtipo in tipo.values():\n",
    "                    if isinstance(subtipo, list):\n",
    "                        print(f'        L3. Lista: {len(subtipo)} elementos')\n",
    "                        for subsubtipo in subtipo:\n",
    "                            if isinstance(subsubtipo, list):\n",
    "                                print(f'            L4. Lista: {subsubtipo}')\n",
    "                            elif isinstance(subsubtipo, dict):\n",
    "                                print(f'            L4. Mapa: {subsubtipo.keys()}')\n",
    "                                for subsubsubtipo in subsubtipo.values():\n",
    "                                    if isinstance(subsubsubtipo, list):\n",
    "                                        print(f'                L5. Lista: {subsubsubtipo}')\n",
    "                                    elif isinstance(subsubsubtipo, dict):\n",
    "                                        print(f'                L5. Mapa: {subsubsubtipo.keys()}')\n",
    "                                    elif isinstance(subsubsubtipo, str):\n",
    "                                        print(f'                L5. String: {subsubsubtipo}')                                  \n",
    "                            elif isinstance(subsubtipo, str):\n",
    "                                print(f'            L4. String: {subsubtipo}')     \n",
    "                    elif isinstance(subtipo, dict):\n",
    "                        print(f'        L3. Mapa: {subtipo.keys()}')\n",
    "                        for subsubtipo in subtipo.values():\n",
    "                            if isinstance(subsubtipo, list):\n",
    "                                print(f'            L4. Lista: {subsubtipo}')\n",
    "                            elif isinstance(subsubtipo, dict):\n",
    "                                print(f'            L4. Mapa: {subsubtipo.keys()}')\n",
    "                            elif isinstance(subsubtipo, str):\n",
    "                                print(f'            L4. String: {subsubtipo}')                             \n",
    "                    elif isinstance(tipo, str):\n",
    "                        print(f'        L3. String: {subtipo}')                \n",
    "            elif isinstance(tipo, str):\n",
    "                print(f'    L2. String: {tipo}')\n",
    "    elif isinstance(dict_pesq, str):\n",
    "        print(f'L1. String: {dict_pesq}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list[20:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991a5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_list[20].get('Identificação').items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_list[5].get('Idiomas'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e49f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(x.get('Descrição') for x in dict_list[5].get('Linhas de Pesquisa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7213c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_list[5].get('Áreas').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0886075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tipos=[]\n",
    "for pesq in dict_list:\n",
    "    for t, s in pesq.get('Produções').items():\n",
    "        if t not in tipos:\n",
    "            tipos.append(t)\n",
    "            print(t, type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_list[1].get('Produções').get('Artigos completos publicados em periódicos')[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb7c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_list[5].get('Atuação Profissional'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_list[5].get('Formação').items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e1f72",
   "metadata": {},
   "source": [
    "## Classe para gerar dados para grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "# import json\n",
    "\n",
    "# class Neo4jConnection:\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "\n",
    "#     def persist_data(self, data):\n",
    "#         with self._driver.session() as session:\n",
    "#             for person_data in data:\n",
    "#                 person_id = person_data['Identificação']['ID Lattes']\n",
    "#                 prepared_data, relationships = self._prepare_data(person_data, person_id)\n",
    "#                 session.write_transaction(self._create_person_node, person_id, prepared_data)\n",
    "#                 self._create_relationships(session, person_id, relationships)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _create_person_node(tx, person_id, person_data):\n",
    "#         tx.run(\n",
    "#             \"MERGE (p:Person {id_lattes: $person_id}) \"\n",
    "#             \"SET p += $person_data\",\n",
    "#             person_id=person_id,\n",
    "#             person_data=person_data\n",
    "#         )\n",
    "\n",
    "#     def _prepare_data(self, data, person_id):\n",
    "#         prepared_data = {}\n",
    "#         relationships = []\n",
    "#         for key, value in data.items():\n",
    "#             if isinstance(value, dict):\n",
    "#                 label = key.capitalize().replace(' ', '_')\n",
    "#                 prepared_data.update({f'{label}_{k}': v for k, v in value.items()})\n",
    "#                 sub_prepared_data, sub_relationships = self._prepare_data(value, person_id)\n",
    "#                 prepared_data.update(sub_prepared_data)\n",
    "#                 relationships.extend(sub_relationships)\n",
    "#                 relationships.append((label, {'label': 'Person', 'person_id': person_id}))\n",
    "#             elif isinstance(value, list):\n",
    "#                 for idx, item in enumerate(value):\n",
    "#                     if isinstance(item, dict):\n",
    "#                         nested_label = f'{key}_{idx}'\n",
    "#                         nested_prepared_data, nested_relationships = self._prepare_data(item, person_id)\n",
    "#                         prepared_data.update({f'{nested_label}_{k}': v for k, v in item.items()})\n",
    "#                         prepared_data.update(nested_prepared_data)\n",
    "#                         relationships.extend(nested_relationships)\n",
    "#                         relationships.append((nested_label, {'label': key.capitalize().replace(' ', '_'), 'person_id': person_id}))\n",
    "#                     elif isinstance(item, str):\n",
    "#                         # Tratar strings\n",
    "#                         if \":\" in item:\n",
    "#                             label, value = item.split(\":\", 1)\n",
    "#                             prepared_data[f'{key}_{idx}'] = value.strip()\n",
    "#                             relationships.append((label.strip(), {'label': key.capitalize().replace(' ', '_'), 'person_id': person_id}))\n",
    "#                         else:\n",
    "#                             prepared_data[f'{key}_{idx}'] = item.strip()\n",
    "#         return prepared_data, relationships\n",
    "\n",
    "#     def _create_relationships(self, session, person_id, relationships):\n",
    "#         for label, parent_id in relationships:\n",
    "#             query = (\n",
    "#                 f\"MATCH (p:Person {{id_lattes: '{person_id}'}}) \"\n",
    "#                 f\"MATCH (n:{label} {{id_lattes: '{person_id}_{label}'}}) \"\n",
    "#                 f\"MERGE (p)-[:HAS_{label}]->(n)\"\n",
    "#             )\n",
    "#             if parent_id:\n",
    "#                 query += (\n",
    "#                     f\" MERGE (parent:{parent_id['label']} {{id_lattes: '{parent_id['person_id']}'}}) \"\n",
    "#                     f\"MERGE (parent)-[:HAS_{label}]->(n)\"\n",
    "#                 )\n",
    "#             session.run(query)\n",
    "\n",
    "# # Dados de conexão com o banco de dados Neo4j\n",
    "# uri = \"bolt://localhost:7687\"\n",
    "# user = \"neo4j\"\n",
    "# password = \"password\"\n",
    "\n",
    "# # Conecta-se ao banco de dados Neo4j e persiste os dados\n",
    "# connection = Neo4jConnection(uri, user, password)\n",
    "# connection.persist_data(dict_list)\n",
    "# connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85580969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# from neo4j import GraphDatabase\n",
    "# import ast\n",
    "\n",
    "# class GraphPreparer:\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._uri = uri\n",
    "#         self._user = user\n",
    "#         self._password = password\n",
    "#         self._driver = None\n",
    "\n",
    "#     def connect(self):\n",
    "#         self._driver = GraphDatabase.driver(self._uri, auth=(self._user, self._password))\n",
    "\n",
    "#     def prepare_data_from_file(self, file_path):\n",
    "#         nodes = []\n",
    "#         relationships = []\n",
    "\n",
    "#         with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#             data = json.load(file)\n",
    "\n",
    "#         for person_data in data:\n",
    "#             print(person_data.keys())\n",
    "#             person_id = person_data['Identificação'].get('ID Lattes')\n",
    "#             nodes.append(('Pesquisador', {'id_lattes': person_id}))\n",
    "            \n",
    "#             for language in person_data.get('Idiomas', []):\n",
    "#                 language_name = language['Idioma']\n",
    "#                 proficiency = language['Proficiência']\n",
    "#                 nodes.append(('Idioma', {'nome_idioma': language_name, 'proficiencia': proficiency}))\n",
    "#                 relationships.append(('Pesquisador', {'id_lattes': person_id}, 'FALA', {'nome_idioma': language_name}))\n",
    "            \n",
    "#             for academic_info in person_data.get('Formação', {}).get('Acadêmica', []):\n",
    "#                 description = academic_info['Descrição']\n",
    "#                 nodes.append(('Curso', {'descricao': description}))\n",
    "#                 relationships.append(('Pesquisador', {'id_lattes': person_id}, 'REALIZOU', {'descricao': description}))\n",
    "                \n",
    "#             for professional_info in person_data.get('Atuação Profissional', []):\n",
    "#                 institution = professional_info['Instituição']\n",
    "#                 description = professional_info['Descrição']\n",
    "#                 relationships.append(('Pesquisador', {'id_lattes': person_id}, 'ATUA', {'instituicao': institution, 'descricao': description}))\n",
    "\n",
    "#         return nodes, relationships\n",
    "\n",
    "#     def persist_data(self, data_for_neo4j):\n",
    "#         try:\n",
    "#             with self._driver.session() as session:\n",
    "#                 for data in data_for_neo4j:\n",
    "#                     if data[0] == 'Node':\n",
    "#                         label, properties = data[1:]\n",
    "#                         session.write_transaction(self._create_node, label, **properties)\n",
    "#                     elif data[0] == 'Relationship':\n",
    "#                         start_label, rel_type, end_label = data[1:]\n",
    "#                         session.write_transaction(self._create_relationship, start_label, rel_type, end_label)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error persisting data: {e}\")\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _create_node(tx, label, **properties):\n",
    "#         query = f\"CREATE (n:{label} $props)\"\n",
    "#         tx.run(query, props=properties)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _create_relationship(tx, start_label, rel_type, end_label):\n",
    "#         query = \"MATCH (a:{start_label}), (b:{end_label}) \" \\\n",
    "#                 \"CREATE (a)-[r:{rel_type}]->(b)\"\n",
    "#         tx.run(query, start_label=start_label, rel_type=rel_type, end_label=end_label)\n",
    "\n",
    "#     def close(self):\n",
    "#         if self._driver is not None:\n",
    "#             self._driver.close()\n",
    "\n",
    "# # Exemplo de utilização:\n",
    "# graph_preparer = GraphPreparer(uri=\"bolt://localhost:7687\", user=\"neo4j\", password=\"password\")\n",
    "# graph_preparer.connect()\n",
    "\n",
    "# filepath = os.path.join(folder_data_input,'dict_list.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca32e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_list[0]['Idioma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ecf0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes, relationships = graph_preparer.prepare_data_from_file(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78acb05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_for_neo4j = nodes + relationships\n",
    "# graph_preparer.persist_data(data_for_neo4j)\n",
    "\n",
    "# graph_preparer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1823211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "# from datetime import datetime\n",
    "\n",
    "# uri = \"bolt://localhost:7687\"\n",
    "# user = \"neo4j\"\n",
    "# password = \"password\"\n",
    "# graph_preparer = GraphPreparer(uri, user, password) # Instanciar classe GraphPreparer\n",
    "# graph_preparer.connect() # Conectar ao banco de dados Neo4j\n",
    "# graph_preparer.process_data(dict_list) # Processar e persistir dados\n",
    "\n",
    "# # Transformar os dados para o formato adequado do Neo4j\n",
    "# dados_para_neo4j = graph_preparer.transform_data_for_neo4j(dict_list)\n",
    "# graph_preparer.persist_nodes_and_relationships(dados_para_neo4j) # PersistiR nós e relações no Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e803731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52fd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados_para_neo4j[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def42ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "# # Agora você pode inserir os dados no Neo4j utilizando sua biblioteca de acesso ao banco de dados Neo4j, por exemplo:\n",
    "# neo4j_driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))\n",
    "# with neo4j_driver.session() as session:\n",
    "#     for item in data_for_neo4j:\n",
    "#         label, properties = item\n",
    "#         cypher_query = f\"CREATE (:{label} $properties)\"\n",
    "#         session.run(cypher_query, properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc9672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Função para criar nós e relações\n",
    "# def create_nodes_and_relationships(tx, nodes_and_relationships):\n",
    "#     for item in nodes_and_relationships:\n",
    "#         if len(item) == 3:  # Se for uma relação\n",
    "#             origin_node, rel_type, dest_node = item\n",
    "#             tx.run(\n",
    "#                 f\"MATCH (a), (b) WHERE a.name = $origin_node AND b.name = $dest_node \"\n",
    "#                 \"CREATE (a)-[r:\" + rel_type + \"]->(b)\",\n",
    "#                 origin_node=origin_node, dest_node=dest_node\n",
    "#             )\n",
    "\n",
    "# # Conectando ao banco de dados Neo4j e executando a transação\n",
    "# with GraphDatabase.driver(uri, auth=(user, password)) as driver:\n",
    "#     with driver.session() as session:\n",
    "#         session.write_transaction(create_nodes_and_relationships, relacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed9787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# class Neo4jGraphGenerator:\n",
    "#     def __init__(self, dict_list):\n",
    "#         self.dict_list = dict_list\n",
    "#         self.graph_data = {'nodes': [], 'relationships': []}\n",
    "\n",
    "#     def generate_graph_json(self):\n",
    "#         for item in self.dict_list:\n",
    "#             id_lattes = item.get('Identificação', {}).get('ID Lattes')\n",
    "#             pesquisador = item.get('Identificação', {}).get('Nome')\n",
    "            \n",
    "#             # Adicionar nó de pessoa (Person)\n",
    "#             person_node = {'id': id_lattes, 'label': 'Person', 'name': pesquisador}\n",
    "#             self.graph_data['nodes'].append(person_node)\n",
    "\n",
    "#             areas = item.get('Áreas', {})\n",
    "#             for area in areas.values():\n",
    "#                 # Adicionar nó de Grande Área (GrandeArea)\n",
    "#                 grande_area_node = {'id': area['Grande Área'], 'label': 'GrandeArea', 'description': area['Grande Área']}\n",
    "#                 self.graph_data['nodes'].append(grande_area_node)\n",
    "#                 self.graph_data['relationships'].append({'source': id_lattes, 'target': area['Grande Área'], 'type': 'BELONGS_TO'})\n",
    "                \n",
    "#                 for subarea in area.get('Subáreas', []):\n",
    "#                     # Adicionar nó de Área (Area)\n",
    "#                     area_node = {'id': subarea['Área'], 'label': 'Area', 'description': subarea['Área']}\n",
    "#                     self.graph_data['nodes'].append(area_node)\n",
    "#                     self.graph_data['relationships'].append({'source': area['Grande Área'], 'target': subarea['Área'], 'type': 'BELONGS_TO'})\n",
    "                    \n",
    "#                     # Adicionar nó de Subárea (Subarea)\n",
    "#                     subarea_node = {'id': subarea['Subárea'], 'label': 'Subarea', 'description': subarea['Subárea']}\n",
    "#                     self.graph_data['nodes'].append(subarea_node)\n",
    "#                     self.graph_data['relationships'].append({'source': subarea['Área'], 'target': subarea['Subárea'], 'type': 'BELONGS_TO'})\n",
    "\n",
    "#         return json.dumps(self.graph_data, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da358b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = Neo4jGraphGenerator(dict_list)\n",
    "# generator.generate_graph_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03290d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import re\n",
    "# from neo4j import GraphDatabase\n",
    "\n",
    "# class AreasHandler:\n",
    "\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "        \n",
    "#     def consult_areas_atuacao(self, name):\n",
    "#         with self._driver.session() as session:\n",
    "#             result = session.run(\"MATCH (p:Person {name: $name}) RETURN p.`Áreas de atuação` as areas_atuacao\", name=name)\n",
    "#             record = result.single()\n",
    "#             if record:\n",
    "#                 return record['areas_atuacao']\n",
    "#             return None\n",
    "\n",
    "#     def debug_and_convert(self, areas_str):\n",
    "#         try:\n",
    "#             return json.loads(areas_str)\n",
    "#         except json.JSONDecodeError:\n",
    "#             print(f\"Failed to deserialize JSON string: {areas_str}\")\n",
    "#             return None\n",
    "\n",
    "#     def extract_subarea(self, area_detail):\n",
    "#         # Extract the 'Subárea' content from the area detail\n",
    "#         match = re.search(r'Subárea: ([^/]+)', area_detail)\n",
    "#         if match:\n",
    "#             return match.group(1).strip()\n",
    "#         return None\n",
    "\n",
    "#     def extract_areas(self, area_detail):\n",
    "#         # Extract the 'Grande Área', 'Área', and 'Subárea' contents from the area detail\n",
    "#         grande_area_match = re.search(r'Grande área: ([^/]+)', area_detail)\n",
    "#         area_match = re.search(r'Área: ([^/]+)', area_detail)\n",
    "#         subarea_match = re.search(r'Subárea: ([^/]+)', area_detail)\n",
    "        \n",
    "#         grande_area = grande_area_match.group(1).strip() if grande_area_match else None\n",
    "#         area = area_match.group(1).strip() if area_match else None\n",
    "#         subarea = subarea_match.group(1).strip() if subarea_match else None\n",
    "        \n",
    "#         return grande_area, area, subarea\n",
    "\n",
    "#     def create_areas_relations(self, name):\n",
    "#         # Get 'Áreas de atuação' properties\n",
    "#         areas_properties = self.consult_areas_atuacao(name)\n",
    "\n",
    "#         # Convert the serialized JSON strings back into dictionaries\n",
    "#         try:\n",
    "#             deserialized_areas_properties = self.debug_and_convert(areas_properties)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error deserializing 'Áreas de atuação' properties: {e}\")\n",
    "#             return\n",
    "\n",
    "#         successful_areas_creations = 0\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             for _, area_detail in deserialized_areas_properties.items():\n",
    "#                 try:\n",
    "#                     # Extracting Grande Área, Área, and Subárea from the details\n",
    "#                     match = re.match(r'Grande área: (.*?) / Área: (.*?) / Subárea: (.*?)(?:/Especialidade: (.*?))?\\.?$', area_detail)\n",
    "#                     if not match:\n",
    "#                         print(f\"Unexpected format for 'Áreas de atuação' detail: {area_detail}\")\n",
    "#                         continue\n",
    "#                     grande_area, area, subarea = match.groups()[:3]\n",
    "\n",
    "#                     # Creating or merging nodes for Subárea, Área, and Grande Área\n",
    "#                     session.run(\"MERGE (s:Subárea {name: $subarea})\", subarea=subarea)\n",
    "#                     session.run(\"MERGE (a:Área {name: $area})\", area=area)\n",
    "#                     session.run(\"MERGE (ga:GrandeÁrea {name: $grande_area})\", grande_area=grande_area)\n",
    "\n",
    "#                     # Creating or merging relationships. Using MERGE ensures no duplicate relationships are created.\n",
    "#                     session.run(\"MATCH (p:Person {name: $name}), (s:Subárea {name: $subarea}) MERGE (p)-[r:ATUA_EM]->(s)\", name=name, subarea=subarea)\n",
    "#                     session.run(\"MATCH (ga:GrandeÁrea {name: $grande_area}), (a:Área {name: $area}) MERGE (ga)-[r:CONTÉM_ÁREA]->(a)\", grande_area=grande_area, area=area)\n",
    "#                     session.run(\"MATCH (a:Área {name: $area}), (s:Subárea {name: $subarea}) MERGE (a)-[r:CONTEM_SUBÁREA]->(s)\", area=area, subarea=subarea)\n",
    "\n",
    "#                     successful_areas_creations += 1\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing 'Áreas de atuação' detail '{area_detail}': {e}\")\n",
    "\n",
    "#             # Inform the user about areas\n",
    "#             print(f\"{successful_areas_creations} 'Áreas de atuação' relations successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fdc77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uri = \"bolt://localhost:7687\"\n",
    "# user = \"neo4j\"\n",
    "# password = \"password\"\n",
    "\n",
    "# handleareas = AreasHandler(uri, user, password)\n",
    "# name = 'Antonio Marcos Aires Barbosa'\n",
    "# handleareas.consult_areas_atuacao(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefb3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5003e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "# import urllib.parse\n",
    "# import json\n",
    "# import re\n",
    "\n",
    "# class AdvisorHandler:\n",
    "\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "\n",
    "#     @staticmethod\n",
    "#     def convert_to_primitives(input_data):\n",
    "#         if input_data is None:\n",
    "#             return None\n",
    "#         if isinstance(input_data, dict):\n",
    "#             for key, value in input_data.items():\n",
    "#                 if isinstance(value, dict):  \n",
    "#                     input_data[key] = json.dumps(AdvisorHandler.convert_to_primitives(value), ensure_ascii=False)\n",
    "#                 else:\n",
    "#                     input_data[key] = AdvisorHandler.convert_to_primitives(value)\n",
    "#             return input_data\n",
    "#         elif isinstance(input_data, list):\n",
    "#             return [AdvisorHandler.convert_to_primitives(item) for item in input_data]\n",
    "#         elif isinstance(input_data, str):\n",
    "#             if 'http://' in input_data or 'https://' in input_data:\n",
    "#                 parts = input_data.split(\" \")\n",
    "#                 new_parts = [urllib.parse.quote(part) if part.startswith(('http://', 'https://')) else part for part in parts]\n",
    "#                 return \" \".join(new_parts)\n",
    "#             return input_data\n",
    "#         elif isinstance(input_data, (int, float, bool)):\n",
    "#             return input_data\n",
    "#         else:\n",
    "#             return str(input_data)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def debug_and_convert(input_data):\n",
    "#         try:\n",
    "#             return AdvisorHandler.convert_to_primitives(input_data)\n",
    "#         except:\n",
    "#             print(\"Conversion failed for:\", input_data)\n",
    "#             raise\n",
    "\n",
    "#     def consult_orientacoes(self, name):\n",
    "#         with self._driver.session() as session:\n",
    "#             query = (\n",
    "#                 \"MATCH (p:Person {name: $name})\"\n",
    "#                 \"RETURN p.Orientações AS orientacoes\"\n",
    "#             )\n",
    "#             result = session.run(query, name=name)\n",
    "#             orient_data = result.single()[\"orientacoes\"]\n",
    "#             if orient_data is None:\n",
    "#                 raise ValueError(f\"No data found for 'Orientações' attribute for Person '{name}'\")\n",
    "#             orient_properties_list = json.loads(orient_data)\n",
    "#             return orient_properties_list\n",
    "\n",
    "#     def create_advisor_relations(self, name):\n",
    "#         # Get Orientações properties\n",
    "#         orient_properties = self.consult_orientacoes(name)\n",
    "\n",
    "#         # Convert the serialized JSON strings back into dictionaries\n",
    "#         try:\n",
    "#             deserialized_orient_properties = self.debug_and_convert(orient_properties)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error deserializing Orientações properties: {e}\")\n",
    "#             return\n",
    "\n",
    "#         # Advisory relationship mapping\n",
    "#         advisory_types = {\n",
    "#             \"Dissertação de mestrado\": \"ORIENTOU_MESTRADO\",\n",
    "#             \"Tese de doutorado\": \"ORIENTOU_DOUTORADO\",\n",
    "#             \"Trabalho de conclusão de curso de graduação\": \"ORIENTOU_GRADUAÇÃO\"\n",
    "#         }\n",
    "\n",
    "#         successful_advisory_creations = 0\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             for orientacao_category, advisories in deserialized_orient_properties.items():\n",
    "#                 if isinstance(advisories, str):\n",
    "#                     try:\n",
    "#                         advisories = json.loads(advisories)\n",
    "#                     except json.JSONDecodeError:\n",
    "#                         print(f\"Failed to deserialize JSON string in 'Orientações' for category '{orientacao_category}': {advisories}\")\n",
    "#                         continue\n",
    "\n",
    "#                 if not isinstance(advisories, dict):\n",
    "#                     print(f\"Unexpected data type in 'Orientações' for category '{orientacao_category}': {advisories}\")\n",
    "#                     continue\n",
    "\n",
    "#                 for advisory_type, relationships in advisories.items():\n",
    "#                     relation_label = advisory_types.get(advisory_type)\n",
    "#                     if not relation_label:\n",
    "#                         continue  # skip if the advisory type is not one of the specified ones\n",
    "\n",
    "#                     for _, detail in json.loads(relationships).items():\n",
    "#                         try:\n",
    "#                             student_name = detail.split(\".\")[0]\n",
    "#                             title = detail.split(\".\")[1]\n",
    "                            \n",
    "#                             # Extract the year from the detail string\n",
    "#                             year_match = re.search(r'(\\d{4})', detail)\n",
    "#                             year = year_match.group(1) if year_match else None\n",
    "\n",
    "#                             # Create or merge the Orientações node\n",
    "#                             node_query = (\n",
    "#                                 \"MERGE (a:Orientações {Title: $title}) \"\n",
    "#                                 \"ON CREATE SET a.StudentName = $student_name, a.Tipo = $advisory_type, a.Year = $year \"\n",
    "#                                 \"ON MATCH SET a.Tipo = $advisory_type, a.Year = $year \"  # Ensure the 'Tipo' and 'Year' are always updated\n",
    "#                                 \"RETURN a\"\n",
    "#                             )\n",
    "#                             session.run(node_query, title=title, student_name=student_name, advisory_type=advisory_type, year=year)\n",
    "\n",
    "#                             # Create or update the advisory relationship\n",
    "#                             relation_query = (\n",
    "#                                 f\"MATCH (p:Person {{name: $name}}), (a:Orientações {{Title: $title}}) \"\n",
    "#                                 f\"MERGE (p)-[r:{relation_label}]->(a) \"\n",
    "#                             )\n",
    "#                             session.run(relation_query, name=name, title=title)\n",
    "\n",
    "#                             successful_advisory_creations += 1\n",
    "#                         except Exception as e:\n",
    "#                             print(f\"Error processing advisory '{detail}': {e}\")\n",
    "\n",
    "#         # Inform the user about advisories\n",
    "#         print(f\"{successful_advisory_creations} orientações atualizadas com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "\n",
    "# class DataRemovalHandler:\n",
    "\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         \"\"\"\n",
    "#         Inicializa a classe DataRemovalHandler com informações de conexão ao banco de dados Neo4j.\n",
    "\n",
    "#         Parâmetros:\n",
    "#         - uri (str): URI de conexão ao Neo4j.\n",
    "#         - user (str): Nome de usuário para autenticação.\n",
    "#         - password (str): Senha para autenticação.\n",
    "#         \"\"\"\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         \"\"\"\n",
    "#         Fecha a conexão com o banco de dados Neo4j.\n",
    "#         \"\"\"\n",
    "#         self._driver.close()\n",
    "\n",
    "#     def delete_nodes_by_label(self, label):\n",
    "#         \"\"\"\n",
    "#         Deleta todos os nós associados a um label específico no Neo4j.\n",
    "\n",
    "#         Parâmetro:\n",
    "#         - label (str): O label dos nós a serem deletados.\n",
    "\n",
    "#         Retorna:\n",
    "#         - int: O número de nós deletados.\n",
    "#         \"\"\"\n",
    "#         with self._driver.session() as session:\n",
    "#             # Esta consulta combina com todos os nós do label especificado e os deleta\n",
    "#             result = session.run(f\"MATCH (n:{label}) DETACH DELETE n RETURN count(n) as deleted_count\")\n",
    "#             deleted_count = result.single()[\"deleted_count\"]\n",
    "#             return deleted_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e663506",
   "metadata": {},
   "source": [
    "## Interação dados do e-Lattes\n",
    "\n",
    "- Fazer análise com lista dos nomes no e-lattes e baixar os arquivos gerados\n",
    "- Salvar na pasta _data/in_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090dde8d-29f4-4736-b400-beb9627220af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Funções origem para classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install levenshtein\n",
    "# !pip3 install editdistance\n",
    "# !pip3 install seaborn\n",
    "# !pip3 install pyjarowinkler\n",
    "\n",
    "# import os\n",
    "# import re\n",
    "# import csv\n",
    "# import json\n",
    "# import time\n",
    "# import json\n",
    "# import zipfile\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from string import Formatter\n",
    "# from datetime import date, timedelta\n",
    "# from datetime import datetime as dt\n",
    "# from unidecode import unidecode\n",
    "# from plotly.subplots import make_subplots\n",
    "# from pyjarowinkler.distance import get_jaro_distance\n",
    "# from IPython.display import clear_output, display, HTML\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('colheader_justify', 'left')\n",
    "\n",
    "# class PreparadorDePublicacoes:\n",
    "#     def __init__(self):\n",
    "#         self.data = []\n",
    "#         self.colunas = ['idLattes', 'nome', 'tipo', 'titulo_do_capitulo', 'idioma', 'titulo_do_livro', 'ano', 'doi', 'pais_de_publicacao', 'isbn', \n",
    "#         'nome_da_editora', 'numero_da_edicao_revisao', 'organizadores', 'paginas', 'autores', 'autores-endogeno', 'autores-endogeno-nome', 'tags', \n",
    "#         'Hash', 'tipo_producao', 'natureza', 'titulo', 'nome_do_evento', 'ano_do_trabalho', 'pais_do_evento', 'cidade_do_evento', 'classificacao', \n",
    "#         'periodico', 'volume', 'issn', 'estrato_qualis', 'editora', 'numero_de_paginas', 'numero_de_volumes']\n",
    "\n",
    "#     def extrair_dados(self, registro, tipo_producao):\n",
    "#         linha = {coluna: None for coluna in self.colunas}\n",
    "#         linha['tipo_producao'] = tipo_producao  # Define o tipo de produção com base na chave do dicionário\n",
    "        \n",
    "#         # Mapear diretamente os campos do registro para a linha, assegurando que todos os campos desejados sejam extraídos\n",
    "#         for campo in ['titulo', 'idioma', 'periodico', 'ano', 'volume', 'issn', 'estrato_qualis', 'pais_de_publicacao', 'paginas', 'doi']:\n",
    "#             linha[campo] = registro.get(campo, '')\n",
    "\n",
    "#         # Tratar os autores como uma string concatenada se eles existirem\n",
    "#         linha['autores'] = '; '.join(registro.get('autores', []))\n",
    "\n",
    "#         # Tratar os campos 'autores-endogeno' e 'autores-endogeno-nome'\n",
    "#         if 'autores-endogeno' in registro and registro['autores-endogeno']:\n",
    "#             id_endogeno = registro['autores-endogeno'][0]\n",
    "#             linha['idLattes'] = id_endogeno\n",
    "#             linha['nome'] = registro['autores-endogeno-nome'][0].get(id_endogeno, None)\n",
    "        \n",
    "#         # Adicionar os outros campos conforme necessário aqui\n",
    "#         # Por exemplo, tratamento de 'tags', 'Hash', etc., quando necessário\n",
    "\n",
    "#         return linha\n",
    "\n",
    "#     def processar_publicacoes(self):\n",
    "#         linhas = []\n",
    "#         # Itera diretamente sobre cada registro em self.data\n",
    "#         for registro in self.data:\n",
    "#             linha = self.extrair_dados(registro, registro.get('tipo_producao', 'Desconhecido'))\n",
    "#             linhas.append(linha)\n",
    "#         return linhas\n",
    "\n",
    "#     def extract_zips(self, pathzip):\n",
    "#         destination = os.path.join(os.getcwd(), '_data', 'in_json')\n",
    "#         if not os.path.exists(destination):\n",
    "#             os.makedirs(destination)\n",
    "#             print(f\"Criada pasta para armazenar dados descompactados: {destination}\")\n",
    "#         else:\n",
    "#             print(f\"Descompactando arquivos para: {destination}\")\n",
    "\n",
    "#         with zipfile.ZipFile(pathzip, 'r') as zip_ref:\n",
    "#             zip_ref.extractall(destination)\n",
    "        \n",
    "#         print(\"Descompactação concluída...\")\n",
    "#         return destination  # Retorna o caminho onde os arquivos foram descompactados\n",
    "\n",
    "#     def find_and_merge_publication_json_files(self, pathjson):\n",
    "#         all_data = []\n",
    "#         for filename in os.listdir(pathjson):\n",
    "#             if 'publication.json' in filename:\n",
    "#                 print(f\"Extraindo dados do arquivo '{filename}'...\")\n",
    "#                 with open(os.path.join(pathjson, filename), 'r', encoding='utf-8') as file:\n",
    "#                     file_data = json.load(file)\n",
    "#                     for tipo_producao in file_data:  # Para cada tipo de produção no arquivo\n",
    "#                         for ano in file_data[tipo_producao]:  # Para cada ano dentro de um tipo de produção\n",
    "#                             for registro in file_data[tipo_producao][ano]:  # Itera sobre cada registro\n",
    "#                                 # Adicionar ou atualizar o campo 'tipo_producao' em cada registro\n",
    "#                                 registro_atualizado = registro.copy()  # Fazer cópia para evitar modificar o original\n",
    "#                                 registro_atualizado['tipo_producao'] = tipo_producao  # Atualizar ou adicionar o campo 'tipo_producao'\n",
    "#                                 all_data.append(registro_atualizado)  # Adicionar o registro atualizado à lista\n",
    "\n",
    "#         # Salva a lista unificada em um novo arquivo JSON\n",
    "#         unified_json_path = os.path.join(pathjson, 'unified_pub.json')\n",
    "#         with open(unified_json_path, 'w', encoding='utf-8') as unified_file:\n",
    "#             json.dump(all_data, unified_file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "#         print(f\"Arquivo unificado criado em: {unified_json_path}\")\n",
    "\n",
    "#         # Atualiza self.data com os dados unidos\n",
    "#         self.data = all_data\n",
    "\n",
    "#     def merge_publication_json_files(self, pathjson):\n",
    "#         \"\"\"\n",
    "#         This function receives a path to a JSON folder, accesses the folder's contents, searches for files\n",
    "#         containing 'publication.json' in their filename, merges their contents and saves the resulting\n",
    "#         data as a CSV file in destination folder.\n",
    "#         \"\"\"\n",
    "#         data = []\n",
    "#         # Looping through the files in the given path\n",
    "#         for filename in os.listdir(pathjson):\n",
    "#             if 'publication.json' in filename:\n",
    "#                 print(f\"Extraindo dados do arquivo {filename}...\")\n",
    "#                 # Opening the file and appending its data to the list\n",
    "#                 with open(os.path.join(pathjson, filename), 'r', encoding='utf-8') as file:\n",
    "#                     data.append(json.load(file))\n",
    "\n",
    "#         # Creating the output directory if it doesn't exist\n",
    "#         destination = os.path.join(os.getcwd(), '_data','powerbi')\n",
    "#         if not os.path.exists(destination):\n",
    "#             os.mkdir(destination)\n",
    "\n",
    "#         # Writing the merged data to a CSV file\n",
    "#         print(f\"Criando arquivo CSV...\")\n",
    "#         with open(os.path.join(destination, 'publication.csv'), 'w', encoding='utf-8', newline='') as csv_file:\n",
    "#             writer = csv.writer(csv_file)\n",
    "#             # Writing the header based on the keys of the first item in the list\n",
    "#             writer.writerow(data[0].keys())\n",
    "#             # Looping through the items in the list and writing them as rows in the CSV file\n",
    "#             for item in data:\n",
    "#                 writer.writerow(item.values())\n",
    "\n",
    "#     def exportar_para_csv(self, nome_arquivo='publicacoes.csv'):\n",
    "#         linhas = self.processar_publicacoes()\n",
    "#         df = pd.DataFrame(linhas, columns=self.colunas)\n",
    "#         filepathcsv = os.path.join(\"./\",\"_data\",\"powerbi\",nome_arquivo)\n",
    "#         df.to_csv(filepathcsv, index=False)\n",
    "#         print(f'Arquivo criado com sucesso em {filepathcsv}')\n",
    "\n",
    "#     def ler_csv_dados(self, pathdata,filename):\n",
    "#         filepath = os.path.join(pathdata,filename)\n",
    "#         df_pub=pd.read_csv(filepath)\n",
    "#         tipos = df_pub['tipo_producao'].value_counts()\n",
    "#         qualis=df_pub['estrato_qualis'].value_counts()  \n",
    "#         quantidade_nan = df_pub['estrato_qualis'].isna().sum()\n",
    "#         tipos_qualis = qualis.count()\n",
    "#         percentual_nan=np.round(quantidade_nan/tipos.sum()*100,1)\n",
    "#         print(f\"\\n{tipos.sum()} linhas no total, distribuídas nos seguintes tipos de produção:\")\n",
    "#         print(f\"{quantidade_nan} linhas ({percentual_nan}% do total de linhas) com NaN no campo estrato_qualis\")\n",
    "#         print(tipos)\n",
    "#         ano_min=df_pub['ano'].min()\n",
    "#         ano_max=df_pub['ano'].max()\n",
    "#         print(f\"\\n{tipos.get('PERIODICO', 0)} publicações em periódicos, no período de {int(ano_min)} a {int(ano_max)}\")\n",
    "#         percentual=np.round(qualis.sum()/tipos.get('PERIODICO', 0)*100,1)\n",
    "#         print(f\"{qualis.sum()} publicações ({percentual}%) classificadas no qualis periodicos conforme estratificação:\")\n",
    "#         quantidade_nan_periodico = df_pub[df_pub['tipo_producao'] == 'PERIODICO']['estrato_qualis'].isna().sum()\n",
    "#         percentual_nan_periodico = np.round(quantidade_nan_periodico/tipos.get('PERIODICO', 0)*100,1)\n",
    "#         print(f\"{quantidade_nan_periodico} publicações em periódicos ({percentual_nan_periodico}%) com valor 'NaN' no estrato_qualis\\n\")\n",
    "#         print(qualis)\n",
    "#         return df_pub\n",
    "\n",
    "#     def ler_xls_dados(self, pathdata,filename):\n",
    "#         filepath = os.path.join(pathdata,filename)\n",
    "#         df_pub=pd.read_excel(filepath)\n",
    "#         tipos = df_pub['tipo_producao'].value_counts()\n",
    "#         qualis=df_pub['estrato_qualis'].value_counts()\n",
    "#         tipos_qualis = qualis.count()\n",
    "#         print(f\"\\n{tipos.sum()} linhas no total, distribuídas nos seguintes tipos de produção:\")\n",
    "#         print(tipos)\n",
    "#         ano_min=df_pub['ano'].min()\n",
    "#         ano_max=df_pub['ano'].max()\n",
    "#         print(f\"\\n{tipos.get('PERIODICO', 0)} publicações em periódicos, no período de {int(ano_min)} a {int(ano_max)}\")\n",
    "#         percentual=np.round(qualis.sum()/tipos.get('PERIODICO', 0)*100,1)\n",
    "#         print(f\"{qualis.sum()} publicações ({percentual}%) classificadas no qualis periodicos conforme estratificação:\")\n",
    "#         print(qualis)\n",
    "#         return df_pub\n",
    "\n",
    "#     def sigla_producao(self, tipo_producao, separador=\"\"):\n",
    "#         \"\"\"\n",
    "#         Função para converter os valores da coluna 'tipo_producao' em siglas, desconsiderando preposições,\n",
    "#         fazendo split de 'tipo_producao' em palavras também pelo caractere \"_\".\n",
    "        \n",
    "#         Parâmetros:\n",
    "#         - tipo_producao: O valor da coluna 'tipo_producao'.\n",
    "#         - separador: O caractere para separar as iniciais. Padrão é \"_\".\n",
    "        \n",
    "#         Retorna:\n",
    "#         - Uma string que é a sigla formada pelas iniciais das palavras em 'tipo_producao', desconsiderando preposições.\n",
    "#         \"\"\"\n",
    "#         # Lista de preposições para serem ignoradas\n",
    "#         preposicoes = ['e', 'de', 'do', 'da', 'dos', 'das', 'em', 'na', 'no', 'nas', 'nos', 'por', 'para', 'com']\n",
    "\n",
    "#         # Mapeamento de exemplo conforme as siglas fornecidas\n",
    "#         mapeamento_siglas = {\n",
    "#             \"DTPB\": 1, #DEMAIS_TIPOS_DE_PRODUCAO_BIBLIOGRAFICA \n",
    "#             \"TJ\": 2, #TEXTO_EM_JORNAIS\n",
    "#             \"E\": 3, #EVENTO\n",
    "#             \"CL\": 4, #CAPITULO_DE_LIVRO\n",
    "#             \"L\": 5, #LIVRO\n",
    "#             \"AA\": 6, #ARTIGO_ACEITO\n",
    "#             \"P\": 7, #PERIODICO\n",
    "#         }\n",
    "\n",
    "#         # Fazendo split por espaço e por underscore\n",
    "#         palavras = tipo_producao.replace('_', ' ').replace('-', ' ').split()\n",
    "\n",
    "#         # Inicializar a lista de iniciais\n",
    "#         iniciais = []\n",
    "\n",
    "#         for palavra in palavras:\n",
    "#             # Verificar se a palavra não é uma preposição e não está vazia\n",
    "#             if palavra.lower() not in preposicoes and palavra:\n",
    "#                 # Adicionar a inicial em maiúsculo à lista de iniciais\n",
    "#                 iniciais.append(palavra[0].upper())\n",
    "\n",
    "#         # Juntar as iniciais para formar a sigla\n",
    "#         sigla = \"\".join(iniciais)\n",
    "\n",
    "#         # Aplicar o mapeamento para encontrar o número correspondente à sigla\n",
    "#         numero = mapeamento_siglas.get(sigla, \"\")\n",
    "\n",
    "#         # Retornar a string formatada com o número e a sigla\n",
    "#         return f\"{numero}-{sigla}\"  \n",
    "\n",
    "#     def sigla_qualis(self, estrato_qualis, separador=\"\"):\n",
    "#         \"\"\"\n",
    "#         Função para converter os valores da coluna 'estrato_qualis' em siglas com números de ordenação,\n",
    "        \n",
    "#         Parâmetros:\n",
    "#         - estrato_qualis: O valor da coluna 'estrato_qualis'.\n",
    "#         - separador: O caractere para separar as iniciais. Padrão é \"_\".\n",
    "        \n",
    "#         Retorna:\n",
    "#         - Uma string que é a sigla formada pelas iniciais das palavras em 'estrato_qualis' antecedida por seu número de ordenação.\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Mapeamento de exemplo conforme as siglas fornecidas\n",
    "#         mapeamento_siglas = {\n",
    "#             \"C\": 1,\n",
    "#             \"B4\": 2,\n",
    "#             \"B3\": 3,\n",
    "#             \"B2\": 4,\n",
    "#             \"B1\": 5,\n",
    "#             \"B2\": 6,\n",
    "#             \"B1\": 7,\n",
    "#             \"A4\": 8,\n",
    "#             \"A3\": 9,\n",
    "#             \"A2\": 10,\n",
    "#             \"A1\": 11,\n",
    "#         }\n",
    "\n",
    "#         # Aplicar o mapeamento para encontrar o número correspondente à sigla\n",
    "#         numero = mapeamento_siglas.get(estrato_qualis, \"\")\n",
    "\n",
    "#         # Retornar a string formatada com o número e a sigla\n",
    "#         return f\"{numero}-{estrato_qualis}\"\n",
    "\n",
    "#     def agrupar_publicacoes(self, filename):\n",
    "#         # Caminho para o arquivo CSV\n",
    "#         pathfilename = os.path.join(os.getcwd(), '_data', 'powerbi', filename)\n",
    "#         df = pd.read_csv(pathfilename)\n",
    "\n",
    "#         # Use .loc para modificar o DataFrame diretamente e evitar o aviso\n",
    "#         df.loc[:, 'sigla_producao'] = df['tipo_producao'].apply(lambda x: self.sigla_producao(x))\n",
    "#         df_publicacoes = df[['idLattes','ano','sigla_producao']]\n",
    "\n",
    "#         # Agrupar por 'ano', 'natureza' e orientador e contar as ocorrências\n",
    "#         contagem_publicacoes = df_publicacoes.groupby(['ano','sigla_producao','idLattes']).size().reset_index(name='contagem')\n",
    "\n",
    "#         # Retornar a contagem de orientações por tipo e por ano\n",
    "#         return contagem_publicacoes\n",
    "\n",
    "#     def agrupar_qualis(self, filename):\n",
    "#         # Caminho para o arquivo CSV\n",
    "#         pathfilename = os.path.join(os.getcwd(), '_data', 'powerbi', filename)\n",
    "#         df = pd.read_csv(pathfilename)\n",
    "\n",
    "#         # # Use .loc para modificar o DataFrame diretamente e evitar o aviso\n",
    "#         df.loc[:, 'estrato_qualis'] = df['estrato_qualis'].apply(lambda x: self.sigla_qualis(x))\n",
    "#         df_publicacoes = df[['idLattes','ano','estrato_qualis']]\n",
    "\n",
    "#         # Remover todas as linhas que contêm pelo menos um valor NaN\n",
    "#         df_publicacoes_limpo = df_publicacoes.dropna()\n",
    "\n",
    "#         # Agrupar por 'ano', 'natureza' e orientador e contar as ocorrências\n",
    "#         contagem_qualis = df_publicacoes_limpo.groupby(['ano','estrato_qualis','idLattes']).size().reset_index(name='contagem')\n",
    "\n",
    "#         # Retornar a contagem de orientações por tipo e por ano\n",
    "#         return contagem_qualis\n",
    "\n",
    "#     def plotar_producoes_barras_empilhadas(self, filename):\n",
    "#         contagem_publicacoes = self.agrupar_publicacoes(filename)\n",
    "#         fig = make_subplots(rows=1, cols=1)\n",
    "#         anos = sorted(contagem_publicacoes['ano'].unique())\n",
    "\n",
    "#         mapeamento_siglas_para_numeros = {\n",
    "#             \"1-DTPB\": 1, # Demais tipos de produção bibliográfica\n",
    "#             \"2-TJ\": 2, # Texto em jornais\n",
    "#             \"3-E\": 3, # Evento\n",
    "#             \"4-CL\": 4, # Capítulo de Livro\n",
    "#             \"5-L\": 5, # Livro\n",
    "#             \"6-AA\": 6, # Artigo Aceito\n",
    "#             \"7-P\": 7, # Periódico\n",
    "#         }\n",
    "\n",
    "#         naturezas_ordenadas = sorted(contagem_publicacoes['sigla_producao'].unique(), key=lambda x: mapeamento_siglas_para_numeros.get(x, 999))\n",
    "\n",
    "#         for natureza in naturezas_ordenadas:\n",
    "#             contagem_por_ano = []\n",
    "#             labels_por_ano = [] # Para armazenar os rótulos de dados\n",
    "#             for ano in anos:\n",
    "#                 contagem = contagem_publicacoes[(contagem_publicacoes['ano'] == ano) & (contagem_publicacoes['sigla_producao'] == natureza)]['contagem'].sum()\n",
    "#                 if mapeamento_siglas_para_numeros.get(natureza, 999) in [1, 2, 3, 4]:\n",
    "#                     contagem = -contagem\n",
    "#                 contagem_por_ano.append(contagem)\n",
    "#                 labels_por_ano.append(str(contagem)) # Convertendo a contagem em string para usar como rótulo\n",
    "            \n",
    "#             # Adicionar a barra ao gráfico com rótulos de dados\n",
    "#             fig.add_trace(go.Bar(x=anos, y=contagem_por_ano, name=natureza, text=labels_por_ano, textposition='auto'))\n",
    "\n",
    "#         # Atualizar o layout para permitir barras empilhadas, ajustar o eixo Y para mostrar valores negativos, e garantir que todos os anos sejam mostrados no eixo X\n",
    "#         fig.update_layout(\n",
    "#             barmode='relative',\n",
    "#             title_text='Contagem de Produções por Tipo e Ano (Produção de divulgação plotadas abaixo do eixo X)',\n",
    "#             xaxis_title=\"Ano\",\n",
    "#             yaxis_title=\"Quantidade de Produções Biliográficas\",\n",
    "#             yaxis=dict(zeroline=True, zerolinewidth=2, zerolinecolor='black'),\n",
    "#         )        \n",
    "#         # Garantir que todos os anos apareçam na barra de rótulos do eixo X\n",
    "#         fig.update_xaxes(tickmode='array', tickvals=anos)\n",
    "#         fig.show()\n",
    "\n",
    "\n",
    "#     def plotar_qualis_barras_empilhadas(self, filename):\n",
    "#         contagem_publicacoes = self.agrupar_qualis(filename)\n",
    "#         contagem_publicacoes.replace(\"-nan\", np.nan, inplace=True)\n",
    "#         contagem_publicacoes.dropna(inplace=True)\n",
    "#         fig = make_subplots(rows=1, cols=1)\n",
    "#         anos = sorted(contagem_publicacoes['ano'].unique())\n",
    "\n",
    "#         mapeamento_siglas_para_numeros = {\n",
    "#             \"1-C\": 1, \"2-B4\": 2, \"3-B3\": 3, \"4-B2\": 4, \"5-B1\": 5,\n",
    "#             \"6-B2\": 6, \"7-B1\": 7, \"8-A4\": 8, \"9-A3\": 9, \"10-A2\": 10, \"11-A1\": 11,\n",
    "#         }\n",
    "#         naturezas_ordenadas = sorted(contagem_publicacoes['estrato_qualis'].unique(), key=lambda x: mapeamento_siglas_para_numeros.get(x, 999))\n",
    "        \n",
    "#         # Obter a paleta de cores 'Greens'\n",
    "#         cores = px.colors.sequential.Greens\n",
    "#         # Certificar que temos cores suficientes para todas as barras, repetindo a paleta se necessário\n",
    "#         num_barras = len(naturezas_ordenadas)\n",
    "#         cores_repetidas = cores * (num_barras // len(cores) + 1)\n",
    "        \n",
    "#         for index, natureza in enumerate(naturezas_ordenadas):\n",
    "#             contagem_por_ano = []\n",
    "#             for ano in anos:\n",
    "#                 contagem = contagem_publicacoes[(contagem_publicacoes['ano'] == ano) & (contagem_publicacoes['estrato_qualis'] == natureza)]['contagem'].sum()\n",
    "#                 if mapeamento_siglas_para_numeros.get(natureza, 999) in [1, 2, 3, 4, 5, 6, 7]:\n",
    "#                     contagem = -contagem\n",
    "#                 contagem_por_ano.append(contagem)\n",
    "            \n",
    "#             # Usar uma cor da paleta para cada barra\n",
    "#             fig.add_trace(go.Bar(x=anos, y=contagem_por_ano, name=natureza, marker_color=cores_repetidas[index]))\n",
    "\n",
    "#         fig.update_layout(\n",
    "#             barmode='relative',\n",
    "#             title_text='Contagem de Produções por Estrato Qualis e Ano (Qualis abaixo de B plotado do eixo X)',\n",
    "#             xaxis_title=\"Ano\",\n",
    "#             yaxis_title=\"Quantidade de Publicações\",\n",
    "#             yaxis=dict(zeroline=True, zerolinewidth=2, zerolinecolor='black'),\n",
    "#         )\n",
    "#         # Garantir que todos os anos apareçam na barra de rótulos do eixo X\n",
    "#         fig.update_xaxes(tickmode='array', tickvals=anos)        \n",
    "#         fig.show()\n",
    "\n",
    "# class PreparadorDeOrientacoes():\n",
    "#     def __init__(self):\n",
    "#         self.data = []\n",
    "#         self.colunas = ['id_lattes_orientadores', 'tipo_orientacao', 'natureza', 'titulo', 'idioma', 'ano', 'id_lattes_aluno', 'nome_aluno', 'instituicao', 'pais', 'curso', 'codigo_do_curso', 'bolsa', 'agencia_financiadora', 'codigo_agencia_financiadora', 'nome_orientadores', 'tags', 'Hash']\n",
    "#         self.pathjson = os.path.join('_data','in_json')\n",
    "#         # self.filename = '863.advise.json'\n",
    "\n",
    "#         # Abrir o arquivo e carregando o JSON\n",
    "#     def open_file(self, filename):\n",
    "#         with open(os.path.join(self.pathjson, filename), 'r', encoding='utf-8') as file:\n",
    "#             data = json.load(file)\n",
    "        \n",
    "#         linhas_achatadas = self.extrair_orientacoes(data)\n",
    "#         df = pd.DataFrame(linhas_achatadas)\n",
    "#         df.to_csv('orientacoes_achatadas.csv', index=False)\n",
    "#         return df\n",
    "    \n",
    "#     def agrupar_orientacoes(self, filename):\n",
    "#         # Caminho para o arquivo JSON\n",
    "#         pathfilename = os.path.join('_data', 'in_json', filename)\n",
    "#         # dict_orientacoes = pd.read_json(pathfilename)\n",
    "\n",
    "#         # Carregar o JSON e aplicar a função\n",
    "#         with open(pathfilename, 'r', encoding='utf-8') as file:\n",
    "#             data = json.load(file)\n",
    "\n",
    "#         linhas_achatadas = self.extrair_orientacoes(data)\n",
    "#         df = pd.DataFrame(linhas_achatadas)\n",
    "\n",
    "#         # Salvar os dados achatados em um CSV\n",
    "#         df.to_csv('orientacoes_achatadas.csv', index=False)\n",
    "\n",
    "#         # Use .loc para modificar o DataFrame diretamente e evitar o aviso\n",
    "#         df.loc[:, 'sigla_natureza'] = df['natureza'].apply(lambda x: self.sigla_natureza(x))\n",
    "#         df_orientacoes = df[['id_lattes_orientadores','ano','sigla_natureza']]\n",
    "\n",
    "#         # Agrupar por 'ano', 'natureza' e orientador e contar as ocorrências\n",
    "#         contagem_orientacoes = df_orientacoes.groupby(['ano','sigla_natureza','id_lattes_orientadores']).size().reset_index(name='contagem')\n",
    "\n",
    "#         # Retornar a contagem de orientações por tipo e por ano\n",
    "#         return contagem_orientacoes\n",
    "\n",
    "#     # Prosseguir com a definição e uso da função para extrair as orientações\n",
    "#     def extrair_orientacoes(self, json_data):\n",
    "#         colunas = self.colunas\n",
    "#         linhas = []\n",
    "\n",
    "#         # Iterar sobre cada tipo de orientação e ano\n",
    "#         for tipo_orientacao, anos in json_data.items():\n",
    "#             for ano, orientacoes in anos.items():\n",
    "#                 for orientacao in orientacoes:\n",
    "#                     # Preparar um dicionário para cada linha de acordo com as colunas definidas\n",
    "#                     linha = {}\n",
    "#                     # Adicionar dados específicos da orientação\n",
    "#                     for campo in orientacao:\n",
    "#                         if campo in colunas:\n",
    "#                             linha[campo] = orientacao[campo]\n",
    "#                     # Tratar 'id_lattes_orientadores' como uma lista, juntar os IDs com vírgula se houver mais de um\n",
    "#                     linha['id_lattes_orientadores'] = ', '.join(orientacao.get('id_lattes_orientadores', []))\n",
    "#                     # Adicionar o tipo de orientação como uma coluna\n",
    "#                     linha['tipo_orientacao'] = tipo_orientacao\n",
    "#                     # Adicionar o ano, garantindo que sobreponha qualquer valor de 'ano' nos dados individuais\n",
    "#                     linha['ano'] = ano\n",
    "#                     linhas.append(linha)\n",
    "\n",
    "#         return linhas\n",
    "\n",
    "#     def sigla_natureza(self, natureza, separador=\"\"):\n",
    "#         \"\"\"\n",
    "#         Função para converter os valores da coluna 'natureza' em siglas, desconsiderando preposições,\n",
    "#         fazendo split de 'natureza' em palavras também pelo caractere \"_\".\n",
    "        \n",
    "#         Parâmetros:\n",
    "#         - natureza: O valor da coluna 'natureza'.\n",
    "#         - separador: O caractere para separar as iniciais. Padrão é \"_\".\n",
    "        \n",
    "#         Retorna:\n",
    "#         - Uma string que é a sigla formada pelas iniciais das palavras em 'natureza', desconsiderando preposições.\n",
    "#         \"\"\"\n",
    "#         # Lista de preposições para serem ignoradas\n",
    "#         preposicoes = ['e', 'de', 'do', 'da', 'dos', 'das', 'em', 'na', 'no', 'nas', 'nos', 'por', 'para', 'com']\n",
    "\n",
    "#         # Mapeamento de exemplo conforme as siglas fornecidas\n",
    "#         mapeamento_siglas = {\n",
    "#             \"OON\": 1, #Orientações de Outra Natureza\n",
    "#             \"IC\": 2, #Iniciação Científica\n",
    "#             \"MCCAE\": 3, #Monografia de Conclusão Curso de Atualização ou Especialização\n",
    "#             \"SPD\": 4, #\n",
    "#             \"TCCG\": 5, #Trabalho de Conclusão de Curso de Graduação\n",
    "#             \"DM\": 6, #Dissertação de Mestrado\n",
    "#             \"TD\": 7, #Tese de Doutorado\n",
    "#         }\n",
    "\n",
    "#         # Fazendo split por espaço e por underscore\n",
    "#         palavras = natureza.replace('_', ' ').replace('-', ' ').split()\n",
    "\n",
    "#         # Inicializar a lista de iniciais\n",
    "#         iniciais = []\n",
    "\n",
    "#         for palavra in palavras:\n",
    "#             # Verificar se a palavra não é uma preposição e não está vazia\n",
    "#             if palavra.lower() not in preposicoes and palavra:\n",
    "#                 # Adicionar a inicial em maiúsculo à lista de iniciais\n",
    "#                 iniciais.append(palavra[0].upper())\n",
    "\n",
    "#         # Juntar as iniciais para formar a sigla\n",
    "#         sigla = \"\".join(iniciais)\n",
    "\n",
    "#         # Aplicar o mapeamento para encontrar o número correspondente à sigla\n",
    "#         numero = mapeamento_siglas.get(sigla, \"Desconhecido\")\n",
    "\n",
    "#         # Retornar a string formatada com o número e a sigla\n",
    "#         return f\"{numero}-{sigla}\"     \n",
    "\n",
    "#     def plotar_orientacoes_barras_agrupadas(self, filename):\n",
    "#         # montar dataframe com agrupamento de orientações por tipo por ano no programa\n",
    "#         contagem_orientacoes = self.agrupar_orientacoes(filename)\n",
    "\n",
    "#         # Criar uma figura com subplots\n",
    "#         fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "#         # Encontrar anos e naturezas únicos para as orientações\n",
    "#         anos = sorted(contagem_orientacoes['ano'].unique())\n",
    "\n",
    "#         # Mapeamento de exemplo conforme as siglas fornecidas\n",
    "#         mapeamento_siglas = {\n",
    "#             \"OON\": 1,\n",
    "#             \"IC\": 2,\n",
    "#             \"MCCAE\": 3,\n",
    "#             \"SPD\": 4,\n",
    "#             \"TCCG\": 5,\n",
    "#             \"DM\": 6,\n",
    "#             \"TD\": 7,\n",
    "#         }\n",
    "\n",
    "#         # Ordenar as naturezas com base nos números associados em mapeamento_siglas\n",
    "#         mapeamento_siglas_para_numeros = {sigla: int(sigla.split('-')[0]) for sigla in contagem_orientacoes['sigla_natureza'].unique()}\n",
    "#         naturezas_ordenadas = sorted(contagem_orientacoes['sigla_natureza'].unique(), key=lambda x: mapeamento_siglas_para_numeros.get(x, 999))\n",
    "\n",
    "#         # Criar uma barra para cada tipo de orientação em cada ano\n",
    "#         for natureza in naturezas_ordenadas:\n",
    "#             contagem_por_ano = []\n",
    "#             for ano in anos:\n",
    "#                 # Somar as contagens para cada ano e natureza\n",
    "#                 contagem = contagem_orientacoes[(contagem_orientacoes['ano'] == ano) & (contagem_orientacoes['sigla_natureza'] == natureza)]['contagem'].sum()\n",
    "#                 contagem_por_ano.append(contagem)\n",
    "            \n",
    "#             # Adicionar a barra ao gráfico\n",
    "#             fig.add_trace(go.Bar(x=anos, y=contagem_por_ano, name=natureza))\n",
    "\n",
    "#         # Atualizar o layout para permitir barras agrupadas\n",
    "#         fig.update_layout(barmode='group', title_text='Contagem de Orientações no Programa por Tipo e Ano', xaxis_title=\"Ano\", yaxis_title=\"Quantidade de Orientações\")\n",
    "\n",
    "#         # Mostrar o gráfico\n",
    "#         fig.show()\n",
    "\n",
    "\n",
    "#     def plotar_orientacoes_barras_empilhadas(self, filename):\n",
    "#         # montar dataframe com agrupamento de orientações por tipo por ano no programa\n",
    "#         contagem_orientacoes = self.agrupar_orientacoes(filename)\n",
    "        \n",
    "#         # Criar uma figura com subplots\n",
    "#         fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "#         # Encontrar anos únicos para as orientações\n",
    "#         anos = sorted(contagem_orientacoes['ano'].unique())\n",
    "\n",
    "#         # Mapeamento para siglas de tipos de orientações\n",
    "#         mapeamento_siglas = {\n",
    "#             \"OON\": 1,\n",
    "#             \"IC\": 2,\n",
    "#             \"MCCAE\": 3,\n",
    "#             \"SPD\": 4,\n",
    "#             \"TCCG\": 5,\n",
    "#             \"DM\": 6,\n",
    "#             \"TD\": 7,\n",
    "#         }\n",
    "\n",
    "#         # Mapeamento para ordenar siglas por duração/complexidade\n",
    "#         mapeamento_siglas_para_numeros = {\n",
    "#             \"1-OON\": 1,\n",
    "#             \"2-IC\": 2,\n",
    "#             \"3-MCCAE\": 3,\n",
    "#             \"4-SPD\": 4,\n",
    "#             \"5-TCCG\": 5,\n",
    "#             \"6-DM\": 6,\n",
    "#             \"7-TD\": 7,\n",
    "#         }\n",
    "\n",
    "#         # Ordenar as naturezas baseando-se no número extraído da sigla\n",
    "#         naturezas_ordenadas = sorted(contagem_orientacoes['sigla_natureza'].unique(), key=lambda x: mapeamento_siglas_para_numeros.get(x, 999))\n",
    "\n",
    "#         # Criar uma barra para cada tipo de orientação em cada ano, seguindo a ordem definida\n",
    "#         for natureza in naturezas_ordenadas:\n",
    "#             contagem_por_ano = []\n",
    "#             for ano in anos:\n",
    "#                 # Somar as contagens para cada ano e natureza\n",
    "#                 contagem = contagem_orientacoes[(contagem_orientacoes['ano'] == ano) & (contagem_orientacoes['sigla_natureza'] == natureza)]['contagem'].sum()\n",
    "#                 # Se a sigla estiver associada ao número 1 ou 2, tornar a contagem negativa\n",
    "#                 if mapeamento_siglas_para_numeros.get(natureza, 999) in [1, 2, 3, 4]:\n",
    "#                     contagem = -contagem\n",
    "#                 contagem_por_ano.append(contagem)\n",
    "            \n",
    "#             # Adicionar a barra ao gráfico\n",
    "#             fig.add_trace(go.Bar(x=anos, y=contagem_por_ano, name=natureza))\n",
    "\n",
    "#         # Atualizar o layout para permitir barras empilhadas e ajustar o eixo Y para mostrar valores negativos\n",
    "#         fig.update_layout(\n",
    "#             barmode='relative',  # Usar 'relative' para empilhar incluindo valores negativos\n",
    "#             title_text='Contagem de Orientações por Tipo e Ano (Orientações de curta duração plotadas abaixo do eixo X)',\n",
    "#             xaxis_title=\"Ano\",\n",
    "#             yaxis_title=\"Quantidade de Orientações\",\n",
    "#             yaxis=dict(zeroline=True, zerolinewidth=2, zerolinecolor='black'),  # Destacar a linha zero\n",
    "#         )\n",
    "\n",
    "#         # Mostrar o gráfico\n",
    "#         fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8007a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"./\"\n",
    "# print(f\"     Pasta corrente: {path}\")\n",
    "# pathjson = os.path.join(path,'_data','in_json')\n",
    "# print(f\"Pasta arquivos JSON: {pathjson}\")\n",
    "# try:\n",
    "#     pathdata = os.path.join(path,'_data','powerbi')\n",
    "#     print(f\" Pasta de dados CSV: {pathdata}\")\n",
    "# except:\n",
    "#     print('Pasta de dados ainda não existe.')\n",
    "\n",
    "# print(\"\\nConteúdo da pasta JSON:\")\n",
    "# list(os.listdir(pathjson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Descompactar arquivo zipado na pasta JSON\n",
    "# prep_pub = PreparadorDePublicacoes()\n",
    "# pathfilezip = '_data/in_zip/890.files.zip'\n",
    "# destination = prep_pub.extract_zips(pathfilezip)\n",
    "\n",
    "# ## Unir todos aquivos de publicações (caso haja mais de um com final publication.json na pasta serão mesclados):\n",
    "# prep_pub.find_and_merge_publication_json_files(pathjson)\n",
    "\n",
    "# ## Mapear arquivo de dados para PowerBI a partir do JSON unificado\n",
    "# linhas = prep_pub.processar_publicacoes()\n",
    "# prep_pub.exportar_para_csv()\n",
    "\n",
    "# ## Ler e montar análise exploratória\n",
    "# filename='publicacoes.csv'\n",
    "# df_pub = prep_pub.ler_csv_dados(pathdata,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61df53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename='890.advise.json'\n",
    "# pathjson = os.path.join('_data','in_json')\n",
    "# pathfilename = os.path.join(pathjson,filename)\n",
    "# print(pathfilename)\n",
    "# dict_orientacoes = pd.read_json(pathfilename)\n",
    "# print(f'{len(dict_orientacoes):02} dicionários com dados de orientações')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_orientacoes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c4685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep_ort = PreparadorDeOrientacoes()\n",
    "# prep_ort.plotar_orientacoes_barras_agrupadas(filename)\n",
    "# prep_ort.plotar_orientacoes_barras_empilhadas(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathcsv = os.path.join('_data','powerbi')\n",
    "# os.listdir(pathcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be258ab8",
   "metadata": {},
   "source": [
    "## Demais passos\n",
    "\n",
    "Calcular índice de publicação em conjunto com alunos do programa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1574aac1",
   "metadata": {},
   "source": [
    "- Levantar nome dos discentes do programa\n",
    "- Levantar os nomes de autores nas publicações de docentes\n",
    "- Identificar por similadidade as publicações onde constam nome de alunos do programa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb00d652",
   "metadata": {},
   "source": [
    "    Padronizar nomes de autores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94552058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def limpar_nomes(linha_texto):\n",
    "#     '''\n",
    "#     Retira erros e sujeira da string formada pela lista de nomes de autor dos artigos retirada do Lattes\n",
    "#      Recebe: Uma string com os nomes de autor\n",
    "#     Retorna: Uma string com os nomes de autor, removidas preposições, acentos, e demais erros pontuais\n",
    "#     '''\n",
    "#     import unicodedata\n",
    "#     import re\n",
    "#     # print('               Analisando:',linha_texto)\n",
    "#     string = linha_texto.replace('Network for Genomic Surveillance in South Africa;Network for Genomic Surveillance in South Africa (NGS-SA);10.1002/jmv.27190;','')\n",
    "#     string = string.replace('Autores: ','').replace('(Org)','').replace('(Org.)','').replace('et. al.','').replace('et al','').replace('(Org).','').replace('.','').replace('\\'','')\n",
    "#     string = string.replace(',,,',',').replace(',,',',').replace(';',', ').replace('-',' ').replace('S?', 'SA').replace('S?', 'SA').replace('ARA?JO', 'ARAUJO').replace('FL?VIO','FLAVIO').replace('F?BIO','FABIO').replace('VIT?RIO','VITORIO')\n",
    "#     string = re.sub(r'[0-9]+', '', string)\n",
    "#     partes_string = string.split(' ')\n",
    "\n",
    "#     ## Retirar partes de nomes caso sejam preposições\n",
    "#     preposicoes = ['da', 'de', 'do', 'das', 'dos', ' e ']\n",
    "#     string = ' '.join(x for x in partes_string if x.lower() not in preposicoes)\n",
    "\n",
    "#     ## Retirar símbolos não unicode, como acentuação gráfica e cedilha\n",
    "#     string = ''.join(ch for ch in unicodedata.normalize('NFKD', string) if not unicodedata.combining(ch))\n",
    "    \n",
    "#     ## Retirar iniciais juntas, separando-as com espaço em branco\n",
    "#     letras_duasconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2}$')            # Duas Letras consoantes maiúsculas juntas do início ao final da string\n",
    "#     letras_tresconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3}$')            # Três Letras consoantes maiúsculas juntas do início ao final da string\n",
    "#     letras_duasconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2},$')       # Duas Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "#     letras_tresconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3},$')       # Três Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "    \n",
    "#     partes_nome=[]\n",
    "#     for j in string.split(' '):\n",
    "#         div_ltrduasconsnts = letras_duasconsnts.findall(j)\n",
    "#         div_ltrtriplicadas = letras_tresconsnts.findall(j)\n",
    "#         div_ltrduasconsntsvirg = letras_duasconsntsvirg.findall(j)\n",
    "#         div_ltrtresconsntsvirg = letras_tresconsntsvirg.findall(j)\n",
    "#         if div_ltrduasconsnts or div_ltrtriplicadas:\n",
    "#             iniciais_separadas = ' '.join(x for x in j)\n",
    "#             partes_nome.append(iniciais_separadas)\n",
    "#         elif div_ltrduasconsntsvirg or div_ltrtresconsntsvirg:\n",
    "#             iniciais_separadas = ' '.join(x for x in j[:-1])\n",
    "#             partes_nome.append(iniciais_separadas+',')\n",
    "#         else:\n",
    "#             partes_nome.append(j)\n",
    "#     string = ' '.join(x for x in partes_nome).strip()\n",
    "#     return string\n",
    "\n",
    "\n",
    "\n",
    "# def padronizar_nome(linha_texto):\n",
    "#     '''\n",
    "#     Procura sobrenomes e abreviaturas e monta nome completo\n",
    "#      Recebe: String com todos os sobrenomes e nomes, abreviados ou não\n",
    "#     Retorna: Nome completo no formato padronizado em SOBRENOME AGNOME, Partes de nomes\n",
    "#       Autor: Marcos Aires (Mar.2022)\n",
    "#     '''\n",
    "#     import unicodedata\n",
    "#     import re\n",
    "#     # print('               Analisando:',linha_texto)\n",
    "#     partes_string = linha_texto.split(' ')\n",
    "\n",
    "#     ## Retirar partes de nomes caso sejam preposições\n",
    "#     preposicoes = ['da', 'de', 'do', 'das', 'dos', ' e ']\n",
    "#     string = ' '.join(x for x in partes_string if x.lower() not in preposicoes)\n",
    "\n",
    "#     ## Retirar símbolos não unicode, como acentuação gráfica e cedilha\n",
    "#     string = ''.join(ch for ch in unicodedata.normalize('NFKD', string) if not unicodedata.combining(ch))\n",
    "    \n",
    "#     ## Expressões regulares para encontrar padrões de divisão de nomes de autores\n",
    "#     sobrenome_inicio   = re.compile(r'^[A-ZÀ-ú-a-z]+,')                  # Sequência de letras maiúsculas no início da string\n",
    "#     sobrenome_composto = re.compile(r'^[A-ZÀ-ú-a-z]+[ ][A-ZÀ-ú-a-z]+,')  # Duas sequências de letras no início da string, separadas por espaço, seguidas por vírgula\n",
    "#     letra_abrevponto   = re.compile(r'^[A-Z][.]')                        # Uma letra maiúscula no início da string, seguida por ponto\n",
    "#     letra_abrevespaco  = re.compile(r'^[A-Z][ ]')                        # Uma letra maiúscula no início da string, seguida por espaço\n",
    "#     letras_dobradas    = re.compile(r'[A-Z]{2}')                         # Duas letras maiúsculas juntas\n",
    "#     letras_dobradasini = re.compile(r'[A-Z]{2}[ ]')                      # Duas letras maiúsculas juntas, seguidas por espaço\n",
    "#     letras_dobradasfim = re.compile(r'[ ][A-Z]{2}')                      # Duas letras maiúsculas juntas, precedidas por espaço\n",
    "\n",
    "#     ## Expressões regulares para encontrar iniciais juntas, separando-as com espaço em branco\n",
    "#     letras_duasconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2}$')            # Duas Letras consoantes maiúsculas juntas do início ao final da string\n",
    "#     letras_tresconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3}$')            # Três Letras consoantes maiúsculas juntas do início ao final da string\n",
    "#     letras_duasconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2},$')       # Duas Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "#     letras_tresconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3},$')       # Três Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "\n",
    "#     ## Agnomes e preprosições a tratar, agnomes vão em maiúsculas para sobrenome e preposições vão em minúsculas para restante das partes de nomes\n",
    "#     nomes=[]\n",
    "#     agnomes       = ['NETO','JUNIOR','FILHO','SEGUNDO','TERCEIRO','SOBRINHO']\n",
    "#     preposicoes   = ['de','da','do','das','dos', ' e ']\n",
    "#     nome_completo = ''\n",
    "    \n",
    "#     ## Ajustar lista de termos, identificar sobrenomes compostos e ajustar sobrenome com ou sem presença de vírgula\n",
    "#     div_sobrenome   = sobrenome_inicio.findall(string)\n",
    "#     div_sbrcomposto = sobrenome_composto.findall(string)\n",
    "    \n",
    "#     # print('-'*100)\n",
    "#     # print('                 Recebido:',string)\n",
    "    \n",
    "#     ## Caso haja vírgulas na string, tratar sobrenomes e sobrenomes compostos\n",
    "#     if div_sobrenome != [] or div_sbrcomposto != []:\n",
    "#         # print('CASO_01: Há víruglas na string')\n",
    "#         div = string.split(', ')\n",
    "#         sobrenome     = div[0].strip().upper()\n",
    "#         try:\n",
    "#             div_espaco    = div[1].split(' ')\n",
    "#         except:\n",
    "#             div_espaco    = ['']\n",
    "#         primeiro      = div_espaco[0].strip('.').strip()\n",
    "        \n",
    "#         # print('     Dividir por vírgulas:',div)\n",
    "#         # print('      Primeira DivVirgula:',sobrenome)\n",
    "#         # print('Segunda DivVrg/DivEspaços:',div_espaco)\n",
    "#         # print('      Primeira DivEspaços:',primeiro)\n",
    "               \n",
    "#         # Caso primeiro nome seja somente duas letras maiúsculas juntas, trata-se de duas iniciais\n",
    "#         if len(primeiro)==2 or letras_tresconsnts.findall(primeiro) or letras_duasconsnts.findall(primeiro):\n",
    "#             # print('CASO_01.a: Há duas letras ou três letras consoantes juntas, são iniciais')\n",
    "#             primeiro_nome=primeiro[0].strip()\n",
    "#             # print('          C01.a1_PrimNome:',primeiro_nome)\n",
    "#             nomes.append(primeiro[1].strip().upper())\n",
    "#             try:\n",
    "#                 nomes.append(primeiro[2].strip().upper())\n",
    "#             except:\n",
    "#                 pass\n",
    "#             try:\n",
    "#                 nomes.append(primeiro[3].strip().upper())\n",
    "#             except:\n",
    "#                 pass            \n",
    "#         else:\n",
    "#             # print('CASO_01.b: Primeiro nome maior que 2 caracteres')\n",
    "#             primeiro_nome = div_espaco[0].strip().title()\n",
    "#             # print('          C01.a2_PrimNome:',primeiro_nome)\n",
    "        \n",
    "#         ## Montagem da lista de partes de nomes do meio\n",
    "#         for nome in div_espaco:\n",
    "#             # print('CASO_01.c: Para cada parte de nome da divisão por espaços após divisão por vírgula')\n",
    "#             if nome not in nomes and nome.lower()!=primeiro_nome.lower() and nome.lower() not in primeiro_nome.lower() and nome!=sobrenome:   \n",
    "#                 # print('CASO_01.c1: Se o nome não está nem como primeiro nome, nem sobrenomes')\n",
    "#                 # print(nome, len(nome))\n",
    "                \n",
    "#                 ## Avaliar se é abreviatura seguida de ponto e remover o ponto\n",
    "#                 if len(nome)<=2 and nome.lower() not in preposicoes:\n",
    "#                     # print('    C01.c1.1_Nome<=02:',nome)\n",
    "#                     for inicial in nome:\n",
    "#                         # print(inicial)\n",
    "#                         if inicial not in nomes and inicial not in primeiro_nome:\n",
    "#                             nomes.append(inicial.replace('.','').strip().title())\n",
    "#                 elif len(nome)==3 and nome.lower() not in preposicoes:\n",
    "#                         # print('    C01.c1.2_Nome==03:',nome)\n",
    "#                         for inicial in nome:\n",
    "#                             if inicial not in nomes and inicial not in primeiro_nome:\n",
    "#                                 nomes.append(inicial.replace('.','').strip().title())\n",
    "#                 else:\n",
    "#                     if nome not in nomes and nome!=primeiro_nome and nome!=sobrenome and nome!='':\n",
    "#                         if nome.lower() in preposicoes:\n",
    "#                             nomes.append(nome.replace('.','').strip().lower())\n",
    "#                         else:\n",
    "#                             nomes.append(nome.replace('.','').strip().title())\n",
    "#                         # print(nome,'|',primeiro_nome)\n",
    "                        \n",
    "#         ## Caso haja sobrenome composto que não esteja nos agnomes considerar somente primeira parte como sobrenome\n",
    "#         if div_sbrcomposto !=[] and sobrenome.split(' ')[1] not in agnomes and sobrenome.split(' ')[0].lower() not in preposicoes:\n",
    "#             # print('CASO_01.d: Sobrenome composto sem agnomes')\n",
    "#             # print(div_sbrcomposto)\n",
    "#             # print('Sobrenome composto:',sobrenome)\n",
    "            \n",
    "#             nomes.append(sobrenome.split(' ')[1].title())\n",
    "#             sobrenome = sobrenome.split(' ')[0].upper().strip()\n",
    "#             # print('Sobrenome:',sobrenome)\n",
    "            \n",
    "#             for i in nomes:\n",
    "#                 if i.lower() in sobrenome.lower():\n",
    "#                     nomes.remove(i)\n",
    "#             # print('    Nomes:',nomes)\n",
    "        \n",
    "#         ## Caso haja preposição como agnome desconsiderar e passar para final dos nomes\n",
    "#         if div_sbrcomposto !=[] and sobrenome.split(' ')[0].lower() in preposicoes:\n",
    "#             # print('CASO_01.e: Preposição no Sobrenome passar para o final dos nomes')\n",
    "#             # print('   div_sbrcomposto:', div_sbrcomposto)\n",
    "#             # print('Sobrenome composto:',div_sbrcomposto)\n",
    "            \n",
    "#             nomes.append(div_sbrcomposto[0].split(' ')[0].lower())\n",
    "#             # print('    Nomes:',nomes)\n",
    "#             sobrenome = div_sbrcomposto[0].split(' ')[1].upper().strip(',').strip()\n",
    "#             # print('Sobrenome:',sobrenome)\n",
    "            \n",
    "#             for i in nomes:\n",
    "#                 # print('CASO_01.e1: Para cada nome avaliar se o sobrenome está na lista')\n",
    "#                 if i.lower() in sobrenome.lower():\n",
    "#                     nomes.remove(i)\n",
    "#             # print('  Nomes:',nomes)\n",
    "        \n",
    "#         # print('Ao final do Caso 01')\n",
    "#         # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "#         # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "#         # print('           Lista de nomes:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "#     ## Caso não haja vírgulas na string considera sobrenome o último nome da string dividida com espaço vazio\n",
    "#     else:\n",
    "#         # print('CASO_02: Não há víruglas na string')\n",
    "#         try:\n",
    "#             div = string.split(' ')\n",
    "#             # print('      Divisões por espaço:',div)\n",
    "            \n",
    "#             if div[-1] in agnomes: # nome final é um agnome\n",
    "#                 sobrenome     = div[-2].upper().strip()+' '+div[-1].upper().strip()\n",
    "#                 for i in div[1:-2]:\n",
    "#                     if i not in sobrenome and i not in preposicoes:\n",
    "#                         nomes.append(i.title().strip())\n",
    "#                     if i in preposicoes:\n",
    "#                         nomes.append(i.lower().strip())\n",
    "#             else:\n",
    "#                 if len(div[-1]) > 2:\n",
    "#                     sobrenome     = div[-1].upper().strip()\n",
    "#                     primeiro_nome = div[1].title().strip()\n",
    "#                     for i in div[1:-1]:\n",
    "#                         if i != sobrenome and i not in preposicoes:\n",
    "#                             nomes.append(i.title().strip())\n",
    "#                         if i in preposicoes:\n",
    "#                             nomes.append(i.lower().strip())\n",
    "#                 else:\n",
    "#                     sobrenome     = div[-2].upper().strip()\n",
    "#                     for i in div[-1]:\n",
    "#                         nomes.append(i.title())\n",
    "#                     primeiro_nome = nomes[0].title().strip()\n",
    "#                     for i in div[1:-1]:\n",
    "#                         if i != sobrenome and i not in preposicoes:\n",
    "#                             nomes.append(i.title().strip())\n",
    "#                         if i in preposicoes:\n",
    "#                             nomes.append(i.lower().strip())\n",
    "#         except:\n",
    "#             sobrenome = div[-1].upper().strip()\n",
    "#             for i in div[1:-1]:\n",
    "#                     if i != sobrenome and i not in preposicoes:\n",
    "#                         nomes.append(i.title().strip())\n",
    "#                     if i in preposicoes:\n",
    "#                         nomes.append(i.lower().strip())\n",
    "            \n",
    "#         if sobrenome.lower() != div[0].lower().strip():\n",
    "#             primeiro_nome=div[0].title().strip()\n",
    "#         else:\n",
    "#             primeiro_nome=''\n",
    "        \n",
    "#         # print('Ao final do Caso 02')\n",
    "#         # print('    Sobrenome sem vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "#         # print('Primeiro nome sem vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "#         # print('Nomes do meio sem vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "#     ## Encontrar e tratar como abreviaturas termos com apenas uma ou duas letras iniciais juntas, com ou sem ponto\n",
    "#     for j in nomes:\n",
    "#         # print('CASO_03: Avaliar cada nome armazenado na variável nomes')\n",
    "#         # Procura padrões com expressões regulares na string\n",
    "#         div_sobrenome      = sobrenome_inicio.findall(j)\n",
    "#         div_sbrcomposto    = sobrenome_composto.findall(j)\n",
    "#         div_abrevponto     = letra_abrevponto.findall(j)\n",
    "#         div_abrevespaco    = letra_abrevespaco.findall(j)\n",
    "#         div_ltrdobradasini = letras_dobradasini.findall(j)\n",
    "#         div_ltrdobradasfim = letras_dobradasfim.findall(j)\n",
    "#         div_ltrdobradas    = letras_dobradas.findall(j)\n",
    "#         div_ltrduasconsnts = letras_duasconsnts.findall(j)\n",
    "#         div_ltrtriplicadas = letras_tresconsnts.findall(j)\n",
    "#         tamanho=len(j)\n",
    "#         # print('\\n', div_ltrdobradasini, div_ltrdobradasfim, tamanho, 'em:',j,len(j))\n",
    "        \n",
    "#         ## Caso houver abreviatura com uma letra em maiúscula nos nomes\n",
    "#         if div_abrevponto !=[] or tamanho==1:\n",
    "#             # print('CASO_03.1: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "#             nome = j.replace('.','').strip()\n",
    "#             if nome not in nomes and nome != sobrenome and nome != primeiro_nome:\n",
    "#                 # print('CASO_03.1a: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "#                 nomes.append(nome.upper())\n",
    "        \n",
    "#         ## Caso houver duas inicias juntas em maiúsculas\n",
    "#         elif div_ltrdobradasini !=[] or div_ltrdobradasfim !=[] or div_ltrdobradas !=[] :\n",
    "#             # print('CASO_03.2: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "#             for letra in j:\n",
    "#                 # print('CASO_03.2a: Avaliar cada inicial do nome')\n",
    "#                 if letra not in nomes and letra != sobrenome and letra != primeiro_nome:\n",
    "#                     # print('CASO_03.2a.1: Se não estiver adicionar inicial aos nomes')\n",
    "#                     nomes.append(letra.upper())\n",
    "        \n",
    "#         # Caso haja agnomes ao sobrenome\n",
    "#         elif sobrenome in agnomes:\n",
    "#             # print('CASO_03.3: Há agnomes nos sobrenomes')\n",
    "#             sobrenome = nomes[-1].upper()+' '+sobrenome\n",
    "#             # print(sobrenome.split(' '))\n",
    "#             # print('Sobrenome composto:',sobrenome)\n",
    "#             for i in nomes:\n",
    "#                 if i.lower() in sobrenome.lower():\n",
    "#                     nomes.remove(i)\n",
    "#             # print('Nomes do meio:',nomes)\n",
    "            \n",
    "#         else:\n",
    "#             # print('CASO_03.4: Não há agnomes nos sobrenomes')\n",
    "#             if j not in nomes and j not in sobrenome and j != primeiro_nome:\n",
    "#                 if len(nomes) == 1:\n",
    "#                     nomes.append(j.upper())\n",
    "#                 elif 1 < len(nomes) <= 3:\n",
    "#                     nomes.append(j.lower())\n",
    "#                 else:\n",
    "#                     nomes.append(j.title())\n",
    "         \n",
    "#         # print('Ao final do Caso 03')\n",
    "#         # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "#         # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "#         # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "#     nomes_meio=' '.join([str for str in nomes]).strip()\n",
    "#     # print('        Qte nomes do meio:',nomes,len(nomes))\n",
    "    \n",
    "#     if primeiro_nome.lower() == sobrenome.lower():\n",
    "#         # print('CASO_04: Primeiro nome é igual ao sobrenome')\n",
    "#         try:\n",
    "#             primeiro_nome=nomes_meio.split(' ')[0]\n",
    "#         except:\n",
    "#             pass\n",
    "#         try:\n",
    "#             nomes_meio.remove(sobrenome)\n",
    "#         except:\n",
    "#             pass\n",
    "    \n",
    "#         # print('Ao final do caso 04')\n",
    "#         # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "#         # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "#         # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "#     ## Caso sobrenome seja só de 1 letra passá-lo para nomes e considerar o próximo nome como sobrenome\n",
    "#     for i in range(len(div)):\n",
    "#         if len(sobrenome)==1 or sobrenome.lower() in preposicoes:\n",
    "#             # print('CASO_05: Mudar sobrenomes até o adequado')\n",
    "#             div    = string.split(', ')\n",
    "#             # print('Divisão por vírgulas:',div)\n",
    "#             avaliar0       = div[0].split(' ')[0].strip()\n",
    "#             if 1< len(avaliar0) < 3:\n",
    "#                 # print('CASO_05.1: 1 < Sobrenome < 3 fica em minúsculas')\n",
    "#                 sbrn0          = avaliar0.lower()\n",
    "#             else:\n",
    "#                 # print('CASO_05.2: Sobrenome de tamanho 1 ou maior que 3 fica em maiúsculas')\n",
    "#                 sbrn0          = avaliar0.title()\n",
    "#             # print('sbrn0:',sbrn0, len(sbrn0))\n",
    "            \n",
    "#             try:\n",
    "#                 avaliar1=div[0].split(' ')[1].strip()\n",
    "#                 # print('avaliar0',avaliar0)\n",
    "#                 # print('avaliar1',avaliar1)\n",
    "#                 if 1 < len(avaliar1) <=3:\n",
    "#                     sbrn1     = avaliar1.lower()\n",
    "#                 else:\n",
    "#                     sbrn1     = avaliar1.title()\n",
    "#                 # print('sbrn1:',sbrn1, len(sbrn1))\n",
    "\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "#             if div != []:\n",
    "#                 # print('CASO_05.3: Caso haja divisão por vírgulas na string')\n",
    "#                 try:\n",
    "#                     div_espaco     = div[1].split(' ')\n",
    "#                 except:\n",
    "#                     div_espaco     = div[0].split(' ')\n",
    "#                 sobrenome      = div_espaco[0].strip().upper()\n",
    "#                 try:\n",
    "#                     primeiro_nome  = div_espaco[1].title().strip()\n",
    "#                 except:\n",
    "#                     primeiro_nome  = div_espaco[0].title().strip()\n",
    "#                 if len(sbrn0) == 1:\n",
    "#                     # print('CASO_05.3a: Avalia primeiro sobrenome de tamanho 1')\n",
    "#                     # print('Vai pros nomes:',str(sbrn0).title())\n",
    "#                     nomes_meio = nomes_meio+str(' '+sbrn0.title())\n",
    "#                     # print('   NomesMeio:',nomes_meio)\n",
    "\n",
    "#                 elif 1 < len(sbrn0) <= 3:\n",
    "#                     # print('CASO_05.3b: Avalia primeiro sobrenome 1< tamanho <=3')\n",
    "#                     # print('Vão pros nomes sbrn0:',sbrn0, 'e sbrn1:',sbrn1)\n",
    "\n",
    "#                     div_tresconsoantes = letras_tresconsnts.findall(sobrenome)\n",
    "#                     if div_tresconsoantes != []:\n",
    "#                         # print('CASO_05.4: Três consoantes como sobrenome')\n",
    "#                         for letra in sobrenome:\n",
    "#                             nomes.append(letra)\n",
    "\n",
    "#                         if len(sobrenome) >2:\n",
    "#                             sobrenome=nomes[0]\n",
    "#                         else:\n",
    "#                             sobrenome=nomes[1]\n",
    "#                         nomes.remove(sobrenome)\n",
    "#                         primeiro_nome=nomes[0]\n",
    "#                         nomes_meio=' '.join([str for str in nomes[1:]]).strip()\n",
    "#                         nome_completo=sobrenome.upper()+', '+nomes_meio                \n",
    "                    \n",
    "#                     try:                       \n",
    "#                         # print(' 05.3b    Lista de Nomes:',nomes_meio)\n",
    "#                         nomes_meio=nomes_meio.replace(sbrn0,'')\n",
    "#                         # print(' 05.3b ReplaceSobrenome0:',nomes_meio)\n",
    "#                         nomes_meio=nomes_meio.replace(sbrn1,'')\n",
    "#                         # print(' 05.3b ReplaceSobrenome1:',nomes_meio)\n",
    "#                     except Exception as e:\n",
    "#                         # print('   Erro ReplaceSobrenome:',e)\n",
    "#                         pass\n",
    "#                     try:\n",
    "#                         nomes_meio.replace(primeiro_nome.title(),'')\n",
    "#                         nomes_meio.replace(primeiro_nome.lower(),'')\n",
    "#                         nomes_meio.replace(primeiro_nome,'')\n",
    "#                         # print(' 05.3b Replace PrimNome:',nomes_meio)\n",
    "#                     except Exception as e:\n",
    "#                         print('Erro no try PrimeiroNome:',e)\n",
    "#                         pass\n",
    "#                     nomes_meio = nomes_meio.replace(sobrenome,'')\n",
    "#                     try:\n",
    "#                         for n,i in enumerate(avaliar1):\n",
    "#                             nomes.append(i.upper())\n",
    "#                             sbrn1     = avaliar1[0]\n",
    "#                         else:\n",
    "#                             sbrn1     = avaliar1.title()\n",
    "#                         # print('sbrn1:',sbrn1, len(sbrn1))\n",
    "#                         nomes_meio = nomes_meio+str(' '+sbrn0)+str(' '+sbrn1)\n",
    "#                     except:\n",
    "#                         nomes_meio = nomes_meio+str(' '+sbrn0)\n",
    "#                     nomes      = nomes_meio.strip().strip(',').split(' ')\n",
    "#                     # print(' 05.3b NomesMeio:',nomes_meio)\n",
    "#                     # print(' 05.3b     Nomes:',nome)\n",
    "\n",
    "#                 else:\n",
    "#                     # print('CASO_05.3c: Avalia primeiro sobrenome >3')\n",
    "#                     nomes_meio = nomes_meio+str(' '+div[0].strip().title())\n",
    "#                     nomes      = nomes_meio.strip().split(' ')\n",
    "#                     # print(' 05.3c NomesMeio:',nomes_meio)\n",
    "#                     # print(' 05.3c     Nomes:',nomes)\n",
    "\n",
    "#                 nomes_meio=nomes_meio.replace(sobrenome,'').replace(',','').strip()\n",
    "#                 nomes_meio=nomes_meio.replace(primeiro_nome,'').strip()\n",
    "\n",
    "#             # print('Ao final do caso 05')\n",
    "#             # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "#             # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "#             # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "#     if sobrenome != '' and primeiro_nome !='':\n",
    "#         nome_completo=sobrenome.upper().replace(',','')+', '+primeiro_nome.replace(',','')+' '+nomes_meio.replace(sobrenome,'').replace(',','')\n",
    "#     elif sobrenome != '':\n",
    "#         nome_completo=sobrenome.upper().replace(',','')+', '+nomes_meio.replace(sobrenome,'').replace(',','')\n",
    "#     else:\n",
    "#         nome_completo=sobrenome.upper()\n",
    "    \n",
    "# #     print('Após ajustes finais')\n",
    "# #     print('     Sobrenome:',sobrenome)\n",
    "# #     print(' Primeiro Nome:',primeiro_nome)\n",
    "# #     print('         Nomes:',nomes)\n",
    "# #     print('     NomesMeio:',nomes_meio)        \n",
    "        \n",
    "# #     print('                Resultado:',nome_completo)\n",
    "    \n",
    "#     return nome_completo.strip()\n",
    "\n",
    "\n",
    "\n",
    "# def padronizar_titulo(titulo_bruto):\n",
    "#     '''\n",
    "#     Retira acentos, expressão (Org.) e espaços vazios do título da publicação\n",
    "#     Autor: Marcos Aires (Fev.2022)\n",
    "#     '''\n",
    "#     import re\n",
    "#     import unicodedata\n",
    "    \n",
    "#     ## Retirar caracteres não unicode\n",
    "#     string = ''.join(ch for ch in unicodedata.normalize('NFKD', titulo_bruto) if not unicodedata.combining(ch))\n",
    "#     string = string.replace('(Org)','').replace('(Org.)','').replace('(Org).','').replace('.',' ').replace('-',' ').replace('\\'',' ').lower()\n",
    "    \n",
    "#     substitui_iniciais=[('rl,', 'r l,'), ('hs,', 'h s,'), ('gc,', 'g c,'), ('sf,', 's f,'), ('fo,', 'f o,'), (' oa,', ' o a,'), ('mss,', 'm s s,'), \n",
    "#                         ('lagares, ma', 'lagares, m a'), ('cota, gf', 'cota, g f'), ('cota gf,', 'cota, g f,'), ('diotaiut,', 'diotaiuti,'), ('grenfell, r f q','queiroz, rafaella fortini grenfell')]\n",
    "#     for i in substitui_iniciais:\n",
    "#         string = string.replace(i[0], i[1])\n",
    "    \n",
    "#     ## Retirar preposições\n",
    "#     preposicoes = ['da', 'de', 'do', 'das', 'dos']\n",
    "#     partes_string = string.split(' ')\n",
    "#     string = ' '.join(x for x in partes_string if x.lower() not in preposicoes)\n",
    "    \n",
    "#     titulo_padronizado = string.strip().strip('\"')\n",
    "    \n",
    "#     return titulo_padronizado\n",
    "\n",
    "\n",
    "\n",
    "# def iniciais_nome(linha_texto):\n",
    "#     '''\n",
    "#     Função para retornar sobrenome+iniciais das partes de nome, na forma: SOBRENOME, X Y Z\n",
    "#      Recebe: String com nome\n",
    "#     Retorna: Tupla com nome e sua versão padronizada em sobrenome+agnome em maiúsculas, seguida de vírgula e das iniciais das demais partes de nome\n",
    "#       Autor: Marcos Aires (Mar.2022)\n",
    "#     '''\n",
    "#     import unicodedata\n",
    "#     import re\n",
    "#     # print('               Analisando:',linha_texto)\n",
    "    \n",
    "#     ## Retirar caracteres não unicode\n",
    "#     string = ''.join(ch for ch in unicodedata.normalize('NFKD', linha_texto) if not unicodedata.combining(ch))\n",
    "#     string = string.replace('(Org)','').replace('(Org.)','').replace('(Org).','').replace('.','')\n",
    "    \n",
    "#     ## Retirar preposições\n",
    "#     preposicoes   = ['da','de','do','das','dos']\n",
    "#     partes_string = string.split(' ')\n",
    "#     string = ' '.join(x for x in partes_string if x.lower() not in preposicoes)\n",
    "        \n",
    "#     ## Expressões regulares para encontrar padrões de divisão de nomes de autores\n",
    "#     sobrenome_inicio   = re.compile(r'^[A-ZÀ-ú-a-z]+,')                 # Sequência de letras maiúsculas no início da string\n",
    "#     sobrenome_composto = re.compile(r'^[A-ZÀ-ú-a-z]+[ ][A-ZÀ-ú-a-z]+,') # Duas sequências de letras no início da string, separadas por espaço, seguidas por vírgula\n",
    "#     letra_abrevponto   = re.compile(r'^[A-Z][.]')                       # Uma letra maiúscula no início da string, seguida por ponto\n",
    "#     letra_abrevespaco  = re.compile(r'^[A-Z][ ]')                       # Uma letra maiúscula no início da string, seguida por espaço\n",
    "#     letras_dobradas    = re.compile(r'[A-Z]{2}')                        # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "#     letras_dobradasini = re.compile(r'[A-Z]{2}[ ]')                     # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "#     letras_dobradasfim = re.compile(r'[ ][A-Z]{2}')                     # Duas letras maiúsculas juntas no final da string, precedida por espaço\n",
    "        \n",
    "#     nomes=[]\n",
    "#     agnomes       = ['NETO','JUNIOR','FILHO','SEGUNDO','TERCEIRO', 'SOBRINHO']\n",
    "#     nome_completo = ''\n",
    "    \n",
    "#     ## Ajustar lista de termos, identificar sobrenomes compostos e ajustar sobrenome com ou sem presença de vírgula\n",
    "#     div_sobrenome      = sobrenome_inicio.findall(string)\n",
    "#     div_sbrcomposto    = sobrenome_composto.findall(string)\n",
    "    \n",
    "#     ## Caso haja vírgulas na string, tratar sobrenomes e sobrenomes compostos\n",
    "#     if div_sobrenome != [] or div_sbrcomposto != []:\n",
    "#         div   = string.split(', ')\n",
    "#         sobrenome     = div[0].strip().upper()\n",
    "#         try:\n",
    "#             div_espaco    = div[1].split(' ')\n",
    "#         except:\n",
    "#             div_espaco  = ['']\n",
    "#         primeiro      = div_espaco[0].strip('.')\n",
    "        \n",
    "#         ## Caso primeiro nome sejam somente duas letras maiúsculas juntas, trata-se de duas iniciais\n",
    "#         if len(primeiro)==2:\n",
    "#             primeiro_nome=primeiro[0].strip()\n",
    "#             nomes.append(primeiro[1].strip())\n",
    "#         else:\n",
    "#             primeiro_nome = div_espaco[0].strip().title()\n",
    "        \n",
    "#         ## Montagem da lista de nomes do meio\n",
    "#         for nome in div_espaco:\n",
    "#             if nome not in nomes and nome.lower()!=primeiro_nome.lower() and nome.lower() not in primeiro_nome.lower() and nome!=sobrenome:   \n",
    "#                 # print(nome, len(nome))\n",
    "                \n",
    "#                 ## Avaliar se é abreviatura seguida de ponto e remover o ponto\n",
    "#                 if len(nome)<=2 and nome.lower() not in preposicoes:\n",
    "#                     for inicial in nome:\n",
    "#                         # print(inicial)\n",
    "#                         if inicial not in nomes and inicial not in primeiro_nome:\n",
    "#                             nomes.append(inicial.replace('.','').strip().title())\n",
    "#                 else:\n",
    "#                     if nome not in nomes and nome!=primeiro_nome and nome!=sobrenome and nome!='':\n",
    "#                         if nome.lower() in preposicoes:\n",
    "#                             nomes.append(nome.replace('.','').strip().lower())\n",
    "#                         else:\n",
    "#                             nomes.append(nome.replace('.','').strip().title())\n",
    "#                         # print(nome,'|',primeiro_nome)\n",
    "                        \n",
    "#         ## Caso haja sobrenome composto que não esteja nos agnomes considerar somente primeira parte como sobrenome\n",
    "#         if div_sbrcomposto !=[] and sobrenome.split(' ')[1] not in agnomes:\n",
    "#             # print(div_sbrcomposto)\n",
    "#             # print('Sobrenome composto:',sobrenome)\n",
    "#             nomes.append(sobrenome.split(' ')[1].title())\n",
    "#             sobrenome = sobrenome.split(' ')[0].upper()\n",
    "#             # print('Sobrenome:',sobrenome.split(' '))\n",
    "#             for i in nomes:\n",
    "#                 if i.lower() in sobrenome.lower():\n",
    "#                     nomes.remove(i)\n",
    "#             # print('Nomes do meio:',nomes)\n",
    "        \n",
    "#         # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "#         # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "#         # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "#     ## Caso não haja vírgulas na string considera sobrenome o último nome da string dividida com espaço vazio\n",
    "#     else:\n",
    "#         try:\n",
    "#             div       = string.split(' ')\n",
    "#             if div[-2] in agnomes:\n",
    "#                 sobrenome = div[-2].upper()+' '+div[-1].strip().upper()\n",
    "#                 for i in nomes[1:-2]:\n",
    "#                     if i not in sobrenome and i not in preposicoes:\n",
    "#                         nomes.append(i.strip().title())\n",
    "#                     if i in preposicoes:\n",
    "#                         nomes.append(i.strip().lower())\n",
    "#             else:\n",
    "#                 sobrenome = div[-1].strip().upper()\n",
    "#                 for i in div[1:-1]:\n",
    "#                     if i not in sobrenome and i not in preposicoes:\n",
    "#                         nomes.append(i.strip().title())\n",
    "#                     if i in preposicoes:\n",
    "#                         nomes.append(i.strip().lower())\n",
    "#         except:\n",
    "#             sobrenome = div[-1].strip().upper()\n",
    "#             for i in div[1:-1]:\n",
    "#                     if i not in sobrenome and i not in preposicoes:\n",
    "#                         nomes.append(i.strip().title())\n",
    "#                     if i in preposicoes:\n",
    "#                         nomes.append(i.strip().lower())\n",
    "            \n",
    "#         if sobrenome.lower() != div[0].strip().lower():\n",
    "#             primeiro_nome=div[0].strip().title()\n",
    "#         else:\n",
    "#             primeiro_nome=''\n",
    "        \n",
    "#         # print('    Sobrenome sem vírgula:',sobrenome)\n",
    "#         # print('Primeiro nome sem vírgula:',primeiro_nome)\n",
    "#         # print('Nomes do meio sem vírgula:',nomes)\n",
    "    \n",
    "#     # Encontrar e tratar como abreviaturas termos com apenas uma ou duas letras iniciais juntas, com ou sem ponto\n",
    "#     for j in nomes:\n",
    "#         # Procura padrões com expressões regulares na string\n",
    "#         div_sobrenome      = sobrenome_inicio.findall(j)\n",
    "#         div_sbrcomposto    = sobrenome_composto.findall(j)\n",
    "#         div_abrevponto     = letra_abrevponto.findall(j)\n",
    "#         div_abrevespaco    = letra_abrevespaco.findall(j)\n",
    "#         div_ltrdobradasini = letras_dobradasini.findall(j)\n",
    "#         div_ltrdobradasfim = letras_dobradasfim.findall(j)\n",
    "#         div_ltrdobradas    = letras_dobradas.findall(j)\n",
    "#         tamanho=len(j)\n",
    "#         # print('\\n', div_ltrdobradasini, div_ltrdobradasfim, tamanho, 'em:',j,len(j))\n",
    "        \n",
    "#         #caso houver abreviatura com uma letra em maiúscula nos nomes\n",
    "#         if div_abrevponto !=[] or tamanho==1:\n",
    "#             cada_nome = j.replace('.','').strip()\n",
    "#             if cada_nome not in nomes and cada_nome != sobrenome and nome != primeiro_nome:\n",
    "#                 nomes.append(cada_nome)\n",
    "        \n",
    "#         #caso houver duas inicias juntas em maiúsculas\n",
    "#         elif div_ltrdobradasini !=[] or div_ltrdobradasfim !=[] or div_ltrdobradas !=[] :\n",
    "#             for letra in j:\n",
    "#                 if letra not in nomes and letra != sobrenome and letra != primeiro_nome:\n",
    "#                     nomes.append(letra)\n",
    "        \n",
    "#         #caso haja agnomes ao sobrenome\n",
    "#         elif sobrenome in agnomes:\n",
    "#             sobrenome = nomes[-1].upper()+' '+sobrenome\n",
    "#             # print(sobrenome.split(' '))\n",
    "#             # print('Sobrenome composto:',sobrenome)\n",
    "#             for i in nomes:\n",
    "#                 if i.lower() in sobrenome.lower():\n",
    "#                     nomes.remove(i)\n",
    "#             # print('Nomes do meio:',nomes)\n",
    "            \n",
    "#         else:\n",
    "#             if j not in nomes and j not in sobrenome and j != primeiro_nome:\n",
    "#                 nomes.append(j)\n",
    "    \n",
    "#     nomes_meio=' '.join([str[0] for str in nomes]).strip()\n",
    "#     # print('Qte nomes do meio',len(nomes),nomes)\n",
    "#     if sobrenome != '' and primeiro_nome !='':\n",
    "#         sobrenome_iniciais = sobrenome+', '+primeiro_nome[0]+' '+nomes_meio\n",
    "#     elif sobrenome != '':\n",
    "#         sobrenome_iniciais = sobrenome\n",
    "    \n",
    "#     return sobrenome_iniciais.strip()\n",
    "\n",
    "\n",
    "# ## Agregar aprendizado supervisionado humano à medida que forem sendo identificados erros na situação atual\n",
    "# lista_extra = [\n",
    "#                 # ('ALBUQUERQUE, Adriano B', 'ALBUQUERQUE, Adriano Bessa'),\n",
    "#                 # ('ALBUQUERQUE, Adriano', 'ALBUQUERQUE, Adriano Bessa'),\n",
    "#                 # ('COELHO, Andre L V', 'COELHO, Andre Luis Vasconcelos'),\n",
    "#                 # ('DUARTE, Joao B F', 'DUARTE, Joao Batista Furlan'),\n",
    "#                 # ('FILHO, Raimir H','HOLANDA FILHO, Raimir'),\n",
    "#                 # ('FILHO, Raimir','HOLANDA FILHO, Raimir'),\n",
    "#                 # ('FORMIGO, A','FORMICO, Maria Andreia Rodrigues'),\n",
    "#                 # ('FORMICO, A','FORMICO, Maria Andreia Rodrigues'),\n",
    "#                 # ('FURLAN, J B D', 'FURLAN, Joao Batista Duarte'),\n",
    "#                 # ('FURTADO, Elizabeth', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "#                 # ('FURTADO, Elizabeth S', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "#                 # ('FURTADO, Elizabeth Sucupira','FURTADO, Maria Elizabeth Sucupira'),\n",
    "#                 # ('FURTADO, M E S', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "#                 # ('FURTADO, Vasco', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "#                 # ('FURTADO, J P', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "#                 # ('FURTADO, J V P', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "#                 # ('FURTADO, Vasco', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "#                 # ('FURTADO, Elizabeth','FURTADO, Maria Elizabeth Sucupira'),\n",
    "#                 # ('HOLANDA, Raimir', 'HOLANDA FILHO, Raimir'),\n",
    "#                 # ('LEITE, G S', 'LEITE, Gleidson Sobreira'),\n",
    "#                 # ('PEQUENO, T H C', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "#                 # ('PEQUENO, Tarcisio','PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "#                 # ('PEQUENO, Tarcisio Cavalcante', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "#                 # ('PINHEIRO, Placido R', 'PINHEIRO, Placido Rogerio'),\n",
    "#                 # ('PINHEIRO, Vladia', 'PINHEIRO, Vladia Celia Monteiro'),\n",
    "#                 # ('RODRIGUES, M A F', 'RODRIGUES, Maria Andreia Formico'),\n",
    "#                 # ('RODRIGUES, Andreia', 'RODRIGUES, Maria Andreia Formico'),\n",
    "#                 # ('JOAO, Batista F Duarte,', 'FURLAN, Joao Batista Duarte'),\n",
    "#                 # ('MACEDO, Antonio Roberto M de', 'MACEDO, Antonio Roberto Menescal de'),\n",
    "#                 # ('MACEDO, D V', 'MACEDO, Daniel Valente'),\n",
    "#                 # ('MENDONCA, Nabor C', 'MENDONCA, Nabor das Chagas'),\n",
    "#                 # ('PEQUENO, Tarcisio', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "#                 # ('PEQUENO, Tarcisio H', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "#                 # ('PINHEIRO, Mirian C D', 'PINHEIRO, Miriam Caliope Dantas'),\n",
    "#                 # ('PINHEIRO, Mirian Caliope Dantas', 'PINHEIRO, Miriam Caliope Dantas'),\n",
    "#                 # ('PINHEIRO, P G C D', 'PINHEIRO, Pedro Gabriel Caliope Dantas'),\n",
    "#                 # ('PINHEIRO, Pedro G C', 'PINHEIRO, Pedro Gabriel Caliope Dantas'),\n",
    "#                 # ('PINHEIRO, Placido R', 'PINHEIRO, Placido Rogerio'),\n",
    "#                 # ('PINHEIRO, Vladia', 'PINHEIRO, Vladia Celia Monteiro'),\n",
    "#                 # ('ROGERIO, Placido Pinheiro', 'PINHEIRO, Placido Rogerio'),\n",
    "#                 # ('REBOUCRAS FILHO, Pedro', 'REBOUCAS FILHO, Pedro Pedrosa'),\n",
    "#                 # ('SAMPAIO, A', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "#                 # ('SAMPAIO, Americo', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "#                 # ('SAMPAIO, Americo Falcone', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "#                 # ('SUCUPIRA, Elizabeth Furtado','FURTADO, Maria Elizabeth Sucupira'),\n",
    "#                 ]\n",
    "\n",
    "\n",
    "# def converter_lista_set(lista):\n",
    "#     set1 = set(lista)\n",
    "#     return set1\n",
    "\n",
    "\n",
    "# def jaccard_similarity(set1, set2):\n",
    "#     '''\n",
    "#     Recebe dois conjuntos como entradas e retorna a similaridade Jaccard entre eles. \n",
    "#     1. calcula a interseção dos dois conjuntos usando a função de interseção e, \n",
    "#     2. calcula a união dos dois conjuntos usando a função de união. \n",
    "#     3. retorna a razão entre o comprimento da interseção e o comprimento da união, que é a similaridade de Jaccard.\n",
    "#     '''\n",
    "#     intersection = set1.intersection(set2)\n",
    "#     union        = set1.union(set2)\n",
    "#     return len(intersection) / len(union)\n",
    "\n",
    "\n",
    "# def similares(lista_autores, lista_grupo, limite_jarowinkler, distancia_levenshtein, lista_extra):\n",
    "#     \"\"\"Função para aplicar padronização no nome de autor da lista de pesquisadores e buscar similaridade na lista de coautores\n",
    "#      Recebe: Lista de pesquisadores do grupo em análise gerada pela lista de nomes dos coautores das publicações em análise\n",
    "#     Utiliza: get_jaro_distance(), editdistance()\n",
    "#     Retorna: Lista de autores com fusão de nomes cuja similaridade esteja dentro dos limites definidos nesta função\n",
    "#       Autor: Marcos Aires (Fev.2022)\n",
    "      \n",
    "#     Refazer: Inserir crítica de, mantendo sequência ordem alfabética, retornar no final nome mais extenso em caso de similaridade;\n",
    "#     \"\"\"\n",
    "#     from pyjarowinkler.distance import get_jaro_distance\n",
    "#     from IPython.display import clear_output\n",
    "#     import editdistance\n",
    "#     import numpy as np\n",
    "#     import time\n",
    "    \n",
    "#     t0=time.time()\n",
    "    \n",
    "#     # limite_jarowinkler=0.85\n",
    "#     # distancia_levenshtein=6\n",
    "#     similares_jwl=[]\n",
    "#     similares_regras=[]\n",
    "#     similares=[]\n",
    "#     tempos=[]\n",
    "    \n",
    "#     count=0\n",
    "#     t1=time.time()\n",
    "#     for i in lista_autores:\n",
    "#         count+=1\n",
    "#         if count > 0:\n",
    "#             tp=time.time()-t1\n",
    "#             tmed=tp/count*2\n",
    "#             tempos.append(tp)\n",
    "#         # print(\"Analisar similaridades com: \", nome_padronizado)\n",
    "        \n",
    "#         count1=0\n",
    "#         for nome in lista_autores:\n",
    "#             if count1 > 0:\n",
    "#                 resta=len(lista_autores)-count\n",
    "#                 print(f'Analisando {count1:3}/{len(lista_autores)} resta analisar {resta:3} nomes. Previsão de término em {np.round(tmed*resta/60,1)} minutos')\n",
    "#             else:\n",
    "#                 print(f'Analisando {count1:3}/{len(lista_autores)} resta analisar {len(lista_autores)-count1} nomes.')\n",
    "            \n",
    "#             t2=time.time()\n",
    "#             count1+=1            \n",
    "\n",
    "#             try:\n",
    "#                 similaridade_jarowinkler = get_jaro_distance(i, nome)\n",
    "#                 print(f'{i:40} | {nome:40} | Jaro-Winkler: {np.round(similaridade_jarowinkler,2):4} Levenshtein: {editdistance.eval(i, nome)}')\n",
    "#                 similaridade_levenshtein = editdistance.eval(i, nome)\n",
    "\n",
    "#                 # inferir similaridade para nomes que estejam acima do limite ponderado definido, mas não idênticos e não muito distantes em edição\n",
    "#                 if  similaridade_jarowinkler > limite_jarowinkler and similaridade_jarowinkler!=1 and similaridade_levenshtein < distancia_levenshtein:\n",
    "#                     # Crítica no nome mais extenso como destino no par (origem, destino)\n",
    "                    \n",
    "#                     similares_jwl.append((i,nome))\n",
    "\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "#             clear_output(wait=True)\n",
    "    \n",
    "#     # Conjunto de regras de validação de similaridade\n",
    "#     # Monta uma lista de nomes a serem retirados antes de montar a lista de troca\n",
    "#     trocar=[]\n",
    "#     retirar=[]\n",
    "#     for i in similares_jwl:\n",
    "#         sobrenome_i = i[0].split(',')[0]\n",
    "#         sobrenome_j = i[1].split(',')[0]\n",
    "\n",
    "#         try:\n",
    "#             iniciais_i  = iniciais_nome(i[0]).split(',')[1].strip()\n",
    "#         except:\n",
    "#             iniciais_i  = ''\n",
    "\n",
    "#         try:\n",
    "#             iniciais_j  = iniciais_nome(i[1]).split(',')[1].strip()\n",
    "#         except:\n",
    "#             iniciais_j  = ''\n",
    "\n",
    "#         try:\n",
    "#             primnome_i = i[0].split(',')[1].strip().split(' ')[0].strip()\n",
    "#         except:\n",
    "#             primnome_i = ''\n",
    "\n",
    "#         try:\n",
    "#             primnome_j = i[1].split(',')[1].strip().split(' ')[0].strip()\n",
    "#         except:\n",
    "#             primnome_j = ''    \n",
    "\n",
    "#         try:\n",
    "#             inicial_i = i[0].split(',')[1].strip()[0]\n",
    "#         except:\n",
    "#             inicial_i = ''\n",
    "\n",
    "#         try:\n",
    "#             resto_i   = i[0].split(',')[1].strip().split(' ')[0][1:]\n",
    "#         except:\n",
    "#             resto_i   = ''\n",
    "\n",
    "#         try:\n",
    "#             inicial_j = i[1].split(',')[1].strip()[0]\n",
    "#         except:\n",
    "#             inicial_j = ''\n",
    "\n",
    "#         try:\n",
    "#             resto_j   = i[1].split(',')[1].strip().split(' ')[0][1:]\n",
    "#         except:\n",
    "#             resto_j = ''\n",
    "\n",
    "#         # Se a distância de edição entre os sobrenomes\n",
    "#         if editdistance.eval(sobrenome_i, sobrenome_j) > 2 or inicial_i!=inicial_j:\n",
    "#             retirar.append(i)\n",
    "#         else:\n",
    "#             if primnome_i!=primnome_j and len(primnome_i)>1:\n",
    "#                 retirar.append(i)\n",
    "#             if primnome_i!=primnome_j and len(primnome_i)>1 and len(primnome_j)>1:\n",
    "#                 retirar.append(i)\n",
    "#             if resto_i!=resto_j and resto_i!='':\n",
    "#                 retirar.append(i)\n",
    "#             if len(i[1]) < len(i[0]):\n",
    "#                 retirar.append(i)\n",
    "#             if len(iniciais_i) != len(iniciais_j):\n",
    "#                 retirar.append(i)\n",
    "\n",
    "#     for i in similares_jwl:\n",
    "#         if i not in retirar:\n",
    "#             trocar.append(i)\n",
    "\n",
    "#         if iniciais_nome(i[0]) in iniciais_nome(i[1]) and len(i[0]) < len(i[1]):\n",
    "#             trocar.append(i)\n",
    "\n",
    "#         if iniciais_nome(i[0]) == iniciais_nome(i[1]) and len(i[0]) < len(i[1]):\n",
    "#              trocar.append(i)\n",
    "    \n",
    "#     trocar=trocar+lista_extra\n",
    "#     trocar.sort()\n",
    "    \n",
    "#     return trocar\n",
    "\n",
    "\n",
    "\n",
    "# def extrair_variantes(df_dadosgrupo):\n",
    "#     ''' Utiliza campo de Nome em Citações do currículo como filtro para obter variantes do nome de cada membro\n",
    "#      Recebe: Dataframe com os dados brutos do grupo de pesquisa agrupados; lista de nomes de pesquisadores de interesse\n",
    "#     Retorna: Lista de tuplas com pares a serem trocados da variante pelo nome padronizado na forma (origem, destino)\n",
    "#     '''\n",
    "#     filtro1   = 'Nome'\n",
    "#     lista_nomes = df_dadosgrupo[(df_dadosgrupo.ROTULOS == filtro1)]['CONTEUDOS'].values\n",
    "\n",
    "#     variantes=[]\n",
    "#     filtro='Nome em citações bibliográficas'\n",
    "#     variantes=df_dadosgrupo[(df_dadosgrupo.ROTULOS == filtro)]['CONTEUDOS'].to_list()\n",
    "\n",
    "#     trocar=[]\n",
    "#     for j in range(len(variantes)):\n",
    "#         padrao_destino = padronizar_nome(lista_nomes[j])\n",
    "#         trocar.append((lista_nomes[j], padrao_destino))\n",
    "#         for k in variantes[j]:\n",
    "#             padrao_origem = padronizar_nome(k)\n",
    "#             trocar.append((k, padrao_destino))\n",
    "#             trocar.append((padrao_origem, padrao_destino))\n",
    "    \n",
    "#     return trocar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fbfc46",
   "metadata": {},
   "source": [
    "    Apurar colaborações docente/discente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d78c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def converter_lista_set(lista):\n",
    "#     set1 = set(lista)\n",
    "#     return set1\n",
    "\n",
    "# def montardf_producao(lista_csv):\n",
    "#     print(f'{len(lista_csv):02} nomes a extrair')\n",
    "#     df_public=pd.DataFrame()\n",
    "#     for nome_csv in lista_csv:\n",
    "#         if 'colaboradores' in nome_csv.lower():\n",
    "#             tipo='colaboradores'\n",
    "#         else:\n",
    "#             tipo='permanentes'\n",
    "        \n",
    "#         df_pub = pd.read_csv(pathcsv+nome_csv)\n",
    "#         print(len(df_pub.index))\n",
    "#         print(df_pub.keys())\n",
    "\n",
    "#         pat='\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'\n",
    "#         df_temp1 = df_pub.Data.str.split(pat=pat,expand=True)\n",
    "#         df_temp1.columns = (['TITULO','RevAut'])\n",
    "\n",
    "#         pat1='\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'\n",
    "#         df_temp2 = df_temp1.RevAut.str.split(pat=pat1,expand=True)\n",
    "#         df_temp2.columns = (['REVISTA','AUTORES'])\n",
    "\n",
    "#         df_temp0 = df_pub.drop(['Data'], axis=1)\n",
    "#         df_pub=df_temp0.merge(df_temp1['TITULO'],left_index=True,right_index=True)\n",
    "#         df_pub=df_pub.merge(df_temp2,left_index=True,right_index=True)\n",
    "#         try:\n",
    "#             df_pub.drop(['Issn','Natureza'], axis=1, inplace=True)\n",
    "#         except:\n",
    "#             pass\n",
    "#         try:\n",
    "#             df_pub.drop(['Tipo','Idioma'], axis=1, inplace=True)\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#         df_public = pd.concat([df_public, df_pub], ignore_index=True)\n",
    "#         print(len(df_public.index))\n",
    "#         print(df_public.keys())\n",
    "        \n",
    "#     ## Extrai o período com base nos dados\n",
    "#     inicio = min(df_public['Ano'])\n",
    "#     final  = max(df_public['Ano'])\n",
    "    \n",
    "#     total_artigos=len(df_public.index)\n",
    "#     # print(f'{total_artigos:4} publicações de artigos de docentes do programa no período de {inicio} a {final} carregadas...') \n",
    "    \n",
    "#     return df_public\n",
    "\n",
    "# def ler_nomesdocentes():    \n",
    "#     print(pathcsv)\n",
    "#     import os, sys\n",
    "\n",
    "#     lista_csv=[]\n",
    "#     dirs = os.listdir(pathcsv)\n",
    "#     for file in dirs:\n",
    "#         if 'nomes_docentes' in file:\n",
    "#             lista_csv.append(file)\n",
    "#     lista_csv.sort()\n",
    "    \n",
    "#     for i in lista_csv:\n",
    "#         print(i)\n",
    "\n",
    "#     return lista_csv\n",
    "\n",
    "\n",
    "# ## ler arquivo com as orientações para gerar a lista de discentes\n",
    "# def ler_lista_orientacoes():\n",
    "#     try:\n",
    "#         l1='lista_orientadores-discentes.csv'\n",
    "#         df_orientacoes = pd.read_csv(pathcsv+l1, delimiter=';', header=None)\n",
    "        \n",
    "#         lista_orientadores = df_orientacoes.iloc[:,0].unique()\n",
    "#         lista_discentes    = df_orientacoes.iloc[:,1].unique()\n",
    "#         print(f'{len(lista_orientadores):4} orientadores, com {len(lista_discentes)} discentes encontrados')\n",
    "#     except Exception as e:\n",
    "#         print('Erro ao gerar lista de orientações:')\n",
    "#         print(e)\n",
    "#         return df_orientacoes\n",
    "        \n",
    "#     return lista_orientadores, lista_discentes \n",
    "\n",
    "\n",
    "# ## montar um dataframe com nome dos discentes de cada orientador\n",
    "# def montardf_orientacoes():\n",
    "#     try:\n",
    "#         l1='lista_orientadores-discentes.csv'\n",
    "#         df_orientacoes = pd.read_csv(pathcsv+l1, delimiter=';', header=None)\n",
    "#         df_orientacoes.columns=['ORIENTADOR','DISCENTE']\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print('Erro ao dividir dataframe de orientações:')\n",
    "#         print(e)\n",
    "#         return\n",
    "        \n",
    "#     return df_orientacoes\n",
    "\n",
    "\n",
    "\n",
    "# def montardf_docentes_permanentes_colaboradores():\n",
    "#     try:\n",
    "#         l1='lista_docentes_colaboradores.csv'\n",
    "#         l2='lista_docentes_permanentes.csv'\n",
    "#         df_docclbr = pd.read_csv(os.path.join(pathcsv,l1), header=None)\n",
    "#         df_docperm = pd.read_csv(os.path.join(pathcsv,l2), header=None)\n",
    "#         df_docentes = pd.concat([df_docperm, df_docclbr], ignore_index=True)\n",
    "#         print(f'{len(df_docentes.index):4} docentes permanentes e colaboradores encontrados')\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "        \n",
    "#     return df_docentes\n",
    "\n",
    "\n",
    "# def jaccard_similarity(set1, set2):\n",
    "#     '''\n",
    "#     Recebe dois conjuntos (sets) como entradas e retorna a similaridade Jaccard entre eles e avalia: \n",
    "#     1. calcula a interseção dos dois conjuntos usando a função de interseção \n",
    "#     2. calcula a união dos dois conjuntos usando a função de união \n",
    "#     3. retorna a razão entre o comprimento da interseção e o comprimento da união, que é a similaridade de Jaccard.\n",
    "#     '''\n",
    "#     intersection = set1.intersection(set2)\n",
    "#     union        = set1.union(set2)\n",
    "#     return len(intersection) / len(union)\n",
    "    \n",
    "# def montardf_docentes(lista_nomes1=False, lista_nomes2=False):\n",
    "#     # print(lista_nomes1)\n",
    "#     # print(lista_nomes2)\n",
    "\n",
    "#     ## Montagem do dataframe de participação docente\n",
    "#     if (lista_nomes1 and lista_nomes2) != False:\n",
    "#         ## Criar dataframe com os nomes do grupo de docentes permanentes\n",
    "#         file_path = os.path.join(pathcsv,'lista_docentes_permanentes.csv')\n",
    "#         df_docentes_permanentes   = pd.read_csv(file_path, header=None)\n",
    "#         # df_docentes_permanentes['GRUPO']='Permanente'\n",
    "#         # try:\n",
    "#         #     df_docentes_permanentes.drop(columns=([1,2]), inplace=True)\n",
    "#         # except:\n",
    "#         #     pass\n",
    "#         # df_docentes_permanentes.columns = ['DOCENTE','GRUPO']\n",
    "#         df_docentes_permanentes.columns = ['DOCENTE','IDLATES','PROGRAMA','GRUPO']\n",
    "\n",
    "#         ## Criar dataframe com os nomes do grupo de docentes colaboradores\n",
    "#         file_path = os.path.join(pathcsv,'lista_docentes_colaboradores.csv')\n",
    "#         df_docentes_colaboradores = pd.read_csv(file_path, header=None)\n",
    "#         # df_docentes_colaboradores['GRUPO']='Colaborador'\n",
    "#         # try:\n",
    "#         #     df_docentes_colaboradores.drop(columns=([1,2]), inplace=True)\n",
    "#         # except:\n",
    "#         #     pass\n",
    "#         df_docentes_colaboradores.columns = ['DOCENTE','IDLATES','PROGRAMA','GRUPO']\n",
    "\n",
    "#         ## Criar um dataframe único com todos grupos de docentes juntos\n",
    "#         df_docentes = pd.concat([df_docentes_permanentes, df_docentes_colaboradores]).reset_index(drop=True)\n",
    "#         return df_docentes\n",
    "\n",
    "#     elif 'permanentes' in lista_nomes1.lower():\n",
    "#         ## Criar dataframe com os nomes do grupo de docentes permanentes\n",
    "#         file_path = os.path.join(pathcsv,lista_nomes1)       \n",
    "#         df_docentes_permanentes   = pd.read_csv(file_path, header=None)\n",
    "#         # df_docentes_permanentes['GRUPO']='Permanente'\n",
    "#         # try:\n",
    "#         #     df_docentes_permanentes.drop(columns=([1,2]), inplace=True)\n",
    "#         # except:\n",
    "#         #     pass\n",
    "#         df_docentes_permanentes.columns = ['DOCENTE','IDLATES','PROGRAMA','GRUPO']\n",
    "#         return df_docentes_permanentes\n",
    "\n",
    "#     elif 'colaboradores' in lista_nomes1.lower():\n",
    "#         ## Criar dataframe com os nomes do grupo de docentes colaboradores\n",
    "#         file_path = os.path.join(pathcsv,lista_nomes1)\n",
    "#         df_docentes_colaboradores = pd.read_csv(file_path, header=None)\n",
    "#         # df_docentes_colaboradores['GRUPO']='Colaborador'\n",
    "#         # try:\n",
    "#         #     df_docentes_colaboradores.drop(columns=([1,2]), inplace=True)\n",
    "#         # except:\n",
    "#         #     pass\n",
    "#         df_docentes_colaboradores.columns = ['DOCENTE','IDLATES','PROGRAMA','GRUPO']\n",
    "#         return df_docentes_colaboradores\n",
    "#     else:\n",
    "#         print('Erro ao montar dataframe de docentes, verifique os nomes de arquivo.')\n",
    "#         return\n",
    "        \n",
    "# def montar_listas(lista_csv, csv_permanentes=None, csv_colaboradores=None):\n",
    "#     if csv_permanentes == None and csv_colaboradores == None:\n",
    "#         csv_permanentes   = 'lista_docentes_permanentes.csv'\n",
    "#         csv_colaboradores = 'lista_docentes_colaboradores.csv'\n",
    "#         print(f'\\nNomes de docentes não informados, utilizando caminho e nomes padrão:')\n",
    "#         print(f'     Docentes   permanentes de {pathcsv}{csv_permanentes}')\n",
    "#         print(f'     Docentes colaboradores de {pathcsv}{csv_colaboradores}')\n",
    "#         try:\n",
    "#             file_path = os.path.join(pathcsv,csv_permanentes)\n",
    "#             df_docperm = pd.read_csv(file_path, header=None)\n",
    "#             file_path = os.path.join(pathcsv,csv_colaboradores)\n",
    "#             df_docclbr = pd.read_csv(file_path, header=None)\n",
    "#             lista_docentes = pd.concat([df_docperm, df_docclbr], ignore_index=True)[0].values\n",
    "#             print(f'{len(lista_docentes):4} docentes permanentes e colaboradores encontrados')\n",
    "#         except Exception as e:\n",
    "#             print(f'Erro ao ler listas de docentes, verificar se os arquivos CSV estão na pasta {pathcsv}')\n",
    "#             print(e)\n",
    "#     elif 'permanentes' in csv_permanentes.lower():\n",
    "#         print(f'\\nArquivo docentes   permanentes informado: {csv_permanentes}')\n",
    "#         try:\n",
    "#             file_path = os.path.join(pathcsv,csv_permanentes)\n",
    "#             lista_docentes = pd.read_csv(file_path, header=None)[0].values\n",
    "#             print(f'{len(lista_docentes)} docentes permanentes encontrados')\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#     elif 'colaboradores' in csv_permanentes.lower():\n",
    "#         print(f'\\nArquivo docentes colaboradores informado: {csv_colaboradores}')\n",
    "#         try:\n",
    "#             file_path = os.path.join(pathcsv,csv_permanentes)\n",
    "#             lista_docentes = pd.read_csv(file_path, header=None)[0].values\n",
    "#             print(f'{len(lista_docentes)} docentes colaboradores encontrados')\n",
    "#         except Exception as e:\n",
    "#             print(e)    \n",
    "#     else:\n",
    "#         print('Erro ao ler listas de docentes, verificar listas')\n",
    "\n",
    "#     df_prod   = montardf_producao(lista_csv)\n",
    "    \n",
    "#     ## Montar a lista de autores com limpar_nomes remove caracteres, preposições e separa iniciais com espaço\n",
    "#     lista_listas = df_prod['AUTORES'].tolist()\n",
    "#     lista_autores_artigos = []\n",
    "#     for i in lista_listas:\n",
    "#         lista_autores_artigos.append(limpar_nomes(i))\n",
    "    \n",
    "#     ## Ler nomes de discentes e orientadores\n",
    "#     lista_orientadores, lista_discentes = ler_lista_orientacoes()\n",
    "    \n",
    "#     return lista_autores_artigos, lista_docentes, lista_orientadores, lista_discentes\n",
    "\n",
    "# def montardf_participacao_docente_discente(df_prod, dic_nomes_docentes, dic_nomes_discentes):\n",
    "#     ## Montar dataframe de participação docente\n",
    "#     df_participacao_docente = pd.DataFrame(dic_nomes_docentes).T\n",
    "#     df_participacao_docente.columns = ['DOCENTE','INDICES_ARTIGOS']\n",
    "#     df_participacao_docente['AUTORIAS'] = [len(x) for x in df_participacao_docente['INDICES_ARTIGOS']]\n",
    "\n",
    "#     ## Montar dataframe de participação discente\n",
    "#     df_participacao_discente = pd.DataFrame(dic_nomes_discentes).T\n",
    "#     df_participacao_discente.columns = ['DISCENTE','INDICES_ARTIGOS']\n",
    "#     df_participacao_discente['AUTORIAS'] = [len(x) for x in df_participacao_discente['INDICES_ARTIGOS']]\n",
    "\n",
    "#     ## Criar lista com os artigos onde foi encontado nome de algum docente\n",
    "#     artigos_com_docentes=[]\n",
    "#     for m in df_participacao_docente['INDICES_ARTIGOS']:\n",
    "#         for n in m:\n",
    "#             if n not in artigos_com_docentes:\n",
    "#                 artigos_com_docentes.append(n)\n",
    "#     artigos_com_docentes.sort()\n",
    "                \n",
    "#     ## Criar lista com os artigos onde foi encontado nome de algum discente\n",
    "#     artigos_com_discentes=[]\n",
    "#     for m in df_participacao_discente['INDICES_ARTIGOS']:\n",
    "#         for n in m:\n",
    "#             if n not in artigos_com_discentes:\n",
    "#                 artigos_com_discentes.append(n)\n",
    "#     artigos_com_discentes.sort()\n",
    "                \n",
    "        \n",
    "#     ## Criar lista com os artigos onde NÃO foi encontado nome de discente\n",
    "#     lista_semparticipacaodiscente=[]\n",
    "#     for i in range(len(df_prod.index)):\n",
    "#         if i not in artigos_com_discentes and i not in lista_semparticipacaodiscente:\n",
    "#             lista_semparticipacaodiscente.append(i)\n",
    "            \n",
    "#     ## Criar lista com os artigos onde NÃO foi encontado nome de docente\n",
    "#     lista_semparticipacaodocente=[]\n",
    "#     for i in range(len(df_prod.index)):\n",
    "#         if i not in artigos_com_docentes and i not in lista_semparticipacaodocente:\n",
    "#             lista_semparticipacaodocente.append(i)\n",
    "\n",
    "#     ## Apresentar resultados das buscas por nomes de autores docentes e discentes\n",
    "#     lista_titulos = pd.Series(df_prod['TITULO'].values).unique().tolist()\n",
    "#     print(len(lista_titulos),'títulos únicos de artigo encontrados')\n",
    "#     pdoc = np.round(100*len(artigos_com_docentes)/len(df_prod.index),2)\n",
    "#     spdoc = np.round(100*len(lista_semparticipacaodocente)/len(df_prod.index),2)\n",
    "#     print(f'{len(artigos_com_docentes):4} ({pdoc:6}%) artigos com nome de  docente encontrado, faltando {len(lista_semparticipacaodocente):3} ({spdoc:5}%)')\n",
    "\n",
    "#     pdis = np.round(100*len(artigos_com_discentes)/len(df_prod.index),2)\n",
    "#     spdis = np.round(100*len(lista_semparticipacaodiscente)/len(df_prod.index),2)\n",
    "#     print(f'{len(artigos_com_discentes):4} ({pdis:6}%) artigos com nome de discente encontrado, faltando {len(lista_semparticipacaodiscente):3} ({spdis:5}%)')\n",
    "\n",
    "#     return df_participacao_docente, df_participacao_discente, lista_semparticipacaodocente, lista_semparticipacaodiscente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616ca80e",
   "metadata": {},
   "source": [
    "    Ler arquivos de dados do disco local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea93d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ler arquivos de publicação de artigos na pasta de arquivos CSV\n",
    "# def ler_artigostodosperiodos():    \n",
    "#     print(pathcsv)\n",
    "#     import os, sys\n",
    "\n",
    "#     lista_csv=[]\n",
    "#     dirs = os.listdir(pathcsv)\n",
    "#     for file in dirs:\n",
    "#         if 'Artigos' in file:\n",
    "#             lista_csv.append(file)\n",
    "#     lista_csv.sort()\n",
    "    \n",
    "#     for i in lista_csv:\n",
    "#         print(i)\n",
    "\n",
    "#     return lista_csv\n",
    "\n",
    "\n",
    "\n",
    "# ## ler arquivos de publicação de de período determinado\n",
    "# def ler_csvptg(inicio=False, final=False, tipo=False, grupo=False):    \n",
    "#     import os, sys\n",
    "\n",
    "#     print(pathcsv)\n",
    "#     lista_csv=[]\n",
    "#     dirs = os.listdir(pathcsv)\n",
    "#     for file in dirs:\n",
    "#         if (str(inicio) or str(final)) == False:\n",
    "#             if tipo.lower() == False:\n",
    "#                 if grupo.lower() == False:\n",
    "#                     lista_csv.append(file)\n",
    "\n",
    "#         elif (str(inicio) and str(final)) in file.lower():\n",
    "#             if unidecode(tipo).lower() in unidecode(file).lower():\n",
    "#                 if unidecode(grupo).lower() in unidecode(file).lower():\n",
    "#                     lista_csv.append(file)\n",
    "#     lista_csv.sort()\n",
    "    \n",
    "#     for i in lista_csv:\n",
    "#         print(i)\n",
    "\n",
    "#     return lista_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f505b4",
   "metadata": {},
   "source": [
    "### Funções para avaliar a PCD e Pontuação de Impacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eef1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def montardf_impacto_docente_discente(df_prod, dic_nomes_docentes, dic_nomes_discentes, inicio, final):\n",
    "#     artigos_com_discentes=[]\n",
    "#     artigos_com_docentes=[]\n",
    "#     lista_semparticipacaodiscente=[]\n",
    "#     lista_semparticipacaodocente=[]\n",
    "\n",
    "#     try:\n",
    "#         ## Montar dataframe de participação docente\n",
    "#         df_impacto_docente = pd.DataFrame(dic_nomes_docentes).T\n",
    "#         df_impacto_docente.columns = ['DOCENTE','INDICES_ARTIGOS','EXTRATOS_QUALIS']\n",
    "#         df_impacto_docente['AUTORIAS'] = [len(x) for x in df_impacto_docente['INDICES_ARTIGOS']]\n",
    "\n",
    "#         ## Criar lista com os artigos onde foi encontado nome de algum docente\n",
    "#         for m in df_impacto_docente['INDICES_ARTIGOS']:\n",
    "#             for n in m:\n",
    "#                 if n not in artigos_com_docentes:\n",
    "#                     artigos_com_docentes.append(n)\n",
    "#         artigos_com_docentes.sort()\n",
    "\n",
    "#         ## Criar lista com os artigos onde NÃO foi encontado nome de docente\n",
    "#         for i in range(len(df_prod.index)):\n",
    "#             if i not in artigos_com_docentes and i not in lista_semparticipacaodocente:\n",
    "#                 lista_semparticipacaodocente.append(i)\n",
    "#     except:\n",
    "#         df_impacto_docente = pd.DataFrame()\n",
    "#         print('Não foi possível encontrar nenhuma ocorrência dos nomes dos docentes com este conjunto de dados')\n",
    "#         pass\n",
    "\n",
    "#     try:\n",
    "#         ## Montar dataframe de participação discente\n",
    "#         df_impacto_discente = pd.DataFrame(dic_nomes_discentes).T\n",
    "#         df_impacto_discente.columns = ['DISCENTE','INDICES_ARTIGOS','EXTRATOS_QUALIS']\n",
    "#         df_impacto_discente['AUTORIAS'] = [len(x) for x in df_impacto_discente['INDICES_ARTIGOS']]\n",
    "\n",
    "#         ## Criar lista com os artigos onde foi encontado nome de algum discente\n",
    "#         for m in df_impacto_discente['INDICES_ARTIGOS']:\n",
    "#             for n in m:\n",
    "#                 if n not in artigos_com_discentes:\n",
    "#                     artigos_com_discentes.append(n)\n",
    "#         artigos_com_discentes.sort()\n",
    "#     except:\n",
    "#         df_impacto_discente = pd.DataFrame()\n",
    "#         print('Não foi possível encontrar nenhuma ocorrência dos nomes dos discentes com este conjunto de dados')\n",
    "#         pass\n",
    "                \n",
    "#     ## Criar lista com os artigos onde NÃO foi encontado nome de discente\n",
    "#     for i in range(len(df_prod.index)):\n",
    "#         if i not in artigos_com_discentes and i not in lista_semparticipacaodiscente:\n",
    "#             lista_semparticipacaodiscente.append(i)\n",
    "\n",
    "#     ## Apresentar resultados das buscas por nomes de autores docentes e discentes\n",
    "#     lista_titulos = pd.Series(df_prod['TITULO'].values).unique().tolist()\n",
    "#     print(len(lista_titulos),'títulos únicos de artigo encontrados')\n",
    "#     pdoc  = np.round(100*len(artigos_com_docentes)/len(df_prod.index),2)\n",
    "#     spdoc = np.round(100*len(lista_semparticipacaodocente)/len(df_prod.index),2)\n",
    "#     print(f'{len(artigos_com_docentes):4} ({pdoc:6}%) artigos com nome de  docente encontrado, faltando {len(lista_semparticipacaodocente):3} ({spdoc:5}%)')\n",
    "\n",
    "#     pdis = np.round(100*len(artigos_com_discentes)/len(df_prod.index),2)\n",
    "#     spdis = np.round(100*len(lista_semparticipacaodiscente)/len(df_prod.index),2)\n",
    "#     print(f'{len(artigos_com_discentes):4} ({pdis:6}%) artigos com nome de discente encontrado, faltando {len(lista_semparticipacaodiscente):3} ({spdis:5}%)')\n",
    "\n",
    "#     ## A1=100, A2=80, B1=60, B2=40, B3=20, B4=10, B5=2\n",
    "#     soma_impacto=[]\n",
    "#     for linha in df_impacto_docente['EXTRATOS_QUALIS']:\n",
    "#         impacto=0\n",
    "#         for extrato in linha:\n",
    "#             if extrato == 'A1':\n",
    "#                 impacto+=100\n",
    "#             elif extrato == 'A2':\n",
    "#                 impacto+=80\n",
    "#             elif extrato == 'B1':\n",
    "#                 impacto+=60\n",
    "#             elif extrato == 'B2':\n",
    "#                 impacto+=40\n",
    "#             elif extrato == 'B3':\n",
    "#                 impacto+=20\n",
    "#             elif extrato == 'B4':\n",
    "#                 impacto+=10\n",
    "#             elif extrato == 'B5':\n",
    "#                 impacto+=2\n",
    "#             elif extrato == 'C':\n",
    "#                 impacto+=0\n",
    "#             elif extrato == 'nan':\n",
    "#                 impacto+=0\n",
    "#         soma_impacto.append(impacto)\n",
    "\n",
    "#     df_impacto_docente['SOMA_IMPACTO'] = soma_impacto\n",
    "#     qte_anos = (final-inicio+1)\n",
    "#     df_impacto_docente['ANOS'] = qte_anos\n",
    "#     df_impacto_docente['IMPACTO_MEDIO_ANUAL'] = np.round(df_impacto_docente['SOMA_IMPACTO']/df_impacto_docente['ANOS'],1)\n",
    "\n",
    "#     return df_impacto_docente, df_impacto_discente\n",
    "\n",
    "\n",
    "\n",
    "# def apurar_pcd_impacto(df_docentes, df_impacto_docente, df_impacto_discente, meta_pcd=50.0, meta_impacto=150.0):\n",
    "#     print(f'Total de nomes de docentes em análise: {len(df_docentes.index)}')\n",
    "#     print(f'Total de nomes de docentes  encontrados nos artigos: {len(df_impacto_docente.index)}')\n",
    "#     print(f'Total de nomes de discentes encontrados nos artigos: {len(df_impacto_discente.index)}')\n",
    "\n",
    "#     df_docentes_pcd_impacto = df_docentes\n",
    "#     ## Montar lista com os índices do dataframe de artigos onde foram achados nomes de discentes na lista de autores\n",
    "#     lista_participacao_discente = []\n",
    "#     for artigos_discentes in df_impacto_discente['INDICES_ARTIGOS']:\n",
    "#         for indice in artigos_discentes:\n",
    "#             lista_participacao_discente.append(indice)\n",
    "\n",
    "#     ## Contar a quantidade de participações de discentes que ocorrem no dataframe de produção docente\n",
    "#     qte_colab_discente=[]\n",
    "#     for docente,artigos_docente in zip(df_impacto_docente['DOCENTE'], df_impacto_docente['INDICES_ARTIGOS']):\n",
    "#         qte=0\n",
    "#         for indice in artigos_docente:\n",
    "#             if indice in lista_participacao_discente:\n",
    "#                 qte+=1\n",
    "            \n",
    "#         qte_colab_discente.append(qte)\n",
    "\n",
    "#     df_docentes_pcd_impacto['PUBLICAÇÕES']  = df_impacto_docente['AUTORIAS']\n",
    "#     df_docentes_pcd_impacto['COM_DISCENTE'] = qte_colab_discente\n",
    "#     df_docentes_pcd_impacto['PCD'] = np.round(100*(df_docentes_pcd_impacto['COM_DISCENTE']/df_impacto_docente['AUTORIAS']),1)\n",
    "#     df_docentes_pcd_impacto['IMPACTO'] = df_impacto_docente['SOMA_IMPACTO']\n",
    "#     df_docentes_pcd_impacto['IMPACTO_MEDIO_ANUAL'] = df_impacto_docente['IMPACTO_MEDIO_ANUAL']\n",
    "\n",
    "#     ## Definir a meta de produção conjunta com discente e apurar o resultado\n",
    "#     # meta_pcd=50.0\n",
    "#     apuracao_pcd     = df_docentes_pcd_impacto.groupby([df_docentes_pcd_impacto.index,'PCD'])\n",
    "#     df_abaixo_pcd    = apuracao_pcd.filter(lambda x: x['PCD'] < meta_pcd)\n",
    "#     df_atingiram_pcd = apuracao_pcd.filter(lambda x: x['PCD'] >= meta_pcd)\n",
    "\n",
    "#     total_docentes         = len(df_docentes_pcd_impacto.index)\n",
    "\n",
    "#     contagem_abaixometa    = len(df_abaixo_pcd.index)\n",
    "#     contagem_atingindometa = len(df_atingiram_pcd.index)\n",
    "#     indicador_pcd = np.round(100*contagem_atingindometa/total_docentes,1)\n",
    "#     print(f'{indicador_pcd}% dos docentes {contagem_atingindometa}/{total_docentes} atingem a meta de {meta_pcd}% publicação com discente')\n",
    "\n",
    "#     ## Definir a meta de impacto por pesquisador e para o grupo\n",
    "#     # meta_impacto=150\n",
    "#     apuracao_impacto     = df_docentes_pcd_impacto.groupby([df_docentes_pcd_impacto.index,'IMPACTO'])\n",
    "#     df_abaixo_impacto    = apuracao_impacto.filter(lambda x: x['IMPACTO_MEDIO_ANUAL'] < meta_impacto)\n",
    "#     df_atingiram_impacto = apuracao_impacto.filter(lambda x: x['IMPACTO_MEDIO_ANUAL'] >= meta_impacto)\n",
    "\n",
    "#     contagem_abaixometa_impacto    = len(df_abaixo_impacto.index)\n",
    "#     contagem_atingindometa_impacto = len(df_atingiram_impacto.index)\n",
    "#     indicador_impacto = np.round(100*contagem_atingindometa_impacto/total_docentes,1)\n",
    "#     print(f'{indicador_impacto}% dos docentes {contagem_atingindometa_impacto}/{total_docentes} atingem a meta de {meta_impacto} pontos de impacto médio por ano das publicações')\n",
    "\n",
    "#     return df_docentes_pcd_impacto, apuracao_pcd, df_abaixo_pcd, df_atingiram_pcd, indicador_pcd, indicador_impacto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cda89d",
   "metadata": {},
   "source": [
    "### Funções para plotagem: \n",
    "    \n",
    "    Plotar gráficos de percentual de participação discente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.offsetbox import (TextArea, DrawingArea, OffsetImage, AnnotationBbox)\n",
    "from matplotlib.cbook import get_sample_data\n",
    "plt.rcParams['font.size']      = 12\n",
    "# plt.rcParams[\"figure.figsize\"] = (15,9)\n",
    "\n",
    "\n",
    "\n",
    "def plotar_pcd(df, grupo=False, inicio=False, final=False):\n",
    "    N    = len(df.index)\n",
    "    percentual = (df['PCD'].values.round(1))\n",
    "\n",
    "    ind   = np.arange(N) # the x locations for the groups\n",
    "    width = 0.75         # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "    # criar figura\n",
    "    fig, ax = plt.subplots(figsize=(25,10))\n",
    "\n",
    "    # plotar barras verticais com cores condicionais se abaixo do valor da variável para aceitação\n",
    "    par = 50 \n",
    "    cor = ['yellow' if (x < par) else 'green' for x in percentual]\n",
    "    p1  = ax.bar(ind, percentual, width, \n",
    "                #  yerr=dsvpad, \n",
    "                 error_kw=dict(lw=0.3, capsize=2, capthick=1),\n",
    "                 label='Percentual de publicação com discente', color=cor)\n",
    "\n",
    "    # plotar os rótulos e título\n",
    "    ax.axhline(par, color='red', linewidth=3, linestyle='dotted')\n",
    "    ax.axhline(70, color='gray', linewidth=3, linestyle='dotted')\n",
    "    if (grupo and inicio and final) != False:\n",
    "        ax.set_title(f'Apuração do percentual de publicação de docentes {grupo.upper()} com discente no período de {inicio} a {final}')\n",
    "    elif grupo == False:\n",
    "        ax.set_title(f'Apuração do percentual de publicação de docentes com discente no período de {inicio} a {final}')\n",
    "    else:\n",
    "        ax.set_title(f'Apuração do percentual de publicação com discente')\n",
    "\n",
    "    ax.set_ylabel('Percentual de artigos publicados com discente')\n",
    "    ax.set_xticks(ind)\n",
    "    \n",
    "    labels_pos=np.arange(1,N+1)\n",
    "    ax.set_xticklabels(labels_pos)\n",
    "\n",
    "    # Label with label_type 'center' instead of the default 'edge'\n",
    "    ax.bar_label(p1, label_type='center')\n",
    "    # ax.bar_label(p1, dsvpad)\n",
    "    # ax.set_yticks(range(0,100))\n",
    "    \n",
    "    # respectivo domínio de cada questão no AGREE II\n",
    "    grupos = ['01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01',\n",
    "              '02','02','02','02','02','02','02','02','02','02','02','02','02','02','02','02',]\n",
    "    \n",
    "    # calcular limites de retângulos dos domínios\n",
    "    lista_dominios   = pd.Series(grupos)\n",
    "    largura_dominios = lista_dominios.value_counts().sort_index().values   \n",
    "    altura = 100\n",
    "    rets=[]   \n",
    "    \n",
    "    for i in range(1,len(largura_dominios)+1):\n",
    "        ret = patches.Rectangle((-0.5,0),\n",
    "                                np.sum(largura_dominios[:i]), altura,\n",
    "#                                 linestyle='dashdot',\n",
    "                                linewidth=2,\n",
    "                                edgecolor='b',\n",
    "                                fill = False)\n",
    "        rets.append(ret)\n",
    "    \n",
    "    # plotar os retângulos das dimensões na área do gráfico\n",
    "    for i in rets:\n",
    "        ax.add_patch(i)\n",
    "        \n",
    "    # plotar legenda, comentar para excluir\n",
    "    # ax.legend(bbox_to_anchor=(0.75,-0.05), ncol=2)\n",
    "    \n",
    "    campo='04'\n",
    "    # savefig_respostas(campo)\n",
    "    \n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "def plotar_medias_impacto(df, grupo=False, inicio=False, final=False):\n",
    "    N      = len(df.index)\n",
    "    pontos = (df['IMPACTO_MEDIO_ANUAL'].values.round(1))\n",
    "\n",
    "    ind   = np.arange(N) # the x locations for the groups\n",
    "    width = 0.75         # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "    # criar figura\n",
    "    fig, ax = plt.subplots(figsize=(25,10))\n",
    "\n",
    "    # plotar barras verticais com cores condicionais se abaixo do valor da variável para aceitação\n",
    "    par = 150 \n",
    "    cor = ['yellow' if (x < par) else 'green' for x in pontos]\n",
    "    p1  = ax.bar(ind, pontos, width, \n",
    "                #  yerr=dsvpad, \n",
    "                 error_kw=dict(lw=0.3, capsize=2, capthick=1),\n",
    "                 label='Pontuação em impacto das publicações de docentes', color=cor)\n",
    "\n",
    "    # plotar os rótulos e título\n",
    "    ax.axhline(par, color='red', linewidth=3, linestyle='dotted')\n",
    "    if (grupo and inicio and final) != False:\n",
    "        ax.set_title(f'Apuração da pontuação de impacto das publicações de docentes {grupo.upper()} no período de {inicio} a {final}')\n",
    "    elif (inicio and final) != False:\n",
    "        ax.set_title(f'Apuração da pontuação de impacto das publicações de docentes no período de {inicio} a {final}')\n",
    "    else:\n",
    "        ax.set_title(f'Apuração da pontuação de impacto médio (total do impacto acumulado / quantidade de anos do período) das publicações de docentes')\n",
    "\n",
    "    ax.set_ylabel('Pontuação ponderada pelo Qualis dos artigos publicados')\n",
    "    ax.set_xticks(ind)\n",
    "    \n",
    "    labels_pos=np.arange(1,N+1)\n",
    "    ax.set_xticklabels(labels_pos)\n",
    "\n",
    "    # Label with label_type 'center' instead of the default 'edge'\n",
    "    ax.bar_label(p1, label_type='center')\n",
    "    # ax.bar_label(p1, dsvpad)\n",
    "    vr_maximo = int(max(pontos)+50)\n",
    "    # ax.set_yticks(range(0,vr_maximo))\n",
    "    \n",
    "    # respectivo domínio de cada questão no AGREE II\n",
    "    grupos = ['01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01','01',\n",
    "              '02','02','02','02','02','02','02','02','02','02','02','02','02','02','02','02',]\n",
    "    \n",
    "    # calcular limites de retângulos dos domínios\n",
    "    lista_dominios   = pd.Series(grupos)\n",
    "    largura_dominios = lista_dominios.value_counts().sort_index().values   \n",
    "    altura = max(pontos)+50\n",
    "    rets=[]   \n",
    "    \n",
    "    for i in range(1,len(largura_dominios)+1):\n",
    "        ret = patches.Rectangle((-0.5,0),\n",
    "                                np.sum(largura_dominios[:i]), altura,\n",
    "#                                 linestyle='dashdot',\n",
    "                                linewidth=2,\n",
    "                                edgecolor='b',\n",
    "                                fill = False)\n",
    "        rets.append(ret)\n",
    "    \n",
    "    # plotar os retângulos das dimensões na área do gráfico\n",
    "    for i in rets:\n",
    "        ax.add_patch(i)\n",
    "        \n",
    "    # plotar legenda, comentar para excluir\n",
    "    # ax.legend(bbox_to_anchor=(0.75,-0.05), ncol=2)\n",
    "    \n",
    "    campo='04'\n",
    "    # savefig_respostas(campo)\n",
    "    \n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fa03cb",
   "metadata": {},
   "source": [
    "## Apurar participação discente e impacto artigos dos docentes\n",
    "### Todos os períodos e grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(pathcsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea408ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes_docentes_permanentes   = 'lista_docentes_permanentes.csv'\n",
    "lista_nomes_docentes_colaboradores = 'lista_docentes_colaboradores.csv'\n",
    "df_docentes = montardf_docentes(lista_nomes_docentes_permanentes, lista_nomes_docentes_colaboradores)\n",
    "\n",
    "## Escolha dos arquivos que alimentarão a análise da produção\n",
    "lista_csv = ler_artigostodosperiodos()\n",
    "lista_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2eb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c09d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfilename = os.path.join(pathcsv,'lista_docentes.csv')\n",
    "lista_csv = pd.read_csv(pathfilename,header=None)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod   = montardf_producao(lista_csv)\n",
    "\n",
    "## Mostrar quantitativos lidos\n",
    "print(f'\\nCarregado dataframe com {len(df_prod.index)} linhas:')\n",
    "lista_titulos = pd.Series(df_prod['TITULO'].values).unique().tolist()\n",
    "print(f'{len(lista_titulos):4} artigos distintos publicados no período')\n",
    "lista_revistas = pd.Series(df_prod['REVISTA'].values).unique().tolist()\n",
    "print(f'{len(lista_revistas):4} revistas distintas utilizadas no período')\n",
    "\n",
    "## Ler nomes de docentes, discentes e papel de orientador\n",
    "lista_autores_artigos, lista_docentes, lista_orientadores, lista_discentes = montar_listas(lista_csv)\n",
    "qte_docentes=len(lista_docentes)\n",
    "qte_discentes=len(lista_discentes)\n",
    "total_iteracoes=(qte_docentes+qte_discentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e2c31",
   "metadata": {},
   "source": [
    "    Organizar lista de autores e iniciais de nomes\n",
    "    PROBLEMA: não está quebrando no número de artigos 1115, mas sim em apenas 2 e última vazia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f515360",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Montar a lista de autores a partir da lista de strings limpa com nomes de autores\n",
    "def organizar_nomes(str_autores_artigo):\n",
    "    erros_organizar  = []\n",
    "    lista_organizada = []\n",
    "    partes_nomes = str_autores_artigo.split(', ')\n",
    "    n       = len(partes_nomes)\n",
    "    pares   = range(0,n+1,2)\n",
    "    impares = range(1,n+1,2)\n",
    "    try:\n",
    "        for i,j in zip(pares,impares):\n",
    "            nome=[]\n",
    "            try:\n",
    "                nomes_ordenado = str(partes_nomes[j].lower()+' '+partes_nomes[i].lower()).replace('  ',' ').strip()\n",
    "            except:\n",
    "                if len(pares) > len(impares):\n",
    "                    nomes_ordenado = str(partes_nomes[j].lower()).replace('  ',' ').strip()\n",
    "                else:\n",
    "                    nomes_ordenado = str(partes_nomes[i].lower()).replace('  ',' ').strip()\n",
    "            lista_organizada.append(nomes_ordenado)\n",
    "    \n",
    "    except Exception as e1:\n",
    "        print('Erro ao montar listas de nomes de autor:',e1)\n",
    "        erros_organizar.append((i,str_autores_artigo))\n",
    "\n",
    "    return lista_organizada, erros_organizar\n",
    "\n",
    "## Quebrar um nome em seu sobrenome seguido das partes de nome\n",
    "def quebrar_partesnomes(nome):\n",
    "    padrao     = padronizar_nome(nome).lower()\n",
    "    sobrenome  = padrao.split(',')[0].strip()\n",
    "    restonomes = padrao.split(',')[1].strip().split(' ')\n",
    "    try:\n",
    "        partenome1 = restonomes[0].strip()\n",
    "    except:\n",
    "        partenome1 = np.NaN\n",
    "    try:\n",
    "        partenome2 = restonomes[1].strip()\n",
    "    except:\n",
    "        partenome2 = np.NaN\n",
    "    try:\n",
    "        partenome3 = restonomes[2].strip()\n",
    "    except:\n",
    "        partenome3 = np.NaN        \n",
    "    # print(f'{sobrenome:15} | {partenome1:1} | {partenome2:1} | {partenome3}')\n",
    "    \n",
    "    return sobrenome, partenome1, partenome2, partenome3\n",
    "\n",
    "\n",
    "## Quebrar um nome em seu sobrenome seguido as iniciais das partes de nome\n",
    "def quebrar_iniciais(nome):\n",
    "    padrao = iniciais_nome(nome).lower()\n",
    "    sobrenome  = padrao.split(',')[0].strip()\n",
    "    restonomes = padrao.split(',')[1].strip().split(' ')\n",
    "\n",
    "    try:\n",
    "        partenome1 = restonomes[0].strip()\n",
    "    except:\n",
    "        partenome1 = np.NaN\n",
    "    try:\n",
    "        partenome2 = restonomes[1].strip()\n",
    "    except:\n",
    "        partenome2 = np.NaN\n",
    "    try:\n",
    "        partenome3 = restonomes[2].strip()\n",
    "    except:\n",
    "        partenome3 = np.NaN        \n",
    "    # print(f'{sobrenome:15} | {partenome1:1} | {partenome2:1} | {partenome3}')\n",
    "    \n",
    "    return sobrenome, partenome1, partenome2, partenome3\n",
    "\n",
    "\n",
    "## compilar padrão regular expression para buscar ocorência de duas das quatro partes de nome dentro de janela de no máximo 2 palavras de distância\n",
    "def compilar_partes(sobrenome, partenome1, partenome2, partenome3):\n",
    "    return re.compile(r'\\b({0}|{1}|{2}|{3})(?:\\W+\\w+){{0,2}}?\\W+({1}&{2}|{2}&{3}|{0}&{1}|{0}&{3})\\b'.format(sobrenome, partenome1, partenome2, partenome3), flags=re.IGNORECASE)\n",
    "\n",
    "def compilar_iniciais(sobrenome, inicial1, inicial2, inicial3):\n",
    "    return re.compile(r'\\b({0})(?:\\W+\\w+){{0,1}}?\\W+({1}|{2}|{3})\\b'.format(sobrenome, inicial1, inicial2, inicial3), flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ffe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_dicionarios(df_prod, lista_docentes, lista_discentes, inicio = min(df_prod['Ano']), final  = max(df_prod['Ano'])):\n",
    "    qte_docentes     = len(lista_docentes)\n",
    "    qte_discentes    = len(lista_discentes)\n",
    "    total_iteracoes  = (qte_docentes+qte_discentes)\n",
    "    \n",
    "    ## Monta uma lista de strings com nomes dos autores de cada artigo na forma extraída pelo e-lattes\n",
    "    lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "    qte_artigos         = len(lista_nomes_autores)\n",
    "        \n",
    "    ## Define os limites para considerar duas strings com nomes similares entre si\n",
    "    limite_jaro_nome        = 0.88\n",
    "    limite_jaro_iniciais    = 0.75\n",
    "    limite_jaccard_iniciais = 0.32\n",
    "\n",
    "    ## Função para calcular similaridade dos nomes de docentes com cada nome de autor da lista de autores de cada artigo\n",
    "    t1 = time.time()\n",
    "    dic_nomes_docentes  = {}\n",
    "    dic_nomes_discentes = {}    \n",
    "    erros=[]\n",
    "    rot1='Comparando nome do docente'\n",
    "    rot2='Sobren/Iniciais docen'\n",
    "    rot3='Sobrenome/Iniciais autor'\n",
    "    rot4='I.Doc'\n",
    "    rot5='I.Aut'\n",
    "    rot6='Jaro-Winkler'\n",
    "    rot7='Jaccard'\n",
    "    for m,docente in enumerate(lista_docentes):\n",
    "        achados_docentes     = []\n",
    "        lista_indice_docente = []\n",
    "        lista_qualis_docente = []\n",
    "        docentes_naoencontrados = []          \n",
    "        contagem=m+1\n",
    "        # clear_output(wait=True)       \n",
    "        try:\n",
    "            nome_docente_padronizado = padronizar_nome(docente).lower()\n",
    "            iniciais_nome_docente    = iniciais_nome(docente).lower()\n",
    "            string_iniciais_docente  = ' '.join(x.strip() for x in iniciais_nome_docente.split(',')[1:])\n",
    "            set_iniciais_docente     = converter_lista_set([x.strip() for x in iniciais_nome_docente.split(',')[1:]])                \n",
    "            print(f'\\nCálculo das similaridades autores-docentes (nome/iniciais/Jaccard):')\n",
    "            print(f'{rot1:^40} |{rot2:^20}| {rot3:^25}|{rot4:^5}|{rot5:^5}|{rot6:^15}|{rot7:^10}')\n",
    "            ## Monta a lista de autores com a divisão da string organizada padronizada no formato: {sobrenome, iniciais de nomes}\n",
    "            lst_autores_artigo = []\n",
    "            lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "            for n,nomes_autor in enumerate(lista_nomes_autores):\n",
    "                autores,erros = organizar_nomes(nomes_autor)\n",
    "                for o,autor in enumerate(autores):\n",
    "                    qte_autores_artigo = len(autores)\n",
    "                    # print(f'{o+1:2}/{qte_autores_artigo:2} nomes de autor do artigo em análise, restando {qte_autores_artigo-o-1:2}')\n",
    "                    nome_autor_padronizado = padronizar_nome(autor).lower()\n",
    "                    try:    \n",
    "                        iniciais_nome_autor    = iniciais_nome(autor).lower()\n",
    "                        string_iniciais_autor  = ' '.join(x.strip() for x in iniciais_nome_autor.split(',')[1:])\n",
    "                        set_iniciais_autor     = converter_lista_set([x.strip() for x in iniciais_nome_autor.split(',')[1:]])\n",
    "                        # time.sleep(1)\n",
    "                        ## Cálculos de similaridades entre os nomes do autor e do docente\n",
    "                        if iniciais_nome_docente and iniciais_nome_autor != '':\n",
    "                            similaridade_nome     = get_jaro_distance(iniciais_nome_docente, iniciais_nome_autor)\n",
    "                            similaridade_iniciais = get_jaro_distance(string_iniciais_docente, string_iniciais_autor)\n",
    "                            similaridade_jaccard  = np.round(jaccard_similarity(set_iniciais_docente, set_iniciais_autor),2)\n",
    "                            print(f'\\nCálculo das similaridades autores-discentes (nome/iniciais/Jaccard):')\n",
    "                            print(f'{padronizar_nome(docente):^40} | {iniciais_nome_docente:<20}|{iniciais_nome_autor:<20} {similaridade_nome:^5}|{string_iniciais_docente:^5}|{string_iniciais_autor:^5}|{similaridade_iniciais:^15}|{similaridade_jaccard:^10}')\n",
    "                            clear_output(wait=True)\n",
    "                            if similaridade_nome > limite_jaro_nome and similaridade_iniciais > limite_jaro_iniciais and similaridade_jaccard > limite_jaccard_iniciais:\n",
    "                                if n not in lista_indice_docente:\n",
    "                                    print(f'Similaridade encontrada no artigo {n+1}/{qte_artigos}, docente {m+1}/{qte_docentes}')\n",
    "                                    print(f'{rot1:^40} |{rot2:^20}| {rot3:^25}|{rot4:^5}|{rot5:^5}|{rot6:^15}|{rot7:^10}')\n",
    "                                    print(f'{padronizar_nome(docente):^40} | {iniciais_nome_docente:<20}|{iniciais_nome_autor:<20} {similaridade_nome:^5}|{string_iniciais_docente:^5}|{string_iniciais_autor:^5}|{similaridade_iniciais:^15}|{similaridade_jaccard:^10}')\n",
    "                                    achados_docentes.append(docente)\n",
    "                                    lista_indice_docente.append(n)\n",
    "                                    # print(len(lista_indice_docente))\n",
    "                                    extrato = df_prod['Qualis'][n]\n",
    "                                    lista_qualis_docente.append(extrato)\n",
    "                                    clear_output(wait=True)                                    \n",
    "                    except Exception as e1:\n",
    "                        # print(f'Erro na etapa 1 de gerar_dicionarios, ao tratar iniciais do nome de autor/docente da linha  {n}/{o}/{qte_docentes}/{qte_artigos}')\n",
    "                        # print(e1)\n",
    "                        similaridade_iniciais = np.NaN\n",
    "                        similaridade_jaccard  = np.NaN\n",
    "                        erros.append(('e1_similaridadesdocente',m,n,o,e1))                    \n",
    "                lst_autores_artigo.append(iniciais_nome_autor)\n",
    "            # print(f'Lista organizada de nomes de autores: {len(lst_autores_artigo)} listas de autores de artigos publicados no período')\n",
    "\n",
    "            ## Ao final da leitura todos artigos para cada docente, criar o dicionário de docentes quando docente tenha aparecido na linha de autores\n",
    "            if lista_indice_docente != []:\n",
    "                dic_nomes_docentes[m] = (docente, lista_indice_docente, lista_qualis_docente)\n",
    "            else:\n",
    "                docentes_naoencontrados.append(docente)\n",
    "\n",
    "            tdec=time.time()-t1\n",
    "            # tres=tdec/(m+1)*((qte_docentes-m)+qte_discentes)\n",
    "            # print(f'Analisadas{m+1:4}/{total_iteracoes} iterações em {horas(tdec)}, restando {total_iteracoes-m}. Busca{m+1:4}/{qte_docentes:<4}docente: {docente.title():50}')\n",
    "            # print(f'Nome do docente foi encontrado em {len(lista_indice_docente):2} artigos')\n",
    "        except Exception as e2:\n",
    "            # print(f'Erro na etapa 2 de gerar_dicionarios, ao calcular similaridades de autor/docente  da linha {n}/{o}/{qte_docentes}/{qte_artigos}')\n",
    "            # print(e2)\n",
    "            erros.append(('e2_padronizardocentes',m,n,o,e2)) \n",
    "\n",
    "    ## Função para calcular similaridade dos nomes de discentes com cada nome de autor da lista de autores de cada artigo\n",
    "    for p,discente in enumerate(lista_discentes):\n",
    "        achados_discentes     = []\n",
    "        lista_indice_discente = []\n",
    "        lista_qualis_discente = []\n",
    "        discentes_naoencontrados = []\n",
    "        contagem=m+p+1\n",
    "        # clear_output(wait=True)       \n",
    "        try:\n",
    "            nome_discente_padronizado = padronizar_nome(discente).lower()\n",
    "            iniciais_nome_discente    = iniciais_nome(discente).lower()\n",
    "            string_iniciais_discente  = ' '.join(x.strip() for x in iniciais_nome_discente.split(',')[1:])\n",
    "            set_iniciais_discente     = converter_lista_set([x.strip() for x in iniciais_nome_discente.split(',')[1:]])\n",
    "            rot2='Sobren/Iniciais disce'\n",
    "            rot4='I.Dis'            \n",
    "            ## Monta a lista de autores com a divisão da string organizada padronizada no formato: {sobrenome, iniciais de nomes}\n",
    "            lst_autores_artigo = []\n",
    "            lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "            for n,nomes_autor in enumerate(lista_nomes_autores):\n",
    "                # clear_output(wait=True)\n",
    "                # print(f'Procurando {nome_discente_padronizado.title()} em {n+1:2}/{qte_artigos:<2} artigos, restando {qte_artigos-n-1:<2}')\n",
    "                autores,erros = organizar_nomes(nomes_autor)\n",
    "                for q,autor in enumerate(autores):\n",
    "                    qte_autores_artigo = len(autores)\n",
    "                    nome_autor_padronizado = padronizar_nome(autor).lower()\n",
    "                    # print(f'{q+1:2}/{qte_autores_artigo:2} nomes de autor do artigo em análise, restando {qte_autores_artigo-q-1:2}')\n",
    "                    nome_autor_padronizado = padronizar_nome(autor).lower()\n",
    "                    try:    \n",
    "                        iniciais_nome_autor    = iniciais_nome(autor).lower()\n",
    "                        string_iniciais_autor  = ' '.join(x.strip() for x in iniciais_nome_autor.split(',')[1:])\n",
    "                        set_iniciais_autor     = converter_lista_set([x.strip() for x in iniciais_nome_autor.split(',')[1:]])   \n",
    "                        ## Cálculos de similaridades entre os nomes do autor e do discente\n",
    "                        if iniciais_nome_discente and iniciais_nome_autor != '':\n",
    "                            similaridade_nome     = get_jaro_distance(iniciais_nome_discente, iniciais_nome_autor)\n",
    "                            similaridade_iniciais = get_jaro_distance(string_iniciais_discente, string_iniciais_autor)\n",
    "                            similaridade_jaccard  = np.round(jaccard_similarity(set_iniciais_discente, set_iniciais_autor),2)\n",
    "                            print(f'{padronizar_nome(discente):^40} | {iniciais_nome_discente:<20}|{iniciais_nome_autor:<20} {similaridade_nome:^5}|{string_iniciais_docente:^5}|{string_iniciais_autor:^5}|{similaridade_iniciais:^15}|{similaridade_jaccard:^10}')                            \n",
    "                            if similaridade_nome > limite_jaro_nome and similaridade_iniciais > limite_jaro_iniciais and similaridade_jaccard > limite_jaccard_iniciais:\n",
    "                                if n not in lista_indice_discente:\n",
    "                                    print(f'Similaridade encontrada no artigo {n+1}/{qte_artigos}, discente {p+1}/{qte_discentes}')\n",
    "                                    print(f'{rot1:^40} |{rot2:^20}| {rot3:^25}|{rot4:^5}|{rot5:^5}|{rot6:^15}|{rot7:^10}')\n",
    "                                    print(f'{padronizar_nome(discente):^40} | {iniciais_nome_discente:<20}|{iniciais_nome_autor:<20} {similaridade_nome:^5}|{string_iniciais_discente:^5}|{string_iniciais_autor:^5}|{similaridade_iniciais:^15}|{similaridade_jaccard:^10}')\n",
    "                                    achados_discentes.append(discente)\n",
    "                                    lista_indice_discente.append(n)\n",
    "                                    # print(len(lista_indice_discente))\n",
    "                                    extrato = df_prod['Qualis'][n]\n",
    "                                    lista_qualis_discente.append(extrato)\n",
    "                                    clear_output(wait=True)\n",
    "                    except Exception as e3:\n",
    "                        similaridade_iniciais = np.NaN\n",
    "                        similaridade_jaccard  = np.NaN\n",
    "                        # print(f'Erro na etapa 3 de gerar_dicionarios, ao calcular similaridades de nomes de autor/discente da linha {n}/{o}/{qte_discentes}/{qte_artigos}')\n",
    "                        # print(e3)\n",
    "                        erros.append(('e3_buscadiscentes',p,n,q,e3))\n",
    "        \n",
    "            ## Ao final da leitura todos artigos para cada discente, criar o dicionário de discente quando docente tenha aparecido na linha de autores\n",
    "            if lista_indice_discente != []:\n",
    "                dic_nomes_discentes[o] = (discente, lista_indice_discente, lista_qualis_discente)\n",
    "            else:\n",
    "                discentes_naoencontrados.append(discente)            \n",
    "            \n",
    "            tdec=time.time()-t1\n",
    "            # tres=tdec/(o+p+1)*((qte_discentes-p)+qte_discentes)\n",
    "            # print(f'Analisadas{contagem+1:4}/{total_iteracoes} iterações em {horas(tdec)}, restando {horas(tres)} para iterar {total_iteracoes-contagem-1}. Busca{p+1:4}/{qte_discentes:<4}discente: {discente.title():50}')\n",
    "            # print(f'Nome do discente foi encontrado em {len(lista_indice_discente):2} artigos')   \n",
    "        except Exception as e4:\n",
    "            # print('Erro na etapa 4 de gerar_dicionarios, ao finalizar montagem dos dicionários:',e4)\n",
    "            erros.append(('e4_padronizardiscente',m,n,e4))\n",
    "\n",
    "    return dic_nomes_docentes, dic_nomes_discentes, docentes_naoencontrados, discentes_naoencontrados, erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770168bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_nomes_docentes, dic_nomes_discentes, docentes_naoencontrados, discentes_naoencontrados, erros = gerar_dicionarios(df_prod, lista_docentes, lista_discentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_nomes_docentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docentes_naoencontrados),'total de nomes de  docentes não encontrados nos artigos')\n",
    "print(len(discentes_naoencontrados),'total de nomes de discentes não encontrados nos artigos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afedd039",
   "metadata": {},
   "outputs": [],
   "source": [
    "discentes_naoencontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(erros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac927dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "erros[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdffe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista_artigos_problemas = []\n",
    "# lista_autores_problemas = []\n",
    "# for etapa,docente,i,discente,artigo in erros:\n",
    "#     if i not in lista_artigos_problemas:\n",
    "#         lista_artigos_problemas.append(i)\n",
    "#         lista_autores_problemas.append(df_prod['AUTORES'][i])\n",
    "\n",
    "# df_artigos_problemas=pd.DataFrame(lista_artigos_problemas).reset_index(drop=True)\n",
    "# df_artigos_problemas['LISTA_AUTORES'] = lista_autores_problemas\n",
    "# df_artigos_problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d13905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Lista ordenada alfabeticamente pelos sobrenomes de docentes\n",
    "# lista_docentes_sobrenome=[]\n",
    "# for i in lista_docentes:\n",
    "#     lista_docentes_sobrenome.append(iniciais_nome(i))\n",
    "    \n",
    "# lista_docentes_sobrenome.sort()\n",
    "# for j in lista_docentes_sobrenome:\n",
    "#     print(f'{j.lower()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a71542",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2017\n",
    "final  = 2022\n",
    "df_impacto_docente, df_impacto_discente = montardf_impacto_docente_discente(df_prod, dic_nomes_docentes, dic_nomes_discentes, inicio, final)\n",
    "df_impacto_docente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d83d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docentes = montardf_docentes(lista_nomes_docentes_permanentes, lista_nomes_docentes_colaboradores)\n",
    "df_docentes_pcd_impacto, apuracao_pcd, df_abaixo_pcd, df_atingiram_pcd, indicador_pcd, indicador_impacto = apurar_pcd_impacto(df_docentes, df_impacto_docente, df_impacto_discente, meta_pcd=50.0, meta_impacto=150.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36af03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotar_pcd(df_docentes_pcd_impacto)\n",
    "plotar_medias_impacto(df_docentes_pcd_impacto, grupo=False, inicio=False, final=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd992d",
   "metadata": {},
   "source": [
    "### Funções avaliação PCD e Impacto Médio Anual: \n",
    "    Avaliar indicadores PCD e Somatório do Fator de Impacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes):\n",
    "    ## Ler arquivos de dados\n",
    "    lista_csv   = ler_csvptg(inicio, final, tipo, grupo)\n",
    "    df_public   = montardf_producao(lista_csv)\n",
    "    df_docentes = montardf_docentes(lista_nomes_docentes)\n",
    "    lista_autores_artigos, lista_docentes, lista_orientadores, lista_discentes = montar_listas(lista_csv, lista_nomes_docentes)\n",
    "\n",
    "    ## Avaliação da Publicação Conjunta com Discentes (PCD) e do Impacto Médio Anual (IMA)\n",
    "    dic_nomes_docentes, dic_nomes_discentes, docentes_naoencontrados, discentes_naoencontrados, erros = gerar_dicionarios(df_public, lista_docentes, lista_discentes, inicio, final)\n",
    "    df_impacto_docente, df_impacto_discente = montardf_impacto_docente_discente(df_public, dic_nomes_docentes, dic_nomes_discentes, inicio, final)\n",
    "\n",
    "    ## Gerar gráfico de apuração de impacto médio anual por docente\n",
    "    df_docentes_pcd_impacto, apuracao_pcd, df_abaixo_pcd, df_atingiram_pcd, indicador_pcd, indicador_impacto = apurar_pcd_impacto(df_docentes, df_impacto_docente, df_impacto_discente)\n",
    "    plotar_pcd(df_docentes_pcd_impacto, grupo, inicio, final)\n",
    "    plotar_medias_impacto(df_docentes_pcd_impacto, grupo, inicio, final)\n",
    "\n",
    "    return df_public, df_impacto_docente, df_impacto_discente, df_docentes_pcd_impacto, indicador_pcd, indicador_impacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85feab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f486c9c2",
   "metadata": {},
   "source": [
    "### Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,b='',''\n",
    "# get_jaro_distance(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbcfc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b='1','0'\n",
    "get_jaro_distance(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4fb0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "print(len(lista_nomes_autores))\n",
    "print(lista_nomes_autores[0])\n",
    "\n",
    "## Verifica se a divisão em nomes de autor é par (sobrenome separado de nomes por vírgula)\n",
    "for i in lista_nomes_autores[:14]:\n",
    "    qte_nomes_autor = len(i.split(','))\n",
    "    if qte_nomes_autor/2 != qte_nomes_autor//2:\n",
    "        print(qte_nomes_autor,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ed58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m,docente in enumerate(lista_docentes):\n",
    "    nome_docente_padronizado = padronizar_nome(docente).lower()\n",
    "    iniciais_nome_docente    = iniciais_nome(docente).lower()\n",
    "    print(iniciais_nome_docente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4278bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ## Monta a lista de autores com a divisão da string de nomes acima por: sobrenome, nomes\n",
    "    # lst_autores_artigo = []\n",
    "    # lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "    # for n,nomes_autor in enumerate(lista_nomes_autores):\n",
    "    #     autores,erros = organizar_nomes(nomes_autor)\n",
    "    #     # print(autores,'\\n')\n",
    "    #     for o,autor in enumerate(autores):\n",
    "    #         # print(autor)\n",
    "    #         # print(f'{o+1:2}/{qte_autores_artigo:2} nomes de autor do artigo em análise, restando {qte_autores_artigo-o-1:2}')\n",
    "    #         sobrenome_iniciais_autor = iniciais_nome(autor).lower()\n",
    "    #         string_iniciais_autor    = ' '.join(x.strip() for x in sobrenome_iniciais_autor.split(',')[1:])\n",
    "    #         set_iniciais_autor       = converter_lista_set([x.strip() for x in sobrenome_iniciais_autor.split(',')[1:]])\n",
    "    #         print(f'{sobrenome_iniciais_autor:20}|{string_iniciais_autor:^9}|{set_iniciais_autor}')\n",
    "    #     lst_autores_artigo.append(sobrenome_iniciais_autor)\n",
    "    # print(f'Lista organizada de nomes de autores: {len(lst_autores_artigo)} listas de autores de artigos publicados no período')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qte_docentes     = len(lista_docentes)\n",
    "qte_discentes    = len(lista_discentes)\n",
    "total_iteracoes  = (qte_docentes+qte_discentes)\n",
    "\n",
    "## Monta uma lista de strings com nomes dos autores de cada artigo\n",
    "lista_nomes_autores = [limpar_nomes(x) for x in df_prod['AUTORES'].values]\n",
    "qte_artigos         = len(lista_nomes_autores)\n",
    "\n",
    "## Monta a lista de autores com a divisão da string de nomes acima por: sobrenome, nomes\n",
    "lst_autores_artigo = []\n",
    "for cada_lista_autores in lista_nomes_autores:\n",
    "    lista_organizada, erros_organizar = organizar_nomes(cada_lista_autores)\n",
    "    lst_autores_artigo.append(lista_organizada)\n",
    "print(f'{len(lst_autores_artigo)} listas de autores de {qte_artigos} artigos publicados no período')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes_autores[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_autores_artigo[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e752b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a='a b c de oliveira'\n",
    "padronizar_nome(a)\n",
    "iniciais_nome(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078c009e",
   "metadata": {},
   "source": [
    "## Apuração segmentada por períodos e grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ff296",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolucao_pcd=[]\n",
    "evolucao_impacto=[]\n",
    "tipo_analise=[]\n",
    "grupo_analise=[]\n",
    "periodo_analise=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d437b0",
   "metadata": {},
   "source": [
    "## Quadriênio 2017-2020 de Docentes Permanentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes_docentes_permanentes   = 'lista_docentes_permanentes.csv'\n",
    "lista_nomes_docentes_colaboradores = 'lista_docentes_colaboradores.csv'\n",
    "df_docentes = montardf_docentes(lista_nomes_docentes_permanentes, lista_nomes_docentes_colaboradores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621055ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2017\n",
    "final  = 2020\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'permanentes'\n",
    "lista_nomes_docentes = 'lista_docentes_permanentes.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)\n",
    "evolucao_pcd.append(indicador_pcd)\n",
    "evolucao_impacto.append(indicador_impacto)\n",
    "tipo_analise.append(tipo)\n",
    "grupo_analise.append(grupo)\n",
    "periodo_analise.append([inicio,final])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc16d3f",
   "metadata": {},
   "source": [
    "## .\n",
    "## Quadriênio 2017-2020 de Docentes Colaboradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb5d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2017\n",
    "final  = 2020\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'colaboradores'\n",
    "lista_nomes_docentes = 'lista_docentes_colaboradores.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)\n",
    "evolucao_pcd.append(indicador_pcd)\n",
    "evolucao_impacto.append(indicador_impacto)\n",
    "tipo_analise.append(tipo)\n",
    "grupo_analise.append(grupo)\n",
    "periodo_analise.append([inicio,final])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f22aa",
   "metadata": {},
   "source": [
    "## Avaliação de meio termo biênio [2021-2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd6823",
   "metadata": {},
   "source": [
    "## Biênio 2021-2022 de Docentes Permanentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2021\n",
    "final  = 2022\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'permanentes'\n",
    "lista_nomes_docentes = 'lista_docentes_permanentes.csv'\n",
    "# lista_nomes_docentes = 'lista_docentes_colaboradores.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)\n",
    "evolucao_pcd.append(indicador_pcd)\n",
    "evolucao_impacto.append(indicador_impacto)\n",
    "tipo_analise.append(tipo)\n",
    "grupo_analise.append(grupo)\n",
    "periodo_analise.append([inicio,final])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f19cf",
   "metadata": {},
   "source": [
    "## Biênio 2021-2022 de Docentes Colaboradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2021\n",
    "final  = 2022\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'colaboradores'\n",
    "# lista_nomes_docentes = 'lista_docentes_permanentes.csv'\n",
    "lista_nomes_docentes = 'lista_docentes_colaboradores.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)\n",
    "evolucao_pcd.append(indicador_pcd)\n",
    "evolucao_impacto.append(indicador_impacto)\n",
    "tipo_analise.append(tipo)\n",
    "grupo_analise.append(grupo)\n",
    "periodo_analise.append([inicio,final])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c6a47c",
   "metadata": {},
   "source": [
    "## Evolução de indicadores de gestão do programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31656a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicadores = pd.DataFrame({\n",
    "    'TIPO': pd.Series(tipo_analise),\n",
    "    'GRUPO': pd.Series(grupo_analise),\n",
    "    'PERIODOS': pd.Series(periodo_analise),\n",
    "    'META_PCD_50%': pd.Series(evolucao_pcd),\n",
    "    'META_IMPACTO_150ANO': pd.Series(evolucao_impacto),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a687f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicadores.sort_values(by=['GRUPO'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7fd64a",
   "metadata": {},
   "source": [
    "## Conferência em detalhes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = 2021\n",
    "final  = 2022\n",
    "tipo   = 'artigos'\n",
    "grupo  = 'permanentes'\n",
    "lista_nomes_docentes = 'lista_docentes_permanentes.csv'\n",
    "# lista_nomes_docentes = 'lista_docentes_colaboradores.csv'\n",
    "\n",
    "df_public, df_impacto_docente, df_impacto_discente, df_docentespcd, indicador_pcd, indicador_impacto = avaliar_completo(inicio, final, tipo, grupo, lista_nomes_docentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f942da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_impacto_docente[:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ccbd6a",
   "metadata": {},
   "source": [
    "## Conferência dos achados de nomes de discentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_partes_achadas(lista_discentes, lista_autores, verbose=False):\n",
    "    partes_achadas=[]\n",
    "    discentes_achados=[]\n",
    "    erros=[]\n",
    "    if verbose == True:\n",
    "        print(f'{padronizar_titulo(lista_autores).lower()}')\n",
    "    try:\n",
    "        ## Buscar pelas partes de nomes de autor em cada linha de autores de artigo\n",
    "        for nome in lista_discentes:\n",
    "            sobrenome, partenome1, partenome2, partenome3 = quebrar_partesnomes(nome)\n",
    "            if verbose == True:\n",
    "                print(f'{sobrenome}, {partenome1} {partenome2} {partenome3}')\n",
    "            strbusca_partes = compilar_partes(sobrenome, partenome1, partenome2, partenome3)\n",
    "            try:\n",
    "                achados_partes = re.search(strbusca_partes, padronizar_titulo(lista_autores).lower())\n",
    "                if achados_partes.span() !=None:\n",
    "                    partes_achadas.append(achados_partes.groups())\n",
    "                    discentes_achados.append(nome)\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                pass\n",
    "\n",
    "        ## Buscar pelas iniciais de partes de nomes de autor, que seguem um sobrenome em cada linha de autores de artigo\n",
    "        for nome in lista_discentes:\n",
    "            sobrenome, inicial1, inicial2, inicial3 = quebrar_iniciais(nome)\n",
    "            if verbose == True:\n",
    "                print(f'{sobrenome}, {inicial1} {inicial2} {inicial3}')\n",
    "            strbusca_iniciais = compilar_iniciais(sobrenome, inicial1, inicial2, inicial3)\n",
    "            try:\n",
    "                achados_iniciais = re.search(strbusca_iniciais, padronizar_titulo(lista_autores).lower())\n",
    "                if achados_iniciais.span() !=None and achados_iniciais.groups() not in discentes_achados:\n",
    "                    partes_achadas.append(achados_iniciais.groups())\n",
    "                    discentes_achados.append(nome)\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                pass\n",
    "    except Exception as e:\n",
    "        # print(f'Erro ao buscar partes de nome; {e}')\n",
    "        print(e)\n",
    "    \n",
    "    return partes_achadas, discentes_achados\n",
    "\n",
    "def listar_achados(docente):\n",
    "    lista_csv = ler_artigostodosperiodos()\n",
    "    lista_autores_artigos, lista_docentes, lista_orientadores, lista_discentes = montar_listas(lista_csv)\n",
    "\n",
    "    df_filtrado = df_impacto_docente[(df_impacto_docente.DOCENTE==docente)]\n",
    "\n",
    "    lista_indices = df_filtrado['INDICES_ARTIGOS'].values.tolist()[0]\n",
    "    n=100\n",
    "    print('-'*n)\n",
    "    print(f'\\nDocente: {docente} | {len(lista_indices)} Publicações identificadas para no período [{inicio} a {final}]')\n",
    "    print()\n",
    "    for indice in lista_indices:\n",
    "        print('-'*n)\n",
    "        print(f'Índice da publicação: {indice}')\n",
    "        print(df_public.iloc[indice].values[:3])\n",
    "        lista_autores = padronizar_titulo(df_public.iloc[indice].values[4])\n",
    "        partes_achadas, discentes_achados = mostrar_partes_achadas(lista_discentes, lista_autores, verbose=False)\n",
    "        print()\n",
    "        print(lista_autores)\n",
    "        print('\\nPartes de nomes de alunos encontrados na lista de autores:')\n",
    "        print(partes_achadas)\n",
    "        print('\\nNomes de alunos considerados como encontrados na lista de autores:')\n",
    "        print(discentes_achados)\n",
    "\n",
    "def separar_iniciais(nome):\n",
    "    import re\n",
    "    letras_duasconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2}$')            # Duas Letras consoantes maiúsculas juntas do início ao final da string\n",
    "    letras_tresconsnts = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3}$')            # Três Letras consoantes maiúsculas juntas do início ao final da string\n",
    "    letras_duasconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{2},$')       # Duas Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "    letras_tresconsntsvirg = re.compile(r'^[B-DF-HJ-NP-TV-XZ-r]{3},$')       # Três Letras consoantes maiúsculas juntas do início ao final da string, seguidas de vírgula\n",
    "    partes_nome=[]\n",
    "    for j in nome.split(' '):\n",
    "        div_ltrduasconsnts = letras_duasconsnts.findall(j)\n",
    "        div_ltrtriplicadas = letras_tresconsnts.findall(j)\n",
    "        div_ltrduasconsntsvirg = letras_duasconsntsvirg.findall(j)\n",
    "        div_ltrtresconsntsvirg = letras_tresconsntsvirg.findall(j)\n",
    "        if div_ltrduasconsnts or div_ltrtriplicadas:\n",
    "            iniciais_separadas = ' '.join(x for x in j)\n",
    "            partes_nome.append(iniciais_separadas)\n",
    "        elif div_ltrduasconsntsvirg or div_ltrtresconsntsvirg:\n",
    "            iniciais_separadas = ' '.join(x for x in j[:-1])\n",
    "            partes_nome.append(iniciais_separadas+',')\n",
    "        else:\n",
    "            partes_nome.append(j)\n",
    "    nome_separado = ' '.join(x for x in partes_nome).strip()\n",
    "    return nome_separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1021acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "docente = 'Olindo Assis Martins Filho'\n",
    "listar_achados(docente)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee2749",
   "metadata": {},
   "source": [
    "## Outras funcionalidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374848af",
   "metadata": {},
   "source": [
    "    Formatar tempo (h:min:seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72114631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tempo(start, end):\n",
    "    t=end-start\n",
    "\n",
    "    tempo = timedelta(\n",
    "        weeks   = t//(3600*24*7),\n",
    "        days    = t//(3600*24),\n",
    "        seconds = t,\n",
    "        minutes = t//(60),\n",
    "        hours   = t//(3600),\n",
    "        microseconds=t//1000000,\n",
    "        )\n",
    "    fmt='{H:2}:{M:02}:{S:02}'\n",
    "    return strfdelta(tempo)\n",
    "\n",
    "\n",
    "def horas(segundos): \n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(segundos)) \n",
    "\n",
    "\n",
    "def dias_horas_minutos(td):\n",
    "    x = (td.days, td.seconds//3600, (td.seconds//60)%60, td.seconds)\n",
    "    return x #(days, hrs, mins, seconds)\n",
    "\n",
    "\n",
    "def strfdelta(tdelta, fmt='{H:02}h {M:02}m {S:02}s', inputtype='timedelta'):\n",
    "    \"\"\"Convert a datetime.timedelta object or a regular number to a custom-formatted string, \n",
    "    just like the stftime() method does for datetime.datetime objects.\n",
    "\n",
    "    The fmt argument allows custom formatting to be specified.  Fields can \n",
    "    include seconds, minutes, hours, days, and weeks.  Each field is optional.\n",
    "\n",
    "    Some examples:\n",
    "        '{D:02}d {H:02}h {M:02}m {S:02}s' --> '05d 08h 04m 02s' (default)\n",
    "        '{W}w {D}d {H}:{M:02}:{S:02}'     --> '4w 5d 8:04:02'\n",
    "        '{D:2}d {H:2}:{M:02}:{S:02}'      --> ' 5d  8:04:02'\n",
    "        '{H}h {S}s'                       --> '72h 800s'\n",
    "\n",
    "    The inputtype argument allows tdelta to be a regular number instead of the  \n",
    "    default, which is a datetime.timedelta object.  Valid inputtype strings: \n",
    "        's', 'seconds', \n",
    "        'm', 'minutes', \n",
    "        'h', 'hours', \n",
    "        'd', 'days', \n",
    "        'w', 'weeks'\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert tdelta to integer seconds.\n",
    "    if inputtype == 'timedelta':\n",
    "        remainder = int(tdelta.total_seconds())\n",
    "    elif inputtype in ['s', 'seconds']:\n",
    "        remainder = int(tdelta)\n",
    "    elif inputtype in ['m', 'minutes']:\n",
    "        remainder = int(tdelta)*60\n",
    "    elif inputtype in ['h', 'hours']:\n",
    "        remainder = int(tdelta)*3600\n",
    "    elif inputtype in ['d', 'days']:\n",
    "        remainder = int(tdelta)*86400\n",
    "    elif inputtype in ['w', 'weeks']:\n",
    "        remainder = int(tdelta)*604800\n",
    "\n",
    "    f = Formatter()\n",
    "    desired_fields = [field_tuple[1] for field_tuple in f.parse(fmt)]\n",
    "    possible_fields = ('W', 'D', 'H', 'M', 'S')\n",
    "    constants = {'W': 604800, 'D': 86400, 'H': 3600, 'M': 60, 'S': 1}\n",
    "    values = {}\n",
    "    \n",
    "    for field in possible_fields:\n",
    "        if field in desired_fields and field in constants:\n",
    "            values[field], remainder = divmod(remainder, constants[field])\n",
    "    \n",
    "    return f.format(fmt, **values)\n",
    "\n",
    "\n",
    "# print (timedelta(days=365, hours=8, minutes=15))\n",
    "# print (\"   Hoje é: \" + str(date.today()))\n",
    "# print (\"Agora são: \" + str(datetime.now()))\n",
    "# print (\"Um ano no futuro estaremos em:\" + str(dt.today() + timedelta(days=365)))\n",
    "# hoje = date.today()\n",
    "# print(hoje)\n",
    "# hora = dt.now()\n",
    "# print(hora)\n",
    "# dias_ano = date(hoje.year, 1, 1)\n",
    "# if dias_ano < hoje:\n",
    "#     print (\"Decoridos %d dias do ano\" % ((hoje - dias_ano).days))\n",
    "    \n",
    "# from datetime import datetime\n",
    "# now= datetime.now() #get the current date and time\n",
    "\n",
    "# #%c - local date and time, %x-local's date, %X- local's time\n",
    "# print(now.strftime(\"%c\"))\n",
    "# print(now.strftime(\"%x\"))\n",
    "# print(now.strftime(\"%X\"))\n",
    "\n",
    "# ##### Time Formatting ####\n",
    "# #%I/%H - 12/24 Hour, %M - minute, %S - second, %p - local's AM/PM\n",
    "# print(now.strftime(\"%I:%M:%S %p\")) # 12-Hour:Minute:Second:AM\n",
    "# print(now.strftime(\"%H:%M\")) # 24-Hour:Minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# from neo4j import GraphDatabase\n",
    "# from neo4j.exceptions import Neo4jError\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s', filename='logs/persister.log')\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# class Neo4jPersister:\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._uri = uri\n",
    "#         self._user = user\n",
    "#         self._password = password\n",
    "#         self._driver = GraphDatabase.driver(self._uri, auth=(self._user, self._password))\n",
    "#         self.logger = logger\n",
    "\n",
    "#         # Devem ser persistidos como \n",
    "#         self.tipos = [\n",
    "#             'Identificação',\n",
    "#             'Idiomas',\n",
    "#             'Formação',\n",
    "#             'Atuação Profissional',\n",
    "#             'Linhas de Pesquisa',\n",
    "#             'Áreas',\n",
    "#             'Produções',\n",
    "#             'ProjetosPesquisa',\n",
    "#             'ProjetosExtensão',\n",
    "#             'ProjetosDesenvolvimento',\n",
    "#             'ProjetosOutros',\n",
    "#             'Bancas',\n",
    "#             'Orientações',\n",
    "#             ]\n",
    "\n",
    "#         self.subtipos= [\n",
    "#             'Acadêmica',\n",
    "#             'Pos-Doc',\n",
    "#             'Complementar',\n",
    "#             'Artigos completos publicados em periódicos',\n",
    "#             'Resumos publicados em anais de congressos',\n",
    "#             'Apresentações de Trabalho',\n",
    "#             'Outras produções bibliográficas',\n",
    "#             'Entrevistas, mesas redondas, programas e comentários na mídia',\n",
    "#             'Concurso público',\n",
    "#             'Outras participações',\n",
    "#             'Livros publicados/organizados ou edições',\n",
    "#             'Capítulos de livros publicados',\n",
    "#             'Resumos expandidos publicados em anais de congressos',\n",
    "#             'Resumos publicados em anais de congressos (artigos)',\n",
    "#             'Trabalhos técnicos',\n",
    "#             'Demais trabalhos',\n",
    "#             'Mestrado',\n",
    "#             'Teses de doutorado',\n",
    "#             'Qualificações de Doutorado',\n",
    "#             'Qualificações de Mestrado',\n",
    "#             'Monografias de cursos de aperfeiçoamento/especialização',\n",
    "#             'Trabalhos de conclusão de curso de graduação',\n",
    "#             'Orientações e supervisões concluídas',\n",
    "#             'Citações',\n",
    "#             'Trabalhos completos publicados em anais de congressos',\n",
    "#             'Produtos tecnológicos',\n",
    "#             'Artigos  aceitos para publicação',\n",
    "#             'Assessoria e consultoria',\n",
    "#             'Programas de computador sem registro',\n",
    "#             'Professor titular',\n",
    "#             'Avaliação de cursos',\n",
    "#             'Orientações e supervisões em andamento',\n",
    "#             'Processos ou técnicas',\n",
    "#             'Outras produções artísticas/culturais',\n",
    "#             'Textos em jornais de notícias/revistas',\n",
    "#             'Redes sociais, websites e blogs',\n",
    "#             'Artes Visuais'            \n",
    "#             ]\n",
    "\n",
    "#         self.propriedades = [\n",
    "#             'Nome',\n",
    "#             'ID Lattes',\n",
    "#             'Última atualização',\n",
    "#             ]\n",
    "       \n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "    \n",
    "#     def persistir_revistas_da_planilha(self):\n",
    "#         \"\"\"\n",
    "#         Persiste dados de revistas a partir da planilha 'classificações_publicadas_todas_as_areas_avaliacao1672761192111.xlsx' no Neo4j.\n",
    "\n",
    "#         Args:\n",
    "#             session: Objeto de sessão do Neo4j.\n",
    "#         \"\"\"\n",
    "#         # Leitura da planilha\n",
    "#         dados_qualis = pd.read_excel(os.path.join(LattesScraper.find_repo_root(),'_data','in_xls','classificações_publicadas_todas_as_areas_avaliacao1672761192111.xlsx'))\n",
    "\n",
    "#         # Extração e persistência de dados de revista\n",
    "#         with self._driver.session() as session:\n",
    "#             for index, row in dados_qualis.iterrows():\n",
    "#                 issn = row['ISSN'].replace('-','')\n",
    "#                 nome_revista = row['Título']\n",
    "#                 area_avaliacao = row['Área de Avaliação']\n",
    "#                 estrato = row['Estrato']\n",
    "\n",
    "#                 # Verificação de existência da revista\n",
    "#                 revista_node = session.run(\"\"\"\n",
    "#                     MATCH (j:Revista {issn: $issn})\n",
    "#                     RETURN j\n",
    "#                 \"\"\", issn=issn).single()\n",
    "\n",
    "#                 if not revista_node:\n",
    "#                     # Criação da revista se não existir\n",
    "#                     session.run(\"\"\"\n",
    "#                         CREATE (j:Revista {issn: $issn, nome_revista: $nome_revista, area_avaliacao: $area_avaliacao, estrato: $estrato})\n",
    "#                     \"\"\", nome_revista=nome_revista, issn=issn, area_avaliacao=area_avaliacao,  estrato=estrato)\n",
    "\n",
    "#     # Testes Ok! \n",
    "#     def persist_pessoa_nodes(self, dict_list):\n",
    "#         query_pessoa = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         ON CREATE SET p.nome = $nome, p.ultima_atualizacao = $ultima_atualizacao\n",
    "#         ON MATCH SET p.nome = $nome, p.ultima_atualizacao = $ultima_atualizacao\n",
    "#         \"\"\"\n",
    "#         try:\n",
    "#             with self._driver.session() as session:\n",
    "#                 for item in dict_list:\n",
    "#                     identificacao = item.get('Identificação')\n",
    "#                     nome = identificacao.get('Nome')\n",
    "#                     id_lattes = identificacao.get('ID Lattes')\n",
    "#                     ultima_atualizacao = identificacao.get('Última atualização')\n",
    "#                     if nome:\n",
    "#                         session.run(query_pessoa, id_lattes=id_lattes, nome=nome, ultima_atualizacao=ultima_atualizacao)\n",
    "#         except Exception as e:\n",
    "#             self.logger.error('Erro ao criar node \"Pesquisador\": {}'.format(e))\n",
    "\n",
    "#     # Testes Ok!         \n",
    "#     def persist_pesquisador_grande_area_relationships(self, dict_list):\n",
    "#         query_rel_pessoa_grande_area = \"\"\"\n",
    "#         MATCH (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MATCH (ga:GrandeArea {nome: $grande_area_nome})\n",
    "#         MERGE (p)-[:ATUA_EM]->(ga)\n",
    "#         \"\"\"\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             for item in dict_list:\n",
    "#                 identificacao = item.get('Identificação')\n",
    "#                 id_lattes = identificacao.get('ID Lattes')\n",
    "#                 areas = item.get('Áreas').values()\n",
    "#                 for area_string in areas:\n",
    "#                     grande_area_nome, _, _ = self.extract_area_info(area_string)\n",
    "#                     if grande_area_nome:\n",
    "#                         session.run(query_rel_pessoa_grande_area, id_lattes=id_lattes, grande_area_nome=grande_area_nome)\n",
    "\n",
    "#     # Testes Ok! \n",
    "#     def persist_areas_nodes(self, dict_list):\n",
    "#         query_grande_area = \"\"\"\n",
    "#         MERGE (ga:GrandeArea {nome: $nome})\n",
    "#         \"\"\"\n",
    "#         query_area = \"\"\"\n",
    "#         MATCH (ga:GrandeArea {nome: $grande_area_nome})\n",
    "#         MERGE (a:Area {nome: $nome}) ON CREATE SET a:Area\n",
    "#         MERGE (ga)-[:CONTEM]->(a)\n",
    "#         \"\"\"\n",
    "#         query_subarea = \"\"\"\n",
    "#         MATCH (a:Area {nome: $area_nome})\n",
    "#         MERGE (sa:Subarea {nome: $nome}) ON CREATE SET sa:Subarea\n",
    "#         MERGE (a)-[:CONTEM]->(sa)\n",
    "#         \"\"\"\n",
    "#         query_rel_pessoa_grande_area = \"\"\"\n",
    "#         MATCH (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MATCH (ga:GrandeArea {nome: $grande_area_nome})\n",
    "#         MERGE (p)-[:ATUA_EM]->(ga)    \n",
    "#         \"\"\"\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             for item in dict_list:\n",
    "#                 areas = item.get('Áreas').values()\n",
    "#                 for area_string in areas:\n",
    "#                     grande_area_nome, area_nome, subarea_nome = self.extract_area_info(area_string)\n",
    "                    \n",
    "#                     # Verificar se o nome não está vazio\n",
    "#                     if grande_area_nome:\n",
    "#                         session.run(query_grande_area, nome=grande_area_nome)\n",
    "#                     if area_nome:\n",
    "#                         session.run(query_area, grande_area_nome=grande_area_nome, nome=area_nome)\n",
    "#                     if subarea_nome:\n",
    "#                         session.run(query_subarea, area_nome=area_nome, nome=subarea_nome)\n",
    "                    \n",
    "#                     # Adicionar relacionamento Pesquisador - GrandeÁrea\n",
    "#                     id_lattes = item['Identificação']['ID Lattes']\n",
    "#                     if grande_area_nome:\n",
    "#                         session.run(query_rel_pessoa_grande_area, id_lattes=id_lattes, grande_area_nome=grande_area_nome)\n",
    "\n",
    "#     # Testes Ok! \n",
    "#     @staticmethod\n",
    "#     def extract_area_info(area_string):\n",
    "#         # Extraindo os nomes de GrandeÁrea, Área e Subárea da string\n",
    "#         try:\n",
    "#             grande_area_nome = area_string.split('/')[0].strip().split(': ')[1]\n",
    "#         except:\n",
    "#             grande_area_nome = ''\n",
    "#         try:\n",
    "#             area_nome = area_string.split('/')[1].strip().split(': ')[1]\n",
    "#         except:\n",
    "#             area_nome = ''\n",
    "#         try:\n",
    "#             subarea_nome = area_string.split('/')[2].strip().split(': ')[1]\n",
    "#         except:\n",
    "#             subarea_nome = ''\n",
    "#         return grande_area_nome, area_nome, subarea_nome\n",
    "\n",
    "#     ## PRODUÇÕES\n",
    "#     def persist_producoes_pesquisador(self, dict_list):\n",
    "#         with self._driver.session() as session:\n",
    "#             for pesq in dict_list:\n",
    "#                 identificacao = pesq.get('Identificação')\n",
    "#                 id_lattes = identificacao.get('ID Lattes')\n",
    "#                 producoes = pesq.get('Produções')\n",
    "\n",
    "#                 if not isinstance(producoes, dict):\n",
    "#                     print(f\"Erro!! Dicionário da seção 'Produções' não encontrado para {id_lattes}\")\n",
    "#                     continue\n",
    "\n",
    "#                 for chave_producao, valores_producao in producoes.items():\n",
    "#                     print(f'{chave_producao} | {valores_producao}')\n",
    "#                     if chave_producao == 'Artigos completos publicados em periódicos':\n",
    "#                         # self.persistir_artigos_completos(session, id_lattes, valores_producao)\n",
    "#                         self.persistir_artigos_revistas(session, id_lattes, valores_producao)\n",
    "\n",
    "#     def _get_or_create_node(self, session, label, properties):\n",
    "#         properties = [x.rstrip('.') for x in properties]\n",
    "#         node = session.run(\"MATCH (n: {label}) WHERE {properties} RETURN n\", {\"label\": label, \"properties\": properties}).single()\n",
    "\n",
    "#         if not node:\n",
    "#             node = session.run(\"CREATE (n: {label} {properties}) RETURN n\", {\"label\": label, \"properties\": properties}).single()[\"n\"]\n",
    "#             self._node_created_count += 1\n",
    "\n",
    "#         return node\n",
    "\n",
    "#     def persist_tipo_producao(self, session, id_lattes, tipo_producao):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (t:TipoProducao {nome: $tipo_producao})\n",
    "#         MERGE (p)-[:PRODUZ]->(t)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, tipo_producao=tipo_producao)\n",
    "#         summary = result.consume()\n",
    "#         return summary.counters.nodes_created, summary.counters.nodes_deleted, summary.counters.relationships_created, summary.counters.relationships_deleted\n",
    "\n",
    "#     def persist_subtipo_producao(self, session, id_lattes, tipo_producao, subtipo_producao, dados_producao):\n",
    "#         def checar_e_serializar(dados):\n",
    "#             \"\"\" Verifica e serializa dicionários recursivamente \"\"\"\n",
    "#             if isinstance(dados, dict):\n",
    "#                 for chave, valor in dados.items():\n",
    "#                     if isinstance(valor, dict):\n",
    "#                         dados[chave] = json.dumps(valor)\n",
    "#                     # Checagem adicional para outros tipos inválidos, se necessário\n",
    "#             return dados\n",
    "#         # Serialização recursiva do dicionário\n",
    "#         dados_producao = checar_e_serializar(dados_producao)\n",
    "\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (t:TipoProducao {nome: $tipo_producao})\n",
    "#         MERGE (s:SubtipoProducao {nome: $subtipo_producao})\n",
    "#         MERGE (p)-[PRODUZ:]->(t)-[:DO_TIPO]->(s)\n",
    "#         \"\"\"\n",
    "\n",
    "#         if subtipo_producao in [\"ArtigoCompleto\", \"ResumoCongresso\", \"ApresentacaoTrabalho\", \"OutrasProducoesBibliograficas\"]:\n",
    "#             query_create_node += \"\"\"\n",
    "#             MERGE (o:Ocorrencia {tipo: $subtipo_producao, dados: $dados})\n",
    "#             MERGE (s)-[:OCORRENCIA]->(o)\n",
    "#             \"\"\"\n",
    "\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, tipo_producao=tipo_producao, \n",
    "#                             subtipo_producao=subtipo_producao, dados=dados_producao)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "\n",
    "#         return summary.counters.nodes_created, summary.counters.nodes_deleted, summary.counters.relationships_created, summary.counters.relationships_deleted\n",
    "\n",
    "#     def persistir_artigos_completos(self, session, id_lattes, dados):\n",
    "#         created_nodes = 0\n",
    "#         updated_nodes = 0\n",
    "#         created_relations = 0\n",
    "#         updated_relations = 0\n",
    "        \n",
    "#         for dados_artigo in dados:\n",
    "#             dados_artigo['dados'] = json.dumps(dados_artigo)  # Conversão para JSON da estrutura completa\n",
    "#             query_create_node_artigo = \"\"\"\n",
    "#                 MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#                 CREATE (a:ArtigoPublicado {\n",
    "#                     ano: $ano,\n",
    "#                     fator_impacto_jcr: $fator_impacto_jcr,\n",
    "#                     ISSN: $ISSN,\n",
    "#                     titulo: $titulo,\n",
    "#                     revista: $revista,\n",
    "#                     autores: $autores,\n",
    "#                     Qualis: $Qualis,\n",
    "#                     DOI: $DOI,\n",
    "#                     dados: $dados_artigo\n",
    "#                 })\n",
    "#                 CREATE (p)-[:PRODUZ]->(a)\n",
    "\n",
    "#                 MERGE (j:Revista {nome: $revista, issn: $ISSN})\n",
    "#                 CREATE (a)-[:PUBLICADO_EM]->(j)\n",
    "#             \"\"\"\n",
    "\n",
    "#             result_artigo = session.run(query_create_node_artigo, \n",
    "#                                 id_lattes=id_lattes, \n",
    "#                                 ano=dados_artigo['ano'],\n",
    "#                                 fator_impacto_jcr=dados_artigo['fator_impacto_jcr'],\n",
    "#                                 ISSN=dados_artigo['ISSN'],\n",
    "#                                 titulo=dados_artigo['titulo'],\n",
    "#                                 revista=dados_artigo['revista'],\n",
    "#                                 autores=dados_artigo['autores'],\n",
    "#                                 Qualis=dados_artigo['Qualis'],\n",
    "#                                 DOI=dados_artigo['DOI'],\n",
    "#                                 dados_artigo=dados_artigo\n",
    "#                                 )\n",
    "#             summary_artigo = result_artigo.consume()\n",
    "#             created_nodes += summary_artigo.counters.nodes_created\n",
    "#             updated_nodes += summary_artigo.counters.nodes_deleted\n",
    "#             created_relations += summary_artigo.counters.relationships_created\n",
    "#             updated_relations += summary_artigo.counters.relationships_deleted\n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "\n",
    "#     def persistir_artigos_completos(self, session, id_lattes, dados):\n",
    "#         created_nodes = 0\n",
    "#         updated_nodes = 0\n",
    "#         created_relations = 0\n",
    "#         updated_relations = 0\n",
    "                \n",
    "#         for dados_artigo in dados:\n",
    "#             ano = dados_artigo['ano']\n",
    "#             impact_jcr = dados_artigo['fator_impacto_jcr']\n",
    "#             issn = dados_artigo['ISSN']\n",
    "#             titulo = dados_artigo['titulo']\n",
    "#             revista = dados_artigo['revista']\n",
    "#             autores = dados_artigo['autores']\n",
    "#             qualis = dados_artigo['Qualis']\n",
    "#             doi = dados_artigo['DOI']\n",
    "\n",
    "#             query_create_node_artigo = \"\"\"\n",
    "#                 MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#                 CREATE (a:ArtigoPublicado {ano: $ano, impact_jcr: $impact_jcr, issn: $issn, titulo: $titulo, revista: $revista, autores: $autores, qualis: $qualis, doi: $doi})\n",
    "#                 CREATE (p)-[:PRODUZ]->(a)\n",
    "#                 MERGE (j:Revista {nome: $revista, issn: $issn})\n",
    "#                 CREATE (a)-[:PUBLICADO_EM]->(j)\n",
    "#             \"\"\"\n",
    "#             print(query_create_node_artigo)\n",
    "#             result_artigo = session.run(query_create_node_artigo, \n",
    "#                                 id_lattes=id_lattes, \n",
    "#                                 ano=ano,\n",
    "#                                 impact_jcr=impact_jcr,\n",
    "#                                 issn=issn,\n",
    "#                                 titulo=titulo,\n",
    "#                                 revista=revista,\n",
    "#                                 autores=autores,\n",
    "#                                 qualis=qualis,\n",
    "#                                 doi=doi,\n",
    "#                                 )\n",
    "#             summary_artigo = result_artigo.consume()\n",
    "#             created_nodes += summary_artigo.counters.nodes_created\n",
    "#             updated_nodes += summary_artigo.counters.nodes_deleted\n",
    "#             created_relations += summary_artigo.counters.relationships_created\n",
    "#             updated_relations += summary_artigo.counters.relationships_deleted\n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def buscar_revista_por_issn(self, session, issn):\n",
    "#         query = \"\"\"\n",
    "#             MATCH (revista:Revista {issn: $issn})\n",
    "#             RETURN revista\n",
    "#         \"\"\"\n",
    "\n",
    "#         try:\n",
    "#             result = session.run(query, issn=issn)\n",
    "#             return result.single()\n",
    "#         except Neo4jError as e:\n",
    "#             print(f\"Erro Neo4j ao buscar a revista por ISSN: {e}\")\n",
    "#             return None\n",
    "        \n",
    "#     def persistir_artigos_revistas(self, session, id_lattes, dados):\n",
    "#         \"\"\"\n",
    "#         Função para persistir os dados de artigos completos publicados em periódicos.\n",
    "\n",
    "#         Args:\n",
    "#             session (neo4j.Session): Sessão Neo4j.\n",
    "#             id_lattes (str): ID do Lattes do pesquisador.\n",
    "#             dados (dict): Dicionário contendo os dados dos artigos.\n",
    "\n",
    "#         Returns:\n",
    "#             None\n",
    "#         \"\"\"\n",
    "\n",
    "#         for artigo in dados:\n",
    "#             # Extraindo informações do artigo\n",
    "#             revista_nome  = ''\n",
    "#             created_nodes = ''\n",
    "#             ano = artigo['ano']\n",
    "#             impact_jcr = artigo['fator_impacto_jcr']\n",
    "#             issn = artigo['ISSN']\n",
    "#             titulo = artigo['titulo']\n",
    "#             revista = artigo['revista']\n",
    "#             autores = artigo['autores']\n",
    "#             data_issn = artigo['data_issn']\n",
    "#             doi = artigo['DOI']\n",
    "#             qualis = artigo['Qualis']\n",
    "\n",
    "#             query_create_node_artigo = \"\"\"\n",
    "#                 MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#                 CREATE (a:ArtigoPublicado {ano: $ano, impact_jcr: $impact_jcr, issn: $issn, titulo: $titulo, revista: $revista, autores: $autores, qualis: $qualis, doi: $doi})\n",
    "#                 CREATE (p)-[:PRODUZ]->(a)\n",
    "#                 MERGE (j:Revista {nome: $revista, issn: $issn})\n",
    "#                 CREATE (a)-[:PUBLICADO_EM]->(j)\n",
    "#             \"\"\"\n",
    "            \n",
    "#             # Buscando o nó da revista\n",
    "#             revista_node = self.buscar_revista_por_issn(session, issn)\n",
    "\n",
    "#             # Criando o nó do artigo\n",
    "#             with session.begin_transaction() as tx:\n",
    "#                 tx.run(query_create_node_artigo,\n",
    "#                     id_lattes=id_lattes,\n",
    "#                     ano=ano,\n",
    "#                     impact_jcr=impact_jcr,\n",
    "#                     issn=issn,\n",
    "#                     titulo=titulo,\n",
    "#                     revista=revista,\n",
    "#                     autores=autores,\n",
    "#                     data_issn=data_issn,\n",
    "#                     doi=doi,\n",
    "#                     qualis=qualis\n",
    "#                     )\n",
    "\n",
    "#                 # Criando o relacionamento PUBLICADO_EM\n",
    "#                 if revista_node is not None:\n",
    "#                     node_revista = revista_node[0][1]\n",
    "#                     if node_revista is not None:\n",
    "#                         revista_nome = node_revista['nome_revista']\n",
    "#                         revista_issn = node_revista['issn']\n",
    "#                         revista_area_avaliacao = node_revista['area_avaliacao']\n",
    "#                         revista_estrato = node_revista['estrato']\n",
    "\n",
    "#                     if revista_nome:\n",
    "#                         tx.run(\"\"\"\n",
    "#                             MATCH (a:ArtigoPublicado {doi: $doi}), (j:Revista {nome_revista: $revista_nome, issn: $revista_issn, area_avaliacao: $revista_area_avaliacao, estrato: $revista_estrato})\n",
    "#                             CREATE (a)-[:PUBLICADO_EM]->(j)\n",
    "#                         \"\"\", doi=doi, revista_nome=revista_nome, revista_issn=revista_issn, revista_area_avaliacao=revista_area_avaliacao, revista_estrato=revista_estrato)\n",
    "\n",
    "#                     else:\n",
    "#                         print(\"Erro: O nó da revista não foi encontrado para o ISSN\", issn)\n",
    "#                         # Lógica de tratamento de erro (opcional)\n",
    "#                 else:\n",
    "#                     print(\"Erro: O retorno para a revista com ISSN\", issn, \"é None.\")\n",
    "\n",
    "#                 tx.commit()\n",
    "\n",
    "#         # Atualização dos contadores\n",
    "#         with session.begin_transaction() as tx:\n",
    "#             created_nodes += tx.run(\"MATCH (n) WHERE n:ArtigoPublicado RETURN count(n)\").single()[0]\n",
    "#             updated_nodes += tx.run(\"MATCH (n) WHERE n:ArtigoPublicado SET n.updated_at = datetime() RETURN count(n)\").single()[0]\n",
    "#             created_relations += tx.run(\"MATCH (r) WHERE r:PUBLICADO_EM RETURN count(r)\").single()[0]\n",
    "\n",
    "#     def persistir_resumos_congressos(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (r:ResumoCongresso {titulo: $titulo, ano: $ano, evento: $evento, autores: $autores, data_issn: $data_issn, doi: $doi})\n",
    "#         MERGE (p)-[:PRODUZ]->(r)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, **dados)\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def persistir_apresentacoes_trabalho(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (a:ApresentacaoTrabalho {\n",
    "#             titulo: $titulo,\n",
    "#             ano: $ano,\n",
    "#             evento: $evento,\n",
    "#             autores: $autores\n",
    "#         })\n",
    "#         MERGE (p)-[:PRODUZ]->(a)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, **dados)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def persistir_outras_producoes_bibliograficas(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (o:OutrasProducoesBibliograficas {\n",
    "#             titulo: $titulo,\n",
    "#             ano: $ano,\n",
    "#             autores: $autores,\n",
    "#             doi: $doi\n",
    "#         })\n",
    "#         MERGE (p)-[:PRODUZ]->(o)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, **dados)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def persistir_orientacoes_concluidas(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (o:OrientacaoConcluida {\n",
    "#             tipo: $tipo,\n",
    "#             titulo: $titulo,\n",
    "#             ano: $ano,\n",
    "#             autor: $autor,\n",
    "#             instituicao: $instituicao\n",
    "#         })\n",
    "#         MERGE (p)-[:ORIENTA]->(o)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, **dados)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def persistir_participacoes_bancas(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (b:Banca {\n",
    "#             tipo: $tipo,\n",
    "#             titulo: $titulo,\n",
    "#             ano: $ano,\n",
    "#             instituicao: $instituicao\n",
    "#         })\n",
    "#         MERGE (p)-[:PARTICIPA_BANCA]->(b)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, **dados)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def persistir_projetos_pesquisa(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (pr:ProjetoPesquisa {\n",
    "#             titulo: $titulo,\n",
    "#             ano_inicio: $ano_inicio,\n",
    "#             ano_fim: $ano_fim,\n",
    "#             agencia_financiadora: $agencia_financiadora,\n",
    "#             valor_financiamento: $valor_financiamento\n",
    "#         })\n",
    "#         MERGE (p)-[:COORDENA]->(pr)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, dados=dados)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "#     def persistir_premios_distincoes(self, session, id_lattes, dados):\n",
    "#         query_create_node = \"\"\"\n",
    "#         MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "#         MERGE (pd:PremioDistincao {\n",
    "#             titulo: $titulo,\n",
    "#             ano: $ano,\n",
    "#             instituicao: $instituicao,\n",
    "#         })\n",
    "#         MERGE (p)-[:RECEBE]->(pd)\n",
    "#         \"\"\"\n",
    "#         result = session.run(query_create_node, id_lattes=id_lattes, **dados)\n",
    "\n",
    "#         # Obtendo as informações de contadores\n",
    "#         summary = result.consume()\n",
    "#         created_nodes = summary.counters.nodes_created\n",
    "#         updated_nodes = summary.counters.nodes_deleted  \n",
    "#         created_relations = summary.counters.relationships_created\n",
    "#         updated_relations = summary.counters.relationships_deleted \n",
    "\n",
    "#         return created_nodes, updated_nodes, created_relations, updated_relations\n",
    "\n",
    "# uri = \"bolt://localhost:7687\"\n",
    "# user = \"neo4j\"\n",
    "# password = \"password\"\n",
    "# persister = Neo4jPersister(uri, user, password)\n",
    "\n",
    "\n",
    "    # def run(self, query, **parameters):\n",
    "    #     with self.driver.session() as session:\n",
    "    #         return session.run(query, **parameters)\n",
    "\n",
    "    ## Agrupando nós de artigos por revista\n",
    "    # def persistir_artigos_revistas(self, session, id_lattes, dados):\n",
    "    #     created_nodes = 0\n",
    "    #     updated_nodes = 0\n",
    "    #     created_relations = 0\n",
    "    #     updated_relations = 0\n",
    "\n",
    "    #     for dados_artigo in dados:\n",
    "    #         ano = dados_artigo['ano']\n",
    "    #         impact_jcr = dados_artigo['fator_impacto_jcr']\n",
    "    #         issn = dados_artigo['ISSN']\n",
    "    #         titulo = dados_artigo['titulo']\n",
    "    #         revista = dados_artigo['revista']\n",
    "    #         autores = dados_artigo['autores']\n",
    "    #         qualis = dados_artigo['Qualis']\n",
    "    #         doi = dados_artigo['DOI']\n",
    "            \n",
    "    #         query_create_node_artigo = \"\"\"\n",
    "    #             MERGE (p:Pesquisador {id_lattes: $id_lattes})\n",
    "    #             CREATE (a:ArtigoPublicado {ano: $ano, impact_jcr: $impact_jcr, issn: $issn, titulo: $titulo, revista: $revista, autores: $autores, qualis: $qualis, doi: $doi})\n",
    "    #             CREATE (p)-[:PRODUZ]->(a)\n",
    "    #             MERGE (j:Revista {nome: $revista, issn: $issn})\n",
    "    #             CREATE (a)-[:PUBLICADO_EM]->(j)\n",
    "    #         \"\"\"\n",
    "\n",
    "    #         with session.begin_transaction() as tx:\n",
    "    #             print(\"DEBUG: ISSN da revista:\", issn)\n",
    "    #             # Verificação de existência da revista\n",
    "    #             revista_node = tx.run(\"\"\"\n",
    "    #                 MATCH (j:Revista {issn: $issn})\n",
    "    #                 RETURN j\n",
    "    #             \"\"\", issn=issn).single()\n",
    "\n",
    "    #             if not revista_node:\n",
    "    #                 # Revista não encontrada, crie-a\n",
    "    #                 tx.run(\"\"\"\n",
    "    #                     CREATE (j:Revista {nome: $revista, issn: $issn})\n",
    "    #                 \"\"\", revista=revista, issn=issn)\n",
    "\n",
    "    #                 revista_node = tx.run(\"\"\"\n",
    "    #                     MATCH (j:Revista {issn: $issn})\n",
    "    #                     RETURN j\n",
    "    #                 \"\"\", issn=issn).single()\n",
    "\n",
    "    #             if revista_node is not None:\n",
    "    #                 print(\"DEBUG: Propriedades do nó Revista:\", revista_node.items())  \n",
    "    #                 node_revista = revista_node[0]  # Extrair o objeto Node\n",
    "    #                 print(f\"revista_node[0] {node_revista}\")\n",
    "    #                 issn = node_revista['issn']  # Acessar a propriedade 'issn'\n",
    "    #                 print(f\"node_revista['issn'] {issn}\")\n",
    "    #                 revista_nome = node_revista['nome_revista']\n",
    "    #                 revista_area_avaliacao = node_revista['area_avaliacao']\n",
    "    #                 revista_estrato = node_revista['estrato']\n",
    "    #             else:\n",
    "    #                 print(\"Erro: O retorno para a revista com ISSN\", issn, \"é None.\")\n",
    "\n",
    "    #             # Criação do nó do artigo\n",
    "    #             tx.run(query_create_node_artigo, \n",
    "    #                 id_lattes=id_lattes, \n",
    "    #                 ano=ano,\n",
    "    #                 impact_jcr=impact_jcr,\n",
    "    #                 issn=issn,\n",
    "    #                 titulo=titulo,\n",
    "    #                 revista=revista,\n",
    "    #                 autores=autores,\n",
    "    #                 qualis=qualis,\n",
    "    #                 doi=doi)\n",
    "\n",
    "    #             # Criação do relacionamento PUBLICADO_EM\n",
    "    #             tx.run(\"\"\"\n",
    "    #                 MATCH (a:ArtigoPublicado {doi: $doi}), (j:Revista {nome_revista: $revista_nome, issn: $issn, area_avaliacao: $revista_area_avaliacao, estrato: $revista_estrato})\n",
    "    #                 CREATE (a)-[:PUBLICADO_EM]->(j)\n",
    "    #             \"\"\", doi=doi, revista_nome=revista_nome, issn=issn, revista_area_avaliacao=revista_area_avaliacao, revista_estrato=revista_estrato)\n",
    "\n",
    "    #             tx.commit()\n",
    "\n",
    "    #         # Atualização dos contadores\n",
    "    #         created_nodes += tx.run(\"MATCH (n) WHERE n:ArtigoPublicado RETURN count(n)\").single()[0]\n",
    "    #         updated_nodes += tx.run(\"MATCH (n) WHERE n:ArtigoPublicado SET n.updated_at = datetime() RETURN count(n)\").single()[0]\n",
    "    #         created_relations += tx.run(\"MATCH (r) WHERE r:PUBLICADO_EM RETURN count(r)\").single()[0]\n",
    "    #         updated_relations += tx.run(\"MATCH (r) WHERE r:PUBLICADO_EM SET r.updated_at = datetime() RETURN count(r)\").single()[0]\n",
    "\n",
    "    #     return created_nodes, updated_nodes, created_relations, updated_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d90ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import logging\n",
    "\n",
    "# from neo4j import GraphDatabase\n",
    "\n",
    "# class Neo4jDataPersister:\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._uri = uri\n",
    "#         self._user = user\n",
    "#         self._password = password\n",
    "#         self._driver = GraphDatabase.driver(self._uri, auth=(self._user, self._password))\n",
    "#         self.logger = logging.getLogger(__name__)\n",
    "\n",
    "#         self._node_created_count = 0\n",
    "#         self._node_updated_count = 0\n",
    "#         self._node_deleted_count = 0\n",
    "\n",
    "#         self._relationship_created_count = 0\n",
    "#         self._relationship_updated_count = 0\n",
    "#         self._relationship_deleted_count = 0\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "\n",
    "#     def persist_data_from_json(self, json_data):\n",
    "#         with self._driver.session() as session:\n",
    "#             self._persist_data(session, json_data)\n",
    "\n",
    "#         self.logger.info(\"Total nodes created: %d\", self._node_created_count)\n",
    "#         self.logger.info(\"Total nodes updated: %d\", self._node_updated_count)\n",
    "#         self.logger.info(\"Total nodes deleted: %d\", self._node_deleted_count)\n",
    "\n",
    "#         self.logger.info(\"Total relationships created: %d\", self._relationship_created_count)\n",
    "#         self.logger.info(\"Total relationships updated: %d\", self._relationship_updated_count)\n",
    "#         self.logger.info(\"Total relationships deleted: %d\", self._relationship_deleted_count)\n",
    "\n",
    "#     def _persist_data(self, session, data):\n",
    "#         if isinstance(data, dict):  # Check if it's a dictionary\n",
    "#             for key, value in data.items():\n",
    "#                 if key == 'Identificação':\n",
    "#                     self._handle_identificacao(session, value)\n",
    "#                 elif key == 'Atuação Profissional':\n",
    "#                     self._handle_atuacao_profissional(session, value)\n",
    "#                 elif key == 'Atuação Profissional':\n",
    "#                     self._handle_atuacao_profissional(session, value)                    \n",
    "#                 elif key == 'Produções':\n",
    "#                     self._handle_producoes(session, value)\n",
    "#                 elif isinstance(value, list) and not value:\n",
    "#                     # Ignore empty lists\n",
    "#                     pass\n",
    "#                 elif isinstance(value, dict):\n",
    "#                     if 'JCR2' in value:\n",
    "#                         # Ignore the 'JCR2' subdictionary\n",
    "#                         del value['JCR2']\n",
    "\n",
    "#                     self._persist_data(session, value)\n",
    "\n",
    "#         elif isinstance(data, list):  # Check if it's a list\n",
    "#             for item in data:\n",
    "#                 self._persist_data(session, item)  # Recurse on list items\n",
    "\n",
    "#         else:\n",
    "#             # Handle other data types (strings, numbers, etc.) or raise an error\n",
    "#             self.logger.warning(\"Unexpected data type: %s\", type(data))\n",
    "\n",
    "\n",
    "#     def _handle_identificacao(self, session, data):\n",
    "#         for item in data:\n",
    "#             if item['campo'] == 'ID Lattes':\n",
    "#                 node_id = item['valor']\n",
    "#                 node = self._get_or_create_node(session, 'Pesquisador', {'ID Lattes': node_id})\n",
    "#                 self._persist_other_properties(session, node, data)\n",
    "#             else:\n",
    "#                 node = self._get_or_create_node(session, 'Pesquisador', {data.items()})\n",
    "\n",
    "#     def _handle_atuacao_profissional(self, session, data):\n",
    "#         for item in data:\n",
    "#             node = self._create_node(session, 'AtuaçãoProfissional', item)\n",
    "\n",
    "#     def _handle_producoes(self, session, data):\n",
    "#         for production_type, production_data in data.items():\n",
    "#             if production_type == 'Artigos completos publicados em periódicos':\n",
    "#                 for article in production_data:\n",
    "#                     node = self._create_node(session, production_type, article)\n",
    "#             elif production_type.startswith('1.'):\n",
    "#                 for index, article in enumerate(production_data):\n",
    "#                     node = self._create_node(session, production_type, article)\n",
    "#                     node['OrdemCronológica'] = index + 1\n",
    "\n",
    "#     def _get_or_create_node(self, session, label, properties):\n",
    "#         node = session.run(\"MATCH (n: {label}) WHERE {properties} RETURN n\", {\"label\": label, \"properties\": properties}).single()\n",
    "\n",
    "#         if not node:\n",
    "#             node = session.run(\"CREATE (n: {label} {properties}) RETURN n\", {\"label\": label, \"properties\": properties}).single()[\"n\"]\n",
    "#             self._node_created_count += 1\n",
    "\n",
    "#         return node\n",
    "\n",
    "#     def _create_node(self, session, label, properties):\n",
    "#         node = session.run(\"CREATE (n: {label} {properties}) RETURN n\", {\"label\": label, \"properties\": properties}).single()[\"n\"]\n",
    "#         self._node_created_count += 1\n",
    "\n",
    "#         return node\n",
    "\n",
    "#     def _persist_other_properties(self, session, node, data):\n",
    "#         for key, value in data.items():\n",
    "#             if key not in ['campo', 'valor']:\n",
    "#                 node[key] = value  \n",
    "\n",
    "#     def _create_relationship(self, session, start_node, relationship_type, end_node, properties={}):\n",
    "#         session.run(\"MATCH (a), (b) WHERE ID(a) = {start_node_id} AND ID(b) = {end_node_id} CREATE (a)-[r:{type} {props}]->(b) RETURN r\", \n",
    "#                     {\"start_node_id\": id(start_node), \"end_node_id\": id(end_node), \"type\": relationship_type, \"props\": properties})\n",
    "#         self._relationship_created_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tipos=[]\n",
    "# subtipos=[]\n",
    "# for dict_pesq in dict_list:\n",
    "#     # Avaliando elementos da lista de dicionários do arquivo JSON de entrada\n",
    "#     if isinstance(dict_pesq, dict):\n",
    "#         for key1,val1 in dict_pesq.items():\n",
    "#             if key1 not in tipos:\n",
    "#                 tipos.append(key1)            \n",
    "#             print(f'N01: Elementos armazenados em dicionário:')\n",
    "#             print(f'     {key2:25} | Tipo dos valores: {type(val2)}')\n",
    "#             print(f'       Conteúdo disponível nos valores do dicionário de Nível 01:')\n",
    "#             # Avaliando filhos de primeiro nível na hierarquia (Seções)\n",
    "#             if isinstance(val1, list):\n",
    "#                 print(f'N01: Elementos armazenados em lista:')\n",
    "#                 print(f'     Conteúdo disponível nos valores:')\n",
    "#                 print(f'       {[x for x in val1]}')\n",
    "#             elif isinstance(val1, dict):\n",
    "#                 for key2,val2 in val1.items():\n",
    "#                     if key2 not in subtipos:\n",
    "#                         subtipos.append(key2)\n",
    "#                     print(f'       Chave: {key2:25} | Tipo dos valores: {type(val2)}')\n",
    "#                     print(f'         Conteúdo disponível nos valores do dicionário de Nível 02:')\n",
    "#                     # Avaliando filhos de segundo nível na hierarquia (Tipos de Seções)\n",
    "#                     if isinstance(val2, dict):\n",
    "#                         for key3,val3 in val2.items():\n",
    "#                             if key3 not in tipos:\n",
    "#                                 print(f'         Chave: {key3:25} | Tipo dos valores: {type(val3)}')\n",
    "#                                 print(f'          Conteúdo disponível nos valores do dicionário de Nível 03:')\n",
    "#                                 # Avaliando filhos de terceiro nível na hierarquia (Ocorrências de Tipos de Seções)\n",
    "#                                 if isinstance(val3, dict):\n",
    "#                                     print(f'               Chave: {key3:25} | Tipo dos valores: {type(val3)}')\n",
    "#                                     print(f'                 Conteúdo disponível nos valores do dicionário de Nível 04:')\n",
    "#                                     # print(val3)\n",
    "#             else:\n",
    "#                 print(f'N01: Elementos armazenados em {type(val1)}')\n",
    "#     else:\n",
    "#         print('ERRO NA ESTRUTURA DO JSON!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb43cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a Neo4jDataPersister instance\n",
    "# data_persister = Neo4jDataPersister('neo4j://localhost:7687', 'neo4j', 'password')\n",
    "# filename = 'dict_list.json'\n",
    "# json_data, formatted_creation_date, formatted_modification_date, time_count, unit = jfm.load_from_json(os.path.join(folder_data_input,filename))\n",
    "# print(f\"\\n{len(dict_list)} currículos carregados na lista de dicionários '{filename}'\")\n",
    "\n",
    "# # Persist the data to Neo4j\n",
    "# data_persister.persist_data_from_json(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87596beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pesq in json_data:\n",
    "#     print(len(pesq.get('Produções').keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cede6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ProjectsHandler:\n",
    "\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "\n",
    "#     def consult_data_by_property(self, name, property_name):\n",
    "#         with self._driver.session() as session:\n",
    "#             result = session.run(f\"MATCH (p:Person {{name: $name}}) RETURN p.`{property_name}` as data\", name=name)\n",
    "#             record = result.single()\n",
    "#             return record['data'] if record else None\n",
    "\n",
    "#     def create_projects_relations(self, name):\n",
    "#         successful_creations = 0\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             # Process 'Atuação Profissional' data\n",
    "#             professional_data = self.consult_data_by_property(name, 'Atuação Profissional')\n",
    "#             if professional_data:\n",
    "#                 for institution_name, _ in json.loads(professional_data).items():\n",
    "#                     session.run(\"MERGE (i:Instituição {name: $institution_name})\", institution_name=institution_name)\n",
    "#                     print(f\"Institution node created/merged for: {institution_name}\")\n",
    "\n",
    "#                     session.run(\"MATCH (p:Person {name: $name}), (i:Instituição {name: $institution_name}) MERGE (p)-[:TEM]->(i)\", name=name, institution_name=institution_name)\n",
    "#                     print(f\"Relationship established between {name} and {institution_name}.\")\n",
    "\n",
    "#             # Process other dynamic nodes\n",
    "#             key_labels_to_check = ['Linhas de pesquisa', 'Projetos de pesquisa', 'Projetos de extensão', 'Projetos de desenvolvimento']\n",
    "#             for key in key_labels_to_check:\n",
    "#                 formatted_key = f\"`{key}`\"  # Wrap the key with backticks\n",
    "#                 project_data = self.consult_data_by_property(name, key)\n",
    "#                 if project_data:\n",
    "#                     for project_time, project_name in json.loads(project_data).items():\n",
    "#                         if project_name:  # to avoid empty names\n",
    "#                             session.run(f\"MERGE (p:{formatted_key} {{name: $project_name}})\", project_name=project_name)\n",
    "#                             print(f\"{key} node created/merged for: {project_name}\")\n",
    "\n",
    "#                             session.run(f\"MATCH (a:Person {{name: $name}}), (p:{formatted_key} {{name: $project_name}}) MERGE (a)-[:TEM]->(p)\", name=name, project_name=project_name)\n",
    "#                             print(f\"Relationship established between {name} and {project_name} ({key}).\")\n",
    "#                             successful_creations += 1\n",
    "#                 else:\n",
    "#                     print(f\"'{key}' data not found for {name}\")\n",
    "\n",
    "#         print(f\"{successful_creations} projetos atualizados com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef4303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import re\n",
    "# from neo4j import GraphDatabase\n",
    "\n",
    "# class ArticleHandler:\n",
    "\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "\n",
    "#     def fetch_person_productions(self, name):\n",
    "#         with self._driver.session() as session:\n",
    "#             result = session.run(\"MATCH (p:Person {name: $name}) RETURN p.Produções as produções\", name=name)\n",
    "#             record = result.single()\n",
    "#             return record['produções'] if record else None\n",
    "\n",
    "#     def extract_article_info(self, input_str):\n",
    "#         # Encontre todas as abreviaturas de iniciais em maiúsculas e seus índices\n",
    "#         abbreviations = [(match.group(), match.start()) for match in re.finditer(r'\\b[A-Z]\\.', input_str)]\n",
    "\n",
    "#         # Encontre a posição da maior ocorrência de abreviaturas de iniciais, se houver\n",
    "#         if abbreviations:\n",
    "#             max_abbr_position = max(abbreviations, key=lambda x: x[1])\n",
    "\n",
    "#             # Encontre a primeira ocorrência de '. ' ou ' . ' após a maior ocorrência de abreviaturas de iniciais\n",
    "#             first_separator_candidates = [\n",
    "#                 input_str.find('. ', max_abbr_position[1] + 3),\n",
    "#                 input_str.find(' . ', max_abbr_position[1] + 3),\n",
    "#                 input_str.find('.. ')\n",
    "#             ]\n",
    "#             first_separator_candidates = [pos for pos in first_separator_candidates if pos != -1]\n",
    "\n",
    "#             if first_separator_candidates:\n",
    "#                 first_separator = min(first_separator_candidates)\n",
    "\n",
    "#                 # Encontre a primeira ocorrência de '. ' após o primeiro separador\n",
    "#                 second_separator = input_str.find('. ', first_separator + 2)\n",
    "\n",
    "#                 # Encontre a primeira ocorrência de ', ' após o segundo separador\n",
    "#                 third_separator = input_str.find(', ', second_separator + 2)\n",
    "#             else:\n",
    "#                 first_separator = second_separator = third_separator = -1\n",
    "#         else:\n",
    "#             first_separator = second_separator = third_separator = -1\n",
    "\n",
    "#         # Defina o padrão para encontrar \"p.\" e o conteúdo até a próxima vírgula\n",
    "#         pages_match = re.search(r' p\\.\\s*(.*?),', input_str)\n",
    "#         pages = pages_match.group(1) if pages_match else \"\"\n",
    "\n",
    "#         # Defina o padrão para encontrar \"v.\" e o conteúdo até a próxima vírgula\n",
    "#         volume_match = re.search(r' v\\.\\s*(.*?),', input_str)\n",
    "#         volume = volume_match.group(1) if volume_match else \"\"\n",
    "\n",
    "#         # Encontre a primeira ocorrência de um ano de quatro dígitos seguido de ponto final após o terceiro separador\n",
    "#         year_match = re.search(r' \\d{4}\\.', input_str[third_separator + 2:])\n",
    "#         year = year_match.group().strip('.').strip() if year_match else \"\"\n",
    "\n",
    "#         # Extraia os dados com base nas posições dos separadores\n",
    "#         authors = input_str[:first_separator].strip()\n",
    "#         title = input_str[first_separator + 2:second_separator].strip()\n",
    "#         journal = input_str[second_separator + 2:third_separator].strip()\n",
    "\n",
    "#         # Verifique se a lista de autores e o título não estão vazios\n",
    "#         if not authors or not title:\n",
    "#             return None  # Retorna None para indicar falha\n",
    "\n",
    "#         # Crie um dicionário com os dados extraídos\n",
    "#         article_info = {\n",
    "#             \"authors\": authors,\n",
    "#             \"title\": title,\n",
    "#             \"original_title\": journal,\n",
    "#             \"pages\": pages,\n",
    "#             \"volume\": volume,\n",
    "#             \"year\": year\n",
    "#         }\n",
    "\n",
    "#         return article_info\n",
    "    \n",
    "#     def deserialize_and_create_nodes(self, name):\n",
    "#         print(f\"Fetching 'Produções' data for {name}...\")\n",
    "#         productions_data = self.fetch_person_productions(name)\n",
    "        \n",
    "#         if not productions_data:\n",
    "#             print(f\"'Produções' data not found or empty for {name}.\")\n",
    "#             return\n",
    "\n",
    "#         print(f\"Attempting to deserialize 'Produções' data for {name}...\")\n",
    "#         try:\n",
    "#             productions_data = json.loads(productions_data)\n",
    "#         except json.JSONDecodeError as e:\n",
    "#             print(f\"Failed to deserialize 'Produções' data for {name}: {e}\")\n",
    "#             return\n",
    "\n",
    "#         successful_articles = 0\n",
    "#         unsuccessful_articles = []\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             print(f\"Processing 'Produção bibliográfica' for {name}...\")\n",
    "#             bibliographic_production = productions_data.get(\"Produção bibliográfica\", {})\n",
    "            \n",
    "#             if isinstance(bibliographic_production, str):\n",
    "#                 print(f\"Attempting to deserialize 'Produção bibliográfica' for {name}...\")\n",
    "#                 try:\n",
    "#                     bibliographic_production = json.loads(bibliographic_production)\n",
    "#                 except json.JSONDecodeError as e:\n",
    "#                     print(f\"Failed to deserialize 'Produção bibliográfica' for {name}: {e}\")\n",
    "#                     return\n",
    "\n",
    "#             articles = json.loads(bibliographic_production.get(\"Artigos completos publicados em periódicos\", \"{}\"))\n",
    "\n",
    "#             for _, article_str in articles.items():\n",
    "#                 article_details = self.extract_article_info(article_str)\n",
    "\n",
    "#                 # Vamos imprimir os detalhes de cada artigo e verificar se os autores estão presentes.\n",
    "#                 print(f\"Original Article: {article_str}\")\n",
    "#                 print(f\"Extracted Details: {article_details}\")\n",
    "\n",
    "#                 if article_details:\n",
    "#                     article_details[\"title\"] = article_details[\"title\"].strip()\n",
    "#                     article_details[\"original_title\"] = article_details[\"original_title\"].strip()\n",
    "\n",
    "#                     session.run(f\"MERGE (a:Artigo {{title: $title}}) SET a += $details\", title=article_details[\"title\"], details=article_details)\n",
    "#                     session.run(f\"MATCH (p:Person {{name: $name}}), (a:Artigo {{title: $title}}) MERGE (p)-[:PUBLICOU]->(a)\", name=name, title=article_details[\"title\"])\n",
    "#                     successful_articles += 1\n",
    "#                 else:\n",
    "#                     unsuccessful_articles.append(article_str)\n",
    "\n",
    "#         print(f\"Processed {successful_articles} articles successfully for {name}.\")\n",
    "\n",
    "#         if unsuccessful_articles:\n",
    "#             print(\"Failed to process the following articles:\")\n",
    "#             for article in unsuccessful_articles:\n",
    "#                 print(article)\n",
    "\n",
    "#     def process_articles(self, name):\n",
    "#         self.deserialize_and_create_nodes(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395566b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class JcrHandler:\n",
    "#     def __init__(self, uri, user, password):\n",
    "#         self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "#     def close(self):\n",
    "#         self._driver.close()\n",
    "\n",
    "#     def _consultar_propriedades_jcr(self, tx, name):\n",
    "#         query = (\n",
    "#             \"MATCH (p:Person {name: $name})\"\n",
    "#             \"RETURN p.JCR AS jcr\"\n",
    "#         )\n",
    "#         result = tx.run(query, name=name)\n",
    "#         return [record[\"jcr\"] for record in result]\n",
    "   \n",
    "#     ## Versão para usar com criação de nós secundários retorna JSON\n",
    "#     def consultar_propriedades_jcr(self, name):\n",
    "#         with self._driver.session() as session:\n",
    "#             query = (\n",
    "#                 \"MATCH (p:Person {name: $name})\"\n",
    "#                 \"RETURN p.JCR AS jcr\"\n",
    "#             )\n",
    "#             result = session.run(query, name=name)\n",
    "#             jcr_data = result.single()[\"jcr\"]\n",
    "#             jcr_properties_list = json.loads(jcr_data)\n",
    "#             return jcr_properties_list\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _convert_list_to_dict(lst):\n",
    "#         \"\"\"\n",
    "#         Converts a list into a dictionary with indices as keys.\n",
    "        \n",
    "#         Parameters:\n",
    "#         - lst: list, input list to be transformed.\n",
    "        \n",
    "#         Returns:\n",
    "#         - dict: Transformed dictionary.\n",
    "#         \"\"\"\n",
    "#         return {str(i): item for i, item in enumerate(lst)}\n",
    "    \n",
    "#     def create_person_with_jcr(self, name, jcr_properties):\n",
    "#         with self._driver.session() as session:\n",
    "#             session.write_transaction(self._create_person_with_jcr, name, jcr_properties)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _create_person_with_jcr(tx, name, jcr_properties):\n",
    "#         # Cria o nó Person\n",
    "#         person_query = (\n",
    "#             \"CREATE (p:Person {name: $name}) \"\n",
    "#             \"RETURN p\"\n",
    "#         )\n",
    "#         person_result = tx.run(person_query, name=name)\n",
    "#         person_node = person_result.single()[0]\n",
    "\n",
    "#         # Cria os nós secundários para cada valor único de data-issn\n",
    "#         data_issn_values = set(prop.get(\"data-issn\") for prop in jcr_properties)\n",
    "#         for data_issn in data_issn_values:\n",
    "#             if data_issn:\n",
    "#                 secondary_node_query = (\n",
    "#                     \"CREATE (s:SecondaryNode {data_issn: $data_issn}) \"\n",
    "#                     \"RETURN s\"\n",
    "#                 )\n",
    "#                 tx.run(secondary_node_query, data_issn=data_issn)\n",
    "\n",
    "#                 # Cria a relação entre o nó Person e o nó secundário\n",
    "#                 relation_query = (\n",
    "#                     \"MATCH (p:Person {name: $name}), (s:SecondaryNode {data_issn: $data_issn}) \"\n",
    "#                     \"CREATE (p)-[:HAS_JCR]->(s)\"\n",
    "#                 )\n",
    "#                 tx.run(relation_query, name=name, data_issn=data_issn)\n",
    "\n",
    "#     def createJournalsNodes(self, name):\n",
    "#         # Get JCR properties\n",
    "#         jcr_properties = self.consultar_propriedades_jcr(name)\n",
    "\n",
    "#         # Convert the serialized JSON strings back into dictionaries\n",
    "#         deserialized_jcr_properties = [json.loads(prop) for prop in jcr_properties.values()]\n",
    "\n",
    "#         # Inform the user about the total number of JCR property entries\n",
    "#         total_entries = len(deserialized_jcr_properties)\n",
    "#         print(f\"Read {total_entries} entries from JCR properties of Person '{name}'.\")\n",
    "\n",
    "#         # Extract relevant journal properties and their count\n",
    "#         journal_counts = Counter(prop.get(\"data-issn\") for prop in deserialized_jcr_properties)\n",
    "        \n",
    "#         # Number of unique ISSNs\n",
    "#         unique_issns = len(journal_counts)\n",
    "#         print(f\"Identified {unique_issns} unique ISSN values.\")\n",
    "\n",
    "#         null_count = journal_counts.pop(None, 0)  # Remove None (null) ISSN and get its count\n",
    "#         null_count += journal_counts.pop(\"NULL\", 0)  # Also account for \"NULL\" as a string\n",
    "\n",
    "#         # Counters for journals\n",
    "#         successful_journal_creations = 0\n",
    "\n",
    "#         with self._driver.session() as session:\n",
    "#             for data_issn, count in journal_counts.items():\n",
    "#                 if data_issn and data_issn != \"NULL\":\n",
    "#                     representative_entry = next(prop for prop in deserialized_jcr_properties if prop.get(\"data-issn\") == data_issn)\n",
    "#                     journal_name = representative_entry.get(\"original_title\")\n",
    "#                     fator_impacto = representative_entry.get(\"impact-factor\")\n",
    "#                     jcr_year = representative_entry.get(\"jcr-year\")\n",
    "\n",
    "#                     # Create or merge the Journal node\n",
    "#                     journal_node_query = (\n",
    "#                         \"MERGE (j:Revistas {ISSN: $data_issn}) \"\n",
    "#                         \"ON CREATE SET j.name = $journal_name, j.FatorImpacto = $impact_factor, j.JCRYear = $jcr_year \"  # Corrected this line\n",
    "#                         \"RETURN j\"\n",
    "#                     )\n",
    "#                     session.run(journal_node_query, data_issn=data_issn, journal_name=journal_name, impact_factor=fator_impacto, jcr_year=jcr_year)  # And this line\n",
    "\n",
    "#                     # Create or update the \"PUBLICOU_EM\" relationship\n",
    "#                     relation_query = (\n",
    "#                         \"MATCH (p:Person {name: $name}), (j:Revistas {ISSN: $data_issn}) \"  # corrected this line\n",
    "#                         \"MERGE (p)-[r:PUBLICOU_EM]->(j) \"\n",
    "#                         \"ON CREATE SET r.QuantidadePublicações = $count \"\n",
    "#                         \"ON MATCH SET r.QuantidadePublicações = r.QuantidadePublicações + $count\"\n",
    "#                     )\n",
    "#                     session.run(relation_query, name=name, data_issn=data_issn, count=count)\n",
    "                    \n",
    "#                     successful_journal_creations += 1\n",
    "                \n",
    "#                 if null_count:\n",
    "#                     # For example, to print the count:\n",
    "#                     pass\n",
    "        \n",
    "#         # Inform the user about journals\n",
    "#         print(f\"{successful_journal_creations} Revistas adicionadas com sucesso.\")\n",
    "#         print(f\"{null_count} Revistas não foram criadas por terem valor NULL de ISSN.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4fe327",
   "metadata": {},
   "source": [
    "## Teste extrair homônimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Teste de extração para homônimos\n",
    "# t1 = time.time()\n",
    "# lista_homonimos = [\n",
    "#     'Tania Maria Alves de Almeida',\n",
    "#     'Rodrigo Corrêa de Oliveira',\n",
    "# ]\n",
    "\n",
    "# scraper = LattesScraper(termos_busca, 'bolt://localhost:7687', 'neo4j', 'password', only_doctors=True)\n",
    "# dom_dict_homonimos = scraper.scrape(lista_homonimos, termos_busca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.spacy3': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "197d8f220c237ea2269a397bcc5571d13b6ee9614ab9ae87aa2d290b25dc373b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
