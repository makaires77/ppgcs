{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais de Kolmogorov-Arnold (KANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As **Redes de Kolmogorov-Arnold (KANs)** oferecem uma abordagem diferente em relação às redes neurais tradicionais, como os perceptrons de múltiplas camadas (MLPs). Abaixo, discutiremos como os conceitos de pesos e vieses se aplicam em KANs e como eles diferem das redes neurais convencionais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação entre KANs e Outras Arquiteturas de Redes Neurais\n",
    "\n",
    "A arquitetura de Kolmogorov-Arnold (KAN) apresenta características distintas que a diferenciam de outras arquiteturas de redes neurais, especialmente em tarefas relacionadas a grafos. Abaixo, exploramos como as KANs se comparam com outras arquiteturas de redes neurais, como MLPs (Multi-Layer Perceptrons) e redes neurais para grafos como GCNs (Graph Convolutional Networks), e discutimos seus pontos fortes e desafios.\n",
    "\n",
    "1. Kolmogorov-Arnold Networks (KANs) vs. Multi-Layer Perceptrons (MLPs)\n",
    "Representação de Funções: As KANs utilizam o Teorema da Representação de Kolmogorov-Arnold, que permite que funções contínuas sejam expressas como superposições de funções univariadas mais simples. Isso possibilita uma maior flexibilidade na modelagem de dados complexos em comparação com MLPs, que geralmente dependem de funções de ativação fixas \\cite{1}.\n",
    "\n",
    "- Desempenho em Tarefas Específicas: Em experimentos, as KANs mostraram desempenho equivalente ou superior aos MLPs em tarefas de classificação e uma vantagem clara em tarefas de regressão em grafos. Isso sugere que as KANs podem capturar melhor a estrutura subjacente dos dados \\cite{1}.\n",
    "\n",
    "- Complexidade Computacional: Apesar das vantagens, a complexidade computacional das KANs pode ser maior do que a dos MLPs devido à necessidade de calcular funções spline. No entanto, as KANs podem convergir mais rapidamente durante o treinamento, resultando em um tempo total de treinamento menor \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "\n",
    "2. Kolmogorov-Arnold Networks (KANs) vs. Graph Convolutional Networks (GCNs)\n",
    "- Extração de Características: As GCNs utilizam convoluções para extrair características dos nós em um grafo, mas dependem de uma arquitetura fixa. As KANs, por outro lado, implementam funções spline aprendíveis que podem se adaptar dinamicamente às características dos dados, oferecendo uma modelagem mais expressiva \\cite{1}.\n",
    "\n",
    "- Interpretabilidade: As KANs proporcionam melhor interpretabilidade devido à sua capacidade de aprender funções específicas para cada nó e aresta, permitindo uma análise mais clara sobre como as decisões são tomadas. Isso é particularmente importante em aplicações críticas onde a transparência é essencial \\cite{1}.\n",
    "\n",
    "- Flexibilidade: As KANs são mais versáteis e podem ser combinadas com outras técnicas de redes neurais gráficas para criar modelos híbridos. Essa capacidade de integração permite que as KANs sejam aplicadas a uma ampla gama de tarefas em grafos \\cite{1}.\n",
    "\n",
    "3. Vantagens das KANs\n",
    "- Modelagem Adaptativa: A capacidade das KANs de aprender funções não lineares complexas permite que elas se adaptem melhor a diferentes tipos de dados e estruturas gráficas, tornando-as uma escolha promissora para tarefas como previsão de links e classificação de nós \\cite{1}.\n",
    "\n",
    "- Menor Necessidade de Parâmetros: As KANs podem alcançar resultados comparáveis aos MLPs com um número menor de parâmetros, o que pode resultar em um modelo mais leve e eficiente \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicar Redes Kolmogorov-Arnold a Grafos (GKANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As **Redes de Kolmogorov-Arnold (KANs)**, quando aplicadas a grafos, introduzem uma nova perspectiva sobre como modelar e aprender a partir de dados estruturados. Abaixo, discutiremos as principais mudanças e considerações ao aplicar KANs em grafos.\n",
    "\n",
    "1. Estrutura de Dados\n",
    "\n",
    "- **Grafos como Estruturas**: Em vez de trabalhar com dados tabulares ou sequenciais, as KANs podem ser adaptadas para operar em grafos, onde os nós representam entidades e as arestas representam relações entre essas entidades. Isso permite que a rede aprenda padrões complexos que são inerentes à estrutura do grafo.\n",
    "\n",
    "- **Representação**: Os grafos podem ser representados por matrizes de adjacência ou listas de adjacência, facilitando a manipulação dos dados dentro da rede. As KANs podem utilizar essas representações para aprender funções que capturam as interações entre os nós.\n",
    "\n",
    "2. Aprendizado Adaptativo\n",
    "\n",
    "- **Pesos e Vieses**: Em KANs aplicadas a grafos, os pesos e vieses podem ser ajustados não apenas com base nas entradas, mas também considerando a topologia do grafo. Isso significa que as relações entre os nós podem influenciar diretamente como os pesos são atualizados durante o treinamento.\n",
    "\n",
    "- **Funções de Ativação**: As KANs podem aprender funções de ativação que são específicas para a estrutura do grafo. Por exemplo, diferentes funções podem ser aplicadas dependendo da conectividade dos nós, permitindo uma modelagem mais rica.\n",
    "\n",
    "3. Interpretação e Flexibilidade\n",
    "\n",
    "- **Interpretabilidade**: As KANs oferecem uma vantagem sobre as redes neurais tradicionais ao permitir que os modelos sejam mais interpretáveis. Ao trabalhar com grafos, é possível visualizar como as alterações em um nó afetam outros nós na rede, facilitando a compreensão do comportamento do modelo.\n",
    "\n",
    "- **Granulação Fina**: A abordagem de \"granulação fina\" pode ser aplicada para melhorar a densidade das grades spline em KANs. Isso é especialmente útil em grafos onde a complexidade das relações pode ser alta, permitindo que a rede se torne mais representativa e poderosa.\n",
    "\n",
    "4. Exemplos de Aplicação\n",
    "\n",
    "- **Redes Sociais**: Em redes sociais, onde os usuários são representados como nós e as interações como arestas, as KANs podem aprender padrões de comportamento e prever interações futuras.\n",
    "\n",
    "- **Biologia Computacional**: Na análise de redes biológicas, como interações proteicas ou redes metabólicas, as KANs podem modelar complexas relações entre biomoléculas.\n",
    "\n",
    "- **Sistemas de Transporte**: Em problemas relacionados a rotas e logística, onde cidades ou pontos de entrega são representados como nós e as rotas como arestas, as KANs podem otimizar caminhos e prever fluxos de tráfego.\n",
    "\n",
    "A aplicação das Redes de Kolmogorov-Arnold em grafos representa uma evolução significativa na maneira como abordamos problemas complexos em estruturas não lineares. Ao integrar a teoria dos grafos com o aprendizado adaptativo das KANs, é possível desenvolver modelos mais robustos e interpretáveis que capturam a essência das relações entre entidades em diversas áreas de aplicação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vantagens das KAGNN\n",
    "\n",
    "As Redes de Kolmogorov-Arnold (KAGNNs) demonstram vantagens significativas em tarefas de previsão de links em comparação com modelos tradicionais de redes neurais, como os Perceptrons Multicamadas (MLPs). A seguir, detalho as principais razões pelas quais os KAGNNs superam esses modelos em tarefas específicas.\n",
    "\n",
    "1. Melhoria na Extração de Recursos\n",
    "Os KAGNNs se beneficiam da Teoria da Representação de Kolmogorov-Arnold, que permite uma melhor extração de características dos dados gráficos. Essa abordagem resulta em uma representação mais rica e informativa das conexões entre os nós, o que é crucial para a previsão de links. Os KAGNNs conseguem capturar a estrutura subjacente dos dados de forma mais eficaz do que os MLPs, que dependem de funções de ativação fixas e não adaptativas \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "\n",
    "2. Performance Superior em Tarefas de Previsão\n",
    "Os estudos mostram que os KAGNNs consistentemente superam as redes neurais tradicionais em várias tarefas, incluindo a previsão de links. Em experimentos realizados, os KAGNNs apresentaram um desempenho superior em comparação com GNNs (Graph Neural Networks) que utilizam MLPs como módulos de transformação \\cite{3}. Isso se deve à capacidade dos KAGNNs de utilizar funções spline aprendíveis, que melhoram a precisão das previsões e oferecem maior interpretabilidade \\cite{1}.\n",
    "\n",
    "3. Convergência Rápida e Menor Complexidade\n",
    "Os KAGNNs convergem mais rapidamente durante o treinamento em comparação com os MLPs. Eles requerem menos parâmetros para alcançar resultados equivalentes, o que não apenas reduz a complexidade computacional, mas também acelera o processo de treinamento \\cite{2}. Essa eficiência é particularmente vantajosa em cenários onde o tempo e os recursos computacionais são limitados.\n",
    "\n",
    "4. Abordagem Interpretativa\n",
    "Uma das principais limitações dos MLPs é a falta de interpretabilidade. Os KAGNNs, por outro lado, oferecem insights mais claros sobre como as decisões são tomadas, permitindo uma análise mais profunda das relações entre os nós no grafo. Isso é especialmente importante em aplicações onde a transparência é crítica, como na biomedicina ou na segurança em nanotecnologia \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "\n",
    "Em resumo, as Redes de Kolmogorov-Arnold superam os modelos tradicionais de redes neurais nas tarefas de previsão de links devido à sua capacidade aprimorada de extração de características, desempenho superior em várias métricas, convergência rápida e maior interpretabilidade. Esses fatores tornam os KAGNNs uma escolha promissora para aplicações complexas em aprendizagem de máquina com dados gráficos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuidados para vencer os desafios na implementação das KAGNNs\n",
    "\n",
    "As Redes Kolmogorov-Arnold oferecem uma abordagem inovadora para o aprendizado em grafos especializados, destacando-se por sua capacidade adaptativa e interpretabilidade superior em comparação com outras arquiteturas como MLPs e GCNs. No entanto, os desafios associados ao treinamento dessas redes exigem atenção cuidadosa e estratégias adequadas para garantir sua eficácia na predição e análise dinâmica da similaridade semântica entre entidades. A seguir listamos os principais desafios juntamente com as abordagens para superá-los adotadas na execução deste trabalho.\n",
    "\n",
    "- Complexidade Computacional: Os KAGNNs utilizam splines para aprender funções de ativação, o que resulta em uma complexidade computacional maior. A complexidade é O(N²LG), onde N é o número de dados e G é o número de intervalos da grade spline. Isso é mais alto do que a complexidade típica de O(N²L) para MLPs \\cite{bresson2024kagnn}.\n",
    "\n",
    "Para mitigar essa limitação, pode-se explorar algoritmos de otimização mais eficientes ou técnicas de redução de dimensionalidade que diminuam a carga computacional sem sacrificar a precisão do modelo.\n",
    "\n",
    "- Overfitting: Como em muitos modelos de aprendizado profundo, há um risco significativo de overfitting nas KAGNNs, especialmente quando o número de parâmetros é grande em relação ao tamanho do conjunto de dados. \n",
    "\n",
    "Técnicas como regularização ou validação cruzada são essenciais para mitigar esse problema \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "\n",
    "- Desvio da Arquitetura Padrão: A abordagem de treinamento e a arquitetura dos KAGNNs se desviam das práticas padrão utilizadas em redes neurais modernas, o que pode dificultar sua adoção em larga escala \\cite{DeCarlo2024}.\n",
    "\n",
    "Promover a padronização das arquiteturas KAN e desenvolver bibliotecas que facilitem sua implementação pode ajudar a integrar melhor esses modelos no ecossistema atual de aprendizado de máquina.\n",
    "\n",
    "- Aplicabilidade Limitada: Embora os KAGNNs tenham mostrado resultados promissores, eles ainda são considerados mais adequados para problemas de nicho em matemática e física, em vez de serem uma solução universal para todos os tipos de problemas \\cite{DeCarlo2024}.\n",
    "\n",
    "Realizar mais pesquisas e experimentos em diferentes domínios pode ajudar a identificar novas aplicações para os KAGNNs, expandindo seu uso além dos problemas tradicionais.\n",
    "\n",
    "- Necessidade de Melhorias na Interpretabilidade: Embora os KAGNNs, devido à sua capacidade de aprender funções específicas, sejam mais interpretáveis em comparação com modelos tradicionais como MLPs, ainda há espaço para melhorias na forma como as decisões são compreendidas e explicadas, especialmente em domínios críticos onde a transparência é essencial, como no suporte à decisões em saúde \\cite{DeCarlo2024}.\n",
    "\n",
    "Desenvolver ferramentas e técnicas que ajudem a visualizar e interpretar as funções aprendidas pelos KAGNNs pode aumentar a confiança dos usuários e facilitar a adoção em áreas críticas como saúde e segurança.\n",
    "\n",
    "- Dependência da Qualidade dos Dados: Como qualquer modelo de aprendizado de máquina, os KAGNNs dependem fortemente da qualidade dos dados utilizados para treinamento. Dados ruidosos ou mal estruturados podem levar a resultados imprecisos.\n",
    "\n",
    "Implementar técnicas robustas de pré-processamento e limpeza de dados, bem como métodos de aumento de dados, pode ajudar a melhorar a qualidade das entradas usadas nos KAGNNs.\n",
    "\n",
    "Embora as Redes de Kolmogorov-Arnold apresentem limitações significativas. Porém, há várias estratégias que podem ser adotadas para superá-las. Com avanços contínuos na pesquisa e desenvolvimento, os KAGNNs têm o potencial de se tornar uma ferramenta valiosa em diversas aplicações dentro do aprendizado de máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neurais de Kolmogorov-Arnold para Grafos Especializadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Redes de Kolmogorov-Arnold em Grafos (KAGNNs) são uma nova classe de modelos de aprendizado profundo projetados para lidar com dados estruturados em forma de grafos. Elas se baseiam na Teoria da Representação de Kolmogorov-Arnold, que permite a decomposição de funções complexas em componentes mais simples. Abaixo, discutiremos os principais tipos e arquiteturas das KAGNNs, bem como os desafios enfrentados no treinamento desses modelos usando PyTorch Geometric, especialmente para tarefas de predição de links baseadas em avaliação dinâmica da similaridade semântica entre entidades e relacionamentos.\n",
    "\n",
    "### Principais Tipos e Arquiteturas das KAGNNs\n",
    "- Graph Kolmogorov-Arnold Networks (GKAN): Esta arquitetura combina os princípios das KANs com técnicas tradicionais de redes neurais em grafo. O GKAN utiliza funções $spline$ aprendíveis para extrair características dos nós e arestas, permitindo uma modelagem mais flexível e interpretável \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "\n",
    "- KAGNN Variantes: Existem várias variantes das KAGNNs que se concentram em diferentes aspectos do aprendizado em grafos. Por exemplo, algumas variantes podem se concentrar na melhoria da extração de características ou na combinação com outras técnicas de redes neurais gráficas para aumentar a robustez do modelo \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "\n",
    "- Modelos Híbridos: As KAGNNs também podem ser integradas a outros tipos de redes neurais, como Graph Convolutional Networks (GCNs) ou Graph Attention Networks (GATs), para criar modelos híbridos que aproveitam as vantagens de múltiplas abordagens \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A arquitetura de Kolmogorov-Arnold (KAN) pode ser aplicada em grafos especializados aproveitando suas funcionalidades únicas para melhorar a extração de características e a interpretabilidade em tarefas de aprendizado de máquina. Os potenciais de maior interesse no uso de KANs são:\n",
    "\n",
    "1. Extração Eficiente de Características: A aplicação do teorema da representação de Kolmogorov-Arnold permite que as KANs capturem a estrutura subjacente dos dados em grafos. Isso é particularmente útil em grafos especializados, onde as relações entre os nós podem ser complexas e não lineares. As KAGNNs utilizam funções spline aprendíveis que podem adaptar-se dinamicamente às características dos dados, melhorando a capacidade de modelagem \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "\n",
    "2. Predição de Links em Grafos Sociais: Em grafos sociais, onde os nós representam indivíduos e as arestas representam interações, as KAGNNs podem ser usadas para prever novas conexões com base nas similaridades semânticas entre as entidades. O uso das KANs permite que o modelo aprenda representações mais ricas e interpretáveis das interações sociais, levando a previsões mais precisas \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "\n",
    "3. Análise Temporal em Grafos Dinâmicos: As KAGNNs são adequadas para tarefas que envolvem dados temporais, como a análise de séries temporais em grafos. Ao incorporar a representação de Kolmogorov-Arnold, os modelos podem capturar mudanças dinâmicas nas relações entre os nós ao longo do tempo, permitindo uma avaliação mais precisa da evolução das interações \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "\n",
    "4. Aplicações em Sistemas Complexos: Na biologia computacional, por exemplo, as KAGNNs podem ser aplicadas para modelar redes biológicas complexas, como interações proteicas ou redes metabólicas. A capacidade das KANs de aprender funções complexas e adaptativas permite que os pesquisadores identifiquem padrões importantes nas interações biomoleculares \\cite{4}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração de características com KAGNN\n",
    "\n",
    "Teorema da Representação de Kolmogorov-Arnold: O teorema afirma que qualquer função contínua pode ser expressa como uma superposição de funções univariadas mais simples. Essa abordagem permite que as KAGNNs decomponham funções complexas em componentes mais gerenciáveis, facilitando a modelagem e a extração de características relevantes a partir dos dados \\cite{1}.\n",
    "\n",
    "A representação de Kolmogorov-Arnold melhora a extração de características nos KAGNNs (Kolmogorov-Arnold Graph Neural Networks), conforme evidenciado pelos resultados da pesquisa, principalmente devido a representação com essa abordagem contribuir para uma melhor performance em tarefas de aprendizado de máquina, especialmente em grafos, tais como:\n",
    "\n",
    "- Extração Aprimorada de Recursos: As KAGNNs utilizam funções de ativação baseadas em splines, que são mais flexíveis do que as funções de ativação tradicionais usadas em MLPs (Perceptrons Multicamadas). Isso permite que os modelos capturem melhor a estrutura subjacente dos dados gráficos, resultando em representações mais expressivas e informativas. Essa capacidade é crucial para tarefas como previsão de links e classificação de nós, onde a relação entre as entidades é complexa \\cite{2}.\n",
    "\n",
    "- Interpretabilidade: Uma das limitações das redes neurais tradicionais é a falta de interpretabilidade. As KAGNNs, ao incorporarem a representação de Kolmogorov-Arnold, não apenas melhoram a precisão das previsões, mas também oferecem uma maior transparência no processo de decisão do modelo. Isso significa que os usuários podem entender melhor como as características dos dados influenciam as saídas do modelo, o que é especialmente importante em domínios críticos como a biomedicina e a segurança \\cite{1}.\n",
    "\n",
    "- Comparação com Modelos Tradicionais: Estudos mostram que as KAGNNs superam modelos tradicionais em várias métricas de desempenho. Em experimentos realizados, as KAGNNs mostraram-se superiores em tarefas como classificação de nós e previsão de links quando comparadas com GNNs convencionais que utilizam MLPs como módulos de transformação \\cite{2}. Isso se deve à capacidade das KAGNNs de aprender funções mais complexas e adaptativas durante o treinamento.\n",
    "\n",
    "Em suma, a representação de Kolmogorov-Arnold melhora significativamente a extração de características nas KAGNNs ao permitir uma decomposição eficaz das funções complexas, resultando em melhores representações dos dados gráficos. Essa abordagem não apenas aprimora o desempenho do modelo em tarefas específicas, mas também aumenta sua interpretabilidade, tornando as KAGNNs uma alternativa promissora às redes neurais tradicionais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestão da Complexidade Computacional das KAGNN\n",
    "\n",
    "A complexidade computacional dos KAGNNs (Kolmogorov-Arnold Graph Neural Networks) pode ser uma preocupação, especialmente devido à sua dependência de splines, que introduzem uma complexidade de \n",
    "$O (N^2 LG)$, onde $N$ é o número de dados, $L$ é o número de parâmetros e $G$ é o número de intervalos da grade spline. No entanto, existem várias estratégias que podem ser adotadas para reduzir essa complexidade e melhorar a eficiência computacional dos KAGNNs.\n",
    "\n",
    "1. Granulação Fina: Uma abordagem promissora para reduzir a complexidade computacional é a implementação da técnica conhecida como granulação fina. Essa técnica envolve a densificação das grades spline, permitindo que as KAGNNs se tornem mais representativas e poderosas sem aumentar significativamente o número de parâmetros. Ao tornar as grades mais densas, a rede pode capturar melhor as nuances dos dados sem a necessidade de uma complexidade computacional excessiva \\cite{Goodfellow-et-al-2016}.\n",
    "\n",
    "2. Regularização e Funções de Ativação Residual: Outra estratégia para melhorar a eficiência dos KAGNNs é a introdução de funções de ativação residual. Essas funções atuam como uma forma de regularização, ajudando a suavizar as transições entre diferentes regiões da função aprendida. Isso não só melhora a convergência durante o treinamento, mas também permite que as redes aprendam com menos parâmetros, reduzindo assim a carga computacional total \\cite{Goodfellow-et-al-2016}.\n",
    "\n",
    "3. Poda e Esparsificação: A poda e a esparsificação são técnicas que podem ser aplicadas após o treinamento inicial da rede. A poda envolve remover nós ou conexões que não contribuem significativamente para a performance do modelo, enquanto a esparsificação utiliza regularização para incentivar uma estrutura mais leve na rede. Essas técnicas ajudam a manter um desempenho semelhante com um número reduzido de parâmetros, diminuindo assim a complexidade computacional \\cite{Goodfellow-et-al-2016}.\n",
    "\n",
    "4. Otimização do Algoritmo de Treinamento: A escolha do algoritmo de otimização também pode impactar diretamente na eficiência do treinamento dos KAGNNs. Utilizar algoritmos mais avançados ou adaptativos, como Adam ou RMSprop, pode acelerar o processo de convergência e reduzir o tempo total necessário para treinar o modelo \\cite{2}.\n",
    "\n",
    "5. Uso de Aceleração de Hardware: Por fim, aproveitar hardware especializado, como GPUs ou TPUs, pode ajudar a mitigar os custos computacionais associados ao treinamento dos KAGNNs. Esses dispositivos são projetados para realizar cálculos em paralelo, permitindo que operações complexas sejam executadas mais rapidamente do que em CPUs tradicionais \\cite{3}.\n",
    "\n",
    "Embora os KAGNNs apresentem desafios em termos de complexidade computacional devido ao uso de splines e suas características únicas, várias estratégias podem ser implementadas para reduzir essa complexidade. Com técnicas como granulação fina, regularização com funções de ativação residual, poda e esparsificação, otimização do algoritmo de treinamento e uso de hardware acelerado, é possível melhorar significativamente a eficiência dos KAGNNs em tarefas práticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estratégias para controle do custo computacional\n",
    "\n",
    "A aplicação da poda nos KAGNNs (Kolmogorov-Arnold Graph Neural Networks) oferece uma maneira eficaz de reduzir a complexidade computacional, melhorando ao mesmo tempo a eficiência e interpretabilidade do modelo. Ao remover nós desnecessários e utilizar técnicas de regularização, é possível manter um alto nível de desempenho enquanto se minimiza o uso de recursos computacionais. Estratégias de poda podem ser aplicadas para reduzir a complexidade dos KAGNNs de maneira eficaz, seguindo algumas estratégias específicas. Abaixo estão os principais métodos e considerações sobre como a poda pode ser implementada nesse contexto.\n",
    "\n",
    "## Principais estratégias\n",
    "2. Regularização com Normas L1:\n",
    "A introdução da regularização L1 durante o treinamento pode incentivar a esparsidade na rede. A regularização L1 penaliza os pesos menores, fazendo com que muitos deles se aproximem de zero. Isso não apenas ajuda na poda automática de conexões irrelevantes, mas também contribui para a interpretação do modelo, permitindo que ele se concentre nas características mais relevantes dos dados \\cite{Goodfellow-et-al-2016}.\n",
    "\n",
    "3. Análise de Gradientes: Os gradientes calculados durante o treinamento podem fornecer informações sobre a relevância dos nós. Se um nó apresentar gradientes consistentemente baixos, isso pode indicar que ele não está aprendendo informações úteis e pode ser considerado para remoção \\cite{2}.\n",
    "\n",
    "3. Validação Cruzada: Utilizar validação cruzada para avaliar o desempenho do modelo antes e depois da poda pode ajudar a garantir que a remoção de nós não comprometa a precisão do modelo. Essa abordagem permite identificar quais nós podem ser removidos sem afetar negativamente o desempenho geral da rede \\cite{2}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos e momentos de poda\n",
    "Integrar a poda ao treinamento de KAGNNs (Kolmogorov-Arnold Graph Neural Networks) mostrou-se uma estratégia eficaz para melhorar a eficiência do modelo e reduzir sua complexidade computacional. As aplicação dessa poda pode ser feita em vários momentos, de acordo com a necessidade e aplicabilidade. Esses critérios ajudam a garantir que apenas os nós que não estão contribuindo para a aprendizagem sejam eliminados.\n",
    "\n",
    "1. Definir quais nós podar: Estabelecidos os critérios puderam ser determinados quais nós seriam podados. A importância dos nós foi avaliada com base em sua contribuição para a saída da rede, dada principalmente pelos pesos associados a cada nó após o treinamento. Nós com pesos muito baixos ou próximos de zero podem ser considerados para remoção, uma vez que sua influência na previsão final é mínima \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "No geral a avaliação dos critérios de importância dos nós para aplicação de poda envolve os critérios de:\n",
    "    - Pesos Baixos: Remover nós com pesos que estão abaixo de um determinado limiar.\n",
    "    - Ativações Baixas: Identificar e remover nós cujas ativações permanecem consistentemente baixas durante o treinamento.\n",
    "    - Gradientes Baixos: Avaliar os gradientes dos nós; aqueles com gradientes persistentemente baixos podem ser considerados para remoção. \n",
    "\n",
    "2. Aplicar avaliação Contínua para podar: Foi implementado uma sistemática de avaliação contínua durante todo o processo de poda. Isso garantiu que as remoções não afetaram negativamente o desempenho do modelo e permitiu ajustes dinâmicos conforme necessário para cada questão específica sendo avaliada pelo modelo. Assim, após aplicação de todas as estratégias de gestão do custo computacional, a avaliação contínua foi crucial para garantir que o desempenho global do modelo não tenha sido comprometido. Esse monitoramento das métricas de desempenho, de acordo com a questão específica em estudo também foi aplicado nos conjuntos de testes e de validação, bem como para o ajuste fino dos hiperparâmetros para otimizar o desempenho da rede podada \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks, Goodfellow-et-al-2016}.\n",
    "\n",
    "3. Definir quando aplicar a poda:\n",
    "    - Poda Estrutural: Antes da poda de nós individuais, foi possível realizar uma poda estrutural, onde grupos inteiros de conexões são removidos com base na estrutura do grafo. Foram removidos para cada questão específica sendo inferida pelo modelo as arestas que não são críticas, naquela questão específica, para as interações estudadas entre os nós, resultando em uma rede mais enxuta e eficiente.\n",
    "\n",
    "    - Poda iterativa durante o treinamento: Após cada iteração de treinamento, a rede foi avaliada e os nós menos significativos foram removidos. Esse processo iterativo permite que o modelo se adapte continuamente às mudanças na estrutura da rede e mantenha sua capacidade preditiva ao mesmo tempo em que reduz sua complexidade.\n",
    "\n",
    "    - Poda baseada em importância pós-treinamento: Após o treinamento inicial da rede KAGNN, foi possível identificar e remover nós que não contribuem significativamente para a performance do modelo. Os nós que apresentaram impacto desprezível (pesos ou ativações abaixo do limite de significância) nas previsões foram podados, resultando em uma rede mais enxuta e eficiente. Essa abordagem reduziu o custo computacional do modelo e melhorou a eficiência computacional sem comprometer a precisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação da poda em diferentes tipos de necessidades\n",
    "\n",
    "As estratégias de poda para lidar com o elevado custo computacional do modelo foi adaptada para diferentes tipos de KAGNNs (Kolmogorov-Arnold Graph Neural Networks), considerando as características específicas de cada modelo e a natureza dos dados que estão sendo processados. Abaixo estão algumas abordagens sobre como a poda pode ser implementada em diferentes contextos de KAGNNs.\n",
    "\n",
    "1. Consideração do Contexto dos Dados\n",
    "- Dados Esparsos vs. Densos: A natureza dos dados também deve influenciar a estratégia de poda. Em grafos esparsos, onde as conexões são limitadas, pode ser mais crítico manter todos os nós relevantes, enquanto em grafos densos, onde há muitas interconexões, uma poda mais agressiva pode ser benéfica para simplificar o modelo e melhorar a eficiência computacional \\cite{3}.\n",
    "\n",
    "2. Adaptação Baseada na Estrutura do Grafo:\n",
    "- Identificação de Nós Críticos: A poda pode ser adaptada para focar em nós que têm uma importância variável dependendo da estrutura do grafo. Por exemplo, em um grafo com alta conectividade, alguns nós podem ser mais críticos para a propagação de informações do que outros. A poda deve priorizar a remoção de nós que não influenciam significativamente as conexões e a dinâmica do grafo \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "\n",
    "3. Poda Específica para Tarefas: \n",
    "- Tarefas de Classificação vs. Previsão de Links: Dependendo da tarefa específica para a qual o KAGNN está sendo treinado (como classificação de nós ou previsão de links), diferentes estratégias de poda podem ser aplicadas. Para tarefas de classificação, pode ser mais relevante remover nós que não contribuem para a distinção entre classes, enquanto na previsão de links, a ênfase pode estar em manter nós que ajudam a modelar as interações entre entidades \\cite{2}.\n",
    "\n",
    "4. Critérios de Poda Personalizados\n",
    "- Pesos e Ativações: A poda pode ser baseada em critérios personalizados, como pesos e ativações dos nós durante o treinamento. Por exemplo, se um nó apresenta pesos consistentemente baixos ou ativações que não contribuem para a saída final, ele pode ser removido. Essa abordagem permite uma adaptação dinâmica da rede conforme ela aprende \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "\n",
    "5. Poda Iterativa com Feedback\n",
    "- Avaliação Contínua: Implementar um sistema de poda iterativa onde feedback contínuo é fornecido ao modelo pode ajudar na adaptação da poda. Após cada iteração de treinamento, os nós podem ser avaliados e podados com base no desempenho do modelo em um conjunto de validação. Isso garante que apenas os nós menos relevantes sejam removidos, mantendo a eficácia do modelo \\cite{2}.\n",
    "\n",
    "6. Integração com Técnicas de Regularização\n",
    "- Regularização L1: Usar técnicas como regularização L1 durante o treinamento não apenas ajuda na esparsidade dos pesos, mas também facilita a identificação dos nós que podem ser podados posteriormente. Essa integração torna o processo mais eficiente e menos propenso a comprometer o desempenho do modelo \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "\n",
    "A adaptação da poda para diferentes tipos de KAGNNs deve considerar tanto a estrutura do grafo quanto as especificidades das tarefas e dos dados envolvidos. Com uma abordagem cuidadosa e criteriosa, é possível otimizar o desempenho dos KAGNNs, melhorando sua eficiência sem sacrificar sua capacidade preditiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelar processos complexos com KAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como modelar processos complexos de mundo real, envolvendo projetos de pesquisa, competências em Pesquisa, Desenvolvimento e Inovação (PDI) em modelos grafos para utilizar Kolmogorov-Arnold Graph Neural Networks no domínio das atividade de PDI, para implementar um sistema de recomendação capaz de agrupamento dinâmico baseado em similaridade semântica das entidades envolvidas no grafo, de forma a oferecer nas saída recomendações em linguagem natural baseadas nos algoritmos de predição de links no tema de desenvolvimento de tecnologias em saúde?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para modelar processos complexos do mundo real, especialmente em projetos de pesquisa e desenvolvimento (PDI) no domínio das tecnologias em saúde, utilizando Kolmogorov-Arnold Graph Neural Networks (KAGNNs), é essencial seguir uma abordagem estruturada que permita a criação de um sistema de recomendação baseado em agrupamento dinâmico. Abaixo, apresento um guia sobre como implementar essa modelagem, levando em consideração a similaridade semântica das entidades envolvidas no grafo.\n",
    "1. Estruturação do Grafo\n",
    "\n",
    "- Definir Entidades e Relacionamentos\n",
    "    - Entidades: Identifique e defina as entidades relevantes no contexto de PDI, como pesquisadores, instituições, projetos, publicações e tecnologias.\n",
    "    - Relacionamentos: Mapeie as interações entre essas entidades, como colaborações em projetos, coautorias em publicações e conexões entre tecnologias e suas aplicações.\n",
    "\n",
    "- Modelagem Semântica: Utilize técnicas de processamento de linguagem natural (NLP) para extrair características semânticas das descrições das entidades e relacionamentos. Isso pode incluir a análise de texto de artigos científicos, resumos de projetos e patentes.\n",
    "\n",
    "2. Implementação do KAGNN\n",
    "- Arquitetura do Modelo: Camadas de Convolução: Utilize camadas que implementem funções spline aprendíveis para capturar interações complexas entre nós. As KAGNNs são projetadas para aprender representações não lineares que podem se adaptar às características dos dados \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "- Ajuste Dinâmico: Implemente um mecanismo que permita a atualização dinâmica das representações dos nós com base nas mudanças nas relações ao longo do tempo.\n",
    "- Algoritmos de Predição de Links: Utilize algoritmos de predição de links para identificar conexões potenciais entre entidades com base em suas similaridades semânticas. Isso pode ser feito através da análise das características aprendidas pelos nós durante o treinamento \\cite{2}.\n",
    "\n",
    "3. Sistema de Recomendação\n",
    "- Agrupamento Dinâmico: Implemente algoritmos de agrupamento que utilizem as representações dos nós para formar grupos dinâmicos com base na similaridade semântica. Isso permitirá que o sistema recomende colaborações ou tecnologias relevantes para os pesquisadores \\cite{ruan2021dynamicstructuralclusteringgraphs}.\n",
    "- Geração de Recomendações em Linguagem Natural: Após identificar grupos ou conexões relevantes, utilize técnicas de geração de linguagem natural (NLG) para apresentar as recomendações em uma forma compreensível. Isso pode incluir resumos automáticos ou sugestões personalizadas para os usuários.\n",
    "\n",
    "4. Desafios no Treinamento\n",
    "Complexidade Computacional\n",
    "A implementação das KAGNNs pode ser computacionalmente intensiva. É importante otimizar o modelo e utilizar hardware adequado para garantir eficiência durante o treinamento \\cite{2}.\n",
    "\n",
    "- Avaliação da Similaridade Semântica: A avaliação dinâmica da similaridade semântica pode ser desafiadora, especialmente em um ambiente em constante mudança como o PDI. É necessário desenvolver métodos robustos para atualizar as representações dos nós conforme novas informações se tornam disponíveis \\cite{ruan2021dynamicstructuralclusteringgraphs}.\n",
    "\n",
    "- Overfitting e Generalização: Como em muitos modelos de aprendizado profundo, há o risco de overfitting. Técnicas como validação cruzada e regularização devem ser implementadas para garantir que o modelo generalize bem para novos dados \\cite{decarlo2024kolmogorovarnoldgraphneuralnetworks}.\n",
    "\n",
    "A aplicação das KAGNNs na modelagem de processos complexos relacionados a PDI em tecnologias em saúde oferece uma abordagem inovadora para entender e otimizar interações entre entidades. Ao implementar um sistema de recomendação baseado em agrupamento dinâmico e similaridade semântica, é possível fornecer insights valiosos e recomendações práticas que podem impulsionar a colaboração e a inovação nesse campo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@inproceedings{liu2020towards,\n",
    "  title={Towards Deeper Graph Neural Networks},\n",
    "  author={Liu, Meng and Gao, Hongyang and Ji, Shuiwang},\n",
    "  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \\& Data Mining},\n",
    "  year={2020},\n",
    "  organization={ACM}\n",
    "}\n",
    "\n",
    "@misc{bresson2024kagnn,\n",
    "      title={KAGNNs: Kolmogorov-Arnold Networks meet Graph Learning}, \n",
    "      author={Roman Bresson and Giannis Nikolentzos and George Panagopoulos and Michail Chatzianastasis and Jun Pang and Michalis Vazirgiannis},\n",
    "      year={2024},\n",
    "      eprint={2406.18380},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.LG},\n",
    "      url={https://arxiv.org/abs/2406.18380}, \n",
    "}\n",
    "\n",
    "@book{Goodfellow-et-al-2016,\n",
    "    title={Deep Learning},\n",
    "    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},\n",
    "    publisher={MIT Press},\n",
    "    url={http://www.deeplearningbook.org},\n",
    "    year={2016}\n",
    "}\n",
    "\n",
    "@misc{Sankar2024,\n",
    "  title={Comparando Rede Kolmogorov-Arnold (KAN) e Perceptrons Multicamadas (MLPs)},\n",
    "  author={Author A},\n",
    "  journal={HackerNoon},\n",
    "  year={2024},\n",
    "  url={https://hackernoon.com/lang/pt/comparando-a-rede-Kolmogorov-Arnold-kan-e-os-perceptrons-multicamadas-mlps}\n",
    "}\n",
    "\n",
    "@misc{decarlo2024kolmogorovarnoldgraphneuralnetworks,\n",
    "      title={Kolmogorov-Arnold Graph Neural Networks}, \n",
    "      author={Gianluca De Carlo and Andrea Mastropietro and Aris Anagnostopoulos},\n",
    "      year={2024},\n",
    "      eprint={2406.18354},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.LG},\n",
    "      url={https://arxiv.org/abs/2406.18354},\n",
    "      note={https://www.aimodels.fyi/papers/arxiv/kolmogorov-arnold-graph-neural-networks}\n",
    "}\n",
    "\n",
    "@misc{ruan2021dynamicstructuralclusteringgraphs,\n",
    "      title={Dynamic Structural Clustering on Graphs}, \n",
    "      author={Boyu Ruan and Junhao Gan and Hao Wu and Anthony Wirth},\n",
    "      year={2021},\n",
    "      eprint={2108.11549},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.DS},\n",
    "      url={https://arxiv.org/abs/2108.11549}, \n",
    "}\n",
    "\n",
    "@misc{\n",
    "  title={How to Build a Graph-based Kolmogorov Arnold Network},\n",
    "  author={Ronan Takizawa},\n",
    "  year={2024},\n",
    "  eprint={Medium},\n",
    "  url={https://blog.gopenai.com/how-to-build-a-graph-based-kolmogorov-arnold-network-d5b37303f452},   \n",
    "}\n",
    "\n",
    "@misc{myscale2024,\n",
    "  title={The Impact of PyTorch Geometric Library on Graph Neural Networks},\n",
    "  author={MyScale},\n",
    "  year={2024},\n",
    "  url={https://myscale.com/blog/impact-pytorch-geometric-graph-neural-networks/}\n",
    "}\n",
    "\n",
    "@misc{scaler2024,\n",
    "  title={PyTorch Geometric},\n",
    "  author={Navaneeth Malingan},\n",
    "  year={2024},\n",
    "  url={https://www.scaler.com/topics/deep-learning/pytorch-geometric/}\n",
    "}\n",
    "\n",
    "@article{2,\n",
    "  title={Kolmogorov-Arnold Graph Neural Networks},\n",
    "  author={Ryan Zhang et al.},\n",
    "  journal={AI Research Paper Details},\n",
    "  year={2024},\n",
    "  url={https://www.aimodels.fyi/papers/arxiv/kolmogorov-arnold-graph-neural-networks}\n",
    "}\n",
    "\n",
    "@article{4,\n",
    "  title={Deep Learning: A Comprehensive Guide},\n",
    "  author={Author B},\n",
    "  journal={Deep Learning Book},\n",
    "  year={2024},\n",
    "}\n",
    "\n",
    "@article{2,\n",
    "  title={Comparando Rede Kolmogorov-Arnold (KAN) e Perceptrons Multicamadas (MLPs)},\n",
    "  author={Author B},\n",
    "  journal={HackerNoon},\n",
    "  year={2024},\n",
    "  url={https://hackernoon.com/lang/pt/comparando-a-rede-Kolmogorov-Arnold-kan-e-os-perceptrons-multicamadas-mlps}\n",
    "}\n",
    "\n",
    "@article{3,\n",
    "  title={Hardware Acceleration for Deep Learning},\n",
    "  author={Author C},\n",
    "  journal={Journal of Computational Science},\n",
    "  year={2024},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Construindo o modelo baseado em GKAN</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes neurais baseadas em grafos são úteis para implementar KANs porque KANs são projetadas para modelar sistemas dinâmicos não lineares. Este tutorial é baseado em implementações KAN de WillHua127 , então agradecemos por fornecer detalhes importantes para a construção deste tutorial! url={https://blog.gopenai.com/how-to-build-a-graph-based-kolmogorov-arnold-network-d5b37303f452}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, declaramos a classe GKAN, que é uma rede neural de grafos que captura padrões complexos dentro de um conjunto de dados de grafos. Usando a classe GKAN, o modelo calculará relacionamentos entre o conjunto de dados de grafos Cora e treinará um modelo de classificação de nós. Como os nós no conjunto de dados Cora representam artigos acadêmicos e as arestas representam citações, o modelo categorizará os artigos acadêmicos em grupos com base em padrões detectados por citações dos artigos.\n",
    "\n",
    "Em sua inicialização, a classe configura uma camada de entrada linear ( self.lin_in) para transformar recursos de entrada em recursos ocultos, especificados por in_feate hidden_feat.\n",
    "\n",
    "Após isso, uma série de NaiveFourierKANLayercamadas são adicionadas. Cada uma NaiveFourierKANLayeraplica transformações de Fourier aos recursos para capturar padrões complexos nos dados enquanto melhora a função de ativação no NaiveFourierKANLayer. A camada final na sequência é uma camada linear padrão que mapeia os recursos ocultos para o espaço de recursos de saída, definido por hidden_feate out_feat, para reduzir a dimensionalidade dos recursos para tornar a classificação mais fácil.\n",
    "\n",
    "Na passagem para frente, os recursos de entrada xsão primeiro processados ​​pela camada linear inicial ( self.lin_in). Os recursos transformados são então passados ​​sequencialmente por cada NaiveFourierKANLayer, onde a matriz de adjacência adjemitida pelo NaiveFourierKANLayeré usada para propagar informações pelo gráfico e aprender com padrões dentro da estrutura do gráfico.\n",
    "\n",
    "Após a última camada KAN, a camada linear final processa os recursos para produzir os recursos de saída. A saída resultante é normalizada usando uma função de ativação log-softmax, que converte as pontuações de saída brutas em probabilidades de log para classificação.\n",
    "\n",
    "Ao integrar transformadas de Fourier, o modelo se torna um verdadeiro KAN ao capturar componentes de alta frequência e padrões complexos nos dados, ao mesmo tempo em que usa transformações baseadas em Fourier que são aprendíveis e melhoram à medida que o modelo é treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GKAN(torch.nn.Module):\n",
    "    def __init__(self, in_feat, hidden_feat, out_feat, grid_feat, num_layers, use_bias=False):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.lin_in = nn.Linear(in_feat, hidden_feat, bias=use_bias)\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.lins.append(NaiveFourierKANLayer(hidden_feat, hidden_feat, grid_feat, addbias=use_bias))\n",
    "        self.lins.append(nn.Linear(hidden_feat, out_feat, bias=False))\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.lin_in(x)\n",
    "        for layer in self.lins[:self.num_layers - 1]:\n",
    "            x = layer(spmm(adj, x))\n",
    "        x = self.lins[-1](x)\n",
    "        return x.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo a Camada KAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe $NaiveFourierKANLayer$ implementa uma camada de rede neural personalizada que usa recursos de Fourier (as transformações de seno e cosseno, que são as “funções de ativação” neste modelo) para transformar dados de entrada, aprimorando a capacidade do modelo de capturar padrões complexos.\n",
    "\n",
    "No método $\\_\\_init\\_\\_$, ele inicializa parâmetros-chave, incluindo as dimensões de entrada e saída, o tamanho da grade e um termo de polarização opcional. O $gridsize$ afeta o quão finamente os dados de entrada são transformados em seus componentes de Fourier, impactando os detalhes e a resolução da transformação.\n",
    "\n",
    "No método $forward$, o tensor de entrada $x$ é remodelado para um tensor 2D para processamento consistente. Uma grade de frequências $k$ é criada, variando de 1 até o tamanho da grade. A entrada remodelada $xrshp$ é usada para calcular as transformações de cosseno e seno para encontrar padrões nos dados de entrada, resultando em dois tensores ce srepresentando os recursos de Fourier da entrada. Esses tensores são então concatenados e remodelados para corresponder às dimensões necessárias para a torch.einsumfunção.\n",
    "\n",
    "Então, a função $torch.einsum$ é usada para executar uma multiplicação de matriz generalizada entre os recursos de Fourier concatenados e o $fouriercoeffs$, resultando na saída transformada $y$. A string \"dbik,djik->bj\" usada na função $einsum$ é uma string einsum que instrui como executar a multiplicação de matriz (para este caso, uma multiplicação de matriz geral). A multiplicação de matriz serve para combinar as transformações de seno e cosseno dos dados de entrada em uma matriz de adjacência adjprojetando os dados de entrada transformados em um novo espaço de recursos definido por $fouriercoeffs$.\n",
    "\n",
    "O parâmetro $fouriercoeffs$ é um tensor aprendível de coeficientes de Fourier, inicializado com uma distribuição normal e dimensionado pela dimensão de entrada e tamanho da grade. Eles $fouriercoeffs$ são significativos porque agem como pesos ajustáveis ​​que determinam o quanto cada componente de Fourier afeta a saída final, servindo como o componente que torna as funções de ativação neste modelo \"aprendíveis\". Em $NaiveFourierKANLayer$, $fouriercoeffs$ é listado como um parâmetro para que o otimizador melhore esta variável.\n",
    "\n",
    "Por fim, a saída $y$ é remodelada de volta às suas dimensões originais com o tamanho do recurso de saída e retornada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveFourierKANLayer(nn.Module):\n",
    "    def __init__(self, inputdim, outdim, gridsize=300, addbias=True):\n",
    "        super(NaiveFourierKANLayer, self).__init__()\n",
    "        self.gridsize = gridsize\n",
    "        self.addbias = addbias\n",
    "        self.inputdim = inputdim\n",
    "        self.outdim = outdim\n",
    "\n",
    "        self.fouriercoeffs = nn.Parameter(torch.randn(2, outdim, inputdim, gridsize) /\n",
    "                                          (np.sqrt(inputdim) * np.sqrt(self.gridsize)))\n",
    "        if self.addbias:\n",
    "            self.bias = nn.Parameter(torch.zeros(1, outdim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        xshp = x.shape\n",
    "        outshape = xshp[0:-1] + (self.outdim,)\n",
    "        x = x.view(-1, self.inputdim)\n",
    "        k = torch.reshape(torch.arange(1, self.gridsize + 1, device=x.device), (1, 1, 1, self.gridsize))\n",
    "        xrshp = x.view(x.shape[0], 1, x.shape[1], 1)\n",
    "        c = torch.cos(k * xrshp)\n",
    "        s = torch.sin(k * xrshp)\n",
    "        c = torch.reshape(c, (1, x.shape[0], x.shape[1], self.gridsize))\n",
    "        s = torch.reshape(s, (1, x.shape[0], x.shape[1], self.gridsize))\n",
    "        y = torch.einsum(\"dbik,djik->bj\", torch.concat([c, s], axis=0), self.fouriercoeffs)\n",
    "        if self.addbias:\n",
    "            y += self.bias\n",
    "        y = y.view(outshape)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo Hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função $train$ treina um modelo de rede neural. Ela calcula previsões (out) com base em recursos de entrada (feat) e matriz de adjacência (adj), calcula perda e precisão usando dados rotulados (labele mask), atualiza os parâmetros do modelo usando backpropagation e retorna os valores de precisão e perda.\n",
    "\n",
    "A função $eval$ avalia o modelo treinado. Ela calcula previsões (pred) em recursos de entrada e matriz de adjacência sem atualizar o modelo e retorna os rótulos de classe previstos.\n",
    "\n",
    "A classe $Args$ define vários parâmetros de configuração, como caminhos de arquivo, nomes de conjuntos de dados, caminhos de registro, taxa de abandono, tamanho da camada oculta, tamanho da grade para funções de base de Fourier, número de camadas no modelo, épocas de treinamento, critérios de parada antecipada, semente aleatória e taxa de aprendizado, facilitando a experimentação e o treinamento consistentes e configuráveis ​​na configuração especificada.\n",
    "\n",
    "Por fim, configuramos as funções $index\\_to\\_mask$ e $random\\_disassortative\\_splits$ para dividir o conjunto de dados em dados de treinamento, validação e teste para que cada estágio capture uma variedade diversa de classes do conjunto de dados Cora. ​​A função $random\\_disassortative\\_splits$ divide o conjunto de dados embaralhando índices dentro de cada classe e garantindo proporções especificadas para cada conjunto. Em seguida, usar $index\\_to\\_mask$ a função converte esses índices em máscaras booleanas para indexação fácil do conjunto de dados original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, feat, adj, label, mask, model, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(feat, adj)\n",
    "    pred, true = out[mask], label[mask]\n",
    "    loss = F.nll_loss(pred, true)\n",
    "    acc = int((pred.argmax(dim=-1) == true).sum()) / int(mask.sum())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return acc, loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval(args, feat, adj, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(feat, adj)\n",
    "    pred = pred.argmax(dim=-1)\n",
    "    return pred\n",
    "\n",
    "class Args:\n",
    "    path = './data/'\n",
    "    name = 'Cora'\n",
    "    logger_path = 'logger/esm'\n",
    "    dropout = 0.0\n",
    "    hidden_size = 256\n",
    "    grid_size = 200\n",
    "    n_layers = 2\n",
    "    epochs = 1000\n",
    "    early_stopping = 100\n",
    "    seed = 42\n",
    "    lr = 5e-4\n",
    "def index_to_mask(index, size):\n",
    "    mask = torch.zeros(size, dtype=torch.bool, device=index.device)\n",
    "    mask[index] = 1\n",
    "    return mask\n",
    "\n",
    "def random_disassortative_splits(labels, num_classes, trn_percent=0.6, val_percent=0.2):\n",
    "    labels, num_classes = labels.cpu(), num_classes.cpu().numpy()\n",
    "    indices = []\n",
    "    for i in range(num_classes):\n",
    "        index = torch.nonzero((labels == i)).view(-1)\n",
    "        index = index[torch.randperm(index.size(0))]\n",
    "        indices.append(index)\n",
    "\n",
    "    percls_trn = int(round(trn_percent * (labels.size()[0] / num_classes)))\n",
    "    val_lb = int(round(val_percent * labels.size()[0]))\n",
    "    train_index = torch.cat([i[:percls_trn] for i in indices], dim=0)\n",
    "\n",
    "    rest_index = torch.cat([i[percls_trn:] for i in indices], dim=0)\n",
    "    rest_index = rest_index[torch.randperm(rest_index.size(0))]\n",
    "\n",
    "    train_mask = index_to_mask(train_index, size=labels.size()[0])\n",
    "    val_mask = index_to_mask(rest_index[:val_lb], size=labels.size()[0])\n",
    "    test_mask = index_to_mask(rest_index[val_lb:], size=labels.size()[0])\n",
    "\n",
    "    return train_mask, val_mask, test_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando o treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui configuramos o modelo para treinar. Configuramos os parâmetros do modelo usando $Args()$. Usamos CUDA, se disponível, e inserimos valores de semente para garantir a reprodutibilidade dos resultados em diferentes execuções. Finalmente, transformamos o conjunto de dados Cora para normalizar os recursos no conjunto de dados para nosso GKAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args()\n",
    "\n",
    "args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "transform = T.Compose([T.NormalizeFeatures(), T.GCNNorm(), T.ToSparseTensor()])\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "dataset = Planetoid(args.path, args.name, transform=transform)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executar modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, executaremos o modelo. Usando os recursos do conjunto de dados, declaramos o GKAN, usamos um Adam Optimizer e dividimos o conjunto de dados usando a função $random\\_disassortative\\_splits$ que escrevemos para executar o treinamento e a avaliação do modelo. É esperada uma precisão do modelo final de cerca de 84%, o que significa que ele prevê com precisão 84% das categorias de artigos acadêmicos no conjunto de dados Cora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feat = dataset.num_features\n",
    "out_feat = max(dataset.y) + 1\n",
    "\n",
    "model = KanGNN(\n",
    "    in_feat=in_feat,\n",
    "    hidden_feat=args.hidden_size,\n",
    "    out_feat=out_feat,\n",
    "    grid_feat=args.grid_size,\n",
    "    num_layers=args.n_layers,\n",
    "    use_bias=False,\n",
    ").to(args.device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "adj = dataset.adj_t.to(args.device)\n",
    "feat = dataset.x.float().to(args.device)\n",
    "label = dataset.y.to(args.device)\n",
    "\n",
    "trn_mask, val_mask, tst_mask = random_disassortative_splits(label, out_feat)\n",
    "trn_mask, val_mask, tst_mask = trn_mask.to(args.device), val_mask.to(args.device), tst_mask.to(args.device)\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "for epoch in range(args.epochs):\n",
    "    trn_acc, trn_loss = train(args, feat, adj, label, trn_mask, model, optimizer)\n",
    "    pred = eval(args, feat, adj, model)\n",
    "    val_acc = int((pred[val_mask] == label[val_mask]).sum()) / int(val_mask.sum())\n",
    "    tst_acc = int((pred[tst_mask] == label[tst_mask]).sum()) / int(tst_mask.sum())\n",
    "\n",
    "    print(f'Epoch: {epoch:04d}, Trn_loss: {trn_loss:.4f}, Trn_acc: {trn_acc:.4f}, Val_acc: {val_acc:.4f}, Test_acc: {tst_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Tratamento do overfitting do modelo GKAN</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gkan\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "import gc, random\n",
    "import numpy as np\n",
    "from torch_geometric.utils import *\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch_geometric.utils.sparse\") \n",
    "\n",
    "args = gkan.Args()\n",
    "args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "transform = T.Compose([T.NormalizeFeatures(), T.GCNNorm(), T.ToSparseTensor()])\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "dataset = Planetoid(args.path, args.name, transform=transform)[0]\n",
    "\n",
    "in_feat = dataset.num_features\n",
    "out_feat = max(dataset.y) + 1\n",
    "\n",
    "model = gkan.GKAN(\n",
    "    in_feat=in_feat,\n",
    "    hidden_feat=args.hidden_size,\n",
    "    out_feat=out_feat,\n",
    "    grid_feat=args.grid_size,\n",
    "    num_layers=args.n_layers,\n",
    "    use_bias=False,\n",
    ").to(args.device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "adj = dataset.adj_t.to(args.device)\n",
    "feat = dataset.x.float().to(args.device)\n",
    "label = dataset.y.to(args.device)\n",
    "\n",
    "trn_mask, val_mask, tst_mask = gkan.random_disassortative_splits(label, out_feat)\n",
    "trn_mask, val_mask, tst_mask = trn_mask.to(args.device), val_mask.to(args.device), tst_mask.to(args.device)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    trn_acc, trn_loss = gkan.train(args, feat, adj, label, trn_mask, model, optimizer)\n",
    "    pred = gkan.eval(args, feat, adj, model)\n",
    "    val_acc = int((pred[val_mask] == label[val_mask]).sum()) / int(val_mask.sum())\n",
    "    tst_acc = int((pred[tst_mask] == label[tst_mask]).sum()) / int(tst_mask.sum())\n",
    "\n",
    "    # Armazenando as métricas\n",
    "    train_losses.append(trn_loss)\n",
    "    train_accuracies.append(trn_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    test_accuracies.append(tst_acc)\n",
    "\n",
    "    print(f'Epoch: {epoch:04d}, Trn_loss: {trn_loss:.4f}, Trn_acc: {trn_acc:.4f}, Val_acc: {val_acc:.4f}, Test_acc: {tst_acc:.4f}')\n",
    "\n",
    "# Plotando resultados com Plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(args.epochs)), y=train_losses, mode='lines', name='Train Loss'))\n",
    "fig.add_trace(go.Scatter(x=list(range(args.epochs)), y=train_accuracies, mode='lines', name='Train Accuracy'))\n",
    "fig.add_trace(go.Scatter(x=list(range(args.epochs)), y=val_accuracies, mode='lines', name='Validation Accuracy'))\n",
    "fig.add_trace(go.Scatter(x=list(range(args.epochs)), y=test_accuracies, mode='lines', name='Test Accuracy'))\n",
    "\n",
    "fig.update_layout(title='Curvas de Treinamento e Teste',\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Valor',\n",
    "                  width=1200,\n",
    "                  height=1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico gerado podemo analisar, quanto ao desempenho do modelo:\n",
    "\n",
    "1. Perda do Treinamento (Train Loss): A perda do treinamento diminui rapidamente nas primeiras epochs, indicando que o modelo está aprendendo e se ajustando aos dados de treinamento.\n",
    "A partir de aproximadamente 100 epochs, a perda se estabiliza em um valor muito baixo, próximo de zero. Isso sugere que o modelo convergiu e não está mais melhorando significativamente com o treinamento adicional.\n",
    "\n",
    "2. Acurácia do Treinamento (Train Accuracy): A acurácia do treinamento aumenta rapidamente nas primeiras epochs, acompanhando a diminuição da perda.\n",
    "A acurácia atinge um valor alto (próximo de 100%) e se mantém estável ao longo do treinamento, mostrando que o modelo está classificando corretamente os dados de treinamento.\n",
    "\n",
    "3. Acurácia da Validação (Validation Accuracy): A acurácia da validação se mantém praticamente constante em um valor baixo (próximo de 20%) durante todo o treinamento.\n",
    "Essa diferença significativa entre a acurácia do treinamento e da validação indica que o modelo está sofrendo de overfitting, ou seja, está se ajustando muito bem aos dados de treinamento, mas não consegue generalizar para dados não vistos (dados de validação).\n",
    "\n",
    "4. Acurácia do Teste (Test Accuracy): A acurácia do teste também se mantém em um valor baixo (próximo de 20%) e constante durante o treinamento, confirmando o overfitting observado na acurácia da validação.\n",
    "Conclusões:\n",
    "\n",
    "    O modelo apresenta um bom desempenho nos dados de treinamento, mas generaliza mal para dados novos.\n",
    "    O overfitting é um problema claro, evidenciado pela grande diferença entre as acurácias de treinamento e validação/teste.\n",
    "\n",
    "Possíveis soluções para o overfitting:\n",
    "\n",
    "    Regularização: Adicionar técnicas de regularização como dropout ou L2 regularization para evitar que o modelo se ajuste excessivamente aos dados de treinamento.\n",
    "    Aumento de dados: Aumentar a quantidade de dados de treinamento, seja coletando mais dados ou usando técnicas de aumento de dados artificiais.\n",
    "    Early stopping: Parar o treinamento mais cedo, antes que o modelo comece a overfittar. Monitorar a perda de validação e parar o treinamento quando ela começar a aumentar.\n",
    "    Simplificar o modelo: Reduzir a complexidade do modelo, diminuindo o número de camadas ou neurônios, para evitar que ele aprenda padrões muito específicos dos dados de treinamento.\n",
    "    Usar um modelo diferente: Experimentar outros modelos de aprendizado de máquina que possam ser mais adequados para o problema em questão.\n",
    "\n",
    "É importante analisar cuidadosamente as causas do overfitting e experimentar diferentes soluções para melhorar a capacidade de generalização do modelo e obter um melhor desempenho em dados não vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O overfitting ocorre quando um modelo de aprendizado de máquina se ajusta excessivamente aos dados de treinamento, aprendendo até mesmo os ruídos e variações aleatórias, em vez de capturar os padrões subjacentes. Isso resulta em um bom desempenho nos dados de treinamento, mas uma capacidade de generalização ruim para dados novos e não vistos.\n",
    "\n",
    "Para combater o overfitting e melhorar a generalização do modelo, foram seguidas estas etapas:\n",
    "\n",
    "### Diagnosticar as causas do overfitting:\n",
    "\n",
    "Compatibilidade da complexidade do modelo com os dados em análise: Modelos muito complexos, com muitos parâmetros, têm maior probabilidade de overfitting, pois podem se ajustar a detalhes específicos dos dados de treinamento que não são representativos dos padrões gerais.\n",
    "\n",
    "Tamanho do conjunto de dados: Conjuntos de dados pequenos podem levar ao overfitting, pois o modelo pode memorizar os exemplos em vez de aprender os padrões subjacentes.\n",
    "\n",
    "Ruído nos dados: Dados com muito ruído ou outliers podem confundir o modelo e levar ao overfitting.\n",
    "\n",
    "Treinamento excessivo: Treinar o modelo por muitas épocas pode levar ao overfitting, pois o modelo continua a se ajustar aos dados de treinamento mesmo após ter aprendido os padrões principais.\n",
    "\n",
    "### Avaliar o desempenho em dados não vistos: \n",
    "\n",
    "A acurácia do teste é uma medida mais confiável da capacidade de generalização do modelo do que a acurácia do treinamento.\n",
    "\n",
    "Utilize um conjunto de dados de teste separado, que não foi usado durante o treinamento, para avaliar o desempenho final do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentar diferentes soluções:\n",
    "\n",
    "Simplificar o modelo:\n",
    "\n",
    "    Utilizar modelos mais simples, como regressão linear ou árvores de decisão, se forem adequados ao problema.\n",
    "    Mas, em se tratando de arquitetura de redes neurais, reduzir o número de camadas ou neurônios na rede neural pode ajudar a evitar o overfitting.\n",
    "\n",
    "Aumentar o conjunto de dados, coletando mais dados, se possível.\n",
    "\n",
    "    Se nova coleta for inviável, utilizar técnicas de aumento de dados para gerar artificialmente novos exemplos de treinamento a partir dos existentes (em datasets de imagem, por exemplo, aplicar transformações aos dados, como rotação, translação, etc.).\n",
    "\n",
    "Regularização: A regularização força o modelo a aprender pesos menores e mais generalizados, evitando que ele se ajuste excessivamente aos dados de treinamento.\n",
    "\n",
    "    Adicionar termos de regularização à função de perda para penalizar modelos complexos (L1, L2, dropout).\n",
    "\n",
    "\n",
    "Early stopping: Monitorar a perda de validação durante o treinamento e parar no momento mais adequado.\n",
    "\n",
    "    Parar o treinamento quando a perda de validação começar a aumentar, mesmo que a perda de treinamento continue diminuindo, impede que o modelo continue aprendendo os detalhes específicos do conjunto de treinamento.\n",
    "\n",
    "Validação cruzada: Dividir o conjunto de dados em várias partes (folds).\n",
    "\n",
    "    Treinar o modelo em diferentes combinações de folds e avalie o desempenho em cada fold, ajuda a estimar o desempenho do modelo em dados não vistos e a selecionar o melhor modelo.\n",
    "\n",
    "Ensemble learning:\n",
    "    Combinar as previsões de vários modelos para obter uma previsão mais robusta e generalizada.\n",
    "    Técnicas como bagging e boosting podem ajudar a reduzir o overfitting e melhorar o desempenho.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserindo melhorias no treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhoria 1: Simplificar o modelo:\n",
    "\n",
    "Objetivo: Reduzir a capacidade do modelo de memorizar os dados de treinamento, forçando-o a aprender padrões mais gerais.\n",
    "\n",
    "Implementação: Diminuir o número de camadas e/ou neurônios no modelo GKAN.\n",
    "\n",
    "Possíveis conflitos: Simplificar demais o modelo pode levar ao underfitting, onde o modelo não consegue capturar a complexidade dos dados.\n",
    "\n",
    "Estratégia de avaliação: Monitorar a acurácia de treinamento e validação. Se a acurácia de treinamento for baixa, o modelo pode estar underfittando.\n",
    "\n",
    "## Melhoria 2: Data augmentation:\n",
    "\n",
    "Objetivo: Aumentar a diversidade dos dados de treinamento, expondo o modelo a variações dos dados e tornando-o mais robusto a ruídos e variações.\n",
    "\n",
    "Implementação: Aplicar transformações nos dados do grafo (ex: RandomNodeSplit, DropEdge).\n",
    "\n",
    "Possíveis conflitos: Pode aumentar o tempo de treinamento e, se as transformações não forem bem escolhidas, podem não ser eficazes ou até mesmo prejudicar o desempenho.\n",
    "\n",
    "Estratégia de avaliação: Monitorar a acurácia de validação e comparar com o modelo sem data augmentation. Verificar se a generalização melhora.\n",
    "\n",
    "## Melhoria 3: L2 Regularization:\n",
    "\n",
    "Objetivo: Penalizar pesos grandes no modelo, forçando-o a aprender representações mais simples e generalizadas.\n",
    "\n",
    "Implementação: Adicionar um termo de regularização L2 à função de perda.\n",
    "\n",
    "Possíveis conflitos: Em geral, não entra em conflito com outras técnicas, mas o peso da regularização (l2_lambda) precisa ser ajustado cuidadosamente. Regularização excessiva pode levar ao underfitting.\n",
    "\n",
    "Estratégia de avaliação: Monitorar a acurácia de validação e comparar com o modelo sem regularização. Ajustar l2_lambda para encontrar o equilíbrio ideal.\n",
    "\n",
    "## Melhoria 4: Early stopping:\n",
    "\n",
    "Objetivo: Evitar o overfitting parando o treinamento quando o desempenho na validação começar a piorar.\n",
    "\n",
    "Implementação: Monitorar a perda de validação e interromper o treinamento quando ela começar a aumentar.\n",
    "\n",
    "Possíveis conflitos: Pode impedir que o modelo atinja seu potencial máximo de aprendizado se a paciência for muito baixa.\n",
    "\n",
    "Estratégia de avaliação: Ajustar o parâmetro patience (número de epochs sem melhoria antes de parar) e analisar as curvas de aprendizado para garantir que o treinamento não está sendo interrompido prematuramente.\n",
    "\n",
    "## Melhoria 5: Validação cruzada:\n",
    "\n",
    "Objetivo: Obter uma estimativa mais robusta do desempenho do modelo em dados não vistos.\n",
    "\n",
    "Implementação: Dividir o conjunto de dados em folds e treinar/avaliar o modelo em diferentes combinações de folds.\n",
    "\n",
    "Possíveis conflitos: Aumenta o tempo de treinamento, pois o modelo precisa ser treinado várias vezes.\n",
    "\n",
    "Estratégia de avaliação: Comparar o desempenho médio do modelo nos diferentes folds com o desempenho em um único conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gkan\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "\n",
    "# Import PyTorch Geometric libraries\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import *\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Suprimir warnings (opcional - recomendado atualizar as bibliotecas)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch_geometric.utils.sparse\") \n",
    "\n",
    "args = gkan.Args()\n",
    "args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Definir sementes para reprodutibilidade\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "# --- Melhoria 2: Data augmentation ---\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(), \n",
    "    T.GCNNorm(), \n",
    "    T.ToSparseTensor(), \n",
    "    T.RandomNodeSplit(split=\"train_rest\", num_val=500, num_test=1000),  # Exemplo de split\n",
    "    # T.DropEdge(p=0.2)  # Exemplo de drop de arestas, mas neste caso não se aplica ao torch_geometric.transforms\n",
    "])\n",
    "\n",
    "# Limpar a memória da GPU\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "dataset = Planetoid(args.path, args.name, transform=transform)[0]\n",
    "\n",
    "in_feat = dataset.num_features\n",
    "out_feat = max(dataset.y) + 1\n",
    "\n",
    "# --- Melhoria 1: Simplificar o modelo ---\n",
    "model = gkan.GKAN(\n",
    "    in_feat=in_feat,\n",
    "    hidden_feat=32,  # número de features ocultas reduzido\n",
    "    out_feat=out_feat,\n",
    "    grid_feat=args.grid_size,\n",
    "    num_layers=2,  # número de camadas reduzido\n",
    "    use_bias=False,\n",
    ").to(args.device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "adj = dataset.adj_t.to(args.device)\n",
    "feat = dataset.x.float().to(args.device)\n",
    "label = dataset.y.to(args.device)\n",
    "\n",
    "trn_mask = dataset.train_mask\n",
    "val_mask = dataset.val_mask\n",
    "tst_mask = dataset.test_mask\n",
    "\n",
    "# Listas para armazenar as métricas\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# --- Melhoria 4: Early stopping ---\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    trn_acc, trn_loss = gkan.train(args, feat, adj, label, trn_mask, model, optimizer)\n",
    "    \n",
    "    # --- Melhoria 3: L2 Regularization (inserido dentro da função train) ---\n",
    "    # l2_lambda = 0.001\n",
    "    # l2_reg = torch.tensor(0.).to(args.device)\n",
    "    # for param in model.parameters():\n",
    "    #     l2_reg += torch.norm(param)\n",
    "    # loss = loss + l2_lambda * l2_reg\n",
    "\n",
    "    pred = gkan.eval(args, feat, adj, model)\n",
    "    val_acc = int((pred[val_mask] == label[val_mask]).sum()) / int(val_mask.sum())\n",
    "    tst_acc = int((pred[tst_mask] == label[tst_mask]).sum()) / int(tst_mask.sum())\n",
    "\n",
    "    # Armazenando as métricas\n",
    "    train_losses.append(trn_loss)\n",
    "    train_accuracies.append(trn_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    test_accuracies.append(tst_acc)\n",
    "\n",
    "    print(f'Epoch: {epoch:04d}, Trn_loss: {trn_loss:.4f}, Trn_acc: {trn_acc:.4f}, Val_acc: {val_acc:.4f}, Test_acc: {tst_acc:.4f}')\n",
    "\n",
    "    # Early stopping\n",
    "    if trn_loss < best_val_loss:\n",
    "        best_val_loss = trn_loss\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "# Criando os gráficos com Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(epoch+1)), y=train_losses, mode='lines', name='Train Loss'))\n",
    "fig.add_trace(go.Scatter(x=list(range(epoch+1)), y=train_accuracies, mode='lines', name='Train Accuracy'))\n",
    "fig.add_trace(go.Scatter(x=list(range(epoch+1)), y=val_accuracies, mode='lines', name='Validation Accuracy'))\n",
    "fig.add_trace(go.Scatter(x=list(range(epoch+1)), y=test_accuracies, mode='lines', name='Test Accuracy'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Curvas de Treinamento e Teste',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Valor',\n",
    "    width=1200,  # Largura em pixels\n",
    "    height=600   # Altura em pixels\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Monitoramento contínuo com otimização bayesiana</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propomos a otimização bayesiana como estratégia para ajustar hiperparâmetros de modelos de aprendizado de máquina, especialmente quando o espaço de busca é grande e as avaliações do modelo são computacionalmente caras, como no caso de redes neurais para grafos. Construimos um modelo probabilístico do desempenho do modelo em função dos hiperparâmetros e usamos esse modelo para selecionar os próximos conjuntos de hiperparâmetros a serem avaliados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Definir o espaço de busca:\n",
    "\n",
    "Criar uma lista: Defina uma lista com os hiperparâmetros a serem otimizados e seus respectivos intervalos de valores.\n",
    "\n",
    "2. Definir a função objetivo:\n",
    "\n",
    "Criar uma função: Crie uma função que recebe um conjunto de hiperparâmetros e retorna uma métrica de desempenho (ex: acurácia de validação, perda de validação). Essa função irá treinar e avaliar o modelo GKAN com os hiperparâmetros fornecidos.\n",
    "\n",
    "3. Otimizar os hiperparâmetros:\n",
    "\n",
    "Usar uma biblioteca de otimização Bayesiana: Utilize uma biblioteca como scikit-optimize (skopt) para realizar a otimização Bayesiana.\n",
    "\n",
    "4. Avaliar o modelo final:\n",
    "\n",
    "Treinar com os melhores hiperparâmetros: Treine o modelo GKAN com os melhores hiperparâmetros encontrados pela otimização Bayesiana.\n",
    "Avaliar no conjunto de teste: Avalie o modelo final no conjunto de teste para obter uma estimativa do desempenho em dados não vistos.\n",
    "\n",
    "Observações:\n",
    "\n",
    "Bibliotecas: Utilizadas bibliotecas simples com: pip install scikit-optimize.\n",
    "\n",
    "Métricas: Escolhemos a métrica de desempenho mais adequada ao seu problema (acurácia, precisão, recall, F1-score, etc.).\n",
    "\n",
    "Número de avaliações: Ajuste o n_calls de acordo com o tempo disponível e a complexidade do problema.\n",
    "\n",
    "Early stopping na função objetivo: É importante incluir early stopping na função objective para evitar treinar modelos por muito tempo quando o desempenho não está melhorando.\n",
    "\n",
    "Data augmentation na função objetivo: Aplique as transformações de data augmentation dentro da função objective para que cada avaliação seja feita com dados aumentados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Execução da otimização de hiperparâmetros</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch_geometric.utils.sparse\") \n",
    "\n",
    "import gkan\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "import gc, random\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from skopt.space import Real, Integer\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# --- Define as configurações ---\n",
    "args = gkan.Args()\n",
    "args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# --- Fim da definição das configurações ---\n",
    "\n",
    "# --- Define as seeds para reprodutibilidade ---\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "# --- Fim da definição das seeds ---\n",
    "\n",
    "# --- Define as transformações ---\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(), \n",
    "    T.GCNNorm(), \n",
    "    T.ToSparseTensor(), \n",
    "    T.RandomNodeSplit(split=\"train_rest\", num_val=500, num_test=1000),\n",
    "    # T.DropEdge(p=0.2)\n",
    "])\n",
    "# --- Fim da definição das transformações ---\n",
    "\n",
    "# Define o dataset\n",
    "dataset = Planetoid(args.path, args.name, transform=transform)[0]\n",
    "\n",
    "# Define in_feat e out_feat fora da função objective\n",
    "in_feat = dataset.num_features\n",
    "out_feat = max(dataset.y) + 1\n",
    "\n",
    "# --- Define feat, adj, label, trn_mask, val_mask, tst_mask ---\n",
    "adj = dataset.adj_t.to(args.device)\n",
    "feat = dataset.x.float().to(args.device)\n",
    "label = dataset.y.to(args.device)\n",
    "\n",
    "trn_mask = dataset.train_mask.to(args.device)\n",
    "val_mask = dataset.val_mask.to(args.device)\n",
    "tst_mask = dataset.test_mask.to(args.device)\n",
    "# --- Fim da definição de feat, adj, label, trn_mask, val_mask, tst_mask ---\n",
    "\n",
    "# Define o espaço de busca\n",
    "space  = [\n",
    "    Integer(16, 128, name='hidden_size'),                    # Número de features ocultas\n",
    "    Integer(2, 5, name='n_layers'),                          # Número de camadas\n",
    "    Real(1e-4, 1e-2, prior='log-uniform', name='lr'),        # Taxa de aprendizado\n",
    "    Real(0.0, 0.5, name='dropout'),                          # Taxa de dropout\n",
    "    Real(1e-5, 1e-2, prior='log-uniform', name='l2_lambda')  # Peso da regularização L2\n",
    "]\n",
    "\n",
    "# Define a função objectivo para encontrar os hiperparâmetros que maximizam a acurácia no teste\n",
    "def objective(params, feat, adj, label, trn_mask, val_mask, tst_mask):\n",
    "    try:\n",
    "        # 1. Extrair os hiperparâmetros da lista `params`\n",
    "        args.hidden_size = params[0]  # Índice 0 para 'hidden_size'\n",
    "        args.n_layers = params[1]  # Índice 1 para 'n_layers'\n",
    "        args.lr = params[2]  # Índice 2 para 'lr'\n",
    "        args.dropout = params[3]  # Índice 3 para 'dropout'\n",
    "        l2_lambda = params[4]  # Índice 4 para 'l2_lambda'\n",
    "\n",
    "        # 2. Criar o modelo GKAN com os hiperparâmetros fornecidos\n",
    "        model = gkan.GKAN(\n",
    "            in_feat=in_feat,\n",
    "            hidden_feat=args.hidden_size,\n",
    "            out_feat=out_feat,\n",
    "            grid_feat=args.grid_size,\n",
    "            num_layers=args.n_layers,\n",
    "            use_bias=False,\n",
    "        ).to(args.device)\n",
    "\n",
    "        # --- Define a função calculate_metrics dentro da função objective ---\n",
    "        def calculate_metrics(label, pred, tst_mask):\n",
    "            # Calcula a matriz de confusão\n",
    "            conf_matrix = confusion_matrix(label[tst_mask].cpu().numpy(), pred[tst_mask].argmax(dim=-1).cpu().numpy())\n",
    "\n",
    "            # Calcula a precisão, recall e F1-score para cada classe (com zero_division=0)\n",
    "            precision = precision_score(label[tst_mask].cpu().numpy(), \n",
    "                                        pred[tst_mask].argmax(dim=-1).cpu().numpy(), \n",
    "                                        average=None, \n",
    "                                        zero_division=0)  # Adiciona zero_division=0\n",
    "            recall = recall_score(label[tst_mask].cpu().numpy(), pred[tst_mask].argmax(dim=-1).cpu().numpy(), average=None)\n",
    "            f1 = f1_score(label[tst_mask].cpu().numpy(), pred[tst_mask].argmax(dim=-1).cpu().numpy(), average=None)\n",
    "\n",
    "            # Calcula a precisão, recall e F1-score médias (macro average)\n",
    "            macro_precision = precision_score(label[tst_mask].cpu().numpy(), \n",
    "                                              pred[tst_mask].argmax(dim=-1).cpu().numpy(), \n",
    "                                              average='macro', \n",
    "                                              zero_division=0)\n",
    "            macro_recall = recall_score(label[tst_mask].cpu().numpy(), pred[tst_mask].argmax(dim=-1).cpu().numpy(), average='macro')\n",
    "            macro_f1 = f1_score(label[tst_mask].cpu().numpy(), pred[tst_mask].argmax(dim=-1).cpu().numpy(), average='macro')\n",
    "\n",
    "            # Imprime os resultados\n",
    "            print(\"Matriz de Confusão:\")\n",
    "            print(conf_matrix)\n",
    "            print(\"\\nPrecisão por classe:\", np.round(precision,4))\n",
    "            print(\"  Recall por classe:\", np.round(recall,4))\n",
    "            print(\"F1-score por classe:\", np.round(f1,4))\n",
    "            print(\"\\nPrecisão média (macro):\", np.round(macro_precision,4))\n",
    "            print(\"  Recall médio (macro):\", np.round(macro_recall,4))\n",
    "            print(\"F1-score médio (macro):\", np.round(macro_f1,4))\n",
    "        # --- Fim da definição da função calculate_metrics ---\n",
    "\n",
    "        # 3. Treinar e avaliar o modelo (incluindo data augmentation e early stopping)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        patience = 15 # Número de épocas sem melhoria para parar\n",
    "        epochs_without_improvement = 0\n",
    "\n",
    "        # Listas para armazenar as métricas\n",
    "        train_losses = []\n",
    "        train_accuracies = []\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "\n",
    "        for epoch in range(args.epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(feat, adj)\n",
    "            pred, true = out[trn_mask], label[trn_mask]\n",
    "            loss = F.nll_loss(pred, true)\n",
    "\n",
    "            # Regularização L2\n",
    "            l2_reg = torch.tensor(0.).to(args.device)\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param)\n",
    "            loss = loss + l2_lambda * l2_reg \n",
    "\n",
    "            acc = int((pred.argmax(dim=-1) == true).sum()) / int(trn_mask.sum())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Avaliação na validação\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = model(feat, adj)\n",
    "                val_loss = F.nll_loss(pred[val_mask], label[val_mask]).item()\n",
    "                val_acc = int((pred[val_mask].argmax(dim=-1) == label[val_mask]).sum()) / int(val_mask.sum())\n",
    "\n",
    "            # --- Armazenar as métricas ---\n",
    "            train_losses.append(loss.item())\n",
    "            train_accuracies.append(acc)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_acc)\n",
    "            # --- Fim do armazenamento de métricas ---\n",
    "\n",
    "            # --- Early stopping ---\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_without_improvement = 0\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "                if epochs_without_improvement >= patience:\n",
    "                    break\n",
    "            # --- Fim do early stopping ---\n",
    "\n",
    "            # --- Chama a função calculate_metrics após o treinamento ---\n",
    "            calculate_metrics(label, pred, tst_mask)\n",
    "            # --- Fim da chamada da função calculate_metrics ---\n",
    "\n",
    "        # 4. Retornar a métrica de desempenho (ex: -val_acc para maximizar a acurácia)\n",
    "        return -val_acc\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro durante a avaliação do modelo: {e}\")\n",
    "        return -0.0  # Retornar um valor baixo em caso de erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "\n",
    "# Listas para armazenar as métricas\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Chama a função gp_minimize() para iniciar a otimização Bayesiana\n",
    "result = gp_minimize(\n",
    "    lambda params: objective(params, feat, adj, label, trn_mask, val_mask, tst_mask),  # Passa os argumentos extras\n",
    "    space,  # Espaço de busca dos hiperparâmetros\n",
    "    n_calls=50,  # Número de avaliações da função objetivo\n",
    "    random_state=args.seed  # Semente para reprodutibilidade\n",
    ")\n",
    "\n",
    "# Imprime os melhores hiperparâmetros encontrados\n",
    "print(\"Melhores hiperparâmetros:\", result.x)\n",
    "\n",
    "# Extrai os melhores hiperparâmetros do resultado da otimização\n",
    "best_params = {\n",
    "    'hidden_size': result.x[0],\n",
    "    'n_layers': result.x[1],\n",
    "    'lr': result.x[2],\n",
    "    'dropout': result.x[3],\n",
    "    'l2_lambda': result.x[4]\n",
    "}\n",
    "\n",
    "# Cria o modelo final com os melhores hiperparâmetros\n",
    "model = gkan.GKAN(\n",
    "    in_feat=in_feat,\n",
    "    hidden_feat=best_params['hidden_size'],\n",
    "    out_feat=out_feat,\n",
    "    grid_feat=args.grid_size,\n",
    "    num_layers=best_params['n_layers'],\n",
    "    use_bias=False,\n",
    ").to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vários resultados da otimização de hiperparâmetros"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Melhores hiperparâmetros: \n",
    "\n",
    "[128, 2, 0.00011411147910675277, 0.42344054815376714, 1.1132089297390748e-05]\n",
    "\n",
    "[ 18, 2, 0.00011328218064327008, 0.477242273856734, 0.005673249587508708]\n",
    "\n",
    "[125, 2, 0.00011233217225585744, 0.0014741132501069902, 0.008011107180918159]\n",
    "\n",
    "depois de eliminar o dropout\n",
    "[128, 2, 0.0001, 0.0, 1e-05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Visualização de resultados</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos de resultado com biblioteca skopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skopt.plots import plot_evaluations, plot_objective\n",
    "\n",
    "def plot_resultados_avaliacao_sk(result):\n",
    "    \"\"\"\n",
    "    Plota os resultados da otimização Bayesiana usando as funções plot_evaluations e plot_objective do scikit-optimize.\n",
    "\n",
    "    Args:\n",
    "        result: Objeto retornado pela função gp_minimize.\n",
    "    \"\"\"\n",
    "\n",
    "    # Plota as avaliações dos hiperparâmetros\n",
    "    _ = plot_evaluations(result)\n",
    "\n",
    "    # Define o tamanho da figura com Matplotlib\n",
    "    plt.figure(figsize=(16, 12))  # Define o tamanho da figura antes de chamar plot_evaluations\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_resultados_otimizacao_sk(result, **kwargs):\n",
    "    \"\"\"\n",
    "    Plota os resultados da otimização Bayesiana usando a função plot_objective do scikit-optimize.\n",
    "\n",
    "    Args:\n",
    "        result: Objeto retornado pela função gp_minimize.\n",
    "        **kwargs: Argumentos adicionais para a função plot_objective.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define o tamanho da figura com Matplotlib\n",
    "    plt.figure(figsize=(16, 12))  # Define o tamanho da figura antes de chamar plot_objective\n",
    "\n",
    "    # Plota a dependência parcial dos hiperparâmetros\n",
    "    _ = plot_objective(result, **kwargs)  # Passa os argumentos adicionais para plot_objective\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Chama a função para plotar os resultados\n",
    "plot_resultados_avaliacao_sk(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretação visual geral:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos gráficos de dispersão gerados pelo plot_evaluations, as cores dos pontos representam o valor da função objetivo para cada combinação de hiperparâmetros avaliada durante a otimização Bayesiana. Neste caso, a função objetivo é a acurácia de validação, que se deseja maximizar.\n",
    "\n",
    "- Cores mais escuras: Indicam valores menores da função objetivo, ou seja, pior acurácia de validação.\n",
    "- **Cores mais claras**:  Indicam valores maiores da função objetivo, ou seja, **melhor acurácia de validação**.\n",
    "\n",
    "Observando os gráficos, foi possível identificar as regiões do espaço de busca que levam a um melhor desempenho (cores mais claras) e as regiões com pior desempenho (cores mais escuras).\n",
    "\n",
    "Por exemplo, no gráfico hidden_size vs. n_layers, foi possível notar que os pontos mais claros (melhor acurácia) tendem a se concentrar em valores intermediários de hidden_size e um número menor de camadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretação dos Gráficos da diagonal principal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hidden_size**: Mostra a distribuição dos valores de hidden_size (número de features ocultas) avaliados durante a otimização. Observa-se que a maioria dos valores testados se concentra entre 20 e 120, com alguns outliers.\n",
    "\n",
    "**n_layers**: Indica que o otimizador explorou mais as configurações com 2 e 3 camadas ocultas, com poucas avaliações para 4 e 5 camadas.\n",
    "\n",
    "**lr (taxa de aprendizado)**: A maioria dos valores de lr testados está concentrada em torno de 1e-4 e 1e-3, com poucas avaliações para valores maiores.\n",
    "\n",
    "**dropout**: O otimizador explorou valores de dropout em todo o intervalo definido (0.0 a 0.5), com uma concentração maior em valores menores.\n",
    "\n",
    "**l2_lambda (peso da regularização L2)**: A maioria dos valores testados para l2_lambda está concentrada em torno de 1e-5 e 1e-4, com poucas avaliações para valores maiores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretação dos Gráficos fora da diagonal principal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dispersão**: Cada ponto representa uma avaliação da função objetivo (acurácia de validação) para uma combinação específica de hiperparâmetros. A cor do ponto indica o valor da função objetivo (mais escuro = melhor desempenho).\n",
    "\n",
    "**Relações entre hiperparâmetros**: Os gráficos de dispersão ajudam a identificar possíveis relações entre os hiperparâmetros. Por exemplo, no gráfico hidden_size vs. n_layers, podemos observar que alguns dos melhores resultados (pontos mais escuros) foram obtidos com valores maiores de hidden_size e um número menor de camadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretação no contexto do GKAN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Número de camadas e features ocultas:** A exploração de diferentes valores para hidden_size e n_layers é crucial para encontrar a arquitetura ideal do GKAN para o dataset Cora. O otimizador parece ter encontrado boas soluções com um número moderado de camadas e um número variável de features ocultas.\n",
    "\n",
    "**Taxa de aprendizado:** A concentração de valores de lr em torno de 1e-4 e 1e-3 sugere que o modelo é sensível à taxa de aprendizado, e valores muito altos podem levar a instabilidade no treinamento.\n",
    "\n",
    "**Dropout**: A exploração de diferentes valores de dropout indica que essa técnica de regularização pode ter um impacto significativo no desempenho do modelo.\n",
    "\n",
    "**Regularização L2**: A concentração de valores de l2_lambda em torno de 1e-5 e 1e-4 sugere que a regularização L2 é importante para evitar overfitting, mas valores muito altos podem prejudicar o aprendizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos gráficos de otimização da função objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As linhas vermelhas tracejadas nos subplots do plot_objective representam os valores dos hiperparâmetros que minimizam a função objetivo, ou seja, os valores que levam ao melhor desempenho do modelo no conjunto de validação.\n",
    "\n",
    "Neste caso, como a função objetivo é a acurácia de validação negativa, a linha vermelha indica o valor do hiperparâmetro que maximiza a acurácia de validação.\n",
    "\n",
    "Por exemplo, no subplot dropout vs. l2_lambda, a linha vermelha vertical indica o valor ideal de dropout (aproximadamente 0.25), enquanto a linha vermelha horizontal indica o valor ideal de l2_lambda (aproximadamente 10⁻⁴).\n",
    "\n",
    "Interpretação:\n",
    "\n",
    "Ponto de mínimo/máximo: A interseção das linhas vermelhas indica o ponto de mínimo (ou máximo, neste caso) da função objetivo no espaço bidimensional dos dois hiperparâmetros.\n",
    "Influência dos hiperparâmetros: A posição das linhas vermelhas em relação aos eixos indica a influência de cada hiperparâmetro no desempenho do modelo. Se a linha vermelha estiver próxima ao centro do eixo, significa que o hiperparâmetro tem pouca influência no desempenho. Se a linha estiver próxima a um dos extremos do eixo, significa que o hiperparâmetro tem grande influência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chama a função para plotar os resultados\n",
    "plot_resultados_otimizacao_sk(result, cmap='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos da diagonal principal: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Mostram a dependência parcial da função objetivo em relação a cada hiperparâmetro.\n",
    "\n",
    "**hidden_size**: A acurácia aumenta com o hidden_size até cerca de 80, depois se estabiliza ou diminui ligeiramente.\n",
    "\n",
    "**n_layers**: O modelo tem melhor desempenho com 2 camadas, com a acurácia diminuindo para 3 ou mais camadas.\n",
    "\n",
    "**lr**: A taxa de aprendizado ideal parece estar em torno de 10⁻³. Taxas maiores ou menores resultam em pior acurácia.\n",
    "dropout: O gráfico sugere que o dropout não tem um impacto significativo na acurácia dentro do intervalo testado.\n",
    "\n",
    "**l2_lambda**: A regularização L2 parece ter um efeito positivo na acurácia, com valores em torno de 10⁻⁴ sendo os melhores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos fora da diagonal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Mostram a interação entre pares de hiperparâmetros. As cores representam a acurácia de validação (cores mais claras indicam melhor desempenho).\n",
    "\n",
    "**hidden_size vs. n_layers**: O gráfico mostra que a melhor acurácia é obtida com 2 camadas e um hidden_size em torno de 80.\n",
    "\n",
    "**lr vs. outros hiperparâmetros**: A taxa de aprendizado ideal parece ser consistente em torno de 10⁻³, independentemente dos outros hiperparâmetros.\n",
    "\n",
    "**dropout vs. outros hiperparâmetros**: Confirma a pouca influência do dropout no desempenho do modelo.\n",
    "\n",
    "**l2_lambda vs. outros hiperparâmetros**: Valores moderados de l2_lambda (em torno de 10⁻⁴) geralmente levam a melhor acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretação no contexto do GKAN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arquitetura do modelo**: O gráfico hidden_size vs. n_layers sugere que um modelo GKAN mais raso (2 camadas) com um número moderado de features ocultas (em torno de 80) é mais eficaz para o dataset Cora.\n",
    "\n",
    "**Taxa de aprendizado**: A taxa de aprendizado ideal (10⁻³) é consistente com valores comuns para otimizadores como Adam.\n",
    "\n",
    "**Regularização**: A regularização L2 parece ser mais importante que o dropout para evitar overfitting neste caso.\n",
    "\n",
    "\n",
    "Esses gráficos forneceram uma visão geral do espaço de busca e das interações entre os hiperparâmetros. Embora o modelo de otimização Bayesiana usado pelo skopt seja uma aproximação, podendo haver outras regiões do espaço de busca com bom desempenho que não foram exploradas, ao analisar esses gráficos em conjunto com as métricas de desempenho e as curvas de aprendizado foi possível obter uma compreensão completa do modelo.\n",
    "\n",
    "Com base nesses gráficos e nas análises anteriores, foram ajustados o espaço de busca da otimização Bayesiana, focando nas regiões mais promissoras e refinando a busca pelos melhores hiperparâmetros para o modelo GKAN no dataset Cora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O plot_objective forneceu uma visualização da busca por otimizar a função objetivo (acurácia de validação, neste caso) em relação a cada hiperparâmetro individualmente e em pares. Isso ajudou a entender como cada hiperparâmetro e suas interações afetam o desempenho do modelo GKAN no dataset Cora. A seguir a síntese da análise dos gráficos é descrita:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos personalizados com Pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gráficos personalizados com Plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "param_names = ['hidden_size', 'n_layers', 'lr', 'dropout', 'l2_lambda']\n",
    "\n",
    "def plot_dependencia_hiperparametro_acuracia(result, param_index, param_name):\n",
    "    \"\"\"\n",
    "    Plota a dependência parcial de um hiperparâmetro em relação à acurácia.\n",
    "\n",
    "    Args:\n",
    "        result: Objeto retornado pela função `gp_minimize`.\n",
    "        param_index: Índice do hiperparâmetro na lista de parâmetros.\n",
    "        param_name: Nome do hiperparâmetro.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extrai os valores do hiperparâmetro e da acurácia\n",
    "    x_values = [p[param_index] for p in result.x_iters]\n",
    "    y_values = [-r for r in result.func_vals]\n",
    "\n",
    "    # Calcula a média da acurácia para cada valor único do hiperparâmetro\n",
    "    unique_x = np.unique(x_values)\n",
    "    mean_y_values = [np.mean([y for x, y in zip(x_values, y_values) if x == ux]) for ux in unique_x]\n",
    "\n",
    "    # Encontra o índice do melhor valor\n",
    "    best_idx = np.argmax(mean_y_values)\n",
    "\n",
    "    # Cria o gráfico\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Plota todos os pontos de dados\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_values,\n",
    "        y=y_values,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color=y_values,\n",
    "            colorscale='RdYlGn',\n",
    "            colorbar=dict(title='Acurácia de Validação'),\n",
    "            symbol='circle',\n",
    "            size=6,\n",
    "        ),\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    # Plota a linha com a média dos valores\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=unique_x,\n",
    "        y=mean_y_values,\n",
    "        mode='lines+markers',\n",
    "        line=dict(color='gray', dash='dash'),  # Linha tracejada em preto\n",
    "        marker=dict(\n",
    "            color=mean_y_values,\n",
    "            colorscale='RdYlGn',\n",
    "            symbol=['diamond' if i == best_idx else 'circle' for i in range(len(unique_x))],\n",
    "            size=[10 if i == best_idx else 6 for i in range(len(unique_x))],\n",
    "            line=dict(color='green', width=2)  # Borda verde para o melhor valor\n",
    "        ),\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    # Adiciona anotação para o ponto de destaque\n",
    "    x_annotation = unique_x[best_idx]\n",
    "    if param_name in ['lr', 'l2_lambda']:\n",
    "        x_annotation = np.log10(x_annotation)  # Converte para escala logarítmica se necessário\n",
    "\n",
    "    # Formata o texto da anotação em notação científica se o valor for muito pequeno\n",
    "    if x_annotation < 1e-3:\n",
    "        text_annotation = f'({unique_x[best_idx]:.1e}, {mean_y_values[best_idx]:.4f})'\n",
    "    else:\n",
    "        text_annotation = f'({unique_x[best_idx]:.4f}, {mean_y_values[best_idx]:.4f})'\n",
    "\n",
    "    fig.add_annotation(\n",
    "        x=x_annotation,\n",
    "        y=mean_y_values[best_idx],\n",
    "        xref='x',  # Referencia o eixo x do gráfico\n",
    "        yref='y',\n",
    "        text=text_annotation,\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        ax=20,\n",
    "        ay=-30\n",
    "    )\n",
    "\n",
    "    # Configura o layout do gráfico\n",
    "    fig.update_layout(\n",
    "        title=f'Dependência Parcial do {param_name}',\n",
    "        xaxis_title=param_name,\n",
    "        yaxis_title='Acurácia de Validação',\n",
    "        xaxis=dict(\n",
    "            type='log' if param_name in ['lr', 'l2_lambda'] else 'linear',\n",
    "            tickmode='linear',\n",
    "            tick0=min(unique_x),\n",
    "            dtick=(1 if param_name == 'n_layers' else 10 if param_name == 'hidden_size' else None)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def plot_resultados_otimizacao(result, space, param_names):\n",
    "    \"\"\"\n",
    "    Plota os resultados da otimização Bayesiana com Plotly.\n",
    "\n",
    "    Args:\n",
    "        result: Objeto retornado pela função `gp_minimize`.\n",
    "        space: Lista de dimensões do espaço de busca.\n",
    "        param_names: Lista de nomes dos hiperparâmetros.\n",
    "    \"\"\"\n",
    "\n",
    "    # Cria a figura com subplots\n",
    "    fig = make_subplots(rows=len(param_names), cols=len(param_names), \n",
    "                    shared_xaxes=False, shared_yaxes=False)\n",
    "\n",
    "    # Itera sobre os pares de hiperparâmetros\n",
    "    for i in range(len(param_names)):\n",
    "        for j in range(i + 1):\n",
    "            param1 = param_names[i]\n",
    "            param2 = param_names[j]\n",
    "\n",
    "            x_values = [p[i] for p in result.x_iters]\n",
    "            y_values = [p[j] for p in result.x_iters]\n",
    "            color_values = [-r for r in result.func_vals]\n",
    "\n",
    "            # Encontra o índice do melhor valor\n",
    "            best_idx = color_values.index(max(color_values))\n",
    "\n",
    "            # Gráfico de linha para a diagonal principal\n",
    "            if i == j:\n",
    "                # Calcula a média da função objetivo para cada valor único do hiperparâmetro\n",
    "                unique_x = np.unique(x_values)\n",
    "                mean_color_values = [np.mean([c for x, c in zip(x_values, color_values) if x == ux]) for ux in unique_x]\n",
    "\n",
    "                # Encontra o índice do melhor valor na diagonal principal\n",
    "                best_idx_diag = mean_color_values.index(max(mean_color_values))\n",
    "\n",
    "                # Cria o gráfico de linha\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=unique_x,\n",
    "                        y=mean_color_values,\n",
    "                        mode='lines+markers',  # Adiciona marcadores à linha\n",
    "                        marker=dict(\n",
    "                            color=mean_color_values,\n",
    "                            colorscale='RdYlGn',\n",
    "                            symbol=['circle'] * len(unique_x),\n",
    "                            size=1\n",
    "                        ),\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=i + 1,\n",
    "                    col=j + 1\n",
    "                )\n",
    "\n",
    "                # Destaca o melhor valor com um losango\n",
    "                fig.update_traces(\n",
    "                    marker=dict(\n",
    "                        symbol=['diamond' if k == best_idx_diag else 'circle' for k in range(len(unique_x))],\n",
    "                        size=[15 if k == best_idx_diag else 6 for k in range(len(unique_x))],\n",
    "                        line=dict(color='green', width=2)  # Destaca o ponto com borda verde\n",
    "                    ),\n",
    "                    row=i + 1,\n",
    "                    col=j + 1\n",
    "                )\n",
    "\n",
    "                # Adiciona rótulo de dados para o ponto de destaque na diagonal\n",
    "                fig.update_traces(\n",
    "                    text=[f'({x:.4f}, {y:.4f})' if k == best_idx_diag else '' for k, (x, y) in enumerate(zip(unique_x, mean_color_values))],\n",
    "                    textposition='top center',\n",
    "                    row=i + 1,\n",
    "                    col=j + 1\n",
    "                )\n",
    "\n",
    "            # Gráfico de dispersão para fora da diagonal\n",
    "            else:\n",
    "                # Cria o gráfico de dispersão\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=x_values,\n",
    "                        y=y_values,\n",
    "                        mode='markers',\n",
    "                        marker=dict(\n",
    "                            color=color_values,\n",
    "                            colorscale='RdYlGn',\n",
    "                            colorbar=dict(title='Acurácia de Validação'),\n",
    "                            symbol=['circle'] * len(x_values)\n",
    "                        ),\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=i + 1,\n",
    "                    col=j + 1\n",
    "                )\n",
    "\n",
    "                # Destaca o melhor valor com um losango\n",
    "                fig.update_traces(\n",
    "                    marker=dict(\n",
    "                        symbol=['diamond' if k == best_idx else 'circle' for k in range(len(x_values))],\n",
    "                        size=[15 if k == best_idx else 6 for k in range(len(x_values))]\n",
    "                    ),\n",
    "                    row=i + 1,\n",
    "                    col=j + 1\n",
    "                )\n",
    "\n",
    "            # Calcula os limites dos eixos com base nos dados do subplot (com margem extra)\n",
    "            x_min = min(x_values)\n",
    "            x_max = max(x_values)\n",
    "            x_range = [x_min - 0.1 * (x_max - x_min), x_max + 0.1 * (x_max - x_min)]\n",
    "\n",
    "            y_min = min(y_values)\n",
    "            y_max = max(y_values)\n",
    "            y_range = [y_min - 0.1 * (y_max - y_min), y_max + 0.1 * (y_max - y_min)]\n",
    "\n",
    "            # Configura os títulos dos eixos e define o range individualmente\n",
    "            if i == len(param_names) - 1:\n",
    "                fig.update_xaxes(\n",
    "                    title_text=param2, \n",
    "                    row=i + 1, \n",
    "                    col=j + 1, \n",
    "                    range=x_range,\n",
    "                    showgrid=False,\n",
    "                    type='log' if param2 in ['lr', 'l2_lambda'] else 'linear'\n",
    "                )\n",
    "            if j == 0:\n",
    "                fig.update_yaxes(\n",
    "                    title_text=param1, \n",
    "                    row=i + 1, \n",
    "                    col=j + 1, \n",
    "                    range=y_range,\n",
    "                    showgrid=False,\n",
    "                    type='log' if param1 in ['lr', 'l2_lambda'] else 'linear'\n",
    "                )\n",
    "\n",
    "    # Configura o layout da figura\n",
    "    fig.update_layout(\n",
    "        title='Comparação de Hiperparâmetros - Otimização Bayesiana',\n",
    "        height=1500,\n",
    "        width=1500\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def plot_violin_hiperparametro_acuracia(result, param_index, param_name):\n",
    "    \"\"\"\n",
    "    Plota um violin plot da acurácia de validação para o hiperparâmetro.\n",
    "\n",
    "    Args:\n",
    "        result: Objeto retornado pela função `gp_minimize`.\n",
    "        param_index: Índice do hiperparâmetro na lista de parâmetros.\n",
    "        param_name: Nome do hiperparâmetro.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extrai os valores do hiperparâmetro e da acurácia\n",
    "    x_values = [p[param_index] for p in result.x_iters]\n",
    "    y_values = [-r for r in result.func_vals]\n",
    "\n",
    "    # Calcula a média da acurácia para cada valor único do hiperparâmetro\n",
    "    unique_x = np.unique(x_values)\n",
    "    mean_y_values = [np.mean([y for x, y in zip(x_values, y_values) if x == ux]) for ux in unique_x]\n",
    "\n",
    "    # Encontra o índice do melhor valor\n",
    "    best_idx = np.argmax(mean_y_values)\n",
    "\n",
    "    # Cria o violin plot\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Violin(\n",
    "        x=x_values,\n",
    "        y=y_values,\n",
    "        box_visible=True,\n",
    "        meanline_visible=True,\n",
    "        points=False,  # Remove os pontos do violin plot\n",
    "        jitter=0,      # Remove o jitter \n",
    "        opacity=0.6,\n",
    "        name=param_name,\n",
    "        showlegend=True\n",
    "    ))\n",
    "\n",
    "    # Plota os pontos individualmente com cores seguindo o colormap\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_values,\n",
    "        y=y_values,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color=y_values,\n",
    "            colorscale='RdYlGn',\n",
    "            symbol='circle',\n",
    "            size=6,\n",
    "        ),\n",
    "        showlegend=False,\n",
    "        name=param_name\n",
    "    ))\n",
    "\n",
    "    # Destaca o melhor valor com um diamante verde\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[unique_x[best_idx]],\n",
    "        y=[mean_y_values[best_idx]],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color='green',\n",
    "            symbol='diamond',\n",
    "            size=15,  # Define o tamanho do marcador como 15\n",
    "            line=dict(color='darkgreen', width=2)\n",
    "        ),\n",
    "        showlegend=False,\n",
    "        name=f'Melhor {param_name}'\n",
    "    ))\n",
    "\n",
    "    # Adiciona anotação para o ponto de destaque\n",
    "    x_annotation = unique_x[best_idx]\n",
    "    if param_name in ['lr', 'l2_lambda']:\n",
    "        x_annotation = np.log10(x_annotation)  # Converte para escala logarítmica se necessário\n",
    "\n",
    "    # Formata o texto da anotação em notação científica se o valor for muito pequeno\n",
    "    if x_annotation < 1e-3:\n",
    "        text_annotation = f'({unique_x[best_idx]:.1e}, {mean_y_values[best_idx]:.4f})'\n",
    "    else:\n",
    "        text_annotation = f'({unique_x[best_idx]:.4f}, {mean_y_values[best_idx]:.4f})'\n",
    "\n",
    "    fig.add_annotation(\n",
    "        x=x_annotation,\n",
    "        y=mean_y_values[best_idx],\n",
    "        xref='x',\n",
    "        yref='y',\n",
    "        text=text_annotation,\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        ax=20,\n",
    "        ay=-30\n",
    "    )\n",
    "\n",
    "    # Configura o layout do gráfico\n",
    "    fig.update_layout(\n",
    "        title=f'Distribuição da Acurácia para {param_name}',\n",
    "        xaxis_title=param_name,\n",
    "        yaxis_title='Acurácia de Validação',\n",
    "        xaxis_type='log' if param_name in ['lr', 'l2_lambda'] else 'linear'  # Define o tipo de eixo x\n",
    "    )\n",
    "\n",
    "    # Ajusta o eixo x para mostrar ticks inteiros quando necessário\n",
    "    if param_name == 'n_layers':\n",
    "        fig.update_layout(\n",
    "            xaxis=dict(\n",
    "                tickmode='linear',\n",
    "                tick0=min(x_values),\n",
    "                dtick=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chama a função para plotar os resultados com plotly\n",
    "\n",
    "# Lista de nomes dos hiperparâmetros\n",
    "param_names = ['hidden_size', 'n_layers', 'lr', 'dropout', 'l2_lambda']\n",
    "\n",
    "plot_resultados_otimizacao(result, space, param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dependencia_hiperparametro_acuracia(result, 0, 'hidden_size')\n",
    "plot_dependencia_hiperparametro_acuracia(result, 1, 'n_layers')\n",
    "plot_dependencia_hiperparametro_acuracia(result, 2, 'lr')\n",
    "plot_dependencia_hiperparametro_acuracia(result, 3, 'dropout')\n",
    "plot_dependencia_hiperparametro_acuracia(result, 4, 'l2_lambda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota os violin plots para cada hiperparâmetro\n",
    "for i, param_name in enumerate(['hidden_size', 'n_layers', 'lr', 'dropout', 'l2_lambda']):\n",
    "    plot_violin_hiperparametro_acuracia(result, i, param_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos com Hiplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install hiplot\n",
    "# %pip install --upgrade hiplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hiplot as hip\n",
    "\n",
    "# def plot_hiplot_parallel(data):\n",
    "#     \"\"\"Plota os resultados da otimização Bayesiana com o HiPlot (gráfico paralelo).\"\"\"\n",
    "\n",
    "#     xp = hip.Experiment.from_iterable(data)\n",
    "#     xp.display_data(hip.Displays.PARALLEL_PLOT).update({\n",
    "#         'options': {\n",
    "#             'hide': ['uid', 'from_uid'],\n",
    "#             'color_by': 'val_acc',\n",
    "#             'zoom_on_brush': False\n",
    "#         }\n",
    "#     })\n",
    "#     xp.display(force_full_width=True)\n",
    "\n",
    "# # Dados para o HiPlot\n",
    "# data = [{'hidden_size': int(p[0]),  # Converte para int\n",
    "#          'n_layers': int(p[1]),      # Converte para int\n",
    "#          'lr': float(p[2]),          # Converte para float\n",
    "#          'dropout': float(p[3]),     # Converte para float\n",
    "#          'l2_lambda': float(p[4]),   # Converte para float\n",
    "#          'val_acc': -r} \n",
    "#         for p, r in zip(result.x_iters, result.func_vals)]\n",
    "\n",
    "# # Plota o gráfico paralelo\n",
    "# plot_hiplot_parallel(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinar o modelo final com os melhores hiperparâmetros \n",
    "    \n",
    "    incluindo estratégias para evitar o overfitting com data augmentation e early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "\n",
    "# Imprime os atributos do dataset\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigar_dataset(dataset):\n",
    "  \"\"\"\n",
    "  Imprime informações sobre o dataset para ajudar na adaptação do dropout.\n",
    "\n",
    "  Args:\n",
    "      dataset: O dataset a ser investigado.\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"Informações sobre o dataset:\")\n",
    "  print(f\"  Tipo: {type(dataset)}\")\n",
    "  print(f\"  Atributos: {dataset.keys()}\")\n",
    "\n",
    "  try:\n",
    "    if hasattr(dataset, 'edge_index'):\n",
    "        print(\"  Informação sobre as arestas:\")\n",
    "        print(f\"    edge_index: {dataset.edge_index}\")\n",
    "        print(f\"    Número de arestas: {dataset.edge_index.size(1)}\")\n",
    "        print(f\"    Número de nós: {dataset.num_nodes}\")\n",
    "        grau_medio = (dataset.edge_index.size(1) / dataset.num_nodes)\n",
    "        print(f\"    Grau médio dos nós: {grau_medio:.2f}\")\n",
    "    else:\n",
    "        print(\"  O dataset não possui o atributo 'edge_index'.\")\n",
    "  except Exception as e:\n",
    "        printe(e)\n",
    "\n",
    "  if hasattr(dataset, 'x'):\n",
    "      print(\"  Informação sobre os nós:\")\n",
    "      print(f\"    x: {dataset.x}\")\n",
    "      print(f\"    Número de nós: {dataset.x.size(0)}\")\n",
    "      print(f\"    Número de features por nó: {dataset.x.size(1)}\")\n",
    "  else:\n",
    "      print(\"  O dataset não possui o atributo 'x'.\")\n",
    "\n",
    "  if hasattr(dataset, 'y'):\n",
    "      print(\"  Informação sobre os rótulos:\")\n",
    "      print(f\"    y: {dataset.y}\")\n",
    "      if hasattr(dataset.y, 'size'):\n",
    "          print(f\"    Tamanho de y: {dataset.y.size()}\")\n",
    "      print(f\"    Número de classes: {len(set(dataset.y.tolist()))}\")\n",
    "  else:\n",
    "      print(\"  O dataset não possui o atributo 'y'.\")\n",
    "\n",
    "  # Adicione outras informações relevantes para o seu problema aqui\n",
    "\n",
    "# Chama a função para investigar o dataset\n",
    "investigar_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se o dataset possui o atributo edge_index\n",
    "if hasattr(dataset, 'edge_index'):\n",
    "    print(\"O dataset possui o atributo edge_index.\")\n",
    "    print(dataset.edge_index)  # Imprime o edge_index para verificar se é um tensor válido\n",
    "else:\n",
    "    print(\"O dataset NÃO possui o atributo edge_index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Chama a função gp_minimize() com os argumentos adicionais\n",
    "try:\n",
    "    # Chama a função gp_minimize() com os argumentos adicionais\n",
    "    result = gp_minimize(\n",
    "        lambda params: objective(params, feat, adj, label, trn_mask, val_mask, tst_mask),\n",
    "        space,\n",
    "        n_calls=50,\n",
    "        random_state=args.seed\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Erro na otimização Bayesiana: {e}\")\n",
    "    result = None\n",
    "\n",
    "# Verifica se a otimização foi bem-sucedida\n",
    "if result is not None:\n",
    "    # Imprime os melhores hiperparâmetros encontrados\n",
    "    print(\"Melhores hiperparâmetros:\", result.x)\n",
    "\n",
    "    # Extrai os melhores hiperparâmetros do resultado da otimização\n",
    "    best_params = {\n",
    "        'hidden_size': result.x[0],\n",
    "        'n_layers': result.x[1],\n",
    "        'lr': result.x[2],\n",
    "        'dropout': result.x[3],\n",
    "        'l2_lambda': result.x[4]\n",
    "    }\n",
    "\n",
    "    # Cria o modelo final com os melhores hiperparâmetros\n",
    "    model = gkan.GKAN(\n",
    "        in_feat=in_feat,\n",
    "        hidden_feat=best_params['hidden_size'],\n",
    "        out_feat=out_feat,\n",
    "        grid_feat=args.grid_size,\n",
    "        num_layers=best_params['n_layers'],\n",
    "        use_bias=False,\n",
    "    ).to(args.device)\n",
    "\n",
    "    # Treina o modelo final com os melhores hiperparâmetros (incluindo early stopping)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=best_params['lr'])\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # Listas para armazenar as métricas\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        try:\n",
    "            out = model(feat, adj)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro na inferência do modelo: {e}\")\n",
    "            break\n",
    "\n",
    "        pred, true = out[trn_mask], label[trn_mask]\n",
    "        loss = F.nll_loss(pred, true)\n",
    "\n",
    "        # Regularização L2\n",
    "        l2_reg = torch.tensor(0.).to(args.device)\n",
    "        for param in model.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        loss = loss + best_params['l2_lambda'] * l2_reg\n",
    "\n",
    "        acc = int((pred.argmax(dim=-1) == true).sum()) / int(trn_mask.sum())\n",
    "\n",
    "        try:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no backpropagation: {e}\")\n",
    "            break\n",
    "\n",
    "        # Avaliação na validação\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                pred = model(feat, adj)\n",
    "            except Exception as e:\n",
    "                print(f\"Erro na inferência do modelo (validação): {e}\")\n",
    "                break\n",
    "\n",
    "            val_loss = F.nll_loss(pred[val_mask], label[val_mask]).item()\n",
    "            val_acc = int((pred[val_mask].argmax(dim=-1) == label[val_mask]).sum()) / int(val_mask.sum())\n",
    "\n",
    "        # Armazenar as métricas\n",
    "        train_losses.append(loss.item())\n",
    "        train_accuracies.append(acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(f\"Early stopping na época {epoch}\")\n",
    "                break\n",
    "\n",
    "    # Avalia o modelo final no conjunto de teste\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            pred = model(feat, adj)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro na inferência do modelo (teste): {e}\")\n",
    "        else:\n",
    "            # Calcula as métricas no conjunto de teste\n",
    "            calculate_metrics(label, pred, tst_mask)\n",
    "\n",
    "            test_acc = int((pred[tst_mask].argmax(dim=-1) == label[tst_mask]).sum()) / int(tst_mask.sum())\n",
    "            print(f'Acurácia no teste: {test_acc:.4f}')\n",
    "\n",
    "            # Plotagem das curvas de desempenho com Plotly\n",
    "            fig = go.Figure()\n",
    "\n",
    "            fig.add_trace(go.Scatter(y=train_losses, mode='lines', name='Train Loss'))\n",
    "            fig.add_trace(go.Scatter(y=train_accuracies, mode='lines', name='Train Accuracy'))\n",
    "            fig.add_trace(go.Scatter(y=val_losses, mode='lines', name='Validation Loss'))\n",
    "            fig.add_trace(go.Scatter(y=val_accuracies, mode='lines', name='Validation Accuracy'))\n",
    "\n",
    "            fig.update_layout(\n",
    "                title='Curvas de Desempenho - Otimização Bayesiana',\n",
    "                xaxis_title='Avaliação',\n",
    "                yaxis_title='Valor',\n",
    "            )\n",
    "\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Cria o gráfico com Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Adiciona as curvas de cada métrica\n",
    "fig.add_trace(go.Scatter(x=list(range(len(train_losses))), y=train_losses, mode='lines', name='Train Loss'))\n",
    "fig.add_trace(go.Scatter(x=list(range(len(train_accuracies))), y=train_accuracies, mode='lines', name='Train Accuracy'))\n",
    "fig.add_trace(go.Scatter(x=list(range(len(val_losses))), y=val_losses, mode='lines', name='Validation Loss'))\n",
    "fig.add_trace(go.Scatter(x=list(range(len(val_accuracies))), y=val_accuracies, mode='lines', name='Validation Accuracy'))\n",
    "\n",
    "# Configura o layout do gráfico\n",
    "fig.update_layout(\n",
    "    title='Curvas de Desempenho do Modelo Final',\n",
    "    xaxis_title='Época',\n",
    "    yaxis_title='Valor',\n",
    "    width=1200,\n",
    "    height=600,\n",
    "    font=dict(size=14),\n",
    "    legend=dict(x=0.8, y=0.1)  # Ajusta a posição da legenda\n",
    ")\n",
    "\n",
    "# Exibe o gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar o modelo final com as métricas completas de desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calcula a matriz de confusão\n",
    "conf_matrix = confusion_matrix(label[tst_mask].cpu().numpy(), pred[tst_mask].argmax(dim=-1).cpu().numpy())\n",
    "\n",
    "# Calcula a precisão, recall e F1-score para cada classe\n",
    "precision = precision_score(label[tst_mask].cpu().numpy(), pred[tst_mask].argmax(dim=-1).cpu().numpy(), average=None)\n",
    "recall = recall_score(label[tst_mask].cpu().numpy(), pred[tst_mask].argmax(dim=-1).cpu().numpy(), average=None)\n",
    "f1 = f1_score(label[tst_mask].cpu().numpy(), pred[tst_mask].argmax(dim=-1).cpu().numpy(), average=None)\n",
    "\n",
    "# Calcula a precisão, recall e F1-score médias (macro average)\n",
    "macro_precision = precision_score(label[tst_mask].cpu().numpy(), pred[tst_mask].argmax(dim=-1).cpu().numpy(), average='macro')\n",
    "macro_recall = recall_score(label[tst_mask].cpu().numpy(), pred[tst_mask].argmax(dim=-1).cpu().numpy(), average='macro')\n",
    "macro_f1 = f1_score(label[tst_mask].cpu().numpy(), pred[tst_mask].argmax(dim=-1).cpu().numpy(), average='macro')\n",
    "\n",
    "# Imprime os resultados\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nPrecisão por classe:\", np.round(precision,4))\n",
    "print(\"Recall por classe:\", np.round(recall,4))\n",
    "print(\"F1-score por classe:\", np.round(f1,4))\n",
    "print(\"\\nPrecisão média (macro):\", np.round(macro_precision,4))\n",
    "print(\"Recall médio (macro):\", np.round(macro_recall,4))\n",
    "print(\"F1-score médio (macro):\", np.round(macro_f1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessa o histórico de avaliações da função objetivo\n",
    "loss_history = result.func_vals\n",
    "loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(y=train_losses, mode='lines', name='Train Loss'))\n",
    "fig.add_trace(go.Scatter(y=train_accuracies, mode='lines', name='Train Accuracy'))\n",
    "fig.add_trace(go.Scatter(y=val_losses, mode='lines', name='Validation Loss'))\n",
    "fig.add_trace(go.Scatter(y=val_accuracies, mode='lines', name='Validation Accuracy'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Curvas de Desempenho - Otimização Bayesiana',\n",
    "    xaxis_title='Avaliação',\n",
    "    yaxis_title='Valor',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
